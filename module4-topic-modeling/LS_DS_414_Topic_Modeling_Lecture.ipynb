{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 4, Sprint 1, Module 4*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling (Prepare)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirchilet Allocation Models (Learn)\n",
    "<a id=\"#p1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "LDA is a \"generative probabilistic model\". \n",
    "\n",
    "Let's play with a modoel available [here](https://lettier.com/projects/lda-topic-modeling/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating LDA Models with Gensim (Learn)\n",
    "<a id=\"#p1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Overview\n",
    "### A Litterary Introduction: *Jane Austen V. Charlotte Bronte*\n",
    "Despite being born nearly forty years apart, modern fans often pit Jane Austen & Charlotte Bronte against one another in a battle for litterary  supremacy. The battle centers around the topics of education for women, courting, and marriage. The authors' similiar backgrounds naturally draw comparisons, but the modern fascination is probably due to novelility of British women publishing novels during the early 19th century. \n",
    "\n",
    "Can we help close a litterary battle for supremacy and simply acknowledge that the authors addressed different topics and deserve to be acknowledged as excellent authors each in their own right?\n",
    "\n",
    "We're going to apply Latent Dirichlet Allocation a machine learning alogrithm for topic modeling to each of the author's novels to compare the distribution of topics in their novels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conno\\.virtualenvs\\DS-Unit-4-Sprint-1-NLP-Y17kEYKC\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "import os\n",
    "import re\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim import corpora\n",
    "\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Novel Data\n",
    "I grabbed the novel data pre-split into a bunch of smaller chuncks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/austen-brontÃ«-split'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing\n",
    "**Activity**: update the function `tokenize` with any technique you have learned so far this week. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Plain Python - ''.split command\n",
    "# 2) Spacy - just the lemmas from the document\n",
    "# 3) Gensim - simple_preprocess\n",
    "\n",
    "def tokenize(text):\n",
    "    \"Complete this function\"\n",
    "    \n",
    "    return [token for token in simple_preprocess(text) if token in STOPWORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def gather_data(path_to_data): \n",
    "    data = []\n",
    "    for f in os.listdir(path):\n",
    "        if os.path.isdir(f) == False:\n",
    "            if f[-3:] == 'txt':\n",
    "                with open(os.path.join(path,f)) as t:\n",
    "                    text = t.read().strip('\\n')\n",
    "                    data.append(tokenize(str(text)))       \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = gather_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['by', 'and', 'with', 'and', 'seemed', 'to', 'some', 'of', 'the', 'of']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[0][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a sample string with a  newline character'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"this is a sample string with a \\n newline character\".replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-def78a59a710>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tokens'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['tokens'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [t[:-4] for t in os.listdir(path) if os.path.isdir(t) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "813"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(STOPWORDS).union(set(['said', 'mr', 'mrs']))\n",
    "\n",
    "def tokenize(text):\n",
    "    return [token for token in simple_preprocess(text) if token not in STOPWORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'world', 'test', 'tokenization', 'method']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(\"Hello World! This a test of the tokenization method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "813"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index=titles, data={'tokens':tokens})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0000</th>\n",
       "      <td>[by, and, with, and, seemed, to, some, of, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0001</th>\n",
       "      <td>[she, were, here, again, what, it, is, that, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0002</th>\n",
       "      <td>[all, every, was, every, in, their, not, and, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0003</th>\n",
       "      <td>[of, and, of, which, for, the, last, two, or, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0004</th>\n",
       "      <td>[some, of, the, had, you, have, of, the, has, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            tokens\n",
       "Austen_Emma0000  [by, and, with, and, seemed, to, some, of, the...\n",
       "Austen_Emma0001  [she, were, here, again, what, it, is, that, e...\n",
       "Austen_Emma0002  [all, every, was, every, in, their, not, and, ...\n",
       "Austen_Emma0003  [of, and, of, which, for, the, last, two, or, ...\n",
       "Austen_Emma0004  [some, of, the, had, you, have, of, the, has, ..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['author'] = df.reset_index()['index'].apply(lambda x: x.split('_')[0]).tolist()\n",
    "df['book'] = df.reset_index()['index'].apply(lambda x: x.split('_')[1][:-4]).tolist()\n",
    "df['section'] = df.reset_index()['index'].apply(lambda x: x[-4:]).tolist()\n",
    "df['section'] = df['section'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['author'] = df['author'].map({'Austen':1, 'CBronte':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    441\n",
       "1    372\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.author.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Documents\n",
    "Here we use a new pythonic thingy: the `yield` statement in our fucntion. This allows us to iterate over a bunch of documents without actually reading them into memory. You can see how we use this fucntion later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_stream(path):\n",
    "    for f in os.listdir(path):\n",
    "        if os.path.isdir(f) == False:\n",
    "            if f[-3:] == 'txt':\n",
    "                with open(os.path.join(path,f)) as t:\n",
    "                    text = t.read().strip('\\n')\n",
    "                    tokens = tokenize(str(text))\n",
    "                yield tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_data = doc_stream(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather_data => returns a list\n",
    "# doc_stream => returns a generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object doc_stream at 0x000001A919BD1E58>\n"
     ]
    }
   ],
   "source": [
    "next(streaming_data) # Returns one document at a time from the generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim LDA Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Dictionary Representation of all the words in our corpus\n",
    "id2word = corpora.Dictionary(doc_stream(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "638"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word.token2id['girl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'england'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[869]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(869, 3), (1254, 1), (2485, 1), (16850, 1)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word.doc2bow(tokenize(\"This is a sample message Darcy England England England\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22095"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id2word.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove extreme values from the dataset\n",
    "id2word.filter_extremes(no_below=5, no_above=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8102"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id2word.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a bag of words(bow) representation of our corpus\n",
    "# Note: we haven't actually read any text into memory here\n",
    "# Although abstracted away - tokenization IS happening in the doc_stream f(x)\n",
    "corpus = [id2word.doc2bow(text) for text in doc_stream(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (1, 1),\n",
       " (2, 1),\n",
       " (3, 2),\n",
       " (4, 1),\n",
       " (5, 1),\n",
       " (6, 1),\n",
       " (7, 2),\n",
       " (8, 1),\n",
       " (9, 1)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaMulticore(corpus=corpus,\n",
    "                   id2word=id2word,\n",
    "                   random_state=723812,\n",
    "                   num_topics = 15,\n",
    "                   passes=10,\n",
    "                   workers=8\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.009*\"pounds\" + 0.007*\"mother\" + 0.006*\"sure\" + 0.006*\"think\" + 0.006*\"year\" + 0.004*\"rochester\" + 0.004*\"certainly\" + 0.004*\"thornfield\" + 0.004*\"fairfax\" + 0.004*\"live\"'),\n",
       " (1,\n",
       "  '0.008*\"pelet\" + 0.005*\"thought\" + 0.005*\"like\" + 0.004*\"little\" + 0.004*\"man\" + 0.004*\"hunsden\" + 0.004*\"time\" + 0.003*\"having\" + 0.003*\"pupils\" + 0.003*\"crimsworth\"'),\n",
       " (2,\n",
       "  '0.008*\"madame\" + 0.006*\"little\" + 0.006*\"like\" + 0.004*\"day\" + 0.004*\"vous\" + 0.004*\"thought\" + 0.003*\"know\" + 0.003*\"beck\" + 0.003*\"good\" + 0.003*\"paul\"'),\n",
       " (3,\n",
       "  '0.005*\"night\" + 0.005*\"look\" + 0.005*\"like\" + 0.004*\"old\" + 0.004*\"est\" + 0.004*\"looked\" + 0.003*\"sir\" + 0.003*\"thought\" + 0.003*\"house\" + 0.003*\"hunsden\"'),\n",
       " (4,\n",
       "  '0.007*\"little\" + 0.005*\"madame\" + 0.005*\"like\" + 0.004*\"thought\" + 0.004*\"know\" + 0.004*\"hand\" + 0.004*\"good\" + 0.004*\"night\" + 0.003*\"day\" + 0.003*\"dr\"'),\n",
       " (5,\n",
       "  '0.017*\"elizabeth\" + 0.013*\"darcy\" + 0.010*\"miss\" + 0.010*\"bingley\" + 0.010*\"bennet\" + 0.009*\"jane\" + 0.007*\"know\" + 0.007*\"think\" + 0.006*\"wickham\" + 0.005*\"sister\"'),\n",
       " (6,\n",
       "  '0.006*\"know\" + 0.006*\"jane\" + 0.006*\"life\" + 0.005*\"like\" + 0.005*\"long\" + 0.005*\"love\" + 0.005*\"thought\" + 0.005*\"heart\" + 0.005*\"shall\" + 0.005*\"good\"'),\n",
       " (7,\n",
       "  '0.011*\"frances\" + 0.009*\"monsieur\" + 0.007*\"hunsden\" + 0.007*\"little\" + 0.006*\"english\" + 0.005*\"mdlle\" + 0.004*\"long\" + 0.004*\"time\" + 0.004*\"mademoiselle\" + 0.004*\"shall\"'),\n",
       " (8,\n",
       "  '0.008*\"good\" + 0.006*\"little\" + 0.006*\"like\" + 0.006*\"emma\" + 0.005*\"elton\" + 0.005*\"thought\" + 0.005*\"miss\" + 0.004*\"think\" + 0.004*\"great\" + 0.004*\"woman\"'),\n",
       " (9,\n",
       "  '0.012*\"sir\" + 0.006*\"long\" + 0.006*\"jane\" + 0.006*\"rochester\" + 0.005*\"little\" + 0.005*\"yes\" + 0.005*\"adele\" + 0.004*\"come\" + 0.004*\"life\" + 0.004*\"pounds\"'),\n",
       " (10,\n",
       "  '0.007*\"like\" + 0.005*\"little\" + 0.005*\"rochester\" + 0.005*\"miss\" + 0.004*\"room\" + 0.004*\"time\" + 0.004*\"thought\" + 0.003*\"sir\" + 0.003*\"day\" + 0.003*\"come\"'),\n",
       " (11,\n",
       "  '0.015*\"emma\" + 0.012*\"miss\" + 0.009*\"harriet\" + 0.008*\"thing\" + 0.008*\"weston\" + 0.008*\"think\" + 0.007*\"know\" + 0.007*\"knightley\" + 0.006*\"elton\" + 0.006*\"good\"'),\n",
       " (12,\n",
       "  '0.010*\"jane\" + 0.009*\"emma\" + 0.009*\"little\" + 0.008*\"thing\" + 0.008*\"miss\" + 0.008*\"dear\" + 0.007*\"fairfax\" + 0.006*\"shall\" + 0.006*\"know\" + 0.006*\"like\"'),\n",
       " (13,\n",
       "  '0.011*\"elinor\" + 0.010*\"marianne\" + 0.007*\"sister\" + 0.006*\"mother\" + 0.005*\"time\" + 0.004*\"soon\" + 0.004*\"jennings\" + 0.004*\"willoughby\" + 0.004*\"good\" + 0.004*\"dashwood\"'),\n",
       " (14,\n",
       "  '0.006*\"monsieur\" + 0.004*\"henri\" + 0.004*\"georgiana\" + 0.004*\"mdlle\" + 0.004*\"little\" + 0.003*\"know\" + 0.003*\"good\" + 0.003*\"asked\" + 0.003*\"time\" + 0.003*\"course\"')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [re.findall(r'\"([^\"]*)\"',t[1]) for t in lda.print_topics()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [' '.join(t[0:5]) for t in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Topic 0 ------\n",
      "pounds mother sure think year\n",
      "\n",
      "------ Topic 1 ------\n",
      "pelet thought like little man\n",
      "\n",
      "------ Topic 2 ------\n",
      "madame little like day vous\n",
      "\n",
      "------ Topic 3 ------\n",
      "night look like old est\n",
      "\n",
      "------ Topic 4 ------\n",
      "little madame like thought know\n",
      "\n",
      "------ Topic 5 ------\n",
      "elizabeth darcy miss bingley bennet\n",
      "\n",
      "------ Topic 6 ------\n",
      "know jane life like long\n",
      "\n",
      "------ Topic 7 ------\n",
      "frances monsieur hunsden little english\n",
      "\n",
      "------ Topic 8 ------\n",
      "good little like emma elton\n",
      "\n",
      "------ Topic 9 ------\n",
      "sir long jane rochester little\n",
      "\n",
      "------ Topic 10 ------\n",
      "like little rochester miss room\n",
      "\n",
      "------ Topic 11 ------\n",
      "emma miss harriet thing weston\n",
      "\n",
      "------ Topic 12 ------\n",
      "jane emma little thing miss\n",
      "\n",
      "------ Topic 13 ------\n",
      "elinor marianne sister mother time\n",
      "\n",
      "------ Topic 14 ------\n",
      "monsieur henri georgiana mdlle little\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for id, t in enumerate(topics): \n",
    "    print(f\"------ Topic {id} ------\")\n",
    "    print(t, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge \n",
    "\n",
    "You will apply an LDA model to a customer review dataset to practice the fitting and estimation of LDA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret LDA Results (Learn)\n",
    "<a id=\"#p3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Distance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lda' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-8fed0d6b676a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'lda' is not defined"
     ]
    }
   ],
   "source": [
    "pyLDAvis.gensim.prepare(lda, corpus, id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Model / Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 0.13784581), (11, 0.7755074), (13, 0.084544025)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda[corpus[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "distro = [lda[d] for d in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 0.13785432), (11, 0.7755409), (13, 0.08450204)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distro[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "distro = [lda[d] for d in corpus]\n",
    "\n",
    "def update(doc):\n",
    "        d_dist = {k:0 for k in range(0,15)}\n",
    "        for t in doc:\n",
    "            d_dist[t[0]] = t[1]\n",
    "        return d_dist\n",
    "    \n",
    "new_distro = [update(d) for d in distro]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "813"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_distro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>author</th>\n",
       "      <th>book</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0026</th>\n",
       "      <td>[giving, fair, companion, account, yesterday, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Emma</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0032</th>\n",
       "      <td>[feels, like, snow, place, party, try, day, di...</td>\n",
       "      <td>1</td>\n",
       "      <td>Emma</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBronte_Villette0086</th>\n",
       "      <td>[pierced, opaque, blackness, stood, bougie, qu...</td>\n",
       "      <td>0</td>\n",
       "      <td>Villette</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBronte_Jane0099</th>\n",
       "      <td>[joke, queer, looks, tell, thing, specially, s...</td>\n",
       "      <td>0</td>\n",
       "      <td>Jane</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBronte_Villette0092</th>\n",
       "      <td>[second, landing, floor, comprising, abode, kn...</td>\n",
       "      <td>0</td>\n",
       "      <td>Villette</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 tokens  \\\n",
       "Austen_Emma0026       [giving, fair, companion, account, yesterday, ...   \n",
       "Austen_Emma0032       [feels, like, snow, place, party, try, day, di...   \n",
       "CBronte_Villette0086  [pierced, opaque, blackness, stood, bougie, qu...   \n",
       "CBronte_Jane0099      [joke, queer, looks, tell, thing, specially, s...   \n",
       "CBronte_Villette0092  [second, landing, floor, comprising, abode, kn...   \n",
       "\n",
       "                      author      book  section  \n",
       "Austen_Emma0026            1      Emma       26  \n",
       "Austen_Emma0032            1      Emma       32  \n",
       "CBronte_Villette0086       0  Villette       86  \n",
       "CBronte_Jane0099           0      Jane       99  \n",
       "CBronte_Villette0092       0  Villette       92  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(new_distro, index=titles)\n",
    "df.columns = topics\n",
    "df['author'] = df.reset_index()['index'].apply(lambda x: x.split('_')[0]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pounds mother sure think year</th>\n",
       "      <th>pelet thought like little man</th>\n",
       "      <th>madame little like day vous</th>\n",
       "      <th>night look like old est</th>\n",
       "      <th>little madame like thought know</th>\n",
       "      <th>elizabeth darcy miss bingley bennet</th>\n",
       "      <th>know jane life like long</th>\n",
       "      <th>frances monsieur hunsden little english</th>\n",
       "      <th>good little like emma elton</th>\n",
       "      <th>sir long jane rochester little</th>\n",
       "      <th>like little rochester miss room</th>\n",
       "      <th>emma miss harriet thing weston</th>\n",
       "      <th>jane emma little thing miss</th>\n",
       "      <th>elinor marianne sister mother time</th>\n",
       "      <th>monsieur henri georgiana mdlle little</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0026</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137813</td>\n",
       "      <td>0.775376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0032</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.997455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBronte_Villette0086</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.215017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.782771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CBronte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBronte_Jane0099</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.473159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CBronte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBronte_Villette0092</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.561909</td>\n",
       "      <td>0.027238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370953</td>\n",
       "      <td>0.038246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CBronte</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      pounds mother sure think year  \\\n",
       "Austen_Emma0026                                 0.0   \n",
       "Austen_Emma0032                                 0.0   \n",
       "CBronte_Villette0086                            0.0   \n",
       "CBronte_Jane0099                                0.0   \n",
       "CBronte_Villette0092                            0.0   \n",
       "\n",
       "                      pelet thought like little man  \\\n",
       "Austen_Emma0026                                 0.0   \n",
       "Austen_Emma0032                                 0.0   \n",
       "CBronte_Villette0086                            0.0   \n",
       "CBronte_Jane0099                                0.0   \n",
       "CBronte_Villette0092                            0.0   \n",
       "\n",
       "                      madame little like day vous  night look like old est  \\\n",
       "Austen_Emma0026                               0.0                      0.0   \n",
       "Austen_Emma0032                               0.0                      0.0   \n",
       "CBronte_Villette0086                          0.0                      0.0   \n",
       "CBronte_Jane0099                              0.0                      0.0   \n",
       "CBronte_Villette0092                          0.0                      0.0   \n",
       "\n",
       "                      little madame like thought know  \\\n",
       "Austen_Emma0026                              0.000000   \n",
       "Austen_Emma0032                              0.000000   \n",
       "CBronte_Villette0086                         0.215017   \n",
       "CBronte_Jane0099                             0.000000   \n",
       "CBronte_Villette0092                         0.561909   \n",
       "\n",
       "                      elizabeth darcy miss bingley bennet  \\\n",
       "Austen_Emma0026                                  0.000000   \n",
       "Austen_Emma0032                                  0.000000   \n",
       "CBronte_Villette0086                             0.000000   \n",
       "CBronte_Jane0099                                 0.000000   \n",
       "CBronte_Villette0092                             0.027238   \n",
       "\n",
       "                      know jane life like long  \\\n",
       "Austen_Emma0026                       0.000000   \n",
       "Austen_Emma0032                       0.000000   \n",
       "CBronte_Villette0086                  0.782771   \n",
       "CBronte_Jane0099                      0.522729   \n",
       "CBronte_Villette0092                  0.000000   \n",
       "\n",
       "                      frances monsieur hunsden little english  \\\n",
       "Austen_Emma0026                                           0.0   \n",
       "Austen_Emma0032                                           0.0   \n",
       "CBronte_Villette0086                                      0.0   \n",
       "CBronte_Jane0099                                          0.0   \n",
       "CBronte_Villette0092                                      0.0   \n",
       "\n",
       "                      good little like emma elton  \\\n",
       "Austen_Emma0026                               0.0   \n",
       "Austen_Emma0032                               0.0   \n",
       "CBronte_Villette0086                          0.0   \n",
       "CBronte_Jane0099                              0.0   \n",
       "CBronte_Villette0092                          0.0   \n",
       "\n",
       "                      sir long jane rochester little  \\\n",
       "Austen_Emma0026                                  0.0   \n",
       "Austen_Emma0032                                  0.0   \n",
       "CBronte_Villette0086                             0.0   \n",
       "CBronte_Jane0099                                 0.0   \n",
       "CBronte_Villette0092                             0.0   \n",
       "\n",
       "                      like little rochester miss room  \\\n",
       "Austen_Emma0026                              0.137813   \n",
       "Austen_Emma0032                              0.000000   \n",
       "CBronte_Villette0086                         0.000000   \n",
       "CBronte_Jane0099                             0.473159   \n",
       "CBronte_Villette0092                         0.370953   \n",
       "\n",
       "                      emma miss harriet thing weston  \\\n",
       "Austen_Emma0026                             0.775376   \n",
       "Austen_Emma0032                             0.997455   \n",
       "CBronte_Villette0086                        0.000000   \n",
       "CBronte_Jane0099                            0.000000   \n",
       "CBronte_Villette0092                        0.038246   \n",
       "\n",
       "                      jane emma little thing miss  \\\n",
       "Austen_Emma0026                               0.0   \n",
       "Austen_Emma0032                               0.0   \n",
       "CBronte_Villette0086                          0.0   \n",
       "CBronte_Jane0099                              0.0   \n",
       "CBronte_Villette0092                          0.0   \n",
       "\n",
       "                      elinor marianne sister mother time  \\\n",
       "Austen_Emma0026                                 0.084708   \n",
       "Austen_Emma0032                                 0.000000   \n",
       "CBronte_Villette0086                            0.000000   \n",
       "CBronte_Jane0099                                0.000000   \n",
       "CBronte_Villette0092                            0.000000   \n",
       "\n",
       "                      monsieur henri georgiana mdlle little   author  \n",
       "Austen_Emma0026                                         0.0   Austen  \n",
       "Austen_Emma0032                                         0.0   Austen  \n",
       "CBronte_Villette0086                                    0.0  CBronte  \n",
       "CBronte_Jane0099                                        0.0  CBronte  \n",
       "CBronte_Villette0092                                    0.0  CBronte  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pounds mother sure think year</th>\n",
       "      <th>pelet thought like little man</th>\n",
       "      <th>madame little like day vous</th>\n",
       "      <th>night look like old est</th>\n",
       "      <th>little madame like thought know</th>\n",
       "      <th>elizabeth darcy miss bingley bennet</th>\n",
       "      <th>know jane life like long</th>\n",
       "      <th>frances monsieur hunsden little english</th>\n",
       "      <th>good little like emma elton</th>\n",
       "      <th>sir long jane rochester little</th>\n",
       "      <th>like little rochester miss room</th>\n",
       "      <th>emma miss harriet thing weston</th>\n",
       "      <th>jane emma little thing miss</th>\n",
       "      <th>elinor marianne sister mother time</th>\n",
       "      <th>monsieur henri georgiana mdlle little</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen</th>\n",
       "      <td>0.002680</td>\n",
       "      <td>0.005265</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>0.229068</td>\n",
       "      <td>0.005129</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.016319</td>\n",
       "      <td>0.005213</td>\n",
       "      <td>0.014229</td>\n",
       "      <td>0.352142</td>\n",
       "      <td>0.023068</td>\n",
       "      <td>0.340476</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBronte</th>\n",
       "      <td>0.002808</td>\n",
       "      <td>0.035886</td>\n",
       "      <td>0.061154</td>\n",
       "      <td>0.008203</td>\n",
       "      <td>0.298078</td>\n",
       "      <td>0.005798</td>\n",
       "      <td>0.123300</td>\n",
       "      <td>0.026866</td>\n",
       "      <td>0.007873</td>\n",
       "      <td>0.012273</td>\n",
       "      <td>0.385653</td>\n",
       "      <td>0.005757</td>\n",
       "      <td>0.004657</td>\n",
       "      <td>0.014485</td>\n",
       "      <td>0.004485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pounds mother sure think year  pelet thought like little man  \\\n",
       "author                                                                  \n",
       "Austen                        0.002680                       0.005265   \n",
       "CBronte                       0.002808                       0.035886   \n",
       "\n",
       "         madame little like day vous  night look like old est  \\\n",
       "author                                                          \n",
       "Austen                      0.000558                 0.000027   \n",
       "CBronte                     0.061154                 0.008203   \n",
       "\n",
       "         little madame like thought know  elizabeth darcy miss bingley bennet  \\\n",
       "author                                                                          \n",
       "Austen                          0.002224                             0.229068   \n",
       "CBronte                         0.298078                             0.005798   \n",
       "\n",
       "         know jane life like long  frances monsieur hunsden little english  \\\n",
       "author                                                                       \n",
       "Austen                   0.005129                                 0.000833   \n",
       "CBronte                  0.123300                                 0.026866   \n",
       "\n",
       "         good little like emma elton  sir long jane rochester little  \\\n",
       "author                                                                 \n",
       "Austen                      0.016319                        0.005213   \n",
       "CBronte                     0.007873                        0.012273   \n",
       "\n",
       "         like little rochester miss room  emma miss harriet thing weston  \\\n",
       "author                                                                     \n",
       "Austen                          0.014229                        0.352142   \n",
       "CBronte                         0.385653                        0.005757   \n",
       "\n",
       "         jane emma little thing miss  elinor marianne sister mother time  \\\n",
       "author                                                                     \n",
       "Austen                      0.023068                            0.340476   \n",
       "CBronte                     0.004657                            0.014485   \n",
       "\n",
       "         monsieur henri georgiana mdlle little  \n",
       "author                                          \n",
       "Austen                                0.000000  \n",
       "CBronte                               0.004485  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('author').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "### *Can we see if one of the authors focus more on men than women?*\n",
    "\n",
    "*  Use Spacy for text prepocessing\n",
    "*  Extract the Named Entities from the documents using Spacy (command is fairly straight forward)\n",
    "*  Create unique list of names from the authors (you'll find that there are different types of named entities not all people)\n",
    "*  Label the names with genders (can you this by hand or you use the US census name lists)\n",
    "*  Customize your processing to replace the proper name with your gender from the previous step's lookup table\n",
    "*  Then follow the rest of the LDA flow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the Number of Topics (Learn)\n",
    "<a id=\"#p4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "def compute_coherence_values(dictionary, corpus, limit, start=2, step=3, passes=5):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    limit : Max num of topics\n",
    "    passes: the number of times the entire lda model & coherence values are calculated\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    \n",
    "    coherence_values = []\n",
    "    \n",
    "    for iter_ in range(passes):\n",
    "        for num_topics in range(start, limit, step):\n",
    "            model = LdaMulticore(corpus=corpus, num_topics=num_topics, id2word=dictionary, workers=4)\n",
    "            coherencemodel = CoherenceModel(model=model,dictionary=dictionary,corpus=corpus, coherence='u_mass')\n",
    "            coherence_values.append({'pass': iter_, \n",
    "                                     'num_topics': num_topics, \n",
    "                                     'coherence_score': coherencemodel.get_coherence()\n",
    "                                    })\n",
    "\n",
    "    return coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can take a long time to run.\n",
    "coherence_values = compute_coherence_values(dictionary=id2word, \n",
    "                                                        corpus=corpus,\n",
    "                                                        start=2, \n",
    "                                                        limit=40, \n",
    "                                                        step=6,\n",
    "                                                        passes=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_coherence = pd.DataFrame.from_records(coherence_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coherence_score</th>\n",
       "      <th>num_topics</th>\n",
       "      <th>pass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.603344</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.859198</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.821042</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.710456</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.843094</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   coherence_score  num_topics  pass\n",
       "0        -0.603344           2     0\n",
       "1        -0.859198           8     0\n",
       "2        -0.821042          14     0\n",
       "3        -0.710456          20     0\n",
       "4        -0.843094          26     0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_coherence.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "ax = sns.lineplot(x=\"num_topics\", y=\"coherence_score\", data=topic_coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-374779cc73b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Print the coherence scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoherence_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Num Topics =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" has Coherence Value of\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda[id2word.doc2bow(tokenize(\"This is a sample document to score with a topic distribution.\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "### *Can we see if one of the authors focus more on men than women?*\n",
    "\n",
    "*  Use Spacy for text prepocessing\n",
    "*  Extract the Named Entities from the documents using Spacy (command is fairly straight forward)\n",
    "*  Create unique list of names from the authors (you'll find that there are different types of named entities not all people)\n",
    "*  Label the names with genders (can you this by hand or you use the US census name lists)\n",
    "*  Customize your processing to replace the proper name with your gender from the previous step's lookup table\n",
    "*  Then follow the rest of the LDA flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathansokoll/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/thinc/neural/train.py:7: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from .optimizers import Adam, linear_decay\n",
      "/Users/jonathansokoll/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/thinc/check.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence, Sized, Iterable, Callable\n",
      "/Users/jonathansokoll/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/thinc/check.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence, Sized, Iterable, Callable\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"Ned asked me a question about England today.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ned Ned PROPN\n",
      "asked ask VERB\n",
      "me -PRON- PRON\n",
      "a a DET\n",
      "question question NOUN\n",
      "about about ADP\n",
      "England England PROPN\n",
      "today today NOUN\n",
      ". . PUNCT\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(test)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ned PERSON\n",
      "England GPE\n",
      "today DATE\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_stream(path):\n",
    "    for f in os.listdir(path):\n",
    "        if os.path.isdir(f) == False:\n",
    "            with open(os.path.join(path,f)) as t:\n",
    "                text = t.read().strip('\\n')\n",
    "                yield text\n",
    "\n",
    "def get_people(docstream):\n",
    "    \n",
    "    ppl = []\n",
    "    \n",
    "    for d in docstream:\n",
    "        \n",
    "        doc = nlp(d)\n",
    "        \n",
    "        for ent in doc.ents:\n",
    "            \n",
    "            if ent.label_ == \"PERSON\":\n",
    "                ppl.append(ent.lemma_)\n",
    "                \n",
    "    return set(ppl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = get_people(doc_stream(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(people)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_lookup = {'Adele':'female_charc', 'William Crimsworth':'male_charc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(next(doc_stream(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.ents[0].lemma_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    "### *References*\n",
    "* [Andrew Ng et al paper on LDA](https://ai.stanford.edu/~ang/papers/jair03-lda.pdf)\n",
    "* On [Coherence](https://pdfs.semanticscholar.org/1521/8d9c029cbb903ae7c729b2c644c24994c201.pdf)\n",
    "\n",
    "### *Resources*\n",
    "\n",
    "* [Gensim](https://radimrehurek.com/gensim/): Python package for topic modeling, nlp, word vectorization, and few other things. Well maintained and well documented.\n",
    "* [Topic Modeling with Gensim](http://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#11createthedictionaryandcorpusneededfortopicmodeling): A kind of cookbook for LDA with gensim. Excellent overview, but the you need to be aware of missing import statements and assumed prior knowledge.\n",
    "* [Chinese Restuarant Process](https://en.wikipedia.org/wiki/Chinese_restaurant_process): That really obscure stats thing I mentioned... \n",
    "* [PyLDAvis](https://github.com/bmabey/pyLDAvis): Library for visualizing the topic model and performing some exploratory work. Works well. Has a direct parrell implementation in R as well. \n",
    "* [Rare Technologies](https://rare-technologies.com/): The people that made & maintain gensim and a few other libraries.\n",
    "* [Jane Austen v. Charlotte Bronte](https://www.literaryladiesguide.com/literary-musings/jane-austen-charlotte-bronte-different-alike/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (NLP)",
   "language": "python",
   "name": "python-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
