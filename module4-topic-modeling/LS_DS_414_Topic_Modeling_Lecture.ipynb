{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 4, Sprint 1, Module 4*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling (Prepare)\n",
    "\n",
    "On Monday we talked about summarizing your documents using just token counts. Today, we're going to learn about a much more sophisticated approach - learning 'topics' from documents. Topics are a latent structure. They are not directly observable in the data, but we know they're there by reading them.\n",
    "\n",
    "> **latent**: existing but not yet developed or manifest; hidden or concealed.\n",
    "\n",
    "## Use Cases\n",
    "Primary use case: what the hell are your documents about? Who might want to know that in industry - \n",
    "* Identifying common themes in customer reviews\n",
    "* Discovering the needle in a haystack \n",
    "* Monitoring communications (Email - State Department) \n",
    "\n",
    "## Learning Objectives\n",
    "*At the end of the lesson you should be able to:*\n",
    "* <a href=\"#p1\">Part 1</a>: Describe how an LDA Model works\n",
    "* <a href=\"#p2\">Part 2</a>: Estimate a LDA Model with Gensim\n",
    "* <a href=\"#p3\">Part 3</a>: Interpret LDA results\n",
    "* <a href=\"#p4\">Part 4</a>: Select the appropriate number of topics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirchilet Allocation Models (Learn)\n",
    "<a id=\"#p1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "LDA is a \"generative probabilistic model\". \n",
    "\n",
    "Let's play with a model available [here](https://lettier.com/projects/lda-topic-modeling/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating LDA Models with Gensim (Learn)\n",
    "<a id=\"#p1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Overview\n",
    "### A Literary Introduction: *Jane Austen V. Charlotte Bronte*\n",
    "Despite being born nearly forty years apart, modern fans often pit Jane Austen & Charlotte Bronte against one another in a battle for literary  supremacy. The battle centers around the topics of education for women, courting, and marriage. The authors' similar backgrounds naturally draw comparisons, but the modern fascination is probably due to novelty of British women publishing novels during the early 19th century. \n",
    "\n",
    "Can we help close a literary battle for supremacy and simply acknowledge that the authors addressed different topics and deserve to be acknowledged as excellent authors each in their own right?\n",
    "\n",
    "We're going to apply Latent Dirichlet Allocation a machine learning algorithm for topic modeling to each of the author's novels to compare the distribution of topics in their novels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john/.local/lib/python3.8/site-packages/gensim/corpora/dictionary.py:11: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working\n",
      "  from collections import Mapping, defaultdict\n",
      "/home/john/.local/lib/python3.8/site-packages/scipy/sparse/sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n",
      "/home/john/.local/lib/python3.8/site-packages/gensim/models/doc2vec.py:73: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working\n",
      "  from collections import namedtuple, defaultdict, Iterable\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "import os\n",
    "import re\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim import corpora\n",
    "\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Novel Data\n",
    "I grabbed the novel data pre-split into a bunch of smaller chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/austen-brontÃ«-split'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing\n",
    "**Activity**: update the function `tokenize` with any technique you have learned so far this week. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Plain Python - ''.split command\n",
    "# 2) Spacy - just the lemmas from the document\n",
    "# 3) Gensim - simple_preprocess\n",
    "\n",
    "STOPWORDS = set(STOPWORDS).union(set(['said', 'mr', 'mrs']))\n",
    "\n",
    "def tokenize(text):\n",
    "    return [token for token in simple_preprocess(text) if token not in STOPWORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def gather_data(path_to_data): \n",
    "    data = []\n",
    "    for f in os.listdir(path):\n",
    "        if os.path.isdir(f) == False:\n",
    "            if f[-3:] == 'txt':\n",
    "                with open(os.path.join(path,f)) as t:\n",
    "                    text = t.read().strip('\\n')\n",
    "                    data.append(tokenize(str(text)))       \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = gather_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'jane',\n",
       " 'austen',\n",
       " 'volume',\n",
       " 'chapter',\n",
       " 'emma',\n",
       " 'woodhouse',\n",
       " 'handsome',\n",
       " 'clever',\n",
       " 'rich']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[0][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a sample string with a  newline character'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"this is a sample string with a \\n newline character\".replace('\\n', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [t[:-4] for t in os.listdir(path) if os.path.isdir(t) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "813"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "813"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index=titles, data={'tokens':tokens})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0000</th>\n",
       "      <td>[emma, jane, austen, volume, chapter, emma, wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0001</th>\n",
       "      <td>[taylor, wish, pity, weston, thought, agree, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0002</th>\n",
       "      <td>[behaved, charmingly, body, punctual, body, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0003</th>\n",
       "      <td>[native, highbury, born, respectable, family, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0004</th>\n",
       "      <td>[mention, handsome, letter, weston, received, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            tokens\n",
       "Austen_Emma0000  [emma, jane, austen, volume, chapter, emma, wo...\n",
       "Austen_Emma0001  [taylor, wish, pity, weston, thought, agree, p...\n",
       "Austen_Emma0002  [behaved, charmingly, body, punctual, body, be...\n",
       "Austen_Emma0003  [native, highbury, born, respectable, family, ...\n",
       "Austen_Emma0004  [mention, handsome, letter, weston, received, ..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "\n",
    "# There is be 15 different array to explain the 15 different topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['author'] = df.reset_index()['index'].apply(lambda x: x.split('_')[0]).tolist()\n",
    "df['book'] = df.reset_index()['index'].apply(lambda x: x.split('_')[1][:-4]).tolist()\n",
    "df['section'] = df.reset_index()['index'].apply(lambda x: x[-4:]).tolist()\n",
    "df['section'] = df['section'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['author'] = df['author'].map({'Austen':1, 'CBronte':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    441\n",
       "1    372\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.author.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>author</th>\n",
       "      <th>book</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0000</th>\n",
       "      <td>[emma, jane, austen, volume, chapter, emma, wo...</td>\n",
       "      <td>1</td>\n",
       "      <td>Emma</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0001</th>\n",
       "      <td>[taylor, wish, pity, weston, thought, agree, p...</td>\n",
       "      <td>1</td>\n",
       "      <td>Emma</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0002</th>\n",
       "      <td>[behaved, charmingly, body, punctual, body, be...</td>\n",
       "      <td>1</td>\n",
       "      <td>Emma</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0003</th>\n",
       "      <td>[native, highbury, born, respectable, family, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Emma</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0004</th>\n",
       "      <td>[mention, handsome, letter, weston, received, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Emma</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            tokens  author  \\\n",
       "Austen_Emma0000  [emma, jane, austen, volume, chapter, emma, wo...       1   \n",
       "Austen_Emma0001  [taylor, wish, pity, weston, thought, agree, p...       1   \n",
       "Austen_Emma0002  [behaved, charmingly, body, punctual, body, be...       1   \n",
       "Austen_Emma0003  [native, highbury, born, respectable, family, ...       1   \n",
       "Austen_Emma0004  [mention, handsome, letter, weston, received, ...       1   \n",
       "\n",
       "                 book  section  \n",
       "Austen_Emma0000  Emma        0  \n",
       "Austen_Emma0001  Emma        1  \n",
       "Austen_Emma0002  Emma        2  \n",
       "Austen_Emma0003  Emma        3  \n",
       "Austen_Emma0004  Emma        4  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Documents\n",
    "Here we use a new pythonic thingy: the `yield` statement in our function. This allows us to iterate over a bunch of documents without actually reading them into memory. You can see how we use this function later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#char_names_list = [] ...long and efficient way, so use spacy named entity recognition\n",
    "\n",
    "# This is for getting tokens\n",
    "\n",
    "def doc_stream(path):\n",
    "    for f in os.listdir(path):\n",
    "        if os.path.isdir(f) == False:\n",
    "            if f[-3:] == 'txt':\n",
    "                with open(os.path.join(path,f)) as t:\n",
    "                    text = t.read().strip('\\n')\n",
    "                    tokens = tokenize(text)\n",
    "                yield tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_data = doc_stream(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generators more efficient when can not hold all of the data in RAM\n",
    "\n",
    "# Start here to reset generator\n",
    "\n",
    "type(streaming_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather_data => returns a list\n",
    "# doc_stream => returns a generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'jane',\n",
       " 'austen',\n",
       " 'volume',\n",
       " 'chapter',\n",
       " 'emma',\n",
       " 'woodhouse',\n",
       " 'handsome',\n",
       " 'clever',\n",
       " 'rich',\n",
       " 'comfortable',\n",
       " 'home',\n",
       " 'happy',\n",
       " 'disposition',\n",
       " 'unite',\n",
       " 'best',\n",
       " 'blessings',\n",
       " 'existence',\n",
       " 'lived',\n",
       " 'nearly',\n",
       " 'years',\n",
       " 'world',\n",
       " 'little',\n",
       " 'distress',\n",
       " 'vex',\n",
       " 'youngest',\n",
       " 'daughters',\n",
       " 'affectionate',\n",
       " 'indulgent',\n",
       " 'father',\n",
       " 'consequence',\n",
       " 'sister',\n",
       " 'marriage',\n",
       " 'mistress',\n",
       " 'house',\n",
       " 'early',\n",
       " 'period',\n",
       " 'mother',\n",
       " 'died',\n",
       " 'long',\n",
       " 'ago',\n",
       " 'indistinct',\n",
       " 'remembrance',\n",
       " 'caresses',\n",
       " 'place',\n",
       " 'supplied',\n",
       " 'excellent',\n",
       " 'woman',\n",
       " 'governess',\n",
       " 'fallen',\n",
       " 'little',\n",
       " 'short',\n",
       " 'mother',\n",
       " 'affection',\n",
       " 'sixteen',\n",
       " 'years',\n",
       " 'miss',\n",
       " 'taylor',\n",
       " 'woodhouse',\n",
       " 'family',\n",
       " 'governess',\n",
       " 'friend',\n",
       " 'fond',\n",
       " 'daughters',\n",
       " 'particularly',\n",
       " 'emma',\n",
       " 'intimacy',\n",
       " 'sisters',\n",
       " 'miss',\n",
       " 'taylor',\n",
       " 'ceased',\n",
       " 'hold',\n",
       " 'nominal',\n",
       " 'office',\n",
       " 'governess',\n",
       " 'mildness',\n",
       " 'temper',\n",
       " 'hardly',\n",
       " 'allowed',\n",
       " 'impose',\n",
       " 'restraint',\n",
       " 'shadow',\n",
       " 'authority',\n",
       " 'long',\n",
       " 'passed',\n",
       " 'away',\n",
       " 'living',\n",
       " 'friend',\n",
       " 'friend',\n",
       " 'mutually',\n",
       " 'attached',\n",
       " 'emma',\n",
       " 'liked',\n",
       " 'highly',\n",
       " 'esteeming',\n",
       " 'miss',\n",
       " 'taylor',\n",
       " 'judgment',\n",
       " 'directed',\n",
       " 'chiefly',\n",
       " 'real',\n",
       " 'evils',\n",
       " 'emma',\n",
       " 'situation',\n",
       " 'power',\n",
       " 'having',\n",
       " 'way',\n",
       " 'disposition',\n",
       " 'think',\n",
       " 'little',\n",
       " 'disadvantages',\n",
       " 'threatened',\n",
       " 'alloy',\n",
       " 'enjoyments',\n",
       " 'danger',\n",
       " 'present',\n",
       " 'unperceived',\n",
       " 'means',\n",
       " 'rank',\n",
       " 'misfortunes',\n",
       " 'sorrow',\n",
       " 'came',\n",
       " 'gentle',\n",
       " 'sorrow',\n",
       " 'shape',\n",
       " 'disagreeable',\n",
       " 'consciousness',\n",
       " 'miss',\n",
       " 'taylor',\n",
       " 'married',\n",
       " 'miss',\n",
       " 'taylor',\n",
       " 'loss',\n",
       " 'brought',\n",
       " 'grief',\n",
       " 'wedding',\n",
       " 'day',\n",
       " 'beloved',\n",
       " 'friend',\n",
       " 'emma',\n",
       " 'sat',\n",
       " 'mournful',\n",
       " 'thought',\n",
       " 'continuance',\n",
       " 'wedding',\n",
       " 'bride',\n",
       " 'people',\n",
       " 'gone',\n",
       " 'father',\n",
       " 'left',\n",
       " 'dine',\n",
       " 'prospect',\n",
       " 'cheer',\n",
       " 'long',\n",
       " 'evening',\n",
       " 'father',\n",
       " 'composed',\n",
       " 'sleep',\n",
       " 'dinner',\n",
       " 'usual',\n",
       " 'sit',\n",
       " 'think',\n",
       " 'lost',\n",
       " 'event',\n",
       " 'promise',\n",
       " 'happiness',\n",
       " 'friend',\n",
       " 'weston',\n",
       " 'man',\n",
       " 'unexceptionable',\n",
       " 'character',\n",
       " 'easy',\n",
       " 'fortune',\n",
       " 'suitable',\n",
       " 'age',\n",
       " 'pleasant',\n",
       " 'manners',\n",
       " 'satisfaction',\n",
       " 'considering',\n",
       " 'self',\n",
       " 'denying',\n",
       " 'generous',\n",
       " 'friendship',\n",
       " 'wished',\n",
       " 'promoted',\n",
       " 'match',\n",
       " 'black',\n",
       " 'morning',\n",
       " 'work',\n",
       " 'want',\n",
       " 'miss',\n",
       " 'taylor',\n",
       " 'felt',\n",
       " 'hour',\n",
       " 'day',\n",
       " 'recalled',\n",
       " 'past',\n",
       " 'kindness',\n",
       " 'kindness',\n",
       " 'affection',\n",
       " 'sixteen',\n",
       " 'years',\n",
       " 'taught',\n",
       " 'played',\n",
       " 'years',\n",
       " 'old',\n",
       " 'devoted',\n",
       " 'powers',\n",
       " 'attach',\n",
       " 'amuse',\n",
       " 'health',\n",
       " 'nursed',\n",
       " 'illnesses',\n",
       " 'childhood',\n",
       " 'large',\n",
       " 'debt',\n",
       " 'gratitude',\n",
       " 'owing',\n",
       " 'intercourse',\n",
       " 'seven',\n",
       " 'years',\n",
       " 'equal',\n",
       " 'footing',\n",
       " 'perfect',\n",
       " 'unreserve',\n",
       " 'soon',\n",
       " 'followed',\n",
       " 'isabella',\n",
       " 'marriage',\n",
       " 'left',\n",
       " 'dearer',\n",
       " 'tenderer',\n",
       " 'recollection',\n",
       " 'friend',\n",
       " 'companion',\n",
       " 'possessed',\n",
       " 'intelligent',\n",
       " 'informed',\n",
       " 'useful',\n",
       " 'gentle',\n",
       " 'knowing',\n",
       " 'ways',\n",
       " 'family',\n",
       " 'interested',\n",
       " 'concerns',\n",
       " 'peculiarly',\n",
       " 'interested',\n",
       " 'pleasure',\n",
       " 'scheme',\n",
       " 'speak',\n",
       " 'thought',\n",
       " 'arose',\n",
       " 'affection',\n",
       " 'fault',\n",
       " 'bear',\n",
       " 'change',\n",
       " 'true',\n",
       " 'friend',\n",
       " 'going',\n",
       " 'half',\n",
       " 'mile',\n",
       " 'emma',\n",
       " 'aware',\n",
       " 'great',\n",
       " 'difference',\n",
       " 'weston',\n",
       " 'half',\n",
       " 'mile',\n",
       " 'miss',\n",
       " 'taylor',\n",
       " 'house',\n",
       " 'advantages',\n",
       " 'natural',\n",
       " 'domestic',\n",
       " 'great',\n",
       " 'danger',\n",
       " 'suffering',\n",
       " 'intellectual',\n",
       " 'solitude',\n",
       " 'dearly',\n",
       " 'loved',\n",
       " 'father',\n",
       " 'companion',\n",
       " 'meet',\n",
       " 'conversation',\n",
       " 'rational',\n",
       " 'playful',\n",
       " 'evil',\n",
       " 'actual',\n",
       " 'disparity',\n",
       " 'ages',\n",
       " 'woodhouse',\n",
       " 'married',\n",
       " 'early',\n",
       " 'increased',\n",
       " 'constitution',\n",
       " 'habits',\n",
       " 'having',\n",
       " 'valetudinarian',\n",
       " 'life',\n",
       " 'activity',\n",
       " 'mind',\n",
       " 'body',\n",
       " 'older',\n",
       " 'man',\n",
       " 'ways',\n",
       " 'years',\n",
       " 'beloved',\n",
       " 'friendliness',\n",
       " 'heart',\n",
       " 'amiable',\n",
       " 'temper',\n",
       " 'talents',\n",
       " 'recommended',\n",
       " 'time',\n",
       " 'sister',\n",
       " 'comparatively',\n",
       " 'little',\n",
       " 'removed',\n",
       " 'matrimony',\n",
       " 'settled',\n",
       " 'london',\n",
       " 'sixteen',\n",
       " 'miles',\n",
       " 'daily',\n",
       " 'reach',\n",
       " 'long',\n",
       " 'october',\n",
       " 'november',\n",
       " 'evening',\n",
       " 'struggled',\n",
       " 'hartfield',\n",
       " 'christmas',\n",
       " 'brought',\n",
       " 'visit',\n",
       " 'isabella',\n",
       " 'husband',\n",
       " 'little',\n",
       " 'children',\n",
       " 'house',\n",
       " 'pleasant',\n",
       " 'society',\n",
       " 'highbury',\n",
       " 'large',\n",
       " 'populous',\n",
       " 'village',\n",
       " 'amounting',\n",
       " 'town',\n",
       " 'hartfield',\n",
       " 'spite',\n",
       " 'separate',\n",
       " 'lawn',\n",
       " 'shrubberies',\n",
       " 'belong',\n",
       " 'afforded',\n",
       " 'equals',\n",
       " 'woodhouses',\n",
       " 'consequence',\n",
       " 'looked',\n",
       " 'acquaintance',\n",
       " 'place',\n",
       " 'father',\n",
       " 'universally',\n",
       " 'civil',\n",
       " 'accepted',\n",
       " 'lieu',\n",
       " 'miss',\n",
       " 'taylor',\n",
       " 'half',\n",
       " 'day',\n",
       " 'melancholy',\n",
       " 'change',\n",
       " 'emma',\n",
       " 'sigh',\n",
       " 'wish',\n",
       " 'impossible',\n",
       " 'things',\n",
       " 'till',\n",
       " 'father',\n",
       " 'awoke',\n",
       " 'necessary',\n",
       " 'cheerful',\n",
       " 'spirits',\n",
       " 'required',\n",
       " 'support',\n",
       " 'nervous',\n",
       " 'man',\n",
       " 'easily',\n",
       " 'depressed',\n",
       " 'fond',\n",
       " 'body',\n",
       " 'hating',\n",
       " 'hating',\n",
       " 'change',\n",
       " 'kind',\n",
       " 'matrimony',\n",
       " 'origin',\n",
       " 'change',\n",
       " 'disagreeable',\n",
       " 'means',\n",
       " 'reconciled',\n",
       " 'daughter',\n",
       " 'marrying',\n",
       " 'speak',\n",
       " 'compassion',\n",
       " 'entirely',\n",
       " 'match',\n",
       " 'affection',\n",
       " 'obliged',\n",
       " 'miss',\n",
       " 'taylor',\n",
       " 'habits',\n",
       " 'gentle',\n",
       " 'selfishness',\n",
       " 'able',\n",
       " 'suppose',\n",
       " 'people',\n",
       " 'feel',\n",
       " 'differently',\n",
       " 'disposed',\n",
       " 'think',\n",
       " 'miss',\n",
       " 'taylor',\n",
       " 'sad',\n",
       " 'thing',\n",
       " 'great',\n",
       " 'deal',\n",
       " 'happier',\n",
       " 'spent',\n",
       " 'rest',\n",
       " 'life',\n",
       " 'hartfield',\n",
       " 'emma',\n",
       " 'smiled',\n",
       " 'chatted',\n",
       " 'cheerfully',\n",
       " 'thoughts',\n",
       " 'tea',\n",
       " 'came',\n",
       " 'impossible',\n",
       " 'exactly',\n",
       " 'dinner',\n",
       " 'poor',\n",
       " 'miss']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(streaming_data) # Returns one document at a time from the generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim LDA Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Dictionary Representation of all the words in our corpus\n",
    "id2word = corpora.Dictionary(doc_stream(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3986"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word.token2id['england']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2753, 1), (3986, 3), (6601, 1), (6818, 1)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word.doc2bow(tokenize(\"This is a sample message Darcy England England England\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "7048\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.getsizeof(id2word))\n",
    "print(sys.getsizeof(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22095"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id2word.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove extreme values from the dataset\n",
    "id2word.filter_extremes(no_below=5, no_above=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8102"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id2word.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a bag of words(bow) representation of our corpus\n",
    "# Note: we haven't actually read any text into memory here\n",
    "# Although abstracted away - tokenization IS happening in the doc_stream f(x)\n",
    "corpus = [id2word.doc2bow(text) for text in doc_stream(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (2, 1),\n",
       " (11, 1),\n",
       " (21, 2),\n",
       " (32, 1),\n",
       " (34, 1),\n",
       " (35, 1),\n",
       " (37, 1),\n",
       " (53, 1),\n",
       " (54, 1)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[345][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'away'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaMulticore(corpus=corpus,\n",
    "                   id2word=id2word,\n",
    "                   random_state=723812,\n",
    "                   num_topics = 15, # depends on the corpus\n",
    "                   passes=10,\n",
    "                   workers=12\n",
    "                  )\n",
    "\n",
    "# sklearn does all the computations right away, but gensim does not do this, it uses the print_topics() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.016*\"harriet\" + 0.015*\"emma\" + 0.009*\"weston\" + 0.008*\"elton\" + 0.008*\"good\" + 0.008*\"think\" + 0.008*\"man\" + 0.007*\"miss\" + 0.007*\"knightley\" + 0.006*\"know\"'),\n",
       " (1,\n",
       "  '0.006*\"like\" + 0.006*\"sir\" + 0.006*\"jane\" + 0.006*\"thought\" + 0.005*\"little\" + 0.005*\"good\" + 0.005*\"love\" + 0.004*\"old\" + 0.004*\"poor\" + 0.004*\"man\"'),\n",
       " (2,\n",
       "  '0.011*\"elinor\" + 0.009*\"marianne\" + 0.008*\"elizabeth\" + 0.007*\"sister\" + 0.007*\"miss\" + 0.005*\"time\" + 0.005*\"darcy\" + 0.005*\"mother\" + 0.005*\"soon\" + 0.005*\"lady\"'),\n",
       " (3,\n",
       "  '0.005*\"hand\" + 0.005*\"eyes\" + 0.005*\"john\" + 0.004*\"like\" + 0.004*\"saw\" + 0.004*\"asked\" + 0.004*\"little\" + 0.003*\"time\" + 0.003*\"know\" + 0.003*\"sir\"'),\n",
       " (4,\n",
       "  '0.014*\"miss\" + 0.011*\"jane\" + 0.008*\"emma\" + 0.008*\"know\" + 0.007*\"thing\" + 0.007*\"think\" + 0.006*\"good\" + 0.006*\"little\" + 0.006*\"shall\" + 0.006*\"dear\"'),\n",
       " (5,\n",
       "  '0.007*\"jane\" + 0.006*\"elizabeth\" + 0.006*\"darcy\" + 0.006*\"know\" + 0.005*\"wickham\" + 0.005*\"think\" + 0.004*\"miss\" + 0.004*\"good\" + 0.004*\"love\" + 0.004*\"letter\"'),\n",
       " (6,\n",
       "  '0.007*\"hunsden\" + 0.005*\"miss\" + 0.005*\"helen\" + 0.005*\"temple\" + 0.004*\"bread\" + 0.004*\"tea\" + 0.004*\"come\" + 0.004*\"tyrant\" + 0.004*\"having\" + 0.004*\"little\"'),\n",
       " (7,\n",
       "  '0.010*\"little\" + 0.005*\"madame\" + 0.005*\"like\" + 0.005*\"monsieur\" + 0.004*\"vous\" + 0.004*\"paul\" + 0.004*\"est\" + 0.004*\"bessie\" + 0.003*\"room\" + 0.003*\"think\"'),\n",
       " (8,\n",
       "  '0.005*\"burns\" + 0.005*\"thought\" + 0.005*\"like\" + 0.005*\"scatcherd\" + 0.004*\"miss\" + 0.004*\"day\" + 0.004*\"face\" + 0.004*\"girl\" + 0.003*\"little\" + 0.003*\"dr\"'),\n",
       " (9,\n",
       "  '0.009*\"man\" + 0.007*\"bennet\" + 0.007*\"young\" + 0.007*\"elizabeth\" + 0.006*\"collins\" + 0.006*\"time\" + 0.006*\"father\" + 0.005*\"darcy\" + 0.004*\"thought\" + 0.004*\"longbourn\"'),\n",
       " (10,\n",
       "  '0.006*\"like\" + 0.005*\"little\" + 0.004*\"thought\" + 0.004*\"long\" + 0.004*\"good\" + 0.004*\"know\" + 0.004*\"time\" + 0.004*\"day\" + 0.003*\"night\" + 0.003*\"hand\"'),\n",
       " (11,\n",
       "  '0.021*\"emma\" + 0.010*\"miss\" + 0.009*\"knightley\" + 0.009*\"harriet\" + 0.007*\"thing\" + 0.007*\"little\" + 0.007*\"fairfax\" + 0.006*\"woodhouse\" + 0.006*\"think\" + 0.006*\"elton\"'),\n",
       " (12,\n",
       "  '0.008*\"bretton\" + 0.007*\"know\" + 0.007*\"dr\" + 0.006*\"little\" + 0.005*\"lucy\" + 0.005*\"thought\" + 0.005*\"miss\" + 0.005*\"ginevra\" + 0.005*\"good\" + 0.005*\"graham\"'),\n",
       " (13,\n",
       "  '0.007*\"thousand\" + 0.006*\"mason\" + 0.005*\"like\" + 0.005*\"know\" + 0.004*\"sisters\" + 0.004*\"diana\" + 0.004*\"justice\" + 0.004*\"shall\" + 0.004*\"thought\" + 0.004*\"pounds\"'),\n",
       " (14,\n",
       "  '0.016*\"lydia\" + 0.010*\"mother\" + 0.010*\"wickham\" + 0.010*\"father\" + 0.007*\"uncle\" + 0.007*\"pounds\" + 0.006*\"dashwood\" + 0.006*\"thousand\" + 0.005*\"sure\" + 0.005*\"elizabeth\"')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [re.findall(r'\"([^\"]*)\"',t[1]) for t in lda.print_topics()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [' '.join(t[0:5]) for t in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Topic 0 ------\n",
      "harriet emma weston elton good\n",
      "\n",
      "------ Topic 1 ------\n",
      "like sir jane thought little\n",
      "\n",
      "------ Topic 2 ------\n",
      "elinor marianne elizabeth sister miss\n",
      "\n",
      "------ Topic 3 ------\n",
      "hand eyes john like saw\n",
      "\n",
      "------ Topic 4 ------\n",
      "miss jane emma know thing\n",
      "\n",
      "------ Topic 5 ------\n",
      "jane elizabeth darcy know wickham\n",
      "\n",
      "------ Topic 6 ------\n",
      "hunsden miss helen temple bread\n",
      "\n",
      "------ Topic 7 ------\n",
      "little madame like monsieur vous\n",
      "\n",
      "------ Topic 8 ------\n",
      "burns thought like scatcherd miss\n",
      "\n",
      "------ Topic 9 ------\n",
      "man bennet young elizabeth collins\n",
      "\n",
      "------ Topic 10 ------\n",
      "like little thought long good\n",
      "\n",
      "------ Topic 11 ------\n",
      "emma miss knightley harriet thing\n",
      "\n",
      "------ Topic 12 ------\n",
      "bretton know dr little lucy\n",
      "\n",
      "------ Topic 13 ------\n",
      "thousand mason like know sisters\n",
      "\n",
      "------ Topic 14 ------\n",
      "lydia mother wickham father uncle\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for id, t in enumerate(topics): \n",
    "    print(f\"------ Topic {id} ------\")\n",
    "    print(t, end=\"\\n\\n\")\n",
    "    \n",
    "# difficult with similar topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge \n",
    "\n",
    "You will apply an LDA model to a customer review dataset to practice the fitting and estimation of LDA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret LDA Results (Learn)\n",
    "<a id=\"#p3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Distance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pyLDAvis.gensim.prepare(lda, corpus, id2word) # This will break Jupyer Lab buttons\n",
    "\n",
    "vis = pyLDAvis.gensim.prepare(lda, corpus, id2word)\n",
    "\n",
    "pyLDAvis.save_html(vis, \"../module4-topic-modeling/pyLDAvisLecture.html\")\n",
    "\n",
    "# Put slider close to 0, hover over a topic, and it will show terms that are more unique to that topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Model / Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.23459537), (11, 0.76339704)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda[corpus[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "distro = [lda[d] for d in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.23459746), (11, 0.76339495)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distro[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "distro = [lda[d] for d in corpus]\n",
    "\n",
    "def update(doc):\n",
    "        d_dist = {k:0 for k in range(0,15)}\n",
    "        for t in doc:\n",
    "            d_dist[t[0]] = t[1]\n",
    "        return d_dist\n",
    "    \n",
    "new_distro = [update(d) for d in distro]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "813"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_distro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>author</th>\n",
       "      <th>book</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0000</th>\n",
       "      <td>[emma, jane, austen, volume, chapter, emma, wo...</td>\n",
       "      <td>1</td>\n",
       "      <td>Emma</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0001</th>\n",
       "      <td>[taylor, wish, pity, weston, thought, agree, p...</td>\n",
       "      <td>1</td>\n",
       "      <td>Emma</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0002</th>\n",
       "      <td>[behaved, charmingly, body, punctual, body, be...</td>\n",
       "      <td>1</td>\n",
       "      <td>Emma</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0003</th>\n",
       "      <td>[native, highbury, born, respectable, family, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Emma</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0004</th>\n",
       "      <td>[mention, handsome, letter, weston, received, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Emma</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            tokens  author  \\\n",
       "Austen_Emma0000  [emma, jane, austen, volume, chapter, emma, wo...       1   \n",
       "Austen_Emma0001  [taylor, wish, pity, weston, thought, agree, p...       1   \n",
       "Austen_Emma0002  [behaved, charmingly, body, punctual, body, be...       1   \n",
       "Austen_Emma0003  [native, highbury, born, respectable, family, ...       1   \n",
       "Austen_Emma0004  [mention, handsome, letter, weston, received, ...       1   \n",
       "\n",
       "                 book  section  \n",
       "Austen_Emma0000  Emma        0  \n",
       "Austen_Emma0001  Emma        1  \n",
       "Austen_Emma0002  Emma        2  \n",
       "Austen_Emma0003  Emma        3  \n",
       "Austen_Emma0004  Emma        4  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(new_distro, index=titles)\n",
    "df.columns = topics\n",
    "df['author'] = df.reset_index()['index'].apply(lambda x: x.split('_')[0]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>harriet emma weston elton good</th>\n",
       "      <th>like sir jane thought little</th>\n",
       "      <th>elinor marianne elizabeth sister miss</th>\n",
       "      <th>hand eyes john like saw</th>\n",
       "      <th>miss jane emma know thing</th>\n",
       "      <th>jane elizabeth darcy know wickham</th>\n",
       "      <th>hunsden miss helen temple bread</th>\n",
       "      <th>little madame like monsieur vous</th>\n",
       "      <th>burns thought like scatcherd miss</th>\n",
       "      <th>man bennet young elizabeth collins</th>\n",
       "      <th>like little thought long good</th>\n",
       "      <th>emma miss knightley harriet thing</th>\n",
       "      <th>bretton know dr little lucy</th>\n",
       "      <th>thousand mason like know sisters</th>\n",
       "      <th>lydia mother wickham father uncle</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.763393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0001</th>\n",
       "      <td>0.339857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.427919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.229969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0002</th>\n",
       "      <td>0.669740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.327996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0003</th>\n",
       "      <td>0.191080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.806789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0004</th>\n",
       "      <td>0.485063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106290</td>\n",
       "      <td>0.406799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 harriet emma weston elton good  like sir jane thought little  \\\n",
       "Austen_Emma0000                        0.000000                           0.0   \n",
       "Austen_Emma0001                        0.339857                           0.0   \n",
       "Austen_Emma0002                        0.669740                           0.0   \n",
       "Austen_Emma0003                        0.191080                           0.0   \n",
       "Austen_Emma0004                        0.485063                           0.0   \n",
       "\n",
       "                 elinor marianne elizabeth sister miss  \\\n",
       "Austen_Emma0000                                 0.2346   \n",
       "Austen_Emma0001                                 0.0000   \n",
       "Austen_Emma0002                                 0.0000   \n",
       "Austen_Emma0003                                 0.0000   \n",
       "Austen_Emma0004                                 0.0000   \n",
       "\n",
       "                 hand eyes john like saw  miss jane emma know thing  \\\n",
       "Austen_Emma0000                      0.0                   0.000000   \n",
       "Austen_Emma0001                      0.0                   0.427919   \n",
       "Austen_Emma0002                      0.0                   0.000000   \n",
       "Austen_Emma0003                      0.0                   0.000000   \n",
       "Austen_Emma0004                      0.0                   0.000000   \n",
       "\n",
       "                 jane elizabeth darcy know wickham  \\\n",
       "Austen_Emma0000                           0.000000   \n",
       "Austen_Emma0001                           0.000000   \n",
       "Austen_Emma0002                           0.000000   \n",
       "Austen_Emma0003                           0.806789   \n",
       "Austen_Emma0004                           0.000000   \n",
       "\n",
       "                 hunsden miss helen temple bread  \\\n",
       "Austen_Emma0000                              0.0   \n",
       "Austen_Emma0001                              0.0   \n",
       "Austen_Emma0002                              0.0   \n",
       "Austen_Emma0003                              0.0   \n",
       "Austen_Emma0004                              0.0   \n",
       "\n",
       "                 little madame like monsieur vous  \\\n",
       "Austen_Emma0000                               0.0   \n",
       "Austen_Emma0001                               0.0   \n",
       "Austen_Emma0002                               0.0   \n",
       "Austen_Emma0003                               0.0   \n",
       "Austen_Emma0004                               0.0   \n",
       "\n",
       "                 burns thought like scatcherd miss  \\\n",
       "Austen_Emma0000                                0.0   \n",
       "Austen_Emma0001                                0.0   \n",
       "Austen_Emma0002                                0.0   \n",
       "Austen_Emma0003                                0.0   \n",
       "Austen_Emma0004                                0.0   \n",
       "\n",
       "                 man bennet young elizabeth collins  \\\n",
       "Austen_Emma0000                                 0.0   \n",
       "Austen_Emma0001                                 0.0   \n",
       "Austen_Emma0002                                 0.0   \n",
       "Austen_Emma0003                                 0.0   \n",
       "Austen_Emma0004                                 0.0   \n",
       "\n",
       "                 like little thought long good  \\\n",
       "Austen_Emma0000                            0.0   \n",
       "Austen_Emma0001                            0.0   \n",
       "Austen_Emma0002                            0.0   \n",
       "Austen_Emma0003                            0.0   \n",
       "Austen_Emma0004                            0.0   \n",
       "\n",
       "                 emma miss knightley harriet thing  \\\n",
       "Austen_Emma0000                           0.763393   \n",
       "Austen_Emma0001                           0.229969   \n",
       "Austen_Emma0002                           0.327996   \n",
       "Austen_Emma0003                           0.000000   \n",
       "Austen_Emma0004                           0.106290   \n",
       "\n",
       "                 bretton know dr little lucy  \\\n",
       "Austen_Emma0000                     0.000000   \n",
       "Austen_Emma0001                     0.000000   \n",
       "Austen_Emma0002                     0.000000   \n",
       "Austen_Emma0003                     0.000000   \n",
       "Austen_Emma0004                     0.406799   \n",
       "\n",
       "                 thousand mason like know sisters  \\\n",
       "Austen_Emma0000                               0.0   \n",
       "Austen_Emma0001                               0.0   \n",
       "Austen_Emma0002                               0.0   \n",
       "Austen_Emma0003                               0.0   \n",
       "Austen_Emma0004                               0.0   \n",
       "\n",
       "                 lydia mother wickham father uncle  author  \n",
       "Austen_Emma0000                                0.0  Austen  \n",
       "Austen_Emma0001                                0.0  Austen  \n",
       "Austen_Emma0002                                0.0  Austen  \n",
       "Austen_Emma0003                                0.0  Austen  \n",
       "Austen_Emma0004                                0.0  Austen  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>harriet emma weston elton good</th>\n",
       "      <th>like sir jane thought little</th>\n",
       "      <th>elinor marianne elizabeth sister miss</th>\n",
       "      <th>hand eyes john like saw</th>\n",
       "      <th>miss jane emma know thing</th>\n",
       "      <th>jane elizabeth darcy know wickham</th>\n",
       "      <th>hunsden miss helen temple bread</th>\n",
       "      <th>little madame like monsieur vous</th>\n",
       "      <th>burns thought like scatcherd miss</th>\n",
       "      <th>man bennet young elizabeth collins</th>\n",
       "      <th>like little thought long good</th>\n",
       "      <th>emma miss knightley harriet thing</th>\n",
       "      <th>bretton know dr little lucy</th>\n",
       "      <th>thousand mason like know sisters</th>\n",
       "      <th>lydia mother wickham father uncle</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen</th>\n",
       "      <td>0.103918</td>\n",
       "      <td>0.006973</td>\n",
       "      <td>0.428129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211959</td>\n",
       "      <td>0.088507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.001807</td>\n",
       "      <td>0.017822</td>\n",
       "      <td>0.013380</td>\n",
       "      <td>0.086611</td>\n",
       "      <td>0.004561</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.03330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBronte</th>\n",
       "      <td>0.003945</td>\n",
       "      <td>0.012633</td>\n",
       "      <td>0.008016</td>\n",
       "      <td>0.013694</td>\n",
       "      <td>0.036295</td>\n",
       "      <td>0.003886</td>\n",
       "      <td>0.005369</td>\n",
       "      <td>0.137135</td>\n",
       "      <td>0.015776</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.746323</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.007101</td>\n",
       "      <td>0.004740</td>\n",
       "      <td>0.00102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         harriet emma weston elton good  like sir jane thought little  \\\n",
       "author                                                                  \n",
       "Austen                         0.103918                      0.006973   \n",
       "CBronte                        0.003945                      0.012633   \n",
       "\n",
       "         elinor marianne elizabeth sister miss  hand eyes john like saw  \\\n",
       "author                                                                    \n",
       "Austen                                0.428129                 0.000000   \n",
       "CBronte                               0.008016                 0.013694   \n",
       "\n",
       "         miss jane emma know thing  jane elizabeth darcy know wickham  \\\n",
       "author                                                                  \n",
       "Austen                    0.211959                           0.088507   \n",
       "CBronte                   0.036295                           0.003886   \n",
       "\n",
       "         hunsden miss helen temple bread  little madame like monsieur vous  \\\n",
       "author                                                                       \n",
       "Austen                          0.000000                          0.000291   \n",
       "CBronte                         0.005369                          0.137135   \n",
       "\n",
       "         burns thought like scatcherd miss  \\\n",
       "author                                       \n",
       "Austen                            0.001807   \n",
       "CBronte                           0.015776   \n",
       "\n",
       "         man bennet young elizabeth collins  like little thought long good  \\\n",
       "author                                                                       \n",
       "Austen                             0.017822                       0.013380   \n",
       "CBronte                            0.000056                       0.746323   \n",
       "\n",
       "         emma miss knightley harriet thing  bretton know dr little lucy  \\\n",
       "author                                                                    \n",
       "Austen                            0.086611                     0.004561   \n",
       "CBronte                           0.001341                     0.007101   \n",
       "\n",
       "         thousand mason like know sisters  lydia mother wickham father uncle  \n",
       "author                                                                        \n",
       "Austen                           0.000028                            0.03330  \n",
       "CBronte                          0.004740                            0.00102  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('author').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "### *Can we see if one of the authors focus more on men than women?*\n",
    "\n",
    "*  Use Spacy for text preprocessing\n",
    "*  Extract the Named Entities from the documents using Spacy (command is fairly straight forward)\n",
    "*  Create unique list of names from the authors (you'll find that there are different types of named entities not all people)\n",
    "*  Label the names with genders (can you this by hand or you use the US census name lists)\n",
    "*  Customize your processing to replace the proper name with your gender from the previous step's lookup table\n",
    "*  Then follow the rest of the LDA flow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the Number of Topics (Learn)\n",
    "<a id=\"#p4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "def compute_coherence_values(dictionary, corpus, limit, start=2, step=3, passes=5):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    limit : Max num of topics\n",
    "    passes: the number of times the entire lda model & coherence values are calculated\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    \n",
    "    coherence_values = []\n",
    "    \n",
    "    for iter_ in range(passes):\n",
    "        for num_topics in range(start, limit, step):\n",
    "            model = LdaMulticore(corpus=corpus, num_topics=num_topics, id2word=dictionary, workers=4)\n",
    "            coherencemodel = CoherenceModel(model=model,dictionary=dictionary,corpus=corpus, coherence='u_mass')\n",
    "            coherence_values.append({'pass': iter_, \n",
    "                                     'num_topics': num_topics, \n",
    "                                     'coherence_score': coherencemodel.get_coherence()\n",
    "                                    })\n",
    "\n",
    "    return coherence_values\n",
    "\n",
    "# higher coherence means when the topics were taken, words samlpled according to proportions, would recreate the document really well\n",
    "# complex, but good to have intuition, and study more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can take a long time to run.\n",
    "#%%time\n",
    "\n",
    "coherence_values = compute_coherence_values(dictionary=id2word, \n",
    "                                                        corpus=corpus,\n",
    "                                                        start=2, \n",
    "                                                        limit=40, \n",
    "                                                        step=2,\n",
    "                                                        passes=1) # don't want this number to be low, because then the model won't learn, too high and wastes computatinal resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_coherence = pd.DataFrame.from_records(coherence_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pass</th>\n",
       "      <th>num_topics</th>\n",
       "      <th>coherence_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.678043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.709777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.714067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.761545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.784399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pass  num_topics  coherence_score\n",
       "0     0           2        -0.678043\n",
       "1     0           4        -0.709777\n",
       "2     0           6        -0.714067\n",
       "3     0           8        -0.761545\n",
       "4     0          10        -0.784399"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_coherence.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "ax = sns.lineplot(x=\"num_topics\", y=\"coherence_score\", data=topic_coherence)\n",
    "\n",
    "# Don't want topics too low, or too high, maybe around 9 in this example, then go back and retrain LDA model on this number\n",
    "# go back and rename topics with human intuition, not easy to do, but useful\n",
    "# What are topics useful for? ie: use topics for recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the coherence scores\n",
    "#for m, cv in zip(x, coherence_values):\n",
    "#    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.016701119),\n",
       " (1, 0.01670116),\n",
       " (2, 0.01670115),\n",
       " (3, 0.016701119),\n",
       " (4, 0.016701132),\n",
       " (5, 0.01670112),\n",
       " (6, 0.016701119),\n",
       " (7, 0.016701138),\n",
       " (8, 0.016701119),\n",
       " (9, 0.016701167),\n",
       " (10, 0.7661841),\n",
       " (11, 0.016701164),\n",
       " (12, 0.01670119),\n",
       " (13, 0.016701119),\n",
       " (14, 0.016701119)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda[id2word.doc2bow(tokenize(\"This is a sample document to score with a topic distribution.\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    "### *References*\n",
    "* [Andrew Ng et al paper on LDA](https://ai.stanford.edu/~ang/papers/jair03-lda.pdf)\n",
    "* On [Coherence](https://pdfs.semanticscholar.org/1521/8d9c029cbb903ae7c729b2c644c24994c201.pdf)\n",
    "\n",
    "### *Resources*\n",
    "\n",
    "* [Gensim](https://radimrehurek.com/gensim/): Python package for topic modeling, nlp, word vectorization, and few other things. Well maintained and well documented.\n",
    "* [Topic Modeling with Gensim](http://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#11createthedictionaryandcorpusneededfortopicmodeling): A kind of cookbook for LDA with gensim. Excellent overview, but the you need to be aware of missing import statements and assumed prior knowledge.\n",
    "* [Chinese Restuarant Process](https://en.wikipedia.org/wiki/Chinese_restaurant_process): That really obscure stats thing I mentioned... \n",
    "* [PyLDAvis](https://github.com/bmabey/pyLDAvis): Library for visualizing the topic model and performing some exploratory work. Works well. Has a direct parrell implementation in R as well. \n",
    "* [Rare Technologies](https://rare-technologies.com/): The people that made & maintain gensim and a few other libraries.\n",
    "* [Jane Austen v. Charlotte Bronte](https://www.literaryladiesguide.com/literary-musings/jane-austen-charlotte-bronte-different-alike/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
