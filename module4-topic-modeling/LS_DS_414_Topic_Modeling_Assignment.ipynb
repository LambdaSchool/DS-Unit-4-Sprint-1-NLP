{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Topic Modeling\n",
    "## *Data Science Unit 4 Sprint 1 Assignment 4*\n",
    "\n",
    "Analyze a corpus of Amazon reviews from Unit 4 Sprint 1 Module 1's lecture using topic modeling: \n",
    "\n",
    "- Fit a Gensim LDA topic model on Amazon Reviews\n",
    "- Select appropriate number of topics\n",
    "- Create some dope visualization of the topics\n",
    "- Write a few bullets on your findings in markdown at the end\n",
    "- **Note**: You don't *have* to use generators for this assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "import os\n",
    "import re\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim import corpora\n",
    "\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "import pandas as pd\n",
    "os.getcwd()\n",
    "df = pd.read_csv('Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(STOPWORDS).union('amazon')\n",
    "def tokenize(corpus):\n",
    "    '''Tokenizer, excludes stop words'''\n",
    "    return [token for token in simple_preprocess(corpus) if token not in STOPWORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_tokenized'] = df['reviews.text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [order, item, bad, quality, missing, backup, s...\n",
       "1               [bulk, expensive, way, products, like]\n",
       "2                             [duracell, price, happy]\n",
       "3              [work, brand, batteries, better, price]\n",
       "4             [batteries, long, lasting, price, great]\n",
       "Name: review_tokenized, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review_tokenized'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_stream(Series):\n",
    "    '''Stream tokens from pandas Series for corpora construction'''\n",
    "    for token_list in Series:\n",
    "        yield token_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a corpora of words from Amazon review\n",
    "id2word = corpora.Dictionary(doc_stream(df['review_tokenized']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter most common words\n",
    "id2word.filter_extremes(no_below=3, no_above=.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1),\n",
       "  (1, 1),\n",
       "  (2, 1),\n",
       "  (3, 1),\n",
       "  (4, 1),\n",
       "  (5, 1),\n",
       "  (6, 1),\n",
       "  (7, 1),\n",
       "  (8, 1),\n",
       "  (9, 1),\n",
       "  (10, 1)],\n",
       " [(11, 1), (12, 1), (13, 1), (14, 1), (15, 1)],\n",
       " [(16, 1), (17, 1), (18, 1)],\n",
       " [(10, 1), (18, 1), (19, 1), (20, 1), (21, 1)],\n",
       " [(18, 1), (19, 1), (22, 1), (23, 1), (24, 1)]]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build corpus\n",
    "corpus = [id2word.doc2bow(text) for text in doc_stream(df['review_tokenized'])]\n",
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.060*\"kindle\" + 0.017*\"bought\" + 0.016*\"reading\" + 0.015*\"love\" + 0.014*\"screen\" + 0.014*\"read\" + 0.014*\"tablet\" + 0.012*\"books\" + 0.012*\"use\" + 0.012*\"new\"'),\n",
       " (1,\n",
       "  '0.181*\"great\" + 0.113*\"price\" + 0.055*\"batteries\" + 0.042*\"work\" + 0.034*\"product\" + 0.028*\"long\" + 0.025*\"value\" + 0.023*\"buy\" + 0.019*\"works\" + 0.017*\"deal\"'),\n",
       " (2,\n",
       "  '0.039*\"battery\" + 0.025*\"life\" + 0.020*\"recommend\" + 0.020*\"kindle\" + 0.019*\"charge\" + 0.019*\"case\" + 0.015*\"highly\" + 0.014*\"screen\" + 0.013*\"time\" + 0.012*\"long\"'),\n",
       " (3,\n",
       "  '0.094*\"batteries\" + 0.018*\"amazon\" + 0.018*\"long\" + 0.014*\"battery\" + 0.014*\"use\" + 0.014*\"brand\" + 0.013*\"good\" + 0.012*\"work\" + 0.011*\"time\" + 0.010*\"duracell\"'),\n",
       " (4,\n",
       "  '0.075*\"best\" + 0.026*\"device\" + 0.023*\"buy\" + 0.015*\"great\" + 0.015*\"bought\" + 0.014*\"light\" + 0.010*\"tablet\" + 0.008*\"thanks\" + 0.008*\"use\" + 0.008*\"tablets\"'),\n",
       " (5,\n",
       "  '0.047*\"easy\" + 0.043*\"loves\" + 0.042*\"use\" + 0.038*\"love\" + 0.035*\"great\" + 0.031*\"tablet\" + 0.028*\"bought\" + 0.023*\"old\" + 0.021*\"games\" + 0.020*\"kids\"'),\n",
       " (6,\n",
       "  '0.080*\"tablet\" + 0.029*\"kids\" + 0.027*\"year\" + 0.024*\"great\" + 0.023*\"old\" + 0.019*\"games\" + 0.014*\"child\" + 0.012*\"friendly\" + 0.012*\"use\" + 0.011*\"time\"'),\n",
       " (7,\n",
       "  '0.049*\"tablet\" + 0.047*\"amazon\" + 0.027*\"apps\" + 0.015*\"kids\" + 0.015*\"play\" + 0.014*\"google\" + 0.014*\"store\" + 0.013*\"like\" + 0.013*\"prime\" + 0.012*\"great\"'),\n",
       " (8,\n",
       "  '0.025*\"amazon\" + 0.019*\"like\" + 0.016*\"ok\" + 0.014*\"batteries\" + 0.014*\"lot\" + 0.014*\"worth\" + 0.010*\"buying\" + 0.009*\"buy\" + 0.009*\"ll\" + 0.009*\"ve\"'),\n",
       " (9,\n",
       "  '0.145*\"good\" + 0.041*\"price\" + 0.030*\"great\" + 0.030*\"tablet\" + 0.027*\"nice\" + 0.021*\"quality\" + 0.015*\"product\" + 0.015*\"use\" + 0.012*\"sound\" + 0.012*\"works\"')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LdaMulticore(corpus=corpus,\n",
    "                   id2word=id2word,\n",
    "                   random_state=42,\n",
    "                   num_topics=10,\n",
    "                   passes=10,\n",
    "                   workers=4)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [re.findall(r'\"([^\"]*)\"',t[1]) for t in lda.print_topics()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [' '.join(t[0:5]) for t in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Topic 0 ------\n",
      "kindle bought reading love screen\n",
      "\n",
      "------ Topic 1 ------\n",
      "great price batteries work product\n",
      "\n",
      "------ Topic 2 ------\n",
      "battery life recommend kindle charge\n",
      "\n",
      "------ Topic 3 ------\n",
      "batteries amazon long battery use\n",
      "\n",
      "------ Topic 4 ------\n",
      "best device buy great bought\n",
      "\n",
      "------ Topic 5 ------\n",
      "easy loves use love great\n",
      "\n",
      "------ Topic 6 ------\n",
      "tablet kids year great old\n",
      "\n",
      "------ Topic 7 ------\n",
      "tablet amazon apps kids play\n",
      "\n",
      "------ Topic 8 ------\n",
      "amazon like ok batteries lot\n",
      "\n",
      "------ Topic 9 ------\n",
      "good price great tablet nice\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for id, t in enumerate(topics): \n",
    "    print(f\"------ Topic {id} ------\")\n",
    "    print(t, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "As per usual with conceptual assignments, I found that the procedure here seemed a lot longer in the lecture than it was in the assingment. I'm excited about LDA, especially because I realized it's what amazon uses to display top review keywords. It seems to me like a great way to differentiate between different ideas through a computer. One thing I struggle with, however, is its interpretability. I think bias can come into play when a human has to interpret the topic words themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stretch Goals\n",
    "\n",
    "* Incorporate Named Entity Recognition in your analysis\n",
    "* Incorporate some custom pre-processing from our previous lessons (like spacy lemmatization)\n",
    "* Analyze a dataset of interest to you with topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (NLP)",
   "language": "python",
   "name": "python-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
