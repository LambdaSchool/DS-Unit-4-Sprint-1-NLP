{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Topic Modeling\n",
    "## *Data Science Unit 4 Sprint 1 Assignment 4*\n",
    "\n",
    "Analyze a corpus of Amazon reviews from Unit 4 Sprint 1 Module 1's lecture using topic modeling: \n",
    "\n",
    "- Fit a Gensim LDA topic model on Amazon Reviews\n",
    "- Select appropriate number of topics\n",
    "- Create some dope visualization of the topics\n",
    "- Write a few bullets on your findings in markdown at the end\n",
    "- **Note**: You don't *have* to use generators for this assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim \n",
    "import os\n",
    "import re\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim import corpora\n",
    "\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    I order 3 of them and one of the item is bad q...\n",
       "1    Bulk is always the less expensive way to go fo...\n",
       "2    Well they are not Duracell but for the price i...\n",
       "3    Seem to work as well as name brand batteries a...\n",
       "4    These batteries are very long lasting the pric...\n",
       "Name: reviews.text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['reviews.text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(STOPWORDS).union(['amazon', 'bought', 'price'])\n",
    "def tokenize(text):\n",
    "    return [token for token in simple_preprocess(text) if token not in set(STOPWORDS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['reviews.text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [order, item, bad, quality, missing, backup, s...\n",
       "1               [bulk, expensive, way, products, like]\n",
       "2                                    [duracell, happy]\n",
       "3                     [work, brand, batteries, better]\n",
       "4                    [batteries, long, lasting, great]\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word=corpora.Dictionary(df['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word.token2id['batteries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'switches'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [id2word.doc2bow(text) for text in df['tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaMulticore(corpus=corpus,\n",
    "                   id2word=id2word,\n",
    "                   random_state=723812,\n",
    "                   num_topics = 5,\n",
    "                   passes=10,\n",
    "                   workers=6\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.039*\"good\" + 0.025*\"great\" + 0.023*\"product\" + 0.022*\"batteries\" + 0.014*\"use\" + 0.013*\"works\" + 0.011*\"deal\" + 0.009*\"long\" + 0.008*\"box\" + 0.007*\"time\"'),\n",
       " (1,\n",
       "  '0.047*\"tablet\" + 0.032*\"kids\" + 0.024*\"great\" + 0.022*\"apps\" + 0.021*\"old\" + 0.020*\"year\" + 0.018*\"games\" + 0.016*\"loves\" + 0.016*\"love\" + 0.014*\"play\"'),\n",
       " (2,\n",
       "  '0.036*\"great\" + 0.035*\"tablet\" + 0.030*\"use\" + 0.030*\"kindle\" + 0.029*\"easy\" + 0.023*\"love\" + 0.015*\"loves\" + 0.014*\"books\" + 0.012*\"reading\" + 0.011*\"gift\"'),\n",
       " (3,\n",
       "  '0.074*\"batteries\" + 0.046*\"great\" + 0.034*\"good\" + 0.023*\"buy\" + 0.021*\"work\" + 0.021*\"long\" + 0.014*\"value\" + 0.014*\"brand\" + 0.014*\"battery\" + 0.012*\"quality\"'),\n",
       " (4,\n",
       "  '0.019*\"tablet\" + 0.017*\"like\" + 0.016*\"screen\" + 0.013*\"good\" + 0.013*\"use\" + 0.013*\"great\" + 0.011*\"device\" + 0.009*\"kindle\" + 0.009*\"ipad\" + 0.008*\"battery\"')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [re.findall(r'\"([^\"]*)\"',t[1]) for t in lda.print_topics()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [' '.join(t[0:5]) for t in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Topic 0 ------\n",
      "good great product batteries use\n",
      "\n",
      "------ Topic 1 ------\n",
      "tablet kids great apps old\n",
      "\n",
      "------ Topic 2 ------\n",
      "great tablet use kindle easy\n",
      "\n",
      "------ Topic 3 ------\n",
      "batteries great good buy work\n",
      "\n",
      "------ Topic 4 ------\n",
      "tablet like screen good use\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for id, t in enumerate(topics): \n",
    "    print(f\"------ Topic {id} ------\")\n",
    "    print(t, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "def compute_coherence_values(dictionary, corpus, limit, start=2, step=3, passes=5):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    limit : Max num of topics\n",
    "    passes: the number of times the entire lda model & coherence values are calculated\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    \n",
    "    coherence_values =[]\n",
    "    \n",
    "    for iter_ in range (passes):\n",
    "        for num_topics in range(start, limit, step):\n",
    "            model = LdaMulticore(corpus=corpus, num_topics=num_topics, id2word=dictionary, workers=4)\n",
    "            coherencemodel = CoherenceModel(model=model, dictionary=dictionary, corpus=corpus, coherence='u_mass')\n",
    "            coherence_values.append({'pass': iter_,\n",
    "                                    'num_topics': num_topics,\n",
    "                                    'coherence_score': coherencemodel.get_coherence()\n",
    "                                    })\n",
    "    \n",
    "    return coherence_values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-f3b1b4776423>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                            \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                            \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                                            passes=40)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-41-4ab3e4d3cc8e>\u001b[0m in \u001b[0;36mcompute_coherence_values\u001b[1;34m(dictionary, corpus, limit, start, step, passes)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0miter_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mnum_topics\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLdaMulticore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[0mcoherencemodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCoherenceModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoherence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'u_mass'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             coherence_values.append({'pass': iter_,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\U4-S1-NLP\\lib\\site-packages\\gensim\\models\\ldamulticore.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics, dtype)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mdecay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_every\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_every\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[0mgamma_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgamma_threshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminimum_probability\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mminimum_probability\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m             \u001b[0mminimum_phi_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mminimum_phi_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mper_word_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mper_word_topics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m         )\n\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\U4-S1-NLP\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[0;32m    369\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 371\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    372\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minit_dir_prior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\U4-S1-NLP\\lib\\site-packages\\gensim\\models\\ldamulticore.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[1;31m# wait for all outstanding jobs to finish\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mqueue_size\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m                 \u001b[0mprocess_result_queue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mreallen\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlencorpus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\U4-S1-NLP\\lib\\site-packages\\gensim\\models\\ldamulticore.py\u001b[0m in \u001b[0;36mprocess_result_queue\u001b[1;34m(force)\u001b[0m\n\u001b[0;32m    238\u001b[0m                             ((force and queue_size[0] == 0) or\n\u001b[0;32m    239\u001b[0m                                  (self.eval_every != 0 and (self.num_updates / updateafter) % self.eval_every == 0)):\n\u001b[1;32m--> 240\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_perplexity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_docs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlencorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[0mchunk_stream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunks_as_numpy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\U4-S1-NLP\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36mlog_perplexity\u001b[1;34m(self, chunk, total_docs)\u001b[0m\n\u001b[0;32m    577\u001b[0m         \u001b[0mcorpus_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnt\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocument\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0msubsample_ratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtotal_docs\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m         \u001b[0mperwordbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubsample_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubsample_ratio\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msubsample_ratio\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcorpus_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m         logger.info(\n\u001b[0;32m    581\u001b[0m             \u001b[1;34m\"%.3f per-word bound, %.1f perplexity estimate based on a held-out corpus of %i documents with %i words\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\U4-S1-NLP\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36mbound\u001b[1;34m(self, corpus, gamma, subsample_ratio)\u001b[0m\n\u001b[0;32m    815\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bound: at document #%i\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgamma\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 817\u001b[1;33m                 \u001b[0mgammad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    818\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m                 \u001b[0mgammad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\U4-S1-NLP\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36minference\u001b[1;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[0;32m    496\u001b[0m                 \u001b[0mElogthetad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdirichlet_expectation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgammad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m                 \u001b[0mexpElogthetad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mElogthetad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m                 \u001b[0mphinorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpElogthetad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpElogbetad\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    499\u001b[0m                 \u001b[1;31m# If gamma hasn't changed much, we're done.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m                 \u001b[0mmeanchange\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_absolute_difference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgammad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlastgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "coherence_values = compute_coherence_values(dictionary=id2word,\n",
    "                                           corpus=corpus,\n",
    "                                           start=2,limit=40,\n",
    "                                           step=6,\n",
    "                                           passes=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stretch Goals\n",
    "\n",
    "* Incorporate Named Entity Recognition in your analysis\n",
    "* Incorporate some custom pre-processing from our previous lessons (like spacy lemmatization)\n",
    "* Analyze a dataset of interest to you with topic modeling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
