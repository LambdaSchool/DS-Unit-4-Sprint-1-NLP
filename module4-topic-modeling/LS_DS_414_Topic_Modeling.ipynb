{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Topic Modeling\n",
    "## *Data Science Unit 4 Sprint 1 Lesson 4*\n",
    "On Monday we talked about summarizing your documents using just token counts. Today, we're going to learn about a much more sophiscated approach - learning 'topics' from documents. Topics are a latent structure. They are not directly observable in the data, but we know they're there by reading them.\n",
    "\n",
    "> **latent**: existing but not yet developed or manifest; hidden or concealed.\n",
    "\n",
    "## Use Cases\n",
    "Primary use case: what the hell are your documents about? Who might want to know that in industry - \n",
    "* Identifing common themes in customer reviews\n",
    "* Discoverying the needle in a haystack \n",
    "* Monitoring communications (Email - State Department) \n",
    "\n",
    "## Learning Objectives\n",
    "*At the end of the lesson you should be able to:*\n",
    "* <a href=\"#p1\">Part 1</a>: Describe how an LDA Model words\n",
    "* <a href=\"#p2\">Part 2</a>: Estimate a LDA Model with Gensim\n",
    "* <a href=\"#p3\">Part 3</a>: Interpret LDA results\n",
    "* <a href=\"#p4\">Part 4</a>: Select the appropriate number of topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Latent Dirchilet Allocation (LDA) Models\n",
    "<a id=\"#p1\"></a>\n",
    "\n",
    "LDA is a \"generative probabilistic model\". \n",
    "\n",
    "Let's play with a modoel available [here](https://lettier.com/projects/lda-topic-modeling/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Estimating LDA Models with Gensim\n",
    "<a id=\"#p1\"></a>\n",
    "\n",
    "### A Litterary Introduction: *Jane Austen V. Charlotte Bronte*\n",
    "Despite being born nearly forty years apart, modern fans often pit Jane Austen & Charlotte Bronte against one another in a battle for litterary  supremacy. The battle centers around the topics of education for women, courting, and marriage. The authors' similiar backgrounds naturally draw comparisons, but the modern fascination is probably due to novelility of British women publishing novels during the early 19th century. \n",
    "\n",
    "Can we help close a litterary battle for supremacy and simply acknowledge that the authors addressed different topics and deserve to be acknowledged as excellent authors each in their own right?\n",
    "\n",
    "We're going to apply Latent Dirichlet Allocation a machine learning alogrithm for topic modeling to each of the author's novels to compare the distribution of topics in their novels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "import os\n",
    "import re\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim import corpora\n",
    "\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Novel Data\n",
    "I grabbed the novel data pre-split into a bunch of smaller chuncks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing\n",
    "**Challenge**: update the function `tokenize` with any technique you have learned so far this week. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [t[:-4] for t in os.listdir(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CBronte_Jane0002',\n",
       " 'CBronte_Jane0000',\n",
       " 'CBronte_Jane0001',\n",
       " 'Austen_Emma0001',\n",
       " 'Austen_Emma0000']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(STOPWORDS).union(set(['said', 'mr', 'mrs', 'miss', 'sir']))\n",
    "\n",
    "def tokenize(text):\n",
    "    return [token for token in simple_preprocess(text) if token not in STOPWORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'world', 'test', 'tokenization', 'method']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(\"Hello World! This a test of the tokenization method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index=titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CBronte_Jane0002</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBronte_Jane0000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBronte_Jane0001</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0001</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0000</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [CBronte_Jane0002, CBronte_Jane0000, CBronte_Jane0001, Austen_Emma0001, Austen_Emma0000]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['author'] = df.reset_index()['index'].apply(lambda x: x.split('_')[0]).tolist()\n",
    "df['book'] = df.reset_index()['index'].apply(lambda x: x.split('_')[1][:-4]).tolist()\n",
    "df['section'] = df.reset_index()['index'].apply(lambda x: x[-4:]).tolist()\n",
    "df['section'] = df['section'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['author'] = df['author'].map({'Austen':1, 'CBronte':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3\n",
       "0    3\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.author.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Documents\n",
    "Here we use a new pythonic thingy: the `yield` statement in our fucntion. This allows us to iterate over a bunch of documents without actually reading them into memory. You can see how we use this fucntion later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_stream(path):\n",
    "    for f in os.listdir(path):\n",
    "        with open(os.path.join(path,f)) as t:\n",
    "            text = t.read().strip('\\n')\n",
    "            tokens = tokenize(str(text))\n",
    "            yield tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim LDA Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Dictionary Representation of all the words in our corpus\n",
    "id2word = corpora.Dictionary(doc_stream(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove extreme values from the dataset\n",
    "id2word.filter_extremes(no_below=5, no_above=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a bag of words(bow) representation of our corpus\n",
    "# Note: we haven't actually read any text into memory here\n",
    "corpus = [id2word.doc2bow(text) for text in doc_stream(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaMulticore(corpus=corpus,\n",
    "                   id2word=id2word,\n",
    "                   random_state=723812,\n",
    "                   num_topics = 3,\n",
    "                   passes=10,\n",
    "                   workers=4\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [re.findall(r'\"([^\"]*)\"',t[1]) for t in lda.print_topics()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [' '.join(t[2:5]) for t in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thought hour like\n"
     ]
    }
   ],
   "source": [
    "print(topics[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Interpret LDA Results\n",
    "<a id=\"#p3\"></a>\n",
    "\n",
    "### Topic Distance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el711821123112734169484305280\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el711821123112734169484305280_data = {\"mdsDat\": {\"x\": [-0.09365038517321392, 0.08627973031117854, 0.007370654862035436], \"y\": [0.0, 0.0, 0.0], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [51.313175201416016, 46.165992736816406, 2.5208349227905273]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"Freq\": [23.0, 14.0, 12.0, 8.0, 10.0, 6.0, 19.974838256835938, 6.056071758270264, 4.4139227867126465, 2.4838204383850098, 3.0699310302734375, 2.486295700073242, 11.989194869995117, 8.63563346862793, 3.675839424133301, 5.451603412628174, 1.9701429605484009, 2.902081251144409, 0.3165365159511566, 0.31543731689453125, 0.3151546120643616, 0.3156490623950958, 0.3137993812561035, 0.3140493929386139], \"Term\": [\"like\", \"think\", \"day\", \"way\", \"thought\", \"hour\", \"like\", \"way\", \"thought\", \"hour\", \"day\", \"think\", \"think\", \"day\", \"hour\", \"thought\", \"way\", \"like\", \"hour\", \"way\", \"thought\", \"day\", \"think\", \"like\"], \"Total\": [23.0, 14.0, 12.0, 8.0, 10.0, 6.0, 23.190967559814453, 8.341651916503906, 10.180681228637695, 6.4761962890625, 12.02121353149414, 14.789289474487305, 14.789289474487305, 12.02121353149414, 6.4761962890625, 10.180681228637695, 8.341651916503906, 23.190967559814453, 6.4761962890625, 8.341651916503906, 10.180681228637695, 12.02121353149414, 14.789289474487305, 23.190967559814453], \"loglift\": [6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.5178999900817871, 0.34700000286102295, -0.16850000619888306, -0.29109999537467957, -0.6977999806404114, -1.1159000396728516, 0.5630000233650208, 0.4422000050544739, 0.20659999549388885, 0.14830000698566437, -0.670199990272522, -1.305400013923645, 0.6621000170707703, 0.40549999475479126, 0.2054000049829483, 0.040800001472234726, -0.17229999601840973, -0.621399998664856], \"logprob\": [6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -0.6557999849319458, -1.8492000102996826, -2.1654999256134033, -2.740499973297119, -2.528599977493286, -2.739500045776367, -1.0606000423431396, -1.388700008392334, -2.242799997329712, -1.8487000465393066, -2.866499900817871, -2.479099988937378, -1.7871999740600586, -1.7906999588012695, -1.791599988937378, -1.7899999618530273, -1.7958999872207642, -1.7950999736785889]}, \"token.table\": {\"Topic\": [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2], \"Freq\": [0.24955883622169495, 0.7486764788627625, 0.30882325768470764, 0.6176465153694153, 0.8624047040939331, 0.12936070561408997, 0.13523299992084503, 0.8113980293273926, 0.3929010033607483, 0.49112626910209656, 0.7192819714546204, 0.23976066708564758], \"Term\": [\"day\", \"day\", \"hour\", \"hour\", \"like\", \"like\", \"think\", \"think\", \"thought\", \"thought\", \"way\", \"way\"]}, \"R\": 6, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 1, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el711821123112734169484305280\", ldavis_el711821123112734169484305280_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el711821123112734169484305280\", ldavis_el711821123112734169484305280_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el711821123112734169484305280\", ldavis_el711821123112734169484305280_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x    y  topics  cluster       Freq\n",
       "topic                                           \n",
       "1     -0.093650  0.0       1        1  51.313175\n",
       "0      0.086280  0.0       2        1  46.165993\n",
       "2      0.007371  0.0       3        1   2.520835, topic_info=  Category       Freq     Term      Total  loglift  logprob\n",
       "1  Default  23.000000     like  23.000000   6.0000   6.0000\n",
       "2  Default  14.000000    think  14.000000   5.0000   5.0000\n",
       "0  Default  12.000000      day  12.000000   4.0000   4.0000\n",
       "4  Default   8.000000      way   8.000000   3.0000   3.0000\n",
       "3  Default  10.000000  thought  10.000000   2.0000   2.0000\n",
       "5  Default   6.000000     hour   6.000000   1.0000   1.0000\n",
       "1   Topic1  19.974838     like  23.190968   0.5179  -0.6558\n",
       "4   Topic1   6.056072      way   8.341652   0.3470  -1.8492\n",
       "3   Topic1   4.413923  thought  10.180681  -0.1685  -2.1655\n",
       "5   Topic1   2.483820     hour   6.476196  -0.2911  -2.7405\n",
       "0   Topic1   3.069931      day  12.021214  -0.6978  -2.5286\n",
       "2   Topic1   2.486296    think  14.789289  -1.1159  -2.7395\n",
       "2   Topic2  11.989195    think  14.789289   0.5630  -1.0606\n",
       "0   Topic2   8.635633      day  12.021214   0.4422  -1.3887\n",
       "5   Topic2   3.675839     hour   6.476196   0.2066  -2.2428\n",
       "3   Topic2   5.451603  thought  10.180681   0.1483  -1.8487\n",
       "4   Topic2   1.970143      way   8.341652  -0.6702  -2.8665\n",
       "1   Topic2   2.902081     like  23.190968  -1.3054  -2.4791\n",
       "5   Topic3   0.316537     hour   6.476196   0.6621  -1.7872\n",
       "4   Topic3   0.315437      way   8.341652   0.4055  -1.7907\n",
       "3   Topic3   0.315155  thought  10.180681   0.2054  -1.7916\n",
       "0   Topic3   0.315649      day  12.021214   0.0408  -1.7900\n",
       "2   Topic3   0.313799    think  14.789289  -0.1723  -1.7959\n",
       "1   Topic3   0.314049     like  23.190968  -0.6214  -1.7951, token_table=      Topic      Freq     Term\n",
       "term                          \n",
       "0         1  0.249559      day\n",
       "0         2  0.748676      day\n",
       "5         1  0.308823     hour\n",
       "5         2  0.617647     hour\n",
       "1         1  0.862405     like\n",
       "1         2  0.129361     like\n",
       "2         1  0.135233    think\n",
       "2         2  0.811398    think\n",
       "3         1  0.392901  thought\n",
       "3         2  0.491126  thought\n",
       "4         1  0.719282      way\n",
       "4         2  0.239761      way, R=6, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 1, 3])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.gensim.prepare(lda, corpus, id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Model / Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "distro = [lda[d] for d in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.027573157), (1, 0.94966704), (2, 0.022759818)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distro[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(doc):\n",
    "        d_dist = {k:0 for k in range(0,3)}\n",
    "        for t in doc:\n",
    "            d_dist[t[0]] = t[1]\n",
    "        return d_dist\n",
    "    \n",
    "new_distro = [update(d) for d in distro]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(new_distro, index=titles)\n",
    "df.columns = topics\n",
    "df['author'] = df.reset_index()['index'].apply(lambda x: x.split('_')[0]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thought hour like</th>\n",
       "      <th>thought day think</th>\n",
       "      <th>way thought like</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CBronte_Jane0002</th>\n",
       "      <td>0.027573</td>\n",
       "      <td>0.949667</td>\n",
       "      <td>0.022760</td>\n",
       "      <td>CBronte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBronte_Jane0000</th>\n",
       "      <td>0.539689</td>\n",
       "      <td>0.429277</td>\n",
       "      <td>0.031034</td>\n",
       "      <td>CBronte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBronte_Jane0001</th>\n",
       "      <td>0.055227</td>\n",
       "      <td>0.901606</td>\n",
       "      <td>0.043167</td>\n",
       "      <td>CBronte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0001</th>\n",
       "      <td>0.497303</td>\n",
       "      <td>0.479713</td>\n",
       "      <td>0.022984</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austen_Emma0000</th>\n",
       "      <td>0.934521</td>\n",
       "      <td>0.034258</td>\n",
       "      <td>0.031221</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  thought hour like  thought day think  way thought like  \\\n",
       "CBronte_Jane0002           0.027573           0.949667          0.022760   \n",
       "CBronte_Jane0000           0.539689           0.429277          0.031034   \n",
       "CBronte_Jane0001           0.055227           0.901606          0.043167   \n",
       "Austen_Emma0001            0.497303           0.479713          0.022984   \n",
       "Austen_Emma0000            0.934521           0.034258          0.031221   \n",
       "\n",
       "                   author  \n",
       "CBronte_Jane0002  CBronte  \n",
       "CBronte_Jane0000  CBronte  \n",
       "CBronte_Jane0001  CBronte  \n",
       "Austen_Emma0001    Austen  \n",
       "Austen_Emma0000    Austen  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thought hour like</th>\n",
       "      <th>thought day think</th>\n",
       "      <th>way thought like</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen</th>\n",
       "      <td>0.679724</td>\n",
       "      <td>0.296783</td>\n",
       "      <td>0.023493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBronte</th>\n",
       "      <td>0.207496</td>\n",
       "      <td>0.760183</td>\n",
       "      <td>0.032320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         thought hour like  thought day think  way thought like\n",
       "author                                                         \n",
       "Austen            0.679724           0.296783          0.023493\n",
       "CBronte           0.207496           0.760183          0.032320"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('author').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## can we see if one author focuses more on men than women? or vice verca? - Ned\n",
    "\n",
    "* use spacy for text pre processing\n",
    "* extract the Named entitities from the documents using Spacy\n",
    "* create unique list of names from authors\n",
    "* label the names with genders (by hand or use US census name list)\n",
    "* customize your processing to replace proper name with your gender from previous step's lookup table\n",
    "* then follow the rest of LDA flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Selecting the Number of Topics\n",
    "<a id=\"#p4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "def compute_coherence_values(dictionary, corpus, path, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    path : path to input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        stream = doc_stream(path)\n",
    "        model = LdaMulticore(corpus=corpus, num_topics=num_topics, id2word=id2word, workers=4)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=stream, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can take a long time to run.\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, \n",
    "                                                        corpus=corpus, \n",
    "                                                        path=path, \n",
    "                                                        start=2, \n",
    "                                                        limit=40, \n",
    "                                                        step=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show graph\n",
    "# looking for elbow, to pick best number of topics (this one shows nothing because so little data)\n",
    "\n",
    "limit=40; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Topics = 2  has Coherence Value of 0.4026\n",
      "Num Topics = 8  has Coherence Value of 0.4026\n",
      "Num Topics = 14  has Coherence Value of 0.4026\n",
      "Num Topics = 20  has Coherence Value of 0.4026\n",
      "Num Topics = 26  has Coherence Value of 0.4026\n",
      "Num Topics = 32  has Coherence Value of 0.4026\n",
      "Num Topics = 38  has Coherence Value of 0.4026\n"
     ]
    }
   ],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "## Resources\n",
    "\n",
    "* [Gensim](https://radimrehurek.com/gensim/): Python package for topic modeling, nlp, word vectorization, and few other things. Well maintained and well documented.\n",
    "* [Topic Modeling with Gensim](http://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#11createthedictionaryandcorpusneededfortopicmodeling): A kind of cookbook for LDA with gensim. Excellent overview, but the you need to be aware of missing import statements and assumed prior knowledge.\n",
    "* [Chinese Restuarant Process](https://en.wikipedia.org/wiki/Chinese_restaurant_process): That really obscure stats thing I mentioned... \n",
    "* [PyLDAvis](https://github.com/bmabey/pyLDAvis): Library for visualizing the topic model and performing some exploratory work. Works well. Has a direct parrell implementation in R as well. \n",
    "* [Rare Technologies](https://rare-technologies.com/): The people that made & maintain gensim and a few other libraries.\n",
    "* [Jane Austen v. Charlotte Bronte](https://www.literaryladiesguide.com/literary-musings/jane-austen-charlotte-bronte-different-alike/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"ned asked me a question about England today.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ned ne VERB\n",
      "asked ask VERB\n",
      "me -PRON- PRON\n",
      "a a DET\n",
      "question question NOUN\n",
      "about about ADP\n",
      "England England PROPN\n",
      "today today NOUN\n",
      ". . PUNCT\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(test)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "England GPE\n",
      "today DATE\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_stream(path):\n",
    "    for f in os.listdir(path):\n",
    "        with open(os.path.join(path,f)) as t:\n",
    "            text = t.read().strip('\\n')\n",
    "            \n",
    "            yield text\n",
    "\n",
    "def get_people(docstream):\n",
    "    \n",
    "    ppl = []\n",
    "    \n",
    "    for d in docstream:\n",
    "        \n",
    "        doc = nlp(d)\n",
    "        \n",
    "        for ent in doc.ents:\n",
    "            if ent.label == 'PERSON':\n",
    "                ppl.append(end.txt)\n",
    "                \n",
    "    return set(ppl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = get_people(doc_stream(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python 3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
