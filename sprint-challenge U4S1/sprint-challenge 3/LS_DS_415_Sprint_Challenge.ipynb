{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Sprint Challenge\n",
    "## *Data Science Unit 4 Sprint 1*\n",
    "\n",
    "After a week of Natural Language Processing, you've learned some cool new stuff: how to process text, how turn text into vectors, and how to model topics from documents. Apply your newly acquired skills to one of the most famous NLP datasets out there: [Yelp](https://www.yelp.com/dataset/challenge). As part of the job selection process, some of my friends have been asked to create analysis of this dataset, so I want to empower you to have a head start.  \n",
    "\n",
    "The real dataset is massive (almost 8 gigs uncompressed). I've sampled the data for you to something more managable for the Sprint Challenge. You can analyze the full dataset as a stretch goal or after the sprint challenge. As you work on the challenge, I suggest adding notes about your findings and things you want to analyze in the future.\n",
    "\n",
    "## Challenge Objectives\n",
    "*Successfully complete these all these objectives to earn a 2. There are more details on each objective further down in the notebook.*\n",
    "* <a href=\"#p1\">Part 1</a>: Write a function to tokenize the yelp reviews\n",
    "* <a href=\"#p2\">Part 2</a>: Create a vector representation of those tokens\n",
    "* <a href=\"#p3\">Part 3</a>: Use your tokens in a classification model on yelp rating\n",
    "* <a href=\"#p4\">Part 4</a>: Estimate & Interpret a topic model of the Yelp reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "yelp = pd.read_json('./data/review_sample.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nDuEqIyRc8YKS1q1fX0CZg</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-03-31 16:50:30</td>\n",
       "      <td>0</td>\n",
       "      <td>eZs2tpEJtXPwawvHnHZIgQ</td>\n",
       "      <td>1</td>\n",
       "      <td>BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...</td>\n",
       "      <td>10</td>\n",
       "      <td>n1LM36qNg4rqGXIcvVXv8w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eMYeEapscbKNqUDCx705hg</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-16 05:31:03</td>\n",
       "      <td>0</td>\n",
       "      <td>DoQDWJsNbU0KL1O29l_Xug</td>\n",
       "      <td>4</td>\n",
       "      <td>Came here for lunch Togo. Service was quick. S...</td>\n",
       "      <td>0</td>\n",
       "      <td>5CgjjDAic2-FAvCtiHpytA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6Q7-wkCPc1KF75jZLOTcMw</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-06-20 19:14:48</td>\n",
       "      <td>1</td>\n",
       "      <td>DDOdGU7zh56yQHmUnL1idQ</td>\n",
       "      <td>3</td>\n",
       "      <td>I've been to Vegas dozens of times and had nev...</td>\n",
       "      <td>2</td>\n",
       "      <td>BdV-cf3LScmb8kZ7iiBcMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k3zrItO4l9hwfLRwHBDc9w</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-07-13 00:33:45</td>\n",
       "      <td>4</td>\n",
       "      <td>LfTMUWnfGFMOfOIyJcwLVA</td>\n",
       "      <td>1</td>\n",
       "      <td>We went here on a night where they closed off ...</td>\n",
       "      <td>5</td>\n",
       "      <td>cZZnBqh4gAEy4CdNvJailQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6hpfRwGlOzbNv7k5eP9rsQ</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-30 02:30:01</td>\n",
       "      <td>0</td>\n",
       "      <td>zJSUdI7bJ8PNJAg4lnl_Gg</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5 to 4 stars\\n\\nNot bad for the price, $12.9...</td>\n",
       "      <td>5</td>\n",
       "      <td>n9QO4ClYAS7h9fpQwa5bhA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool                date  funny  \\\n",
       "0  nDuEqIyRc8YKS1q1fX0CZg     1 2015-03-31 16:50:30      0   \n",
       "1  eMYeEapscbKNqUDCx705hg     0 2015-12-16 05:31:03      0   \n",
       "2  6Q7-wkCPc1KF75jZLOTcMw     1 2010-06-20 19:14:48      1   \n",
       "3  k3zrItO4l9hwfLRwHBDc9w     3 2010-07-13 00:33:45      4   \n",
       "4  6hpfRwGlOzbNv7k5eP9rsQ     1 2018-06-30 02:30:01      0   \n",
       "\n",
       "                review_id  stars  \\\n",
       "0  eZs2tpEJtXPwawvHnHZIgQ      1   \n",
       "1  DoQDWJsNbU0KL1O29l_Xug      4   \n",
       "2  DDOdGU7zh56yQHmUnL1idQ      3   \n",
       "3  LfTMUWnfGFMOfOIyJcwLVA      1   \n",
       "4  zJSUdI7bJ8PNJAg4lnl_Gg      4   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...      10   \n",
       "1  Came here for lunch Togo. Service was quick. S...       0   \n",
       "2  I've been to Vegas dozens of times and had nev...       2   \n",
       "3  We went here on a night where they closed off ...       5   \n",
       "4  3.5 to 4 stars\\n\\nNot bad for the price, $12.9...       5   \n",
       "\n",
       "                  user_id  \n",
       "0  n1LM36qNg4rqGXIcvVXv8w  \n",
       "1  5CgjjDAic2-FAvCtiHpytA  \n",
       "2  BdV-cf3LScmb8kZ7iiBcMA  \n",
       "3  cZZnBqh4gAEy4CdNvJailQ  \n",
       "4  n9QO4ClYAS7h9fpQwa5bhA  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Tokenize Function\n",
    "<a id=\"#p1\"></a>\n",
    "\n",
    "Complete the function `tokenize`. Your function should\n",
    "- accept one document at a time\n",
    "- return a list of tokens\n",
    "\n",
    "You are free to use any method you have learned this week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samue\\Anaconda3\\envs\\DS-U4-S1-NLP\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    return [token for token in simple_preprocess(doc) if token not in STOPWORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp['tokens'] = yelp['text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [beware, fake, fake, fake, small, business, lo...\n",
       "1    [came, lunch, togo, service, quick, staff, fri...\n",
       "2    [ve, vegas, dozens, times, stepped, foot, circ...\n",
       "3    [went, night, closed, street, party, best, act...\n",
       "4    [stars, bad, price, lunch, seniors, pay, eatin...\n",
       "5    [tasty, fast, casual, latin, street, food, men...\n",
       "6    [absolutely, amazing, incredible, production, ...\n",
       "7    [came, pho, enjoyed, got, pm, busy, got, serve...\n",
       "8    [absolutely, unique, experience, nail, shop, f...\n",
       "9    [wow, walked, sat, bar, minutes, bartenders, w...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp['tokens'][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Vector Representation\n",
    "<a id=\"#p2\"></a>\n",
    "1. Create a vector representation of the reviews\n",
    "2. Write a fake review and query for the 10 most similiar reviews, print the text of the reviews. Do you notice any patterns?\n",
    "    - Given the size of the dataset, it will probably be best to use a `NearestNeighbors` model for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazing</th>\n",
       "      <th>best</th>\n",
       "      <th>better</th>\n",
       "      <th>came</th>\n",
       "      <th>come</th>\n",
       "      <th>definitely</th>\n",
       "      <th>delicious</th>\n",
       "      <th>experience</th>\n",
       "      <th>food</th>\n",
       "      <th>friendly</th>\n",
       "      <th>...</th>\n",
       "      <th>people</th>\n",
       "      <th>place</th>\n",
       "      <th>recommend</th>\n",
       "      <th>restaurant</th>\n",
       "      <th>service</th>\n",
       "      <th>staff</th>\n",
       "      <th>time</th>\n",
       "      <th>try</th>\n",
       "      <th>ve</th>\n",
       "      <th>went</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.706692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.508688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363028</td>\n",
       "      <td>0.489918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458496</td>\n",
       "      <td>0.482884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.511373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558702</td>\n",
       "      <td>0.366225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.540582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   amazing      best  better      came  come  definitely  delicious  \\\n",
       "0      0.0  0.000000     0.0  0.000000   0.0         0.0        0.0   \n",
       "1      0.0  0.000000     0.0  0.508688   0.0         0.0        0.0   \n",
       "2      0.0  0.000000     0.0  0.000000   0.0         0.0        0.0   \n",
       "3      0.0  0.511373     0.0  0.000000   0.0         0.0        0.0   \n",
       "4      0.0  0.000000     0.0  0.000000   0.0         0.0        0.0   \n",
       "\n",
       "   experience      food  friendly  ...    people     place  recommend  \\\n",
       "0         0.0  0.000000  0.000000  ...  0.000000  0.000000        0.0   \n",
       "1         0.0  0.000000  0.496724  ...  0.000000  0.000000        0.0   \n",
       "2         0.0  0.000000  0.000000  ...  0.000000  0.000000        0.0   \n",
       "3         0.0  0.000000  0.000000  ...  0.558702  0.366225        0.0   \n",
       "4         0.0  0.700211  0.000000  ...  0.000000  0.000000        0.0   \n",
       "\n",
       "   restaurant   service     staff      time  try        ve      went  \n",
       "0         0.0  0.000000  0.000000  0.706692  0.0  0.000000  0.000000  \n",
       "1         0.0  0.363028  0.489918  0.000000  0.0  0.000000  0.000000  \n",
       "2         0.0  0.000000  0.000000  0.000000  0.0  0.458496  0.482884  \n",
       "3         0.0  0.000000  0.000000  0.000000  0.0  0.000000  0.540582  \n",
       "4         0.0  0.000000  0.000000  0.000000  0.0  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=tokenize, min_df=0.1, max_df=0.9, ngram_range=(1,2))\n",
    "\n",
    "sparse = tfidf.fit_transform(yelp['text'])\n",
    "\n",
    "dtm = pd.DataFrame(sparse.todense(), columns=tfidf.get_feature_names())\n",
    "\n",
    "dtm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=None, n_neighbors=10, p=2, radius=1.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NearestNeighbors(n_neighbors=10, algorithm='ball_tree')\n",
    "nn.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = [\"\"\" I took my family to this establishment and we were immediately seated. \n",
    "            However, it took nearly 30 minutes for someone to take our order. \n",
    "            When they finally did, we waited an hour without any food so we decided\n",
    "            to leave and find somewhere else to leave. When the owner saw us leaving \n",
    "            he was immediately irate and began to chase after us. We tried to drive away \n",
    "            but he ran in front of our car. We started to move forward and he jumped on the hood.\n",
    "            We then proceeded to drive him to the local authorities. \"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 0.        , 0.42529452, 0.46630881, 0.48821427,\n",
       "         0.48995944, 0.4935585 , 0.49501427, 0.49537281, 0.50291764]]),\n",
       " array([[6731, 7091, 6757, 9683, 3530, 2585, 7840,  328, 1883, 6746]],\n",
       "       dtype=int64))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "looking = tfidf.transform(query)\n",
    "nn.kneighbors(looking.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Currently waiting for my food in the drive thru. I don\\'t care how good this food is going to be because this place has some of the worst customer service I have ever experienced. There are 3 people in my car who all have different orders and different questions and before you know it the girl who takes orders complains and asks us to drive to the window instead because she couldn\\'t handle the simple task of actually answering our questions. We waited 20 min to get to the window and order our food because they took 20 min to make the order for the car in front of that BUT WAIT when we got to the window some guy I\\'m guessing he was the cook says \"so you were the ones with all those questions or whatever SO anyways you ordered...\" Like how fucking rude can you be??? And to top it off the girl who took our order laughed and rolled her eyes when he finished taking our order, I\\'m sorry you can\\'t handle customers asking you simple questions about a menu you SHOULD know about. Learn how to train your employees properly.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp['text'][6746]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Excellent!!! Very fresh and tasty. Very well priced a for big portions. Two can eat off one order. My Fav place for Thai food.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp['text'][1883]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I pulled up in the drive-through, said hello twice, and waited a couple minutes before a man said \"yeah, what do you want?\". He got my 3 item order wrong and had to be corrected. When I pulled up to pay he stuck his hand out the window and told me to stop before I was at the window. He was clearly taking the order of the person begging me. Once he was done with that he signaled to me to pull ahead. I worked in fast food long enough to know that he was trying to keep his timer down, but this was extremely rude and unnecessary. He was not friendly at the window either and the food was cold.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp['text'][328]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"9/22/17\\nCalling and placing an order was easy. Payment over the phone with no complications.  Food arrived exactly when they said it would. Great amount of food for the price.  The food also tasted amazing and was the perfect temperature.  Ground and through, I give this place an A+++!!!\\nFast Forward to 11/4/17\\nI called and placed an order at 16:30. I am informed it will be 40 minutes to an hour for delivery, which is more than acceptable for a Saturday evening.  At 17:50, an hour and 20 minutes later, I started calling to see where my order was.  20 minutes of calling with no answer. So I make my own food, leftovers, and at 18:20 the driver shows up.  Really, an hour and 50 minutes? Food is room temperature and I asked what the delay was and I was informed it's a busy night.  Unacceptable.  We have always had great customer service and excellent food, but today proved us wrong.  I asked for the manager to call us and the driver took my number.  If I get a call, I would expect some form of compensation. If no call, no future business from us.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp['text'][7840]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I was very disappointed with the way I was treated my first time ordering from this restaurant.\\nAfter buying a coupon book to support our local high school baseball team, I decided to use a coupon that entitled me to a free order of small breadsticks with any large pizza. I told the man over the phone that I had the coupon, and he quoted me $14 and some odd cents for my order. But when the delivery driver showed up, he told me it was $21. I asked why it was so much, and he said the man on the phone forgot to add something to my bill. I should have looked it over more carefully before I signed it, but I signed it anyway and then reviewed the receipt in my home.\\nThe restaurant charged me for a large order of breadsticks with my pizza. I called to explain their mistake and to ask for the $6 back that they charged me for the breadsticks. A very rude and inexperienced young girl was not helpful or courteous to me, did not apologize for the mistake, and told me she could refund me $3.50 which would be the difference between a small and large order of breadsticks. I tried to explain that I didn\\'t order a large breadstick; I ordered a small FREE one with my coupon. She put me on hold for a moment and then came back and said she could refund me$3.50 because quote \"we can\\'t just give you free food\".\\nI was appalled! I said I was not asking for free food asked to speak to the manager immediately. The manager did not apologize either, and instead of refunding money back to my credit card gave me CREDIT (of $3.50 and not $6) for my next pizza. Why would I want credit if I am never going to order from them ever again?? I don\\'t appreciate being treated that way. Also, their food is not that good.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp['text'][2585]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't love the sushi here, but my husband thinks it is acceptable. We used to order from here if we crave sushi but is broke since the sushi here is very cheap, so we will order the platters and have food for a few meals. The sushi here is about the same level as supermarket sushi.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp['text'][3530]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The most horrible Taco Bell I've ever been too. I made my order and waited for her to take my separate order and didn't say anything for 5 mins. I finally drove up and waited for another 5 mins for her to answer the window for me just to repeat my second order in the pouring rain. Then messed up both orders and combined them into 1 full order when I clearly said 2! It takes about 30 minutes to get food here. Even if your the only one in line. Don't eat here. If I could give it 0 stars I would.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp['text'][9683]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This location is the worst in all of beautiful 'merica. We have used the drive thru on 6 separate occasions in a period of 4 months when we first moved to this neighborhood. EVERY time they forgot items for our order or gave us completely wrong food. Called a couple times to give 'em some feedback without being rude. It has been 2 years now since they screwed up our last order because we don't go there anymore. This Taco Bell/KFC is a mile from our house but we much rather drive 3 miles further and visit the other locations.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp['text'][6757]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'So we are asked to park the car for our order.  12 minutes later we get our food.  Cold fries.   Asked for extra onions on the cheeseburgers.  No extra onions.  What the hell?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp['text'][7091]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Stopped by to pick up some BBQ beef to take home and make sandwiches for the family. Unlike some BBQ places in the valley, the meat was very lean, well cooked with a slightly smokey, well seasoned taste. We did not get any sides nor drinks so I cannot evaluate those. \\nThe cost per pound for the beef was a couple of dollars less than Dave's BBQ, Tom's BBQ or Andrew's BBQ. There were four customers ahead of me in line, but it only took 5 minutes for the food to be ready after I placed my order.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp['text'][6731]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "### Some reviews matched the unhappiness of my fake review but others were positive and just talked about ordering food."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Classification\n",
    "<a id=\"#p3\"></a>\n",
    "Your goal in this section will be to predict `stars` from the review dataset. \n",
    "\n",
    "1. Create a piepline object with a sklearn `CountVectorizer` or `TfidfVector` and any sklearn classifier. Use that pipeline to estimate a model to predict `stars`. Use the Pipeline to predict a star rating for your fake review from Part 2. \n",
    "2. Tune the entire pipeline with a GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words='english')\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "pipe = Pipeline([('vect', vect), ('clf', rfc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   34.2s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'vect__max_df': [0.75, 1.0], 'vect__min_df': [0.02, 0.05], 'vect__max_features': [100, 500], 'clf__n_estimators': [100, 200], 'clf__max_depth': [5, 8]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': [0.75, 1.0],\n",
    "    'vect__min_df': [.02, .05],\n",
    "    'vect__max_features': [100, 500],\n",
    "    'clf__n_estimators': [100, 200],\n",
    "    'clf__max_depth': [5, 8]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(yelp['text'], yelp['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__max_depth': 8,\n",
       " 'clf__n_estimators': 100,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': 500,\n",
       " 'vect__min_df': 0.02}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.predict(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect2 = CountVectorizer(stop_words='english')\n",
    "\n",
    "pipe2 = Pipeline([('vect', vect2), ('clf', rfc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'vect__max_df': [0.75, 1.0], 'vect__min_df': [0.02, 0.05], 'vect__max_features': [100, 500], 'clf__n_estimators': [100, 200], 'clf__max_depth': [5, 8]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': [0.75, 1.0],\n",
    "    'vect__min_df': [.02, .05],\n",
    "    'vect__max_features': [100, 500],\n",
    "    'clf__n_estimators': [100, 200],\n",
    "    'clf__max_depth': [5, 8]\n",
    "}\n",
    "\n",
    "grid_search2 = GridSearchCV(pipe, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search2.fit(yelp['text'], yelp['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search2.predict(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__max_depth': 8,\n",
       " 'clf__n_estimators': 100,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': 500,\n",
       " 'vect__min_df': 0.02}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search2.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stretch goal\n",
    "The difference between the CountVectorizer and the TfidfVectorizer is not apparent here because I implemented stop words. However, with some research, you will find that CountVectorizer simply obtains the count for every word. With the TfidfVectorizer, the use of IDF(Inverse Document Frequency) helps to adjust the weights of count because some words like \"the\" or \"and\" are going to appear more frequently regardless of their importance in the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Topic Modeling\n",
    "\n",
    "Let's find out what those yelp reviews are saying! :D\n",
    "\n",
    "1. Estimate a LDA topic model of the review text\n",
    "    - Keep the `iterations` parameter at or below 5 to reduce run time\n",
    "    - The `workers` parameter should match the number of physical cores on your machine.\n",
    "2. Create 1-2 visualizations of the results\n",
    "    - You can use the most important 3 words of a topic in relevant visualizations. Refer to yesterday's notebook to extract. \n",
    "3. In markdown, write 1-2 paragraphs of analysis on the results of your topic model\n",
    "\n",
    "__*Note*__: You can pass the DataFrame column of text reviews to gensim. You do not have to use a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import LdaMulticore\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn the vocubalary of the yelp data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = Dictionary(yelp['tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a bag of words representation of the entire corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "corpus = [id2word.doc2bow(text) for text in yelp['tokens']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your LDA model should be ready for estimation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "lda = LdaMulticore(corpus=corpus,\n",
    "                   id2word=id2word,\n",
    "                   iterations=5,\n",
    "                   workers=8,\n",
    "                   num_topics = 14 # You can change this parameter\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.013*\"place\" + 0.011*\"food\" + 0.009*\"good\" + 0.008*\"like\" + 0.008*\"time\" + 0.007*\"great\" + 0.005*\"service\" + 0.004*\"love\" + 0.004*\"best\" + 0.003*\"delicious\"'),\n",
       " (1,\n",
       "  '0.014*\"great\" + 0.009*\"service\" + 0.008*\"food\" + 0.007*\"good\" + 0.007*\"place\" + 0.005*\"like\" + 0.005*\"got\" + 0.005*\"time\" + 0.004*\"staff\" + 0.004*\"come\"'),\n",
       " (2,\n",
       "  '0.011*\"place\" + 0.009*\"great\" + 0.009*\"food\" + 0.008*\"good\" + 0.007*\"time\" + 0.007*\"like\" + 0.005*\"service\" + 0.004*\"got\" + 0.004*\"try\" + 0.004*\"order\"'),\n",
       " (3,\n",
       "  '0.012*\"good\" + 0.009*\"food\" + 0.009*\"like\" + 0.009*\"place\" + 0.008*\"service\" + 0.007*\"great\" + 0.006*\"time\" + 0.006*\"nice\" + 0.004*\"got\" + 0.004*\"order\"'),\n",
       " (4,\n",
       "  '0.014*\"good\" + 0.014*\"food\" + 0.008*\"place\" + 0.008*\"service\" + 0.006*\"great\" + 0.006*\"like\" + 0.006*\"time\" + 0.004*\"got\" + 0.004*\"love\" + 0.004*\"come\"'),\n",
       " (5,\n",
       "  '0.011*\"food\" + 0.010*\"good\" + 0.008*\"like\" + 0.007*\"service\" + 0.007*\"great\" + 0.007*\"place\" + 0.007*\"time\" + 0.005*\"got\" + 0.005*\"ve\" + 0.004*\"nice\"'),\n",
       " (6,\n",
       "  '0.011*\"service\" + 0.010*\"place\" + 0.008*\"food\" + 0.007*\"great\" + 0.006*\"time\" + 0.006*\"like\" + 0.006*\"good\" + 0.006*\"ve\" + 0.005*\"love\" + 0.004*\"best\"'),\n",
       " (7,\n",
       "  '0.009*\"good\" + 0.008*\"food\" + 0.008*\"place\" + 0.007*\"great\" + 0.007*\"time\" + 0.006*\"like\" + 0.005*\"service\" + 0.004*\"got\" + 0.004*\"ve\" + 0.004*\"amazing\"'),\n",
       " (8,\n",
       "  '0.013*\"food\" + 0.013*\"good\" + 0.009*\"place\" + 0.008*\"service\" + 0.007*\"like\" + 0.006*\"great\" + 0.006*\"time\" + 0.004*\"got\" + 0.004*\"ve\" + 0.004*\"nice\"'),\n",
       " (9,\n",
       "  '0.011*\"good\" + 0.010*\"great\" + 0.009*\"food\" + 0.008*\"place\" + 0.007*\"time\" + 0.006*\"like\" + 0.005*\"service\" + 0.004*\"best\" + 0.004*\"staff\" + 0.004*\"restaurant\"'),\n",
       " (10,\n",
       "  '0.012*\"food\" + 0.012*\"time\" + 0.010*\"place\" + 0.008*\"great\" + 0.008*\"like\" + 0.007*\"good\" + 0.006*\"service\" + 0.005*\"got\" + 0.005*\"ve\" + 0.004*\"better\"'),\n",
       " (11,\n",
       "  '0.014*\"place\" + 0.010*\"great\" + 0.009*\"good\" + 0.009*\"food\" + 0.009*\"service\" + 0.007*\"like\" + 0.006*\"time\" + 0.005*\"nice\" + 0.004*\"went\" + 0.004*\"got\"'),\n",
       " (12,\n",
       "  '0.009*\"food\" + 0.009*\"service\" + 0.008*\"place\" + 0.008*\"time\" + 0.008*\"like\" + 0.007*\"good\" + 0.006*\"great\" + 0.004*\"got\" + 0.004*\"best\" + 0.003*\"way\"'),\n",
       " (13,\n",
       "  '0.012*\"great\" + 0.012*\"place\" + 0.011*\"good\" + 0.009*\"food\" + 0.007*\"service\" + 0.007*\"like\" + 0.006*\"time\" + 0.005*\"love\" + 0.004*\"staff\" + 0.004*\"order\"')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "words = [re.findall(r'\"([^\"]*)\"', t[1]) for t in lda.print_topics()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [' '.join(t[0:5]) for t in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 1-2 visualizations of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Topic 0 ------\n",
      "place food good like time\n",
      "\n",
      "\n",
      "------ Topic 1 ------\n",
      "great service food good place\n",
      "\n",
      "\n",
      "------ Topic 2 ------\n",
      "place great food good time\n",
      "\n",
      "\n",
      "------ Topic 3 ------\n",
      "good food like place service\n",
      "\n",
      "\n",
      "------ Topic 4 ------\n",
      "good food place service great\n",
      "\n",
      "\n",
      "------ Topic 5 ------\n",
      "food good like service great\n",
      "\n",
      "\n",
      "------ Topic 6 ------\n",
      "service place food great time\n",
      "\n",
      "\n",
      "------ Topic 7 ------\n",
      "good food place great time\n",
      "\n",
      "\n",
      "------ Topic 8 ------\n",
      "food good place service like\n",
      "\n",
      "\n",
      "------ Topic 9 ------\n",
      "good great food place time\n",
      "\n",
      "\n",
      "------ Topic 10 ------\n",
      "food time place great like\n",
      "\n",
      "\n",
      "------ Topic 11 ------\n",
      "place great good food service\n",
      "\n",
      "\n",
      "------ Topic 12 ------\n",
      "food service place time like\n",
      "\n",
      "\n",
      "------ Topic 13 ------\n",
      "great place good food service\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for id, t in enumerate(topics):\n",
    "    print(f\"------ Topic {id} ------\")\n",
    "    print(t, end='\\n')\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samue\\Anaconda3\\envs\\DS-U4-S1-NLP\\lib\\site-packages\\past\\types\\oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable\n"
     ]
    }
   ],
   "source": [
    "import pyLDAvis.gensim\n",
    "\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyLDAvis.gensim.prepare(lda, corpus, id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paragraph \n",
    " Given how Yelp has become somewhat famous for where people go to complain about bad restaurant experiences, I was surprised at how many topics were extremely positive. I think this might have to do with the fact that I didn't remove duplicates or maybe there are a lot of positive reviews. If I had more time, I would comb through the data, make sure I got rid of all the duplicates, and check to see if I missed anything else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stretch Goals\n",
    "\n",
    "Complete one or more of these to push your score towards a three: \n",
    "* Incorporate named entity recognition into your analysis\n",
    "* Compare vectorization methods in the classification section\n",
    "* Analyze more (or all) of the yelp dataset - this one is v. hard. \n",
    "* Use a generator object on the reviews file - this would help you with the analyzing the whole dataset.\n",
    "* Incorporate any of the other yelp dataset entities in your analysis (business, users, etc.)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "u4-s1-nlp"
  },
  "kernelspec": {
   "display_name": "DS-U4-S1-NLP (Python3)",
   "language": "python",
   "name": "ds-u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.14.5"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
