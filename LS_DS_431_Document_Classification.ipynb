{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of LS_DS_431_Document_Classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "display_name": "U4-S1-NLP (Python 3)",
      "language": "python",
      "name": "u4-s1-nlp"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bkrant/DS-Unit-4-Sprint-1-NLP/blob/master/LS_DS_431_Document_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQVs7VE2t4wc",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# Document Classification\n",
        "## *Data Science Unit 4 Sprint 1 Lesson 3*\n",
        "\n",
        "Today's lesson will be different. You already know how to do classification. You ready know how to extract features from documents. So? That means you're ready to combine and practice those skills in a kaggle competition. We we will open with a five minute sprint explaining the competition, and then give you 25 minutes to work. After those twenty five minutes are up, I will give a 5-minute demo an NLP technique that will help you with document classification (*and **maybe** the competition*). \n",
        "\n",
        "Today's all about having fun and practicing your skills.\n",
        "\n",
        "## Learning Objectives\n",
        "* <a href=\"#p0\">Part 0</a>: Kaggle Competition\n",
        "* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n",
        "* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n",
        "* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fy-ity9_t4xE",
        "colab_type": "text"
      },
      "source": [
        "## Text Feature Extraction & Classification Pieplines\n",
        "<a id=\"p1\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD7CN1uKt4xY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataset\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "categories = ['alt.atheism',\n",
        "              'talk.religion.misc']\n",
        "\n",
        "data = fetch_20newsgroups(subset='train', categories=categories)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAc8yq0nt4yI",
        "colab_type": "text"
      },
      "source": [
        "### Sklearn Pipeline Objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsgFCeJut4yZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Statements\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stOqPKBlt4zI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Pipeline\n",
        "\n",
        "vect = TfidfVectorizer(stop_words='english')\n",
        "sgdc = SGDClassifier()\n",
        "\n",
        "pipe = Pipeline([('vect', vect), ('clf', sgdc)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACxOxOERt4zz",
        "colab_type": "code",
        "outputId": "ade85a8a-c4c6-4a32-bb2b-202538326212",
        "colab": {}
      },
      "source": [
        "# Fit Pipeline\n",
        "pipe.fit(data.data, data.target)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Users/jonathansokoll/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
              "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
              "...m_state=None, shuffle=True, tol=None,\n",
              "       validation_fraction=0.1, verbose=0, warm_start=False))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgZWjjjft40u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipe.predict(['Send me lots of money now', 'you won the lottery in Nigeria'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlIOq2wxt41M",
        "colab_type": "text"
      },
      "source": [
        "### Tuning a Pipeline Object with GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7WbHDc0t41W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Experiment Management\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di7jvtr7t41x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = {\n",
        "    'vect__max_df': (0.5, 0.75, 1.0),\n",
        "    'clf__max_iter':(20, 10, 100)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIKNIxsht42h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=-1, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbPm_csGt43m",
        "colab_type": "code",
        "outputId": "6ea38953-dfa4-49fb-ddfa-e44331fa51d1",
        "colab": {}
      },
      "source": [
        "grid_search.fit(data.data, data.target)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    5.1s finished\n",
            "/Users/jonathansokoll/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
              "       estimator=Pipeline(memory=None,\n",
              "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
              "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
              "...m_state=None, shuffle=True, tol=None,\n",
              "       validation_fraction=0.1, verbose=0, warm_start=False))]),\n",
              "       fit_params=None, iid='warn', n_jobs=-1,\n",
              "       param_grid={'vect__max_df': (0.5, 0.75, 1.0), 'clf__max_iter': (20, 10, 100)},\n",
              "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
              "       scoring=None, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq4o1QuRt44x",
        "colab_type": "text"
      },
      "source": [
        "## Latent Semantic Indexing\n",
        "<a id=\"p2\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vavGg7Uyt443",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import\n",
        "\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "svd = TruncatedSVD(n_components=100, \n",
        "                   algorithm='randomized',\n",
        "                   n_iter=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Acc6m38st45l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LSI\n",
        "\n",
        "lsi = Pipeline([('vect', vect), ('svd', svd)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7DCmD36t46M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pipe\n",
        "\n",
        "pipe = Pipeline([('lsi', lsi), ('clf', sgdc)])\n",
        "\n",
        "params = {\n",
        "    'lsi__vect__max_df':\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib4qcyl6t46k",
        "colab_type": "code",
        "outputId": "38987bab-1f7b-4ab6-d698-c3d09bdfb9f7",
        "colab": {}
      },
      "source": [
        "# Fit\n",
        "pipe.fit(data.data, data.target)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Users/jonathansokoll/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "     steps=[('lsi', Pipeline(memory=None,\n",
              "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
              "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "        ngram_range=(1, 1), norm=...m_state=None, shuffle=True, tol=None,\n",
              "       validation_fraction=0.1, verbose=0, warm_start=False))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0MmrQsGt47G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6hnGe3Gt47e",
        "colab_type": "text"
      },
      "source": [
        "## Word Embeddings with Spacy\n",
        "<a id=\"p3\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnF-j5Cbt47p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_lg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eia3Ih2t48u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc = nlp(\"Two bananas in pyjamas\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFRHsjz_t49q",
        "colab_type": "code",
        "outputId": "b5871a0f-e51a-4ea1-fffd-d761299cf3b3",
        "colab": {}
      },
      "source": [
        "bananas_vector = doc.vector\n",
        "print(len(bananas_vector))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-3CazMdt4-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_word_vectors(docs):\n",
        "    return [nlp(doc).vector for doc in docs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wluwIaNkt4_H",
        "colab_type": "code",
        "outputId": "a8e2088b-0f0a-436c-afc9-a945fa7b6a9a",
        "colab": {}
      },
      "source": [
        "X = get_word_vectors(data.data)\n",
        "\n",
        "sgdc.fit(X, data.target)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Users/jonathansokoll/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
              "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
              "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
              "       validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    }
  ]
}