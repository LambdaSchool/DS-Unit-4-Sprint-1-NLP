{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 4, Sprint 1, Module 3*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification (Prepare)\n",
    "\n",
    "Today's guided module project will be different. You already know how to do classification. You ready know how to extract features from documents. So? That means you're ready to combine and practice those skills in a kaggle competition. We we will open with a five minute sprint explaining the competition, and then give you 25 minutes to work. After those twenty five minutes are up, I will give a 5-minute demo an NLP technique that will help you with document classification (*and **maybe** the competition*).\n",
    "\n",
    "Today's all about having fun and practicing your skills. The competition will begin\n",
    "\n",
    "## Learning Objectives\n",
    "* <a href=\"#p0\">Part 0</a>: Kaggle Competition\n",
    "* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n",
    "* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n",
    "* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Feature Extraction & Classification Pipelines (Learn)\n",
    "<a id=\"p1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Sklearn pipelines allow you to stitch together multiple components of a machine learning process. The idea is that you can pass you raw data and get predictions out of the pipeline. This ability to pass raw input and receive a prediction from a singular class makes pipelines well suited for production, because you can pickle a a pipeline without worry about other data preprocessing steps. \n",
    "\n",
    "*Note:* Each time we call the pipeline during grid search, each component is fit again. The vectorizer (tf-idf) is transforming our entire vocabulary during each cross-validation fold. That transformation adds significant run time to our grid search. There *might* be interactions between the vectorizer and our classifier, so we estimate their performance together in the code below. However, if your goal is to reduce run time. Train your vectorizer separately (ie out of the grid-searched pipeline). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along \n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model (try using the pipe method I just demoed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Competition Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.description\n",
    "y_train = train.ratingCategory\n",
    "X_test = test.description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = nlp.Defaults.stop_words.union(['whiskey','whisky','drink','barrel','glass', 'bottle', 'll', 've'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words=STOP_WORDS, ngram_range=(1,3))\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "pipe = Pipeline([('vect', vect), ('rfc', rfc)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 10.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise-deprecating',\n",
       "          estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "          fit_params=None, iid='warn', n_iter=10, n_jobs=-1,\n",
       "          param_distributions={'vect__max_df': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000215E4D6D320>, 'vect__min_df': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000215EB8BB390>, 'rfc__n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000215EB8BB940>, 'rfc__max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000215EB8BB9E8>, 'rfc__max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000215EB8BBF60>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=1)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': uniform(.975, .999),\n",
    "    'vect__min_df': uniform(.005, .015),\n",
    "    'rfc__n_estimators': randint(200, 300),\n",
    "    'rfc__max_features': uniform(0.05, 0.13),\n",
    "    'rfc__max_depth': randint(34,36)\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(pipe,parameters, cv=10, n_jobs=-1, verbose=1)\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7403963787619281"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rfc__max_depth': 35,\n",
       " 'rfc__max_features': 0.16109491931884634,\n",
       " 'rfc__n_estimators': 220,\n",
       " 'vect__max_df': 1.7178875575024461,\n",
       " 'vect__min_df': 0.00830125427092079}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File\n",
    "*Note:* In a typical Kaggle competition, you are only allowed two submissions a day, so you only submit if you feel you cannot achieve higher test accuracy. For this compeition the max daily submissions are capped at **20**. Submit for each demo and for your assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               1\n",
       "2  3341               1\n",
       "3  3764               1\n",
       "4  2306               1"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "submission.to_csv('./data/submission10.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You're trying to achieve 90% Accuracy on your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Indexing (Learn)\n",
    "<a id=\"p2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "4. Make a submission to Kaggle \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(algorithm='randomized', n_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'lsi__svd__n_components': [10,25],\n",
    "    'lsi__vect__min_df': (.05, 0.1),\n",
    "    'lsi__vect__max_df': (0.75, 0.90),\n",
    "    'clf__max_depth':(10,15,20)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSI\n",
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "\n",
    "# Pipe\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', rfc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.1min finished\n",
      "C:\\Users\\JJ\\Anaconda3\\envs\\U4-S1-NLP\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "C:\\Users\\JJ\\Anaconda3\\envs\\U4-S1-NLP\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "          estimator=Pipeline(memory=None,\n",
       "     steps=[('lsi', Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3), norm=...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "          fit_params=None, iid='warn', n_iter=10, n_jobs=-1,\n",
       "          param_distributions={'lsi__svd__n_components': [10, 25], 'lsi__vect__min_df': (0.05, 0.1), 'lsi__vect__max_df': (0.75, 0.9), 'clf__max_depth': (10, 15, 20)},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = RandomizedSearchCV(pipe,parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File\n",
    "*Note:* You are only allowed two submissions a day. Only submit if you feel you cannot achieve higher test accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = cross_val.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               1\n",
       "2  3341               1\n",
       "3  3764               1\n",
       "4  2306               1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "subNumber = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Continue to apply Latent Semantic Indexing (LSI) to various datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings with Spacy (Learn)\n",
    "<a id=\"p3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vectors(docs):\n",
    "    return [nlp(doc).vector for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = get_word_vectors(X_train)\n",
    "\n",
    "len(X) == len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4087"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfc.fit(X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfc.score(X, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()\n",
    "\n",
    "# LSI\n",
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "\n",
    "# Pipe\n",
    "pipe = Pipeline([('lsi', lsi), ('xgb', xgb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'lsi__vect__max_df' : (.85,.95),\n",
    "    'lsi__vect__min_df' : (.025,.05),\n",
    "    'lsi__vect__max_features': (500,1000),\n",
    "    'xgb__learning_rate': (.1,.2,.4),\n",
    "    'xgb__max_depth':(3,6,9),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val = GridSearchCV(pipe, params, cv=5, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:  7.7min finished\n",
      "C:\\Users\\JJ\\Anaconda3\\envs\\U4-S1-NLP\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('lsi', Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3), norm=...\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'lsi__vect__max_df': (0.85, 0.95), 'lsi__vect__min_df': (0.025, 0.05), 'lsi__vect__max_features': (500, 1000), 'xgb__learning_rate': (0.1, 0.2, 0.4), 'xgb__max_depth': (3, 6, 9)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.704183998042574"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(docs):\n",
    "    tokenized = []\n",
    "    for doc in docs:\n",
    "        nlp_doc = nlp(doc)\n",
    "        tokens = ''\n",
    "        for token in nlp_doc:\n",
    "            if (token.is_stop is not True) and (token.is_punct is not True):\n",
    "                tokens = tokens + ' ' + token.text.lower()\n",
    "        tokenized.append(tokens)\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pulled"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(X_train[0])[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_token = get_tokens(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2), min_df=0.01, max_df=0.7, max_features=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect = vect.fit_transform(X_train_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_vect, X_val_vect = train_test_split(X_train_vect, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_val = train_test_split(y_train, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-merror:0.250897\tvalidation_1-merror:0.295499\n",
      "Multiple eval metrics have been passed: 'validation_1-merror' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-merror hasn't improved in 50 rounds.\n",
      "[1]\tvalidation_0-merror:0.248613\tvalidation_1-merror:0.286693\n",
      "[2]\tvalidation_0-merror:0.252529\tvalidation_1-merror:0.276908\n",
      "[3]\tvalidation_0-merror:0.249918\tvalidation_1-merror:0.273973\n",
      "[4]\tvalidation_0-merror:0.246982\tvalidation_1-merror:0.273973\n",
      "[5]\tvalidation_0-merror:0.244698\tvalidation_1-merror:0.272994\n",
      "[6]\tvalidation_0-merror:0.243719\tvalidation_1-merror:0.271037\n",
      "[7]\tvalidation_0-merror:0.241762\tvalidation_1-merror:0.279843\n",
      "[8]\tvalidation_0-merror:0.241436\tvalidation_1-merror:0.271037\n",
      "[9]\tvalidation_0-merror:0.242414\tvalidation_1-merror:0.272994\n",
      "[10]\tvalidation_0-merror:0.241762\tvalidation_1-merror:0.272016\n",
      "[11]\tvalidation_0-merror:0.241109\tvalidation_1-merror:0.271037\n",
      "[12]\tvalidation_0-merror:0.241109\tvalidation_1-merror:0.271037\n",
      "[13]\tvalidation_0-merror:0.241436\tvalidation_1-merror:0.273973\n",
      "[14]\tvalidation_0-merror:0.237194\tvalidation_1-merror:0.272994\n",
      "[15]\tvalidation_0-merror:0.237847\tvalidation_1-merror:0.272994\n",
      "[16]\tvalidation_0-merror:0.236868\tvalidation_1-merror:0.272994\n",
      "[17]\tvalidation_0-merror:0.235889\tvalidation_1-merror:0.272016\n",
      "[18]\tvalidation_0-merror:0.234584\tvalidation_1-merror:0.272016\n",
      "[19]\tvalidation_0-merror:0.233279\tvalidation_1-merror:0.272016\n",
      "[20]\tvalidation_0-merror:0.232953\tvalidation_1-merror:0.270059\n",
      "[21]\tvalidation_0-merror:0.231974\tvalidation_1-merror:0.272016\n",
      "[22]\tvalidation_0-merror:0.230669\tvalidation_1-merror:0.272016\n",
      "[23]\tvalidation_0-merror:0.228385\tvalidation_1-merror:0.274951\n",
      "[24]\tvalidation_0-merror:0.227406\tvalidation_1-merror:0.27593\n",
      "[25]\tvalidation_0-merror:0.226101\tvalidation_1-merror:0.27593\n",
      "[26]\tvalidation_0-merror:0.225122\tvalidation_1-merror:0.276908\n",
      "[27]\tvalidation_0-merror:0.224144\tvalidation_1-merror:0.27593\n",
      "[28]\tvalidation_0-merror:0.222186\tvalidation_1-merror:0.274951\n",
      "[29]\tvalidation_0-merror:0.218597\tvalidation_1-merror:0.272994\n",
      "[30]\tvalidation_0-merror:0.216313\tvalidation_1-merror:0.272016\n",
      "[31]\tvalidation_0-merror:0.215661\tvalidation_1-merror:0.272994\n",
      "[32]\tvalidation_0-merror:0.212398\tvalidation_1-merror:0.272994\n",
      "[33]\tvalidation_0-merror:0.211093\tvalidation_1-merror:0.272016\n",
      "[34]\tvalidation_0-merror:0.208483\tvalidation_1-merror:0.272994\n",
      "[35]\tvalidation_0-merror:0.207504\tvalidation_1-merror:0.273973\n",
      "[36]\tvalidation_0-merror:0.206525\tvalidation_1-merror:0.273973\n",
      "[37]\tvalidation_0-merror:0.206852\tvalidation_1-merror:0.274951\n",
      "[38]\tvalidation_0-merror:0.20522\tvalidation_1-merror:0.27593\n",
      "[39]\tvalidation_0-merror:0.203589\tvalidation_1-merror:0.277887\n",
      "[40]\tvalidation_0-merror:0.20261\tvalidation_1-merror:0.279843\n",
      "[41]\tvalidation_0-merror:0.201305\tvalidation_1-merror:0.277887\n",
      "[42]\tvalidation_0-merror:0.199347\tvalidation_1-merror:0.274951\n",
      "[43]\tvalidation_0-merror:0.195432\tvalidation_1-merror:0.27593\n",
      "[44]\tvalidation_0-merror:0.195432\tvalidation_1-merror:0.272994\n",
      "[45]\tvalidation_0-merror:0.193148\tvalidation_1-merror:0.272016\n",
      "[46]\tvalidation_0-merror:0.191843\tvalidation_1-merror:0.274951\n",
      "[47]\tvalidation_0-merror:0.189886\tvalidation_1-merror:0.272994\n",
      "[48]\tvalidation_0-merror:0.187602\tvalidation_1-merror:0.272016\n",
      "[49]\tvalidation_0-merror:0.185971\tvalidation_1-merror:0.270059\n",
      "[50]\tvalidation_0-merror:0.183687\tvalidation_1-merror:0.272994\n",
      "[51]\tvalidation_0-merror:0.181729\tvalidation_1-merror:0.272016\n",
      "[52]\tvalidation_0-merror:0.178467\tvalidation_1-merror:0.272994\n",
      "[53]\tvalidation_0-merror:0.176509\tvalidation_1-merror:0.272994\n",
      "[54]\tvalidation_0-merror:0.176835\tvalidation_1-merror:0.272994\n",
      "[55]\tvalidation_0-merror:0.176835\tvalidation_1-merror:0.273973\n",
      "[56]\tvalidation_0-merror:0.176509\tvalidation_1-merror:0.276908\n",
      "[57]\tvalidation_0-merror:0.174551\tvalidation_1-merror:0.27593\n",
      "[58]\tvalidation_0-merror:0.173246\tvalidation_1-merror:0.272994\n",
      "[59]\tvalidation_0-merror:0.171941\tvalidation_1-merror:0.272994\n",
      "[60]\tvalidation_0-merror:0.170636\tvalidation_1-merror:0.272016\n",
      "[61]\tvalidation_0-merror:0.168352\tvalidation_1-merror:0.273973\n",
      "[62]\tvalidation_0-merror:0.166395\tvalidation_1-merror:0.272994\n",
      "[63]\tvalidation_0-merror:0.164437\tvalidation_1-merror:0.272016\n",
      "[64]\tvalidation_0-merror:0.163458\tvalidation_1-merror:0.271037\n",
      "[65]\tvalidation_0-merror:0.16248\tvalidation_1-merror:0.272016\n",
      "[66]\tvalidation_0-merror:0.161501\tvalidation_1-merror:0.271037\n",
      "[67]\tvalidation_0-merror:0.159543\tvalidation_1-merror:0.270059\n",
      "[68]\tvalidation_0-merror:0.158564\tvalidation_1-merror:0.270059\n",
      "[69]\tvalidation_0-merror:0.157259\tvalidation_1-merror:0.270059\n",
      "[70]\tvalidation_0-merror:0.155954\tvalidation_1-merror:0.268102\n",
      "[71]\tvalidation_0-merror:0.155628\tvalidation_1-merror:0.26908\n",
      "[72]\tvalidation_0-merror:0.15367\tvalidation_1-merror:0.268102\n",
      "[73]\tvalidation_0-merror:0.151713\tvalidation_1-merror:0.267123\n",
      "[74]\tvalidation_0-merror:0.148777\tvalidation_1-merror:0.268102\n",
      "[75]\tvalidation_0-merror:0.146166\tvalidation_1-merror:0.268102\n",
      "[76]\tvalidation_0-merror:0.145188\tvalidation_1-merror:0.268102\n",
      "[77]\tvalidation_0-merror:0.143556\tvalidation_1-merror:0.26908\n",
      "[78]\tvalidation_0-merror:0.142904\tvalidation_1-merror:0.270059\n",
      "[79]\tvalidation_0-merror:0.141599\tvalidation_1-merror:0.271037\n",
      "[80]\tvalidation_0-merror:0.14062\tvalidation_1-merror:0.272016\n",
      "[81]\tvalidation_0-merror:0.138336\tvalidation_1-merror:0.26908\n",
      "[82]\tvalidation_0-merror:0.136052\tvalidation_1-merror:0.270059\n",
      "[83]\tvalidation_0-merror:0.135073\tvalidation_1-merror:0.270059\n",
      "[84]\tvalidation_0-merror:0.133768\tvalidation_1-merror:0.270059\n",
      "[85]\tvalidation_0-merror:0.132463\tvalidation_1-merror:0.270059\n",
      "[86]\tvalidation_0-merror:0.131158\tvalidation_1-merror:0.271037\n",
      "[87]\tvalidation_0-merror:0.130506\tvalidation_1-merror:0.26908\n",
      "[88]\tvalidation_0-merror:0.129853\tvalidation_1-merror:0.270059\n",
      "[89]\tvalidation_0-merror:0.125612\tvalidation_1-merror:0.273973\n",
      "[90]\tvalidation_0-merror:0.125612\tvalidation_1-merror:0.272994\n",
      "[91]\tvalidation_0-merror:0.125285\tvalidation_1-merror:0.274951\n",
      "[92]\tvalidation_0-merror:0.124307\tvalidation_1-merror:0.273973\n",
      "[93]\tvalidation_0-merror:0.123002\tvalidation_1-merror:0.272016\n",
      "[94]\tvalidation_0-merror:0.122349\tvalidation_1-merror:0.273973\n",
      "[95]\tvalidation_0-merror:0.120718\tvalidation_1-merror:0.274951\n",
      "[96]\tvalidation_0-merror:0.119739\tvalidation_1-merror:0.274951\n",
      "[97]\tvalidation_0-merror:0.118434\tvalidation_1-merror:0.27593\n",
      "[98]\tvalidation_0-merror:0.11615\tvalidation_1-merror:0.27593\n",
      "[99]\tvalidation_0-merror:0.113214\tvalidation_1-merror:0.27593\n",
      "[100]\tvalidation_0-merror:0.112235\tvalidation_1-merror:0.27593\n",
      "[101]\tvalidation_0-merror:0.112235\tvalidation_1-merror:0.276908\n",
      "[102]\tvalidation_0-merror:0.110604\tvalidation_1-merror:0.277887\n",
      "[103]\tvalidation_0-merror:0.109625\tvalidation_1-merror:0.276908\n",
      "[104]\tvalidation_0-merror:0.109299\tvalidation_1-merror:0.276908\n",
      "[105]\tvalidation_0-merror:0.109299\tvalidation_1-merror:0.276908\n",
      "[106]\tvalidation_0-merror:0.108646\tvalidation_1-merror:0.274951\n",
      "[107]\tvalidation_0-merror:0.107667\tvalidation_1-merror:0.27593\n",
      "[108]\tvalidation_0-merror:0.107341\tvalidation_1-merror:0.27593\n",
      "[109]\tvalidation_0-merror:0.105057\tvalidation_1-merror:0.276908\n",
      "[110]\tvalidation_0-merror:0.104405\tvalidation_1-merror:0.276908\n",
      "[111]\tvalidation_0-merror:0.101794\tvalidation_1-merror:0.27593\n",
      "[112]\tvalidation_0-merror:0.099511\tvalidation_1-merror:0.27593\n",
      "[113]\tvalidation_0-merror:0.099184\tvalidation_1-merror:0.276908\n",
      "[114]\tvalidation_0-merror:0.096574\tvalidation_1-merror:0.274951\n",
      "[115]\tvalidation_0-merror:0.096248\tvalidation_1-merror:0.273973\n",
      "[116]\tvalidation_0-merror:0.093964\tvalidation_1-merror:0.272994\n",
      "[117]\tvalidation_0-merror:0.092333\tvalidation_1-merror:0.272016\n",
      "[118]\tvalidation_0-merror:0.09168\tvalidation_1-merror:0.272994\n",
      "[119]\tvalidation_0-merror:0.09168\tvalidation_1-merror:0.272994\n",
      "[120]\tvalidation_0-merror:0.091354\tvalidation_1-merror:0.272994\n",
      "[121]\tvalidation_0-merror:0.090701\tvalidation_1-merror:0.272016\n",
      "[122]\tvalidation_0-merror:0.090375\tvalidation_1-merror:0.272016\n",
      "[123]\tvalidation_0-merror:0.089396\tvalidation_1-merror:0.272016\n",
      "Stopping. Best iteration:\n",
      "[73]\tvalidation_0-merror:0.151713\tvalidation_1-merror:0.267123\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=1000, n_jobs=-1, nthread=None,\n",
       "       objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_set = [(X_train_vect, y_train),\n",
    "            (X_val_vect, y_val)]\n",
    "\n",
    "model = XGBClassifier(\n",
    "    n_estimators=1000,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train_vect, y_train, eval_set=eval_set, eval_metric='merror', early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect = vect.fit_transform(X_train_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['ratingCategory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=1000, n_jobs=-1, nthread=None,\n",
       "       objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(\n",
    "    n_estimators=1000,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_token = get_tokens(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vect = vect.transform(X_test_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')\n",
    "submission.to_csv('./data/submission5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n",
    "4. Make a submission to Kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review\n",
    "\n",
    "To review this module: \n",
    "* Continue working on the Kaggle comeptition\n",
    "* Find another text classification task to work on"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
