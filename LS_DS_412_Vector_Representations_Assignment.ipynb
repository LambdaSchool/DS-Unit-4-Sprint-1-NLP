{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 2*\n",
    "\n",
    "# Document Representations: Bag-Of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "hyj-f9FDcVFp",
    "outputId": "5dd045fe-6e4c-458c-e2fc-253c3da9c805"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading https://files.pythonhosted.org/packages/87/16/4d247e27c55a7b6412e7c4c86f2500ae61afcbf5932b9e3491f8462f8d9e/nltk-3.4.4.zip (1.5MB)\n",
      "Requirement already satisfied, skipping upgrade: six in c:\\users\\dustin\\anaconda3\\lib\\site-packages (from nltk) (1.12.0)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py): started\n",
      "  Building wheel for nltk (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\Dustin\\AppData\\Local\\pip\\Cache\\wheels\\41\\c8\\31\\48ace4468e236e0e8435f30d33e43df48594e4d53e367cf061\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "  Found existing installation: nltk 3.4\n",
      "    Uninstalling nltk-3.4:\n",
      "      Successfully uninstalled nltk-3.4\n",
      "Successfully installed nltk-3.4.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dustin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dustin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "#!pip install -U nltk\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import sent_tokenize # Sentence Tokenizer\n",
    "from nltk.tokenize import word_tokenize # Word Tokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7bcmqfGXrFG"
   },
   "source": [
    "# 1) (optional) Scrape 100 Job Listings that contain the title \"Data Scientist\" from indeed.com\n",
    "\n",
    "At a minimum your final dataframe of job listings should contain\n",
    "- Job Title\n",
    "- Job Description\n",
    "\n",
    "If you choose to not to scrape the data, there is a CSV with outdated data in the directory. Remeber, if you scrape Indeed, you're helping yourself find a job. ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcYlc1URXhlC"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n",
       "      <td>Data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0  b\"<div><div>Job Requirements:</div><ul><li><p>...   \n",
       "1           1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...   \n",
       "2           2  b'<div><p>As a Data Scientist you will be work...   \n",
       "3           3  b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n",
       "4           4  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...   \n",
       "\n",
       "                          title  \n",
       "0               Data scientistÂ   \n",
       "1              Data Scientist I  \n",
       "2  Data Scientist - Entry Level  \n",
       "3                Data Scientist  \n",
       "4                Data Scientist  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "job = 'job_listings.csv'\n",
    "df = pd.read_csv(job)\n",
    "df.head()\n",
    "#raise Exception(\"\\nThis task is not complete. \\nReplace this line with your code for the task.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C4xFZNtX1m2"
   },
   "source": [
    "## 2) Use Spacy to tokenize / clean the listings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhUHuMr-X-II"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "#raise Exception(\"\\nThis task is not complete. \\nReplace this line with your code for the task.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cleanhtml(html):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', html)\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = df['description'].apply(cleanhtml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =====Clean and iterable words - NOT NECESSARY====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    lemmas = []\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        if (token.is_stop == False) and (token.is_punct == False) and (token.pos_ != 'PRON'):\n",
    "            lemmas.append(token.lemma_)\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['tokens'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [b\"Job, Requirements:\\nConceptual, understand,...\n",
       "1    [b'job, description\\n\\na, Data, Scientist, 1, ...\n",
       "2    [b'as, Data, scientist, work, consult, busines...\n",
       "3    [b'$4,969, $, 6,756, monthcontractunder, gener...\n",
       "4    [b'location, USA, \\xe2\\x80\\x93, multiple, loca...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ['b\"Job',\n",
    " 'Requirements:\\\\nConceptual',\n",
    " 'understand',\n",
    " 'Machine',\n",
    " 'Learning',\n",
    " 'model',\n",
    " 'like',\n",
    " 'Nai\\\\xc2\\\\xa8ve',\n",
    " 'Bayes',\n",
    " 'K',\n",
    " 'Means',\n",
    " 'SVM',\n",
    " 'Apriori',\n",
    " 'Linear/',\n",
    " 'Logistic',\n",
    " 'Regression',\n",
    " 'Neural',\n",
    " 'Random',\n",
    " 'Forests',\n",
    " 'Decision',\n",
    " 'Trees',\n",
    " 'K',\n",
    " 'NN',\n",
    " 'hand',\n",
    " 'experience',\n",
    " '2',\n",
    " 'them\\\\nintermediate',\n",
    " 'expert',\n",
    " 'level',\n",
    " 'coding',\n",
    " 'skill',\n",
    " 'Python',\n",
    " 'R.',\n",
    " 'ability',\n",
    " 'write',\n",
    " 'function',\n",
    " 'clean',\n",
    " 'efficient',\n",
    " 'datum',\n",
    " 'manipulation',\n",
    " 'mandatory',\n",
    " 'role)\\\\nexposure',\n",
    " 'package',\n",
    " 'like',\n",
    " 'NumPy',\n",
    " 'SciPy',\n",
    " 'Pandas',\n",
    " 'Matplotlib',\n",
    " 'etc',\n",
    " 'Python',\n",
    " 'GGPlot2',\n",
    " 'dplyr',\n",
    " 'tidyR',\n",
    " 'r\\\\nability',\n",
    " 'communicate',\n",
    " 'Model',\n",
    " 'finding',\n",
    " 'Technical',\n",
    " 'Non',\n",
    " 'technical',\n",
    " 'stake',\n",
    " 'holders\\\\nhand',\n",
    " 'experience',\n",
    " 'SQL',\n",
    " 'Hive',\n",
    " 'similar',\n",
    " 'programming',\n",
    " 'language\\\\nMust',\n",
    " 'past',\n",
    " 'work',\n",
    " 'GitHub',\n",
    " 'Kaggle',\n",
    " 'publish',\n",
    " 'article\\\\nMaster',\n",
    " 'degree',\n",
    " 'Statistics',\n",
    " 'Mathematics',\n",
    " 'Computer',\n",
    " 'Science',\n",
    " 'quant',\n",
    " 'specific',\n",
    " 'field.\\\\napply']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_new_line(text):\n",
    "    j = []\n",
    "    for i in text:\n",
    "        if 'b\"' in i:\n",
    "            i = i.replace('b\"', '')\n",
    "        elif \"b'\" in i:\n",
    "            i = i.replace(\"b'\", '')\n",
    "        if '\\\\n' in i:\n",
    "            i = i.replace('\\\\n', ' ')\n",
    "            j.append(i)\n",
    "        else:\n",
    "            j.append(i)\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['tokens'].apply(clean_new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>[Job, Requirements: Conceptual, understand, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>[job, description  a, Data, Scientist, 1, help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "      <td>[as, Data, scientist, work, consult, business,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[$4,969, $, 6,756, monthcontractunder, general...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[location, USA, \\xe2\\x80\\x93, multiple, locati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0  b\"<div><div>Job Requirements:</div><ul><li><p>...   \n",
       "1           1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...   \n",
       "2           2  b'<div><p>As a Data Scientist you will be work...   \n",
       "3           3  b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n",
       "4           4  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...   \n",
       "\n",
       "                          title  \\\n",
       "0               Data scientistÂ    \n",
       "1              Data Scientist I   \n",
       "2  Data Scientist - Entry Level   \n",
       "3                Data Scientist   \n",
       "4                Data Scientist   \n",
       "\n",
       "                                              tokens  \n",
       "0  [Job, Requirements: Conceptual, understand, Ma...  \n",
       "1  [job, description  a, Data, Scientist, 1, help...  \n",
       "2  [as, Data, scientist, work, consult, business,...  \n",
       "3  [$4,969, $, 6,756, monthcontractunder, general...  \n",
       "4  [location, USA, \\xe2\\x80\\x93, multiple, locati...  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ======================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lgCZNL_YycP"
   },
   "source": [
    "# 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2PZ8Pj_YxcF"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "data = df['description']\n",
    "\n",
    "# Instantiate\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit the data\n",
    "vectorizer.fit(data)\n",
    "\n",
    "# Create a Vocab - All posible words we might use\n",
    "vectorizer.vocabulary_\n",
    "\n",
    "# Transform the data\n",
    "dtm = vectorizer.transform(data)\n",
    "\n",
    "#raise Exception(\"\\nThis task is not complete. \\nReplace this line with your code for the task.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zo1iH_UeY7_n"
   },
   "source": [
    "# 4) Visualize the most common word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5LB00uyZKV5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 9818)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>02115</th>\n",
       "      <th>03</th>\n",
       "      <th>0356</th>\n",
       "      <th>04</th>\n",
       "      <th>062</th>\n",
       "      <th>06366</th>\n",
       "      <th>08</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>zenreach</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zf</th>\n",
       "      <th>zheng</th>\n",
       "      <th>zillow</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 9818 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  02115  03  0356  04  062  06366  08  10   ...    zenreach  zero  \\\n",
       "0   0    0      0   0     0   0    0      0   0   0   ...           0     0   \n",
       "1   0    0      0   0     0   0    0      0   0   0   ...           0     0   \n",
       "2   0    0      0   0     0   0    0      0   0   0   ...           0     0   \n",
       "3   0    0      0   0     0   0    0      0   0   0   ...           0     0   \n",
       "4   0    0      0   0     0   0    0      0   0   0   ...           0     0   \n",
       "\n",
       "   zeus  zf  zheng  zillow  zones  zoom  zuckerberg  zurich  \n",
       "0     0   0      0       0      0     0           0       0  \n",
       "1     0   0      0       0      0     0           0       0  \n",
       "2     0   0      0       0      0     0           0       0  \n",
       "3     0   0      1       0      0     0           0       0  \n",
       "4     0   0      0       0      0     0           0       0  \n",
       "\n",
       "[5 rows x 9818 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "# Get the words counts \n",
    "dtm = pd.DataFrame(dtm.todense(), columns= vectorizer.get_feature_names())\n",
    "print(dtm.shape)\n",
    "dtm.head()\n",
    "#raise Exception(\"\\nThis task is not complete. \\nReplace this line with your code for the task.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dtm.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(dtm.columns)):\n",
    "#     dtm.columns[i], dtm.iloc[:,i].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwFsTqrVZMYi"
   },
   "source": [
    " # 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gx2gZCbl5Np"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>04</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1079302</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>125</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>...</th>\n",
       "      <th>yes</th>\n",
       "      <th>yeti</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>yrs</th>\n",
       "      <th>zenreach</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zf</th>\n",
       "      <th>zillow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000   04   10  100  1079302   11   12  125   14   15   ...    yes  yeti  \\\n",
       "0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0   ...    0.0   0.0   \n",
       "1  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0   ...    0.0   0.0   \n",
       "2  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0   ...    0.0   0.0   \n",
       "3  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0   ...    0.0   0.0   \n",
       "4  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0   ...    0.0   0.0   \n",
       "\n",
       "   york  young  yrs  zenreach  zero  zeus   zf  zillow  \n",
       "0   0.0    0.0  0.0       0.0   0.0   0.0  0.0     0.0  \n",
       "1   0.0    0.0  0.0       0.0   0.0   0.0  0.0     0.0  \n",
       "2   0.0    0.0  0.0       0.0   0.0   0.0  0.0     0.0  \n",
       "3   0.0    0.0  0.0       0.0   0.0   0.0  0.0     0.0  \n",
       "4   0.0    0.0  0.0       0.0   0.0   0.0  0.0     0.0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Instantiate\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "\n",
    "# Fit & Transform and get word count\n",
    "dtm = tfidf.fit_transform(data)\n",
    "\n",
    "# Look at the dataframe\n",
    "docs = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names())\n",
    "docs.head()\n",
    "#raise Exception(\"\\nThis task is not complete. \\nReplace this line with your code for the task.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 6) Create a NearestNeighbor Model. Write the description of your ideal datascience job and query your job listings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 1.28186048, 1.29243201, 1.29554001, 1.3029865 ],\n",
       "        [0.        , 1.25217139, 1.25498183, 1.25677297, 1.2570676 ],\n",
       "        [0.        , 1.23682516, 1.25514087, 1.25777374, 1.2608867 ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 1.30016532, 1.30535051, 1.30917534],\n",
       "        [0.        , 0.06717463, 1.20003281, 1.2309191 , 1.2318678 ],\n",
       "        [0.        , 1.22198102, 1.23991606, 1.24863321, 1.25223614]]),\n",
       " array([[  0, 336, 276, 274, 366],\n",
       "        [  1, 225, 399,  59, 201],\n",
       "        [  2, 307, 357, 318, 407],\n",
       "        ...,\n",
       "        [423,  44,  16, 363,  20],\n",
       "        [424, 382, 201, 366, 264],\n",
       "        [425, 201, 264, 307, 383]], dtype=int64))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "nn = NearestNeighbors(n_neighbors=5, algorithm='ball_tree')\n",
    "\n",
    "# Fit on TF-IDF Vectors\n",
    "nn.fit(dtm.todense())\n",
    "\n",
    "# Query Using knn\n",
    "nn.kneighbors(dtm.todense())\n",
    "\n",
    "#raise Exception(\"\\nThis task is not complete. \\nReplace this line with your code for the task.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(data, x, y):\n",
    "    print(data[x],'\\n')\n",
    "    print(data[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'General Description:\\nAssist researchers and software developers on projects bridging the gap between research and analytics by providing data-driven solutions across several policy areas.\\nWork with research and analytics staff in development of streamlined protocols through gathering requirements.\\nAssist team with schema, business rules and configuration testing processes.\\nSupport development efforts with standardized protocols to manipulate information captured in a fixed format to usable data, using non-traditional data sources like scraping data from social media, mining data from natural language texts, as well as vectorizing images to create analytical dataset to inform policy decisions.\\nAssist development teams drafting and compiling requirements for complex statistical models, machine learning algorithms and deep learning networks.\\nAssist Data Scientists in developing data products that contain dynamic data visualizations to present findings, data explorers that allow users to explore and analyze the data themselves, as well as publish data.\\nPerform functional testing of data products\\nMaintain data product documentation.\\n\\nWork experience and job skills requirements:\\nKnowledge of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, and Decision Forests\\nFamiliarity with data management and machine learning toolkits, such as tidyverse and dyplr in R and pandas and scikit learn in Python\\nExperience using data visualization tools PlotLy and Tableau\\nExperience working with query languages such as SQL.\\nKnowledge of statistics and research methods and regression models.\\nExperience developing technical documentation for datasets, code, and data products.\\nExcellent verbal and written communication skills.\\n\\nEducation Requirements:\\nBA/BS in Applied Mathematics, Applied Statistics, Operations Research, Economics, Business Analytics or a related field' \n",
      "\n",
      "b\"Facebook's mission is to give people the power to build community and bring the world closer together. Through our family of apps and services, we're building a different kind of company that connects billions of people around the world, gives them ways to share what matters most to them, and helps bring people closer together. Whether we're creating new products or helping a small business expand its reach, people at Facebook are builders at heart. Our global teams are constantly iterating, solving problems, and working together to empower people around the world to build community and connect in meaningful ways. Together, we can help people build stronger communities \\xe2\\x80\\x94 we're just getting started.\\nThe Infrastructure Strategy group is responsible for the strategic analysis to support and enable the continued growth critical to Facebook\\xe2\\x80\\x99s infrastructure organization. The ideal candidate will be passionate about Facebook, have strong analytical and modeling aptitude and has experience using data to drive cost effective decision making.\\n\\nRESPONSIBILITIES\\nLeverage data and business principles to solve large-scale web, mobile and data infrastructure problems.\\nWork cross-functionally to define problem statements, collect data, build analytical models and make recommendations.\\nBuild and maintain data driven optimization models, experiments, forecasting algorithms, and machine learning models.\\nLeverage tools like Python, R, Hadoop &amp; SQL to drive efficient analytics.\\nCommunicate final recommendations and drive decision making.\\nMINIMUM QUALIFICATIONS\\nDegree in quantitative field (e.g. Computer Science, Engineering, Mathematics, Statistics, Operations Research or other related field)\\n2+ years of industry or graduate research experience solving analytical problems and building models using quantitative, statistical or machine learning approaches\\nExperience with Machine Learning, Statistics, or other data analysis tools and techniques\\nExperience performing data extraction, cleaning, analysis and presentation for medium to large datasets\\nExperience with at least one programming language (i.e. Python, R, Java, or C++)\\nExperience writing SQL queries\\nExperience with scientific computing and analysis packages such as NumPy, SciPy, Pandas, Scikit-learn, dplyr, or ggplot2\\nExperience with statistics methods such as forecasting, time series, hypothesis testing, classification, clustering or regression analysis\\nExperience with data visualization libraries such as Matplotlib, Pyplot, ggplot2\\nExperience with machine learning libraries and packages such as PyTorch, Caffe2, TensorFlow, Keras or Theano\\nPREFERRED QUALIFICATIONS\\nAdvanced degree (Master\\xe2\\x80\\x99s or PhD) in quantitative field\\nExperience working with distributed computing tools (Hadoop, Hive, Spark, etc.)\\nProficiency in algorithmic complexity\"\n"
     ]
    }
   ],
   "source": [
    "compare(data, 274, 276)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiDfTWceoRkH"
   },
   "source": [
    "## Stretch Goals\n",
    "\n",
    " - Try different visualizations for words and frequencies - what story do you want to tell with the data?\n",
    " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
    " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
    " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
    "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_422_BOW_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "nteract": {
   "version": "0.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
