{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-OJHr-tbuSuI"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 3*\n",
    "\n",
    "# Document Classification\n",
    "\n",
    "Use the following dataset of scraped \"Data Scientist\" and \"Data Analyst\" job listings to create your own Document Classification Models.\n",
    "\n",
    "<https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-2-NLP/master/module3-Document-Classification/job_listings.csv>\n",
    "\n",
    "Requirements:\n",
    "\n",
    "- Apply both CountVectorizer and TfidfVectorizer methods to this data and compare results\n",
    "- Use at least two different classification models to compare differences in model accuracy\n",
    "- Try to \"Hyperparameter Tune\" your model by using different n_gram ranges, max_results, and data cleaning methods\n",
    "- Try and get the highest accuracy possible!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MFreAPN3uGgz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('job_listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>job</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;\\nConceptual understanding in Machine Learning models like Nai\\xc2\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random For...</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Data Scientist 1, you will help us build machine learning models, data pipelines, and micro-services to help our clients navigate their healthcare journ...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be working on consulting side of our business. You will be responsible for analyzing large, complex datasets and identify meaningful patterns that lead to ac...</td>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-u-xs-mb--md\"&gt;&lt;div class=\"jobsearch-JobMetadataHeader-item \"&gt;&lt;span class=\"icl-u-xs-mr--xs\"&gt;$4,969 - $6,756 a month&lt;/span&gt;&lt;/div&gt;&lt;div class=\"jobsearch-Jo...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple locations&lt;/li&gt;\\n&lt;li&gt;2+ years of Analytics experience&lt;/li&gt;\\n&lt;li&gt;Understand business requirements and technical requirements&lt;/li&gt;\\n&lt;li&gt;Can handle data e...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                               description  \\\n",
       "0  b\"<div><div>Job Requirements:</div><ul><li><p>\\nConceptual understanding in Machine Learning models like Nai\\xc2\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random For...   \n",
       "1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Data Scientist 1, you will help us build machine learning models, data pipelines, and micro-services to help our clients navigate their healthcare journ...   \n",
       "2  b'<div><p>As a Data Scientist you will be working on consulting side of our business. You will be responsible for analyzing large, complex datasets and identify meaningful patterns that lead to ac...   \n",
       "3  b'<div class=\"jobsearch-JobMetadataHeader icl-u-xs-mb--md\"><div class=\"jobsearch-JobMetadataHeader-item \"><span class=\"icl-u-xs-mr--xs\">$4,969 - $6,756 a month</span></div><div class=\"jobsearch-Jo...   \n",
       "4  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple locations</li>\\n<li>2+ years of Analytics experience</li>\\n<li>Understand business requirements and technical requirements</li>\\n<li>Can handle data e...   \n",
       "\n",
       "                          title             job  \n",
       "0               Data scientistÂ   Data Scientist  \n",
       "1              Data Scientist I  Data Scientist  \n",
       "2  Data Scientist - Entry Level  Data Scientist  \n",
       "3                Data Scientist  Data Scientist  \n",
       "4                Data Scientist  Data Scientist  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 200)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data Scientist    250\n",
       "Data Analyst      250\n",
       "Name: job, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['job'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312    b'<div><p>Safe Banking Systems, a part of Accu...\n",
       "488    b\"<div></div><div><div><div>We are presently s...\n",
       "466    b'<div class=\"jobsearch-JobMetadataHeader icl-...\n",
       "207    b'<div class=\"jobsearch-JobMetadataHeader icl-...\n",
       "355    b'<div class=\"jobsearch-JobMetadataHeader icl-...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip HTML Tags\n",
    "from html.parser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.fed = []\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = []\n",
    "\n",
    "for text in df['description']:\n",
    "    clean = strip_tags(str(text))\n",
    "    clean = clean.replace('\\n', '')\n",
    "    clean = clean.replace('\\\\', '')\n",
    "    clean = clean.replace('/', '')\n",
    "    vals.append(clean)\n",
    "    \n",
    "df['clean_desc'] = vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['job'].map({\n",
    "    'Data Scientist': '0',\n",
    "    'Data Analyst': '1'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    250\n",
       "0    250\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['clean_desc']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400,), (100,), (400,), (100,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13965\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=None, ngram_range=(1,1), stop_words='english')\n",
    "\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "print(len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized = vectorizer.transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "lr.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = lr.predict(X_train_vectorized)\n",
    "test_predictions = lr.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(f'Train Accuracy: {accuracy_score(y_train, train_predictions)}')\n",
    "print(f'Test Accuracy: {accuracy_score(y_test, test_predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_result = {}\n",
    "lr_result['model'] = 'Logistic Regression'\n",
    "lr_result['acc_train'] = accuracy_score(y_train, train_predictions)\n",
    "lr_result['acc_test'] = accuracy_score(y_test, test_predictions)\n",
    "lr_result['vect_type'] = 'Count'\n",
    "\n",
    "results.append(lr_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9475\n",
      "Test Accuracy: 0.87\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RFC = RandomForestClassifier(n_estimators=100, max_depth=4)\n",
    "\n",
    "RFC.fit(X_train_vectorized, y_train)\n",
    "\n",
    "train_predictions = RFC.predict(X_train_vectorized)\n",
    "test_predictions = RFC.predict(X_test_vectorized)\n",
    "\n",
    "print(f'Train Accuracy: {accuracy_score(y_train, train_predictions)}')\n",
    "print(f'Test Accuracy: {accuracy_score(y_test, test_predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'Logistic Regression',\n",
       "  'acc_train': 1.0,\n",
       "  'acc_test': 0.88,\n",
       "  'vect_type': 'Count'},\n",
       " {'model': 'Random Forest',\n",
       "  'acc_train': 0.995,\n",
       "  'acc_test': 0.84,\n",
       "  'vect_type': 'Count'},\n",
       " {'model': 'Random Forest',\n",
       "  'acc_train': 0.91,\n",
       "  'acc_test': 0.84,\n",
       "  'vect_type': 'Count'},\n",
       " {'model': 'Random Forest',\n",
       "  'acc_train': 0.955,\n",
       "  'acc_test': 0.87,\n",
       "  'vect_type': 'Count'}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_result = {}\n",
    "lr_result['model'] = 'Random Forest'\n",
    "lr_result['acc_train'] = accuracy_score(y_train, train_predictions)\n",
    "lr_result['acc_test'] = accuracy_score(y_test, test_predictions)\n",
    "lr_result['vect_type'] = 'Count'\n",
    "\n",
    "results.append(lr_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 10), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words='english', strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=None, ngram_range=(1,10), stop_words='english')\n",
    "\n",
    "vectorizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf = vectorizer.transform(X_train)\n",
    "test_tf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "lr.fit(train_tf, y_train)\n",
    "\n",
    "train_pred = lr.predict(train_tf)\n",
    "test_pred = lr.predict(test_tf)\n",
    "\n",
    "print(f'Train Accuracy: {accuracy_score(y_train, train_pred)}')\n",
    "print(f'Test Accuracy: {accuracy_score(y_test, test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "result['model'] = 'Logistic'\n",
    "result['acc_train'] = accuracy_score(y_train, train_pred)\n",
    "result['acc_test'] = accuracy_score(y_test, test_pred)\n",
    "result['vect_type'] = 'Tfidf'\n",
    "\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9525\n",
      "Test Accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(max_depth=4, n_estimators=100)\n",
    "\n",
    "rfc.fit(train_tf, y_train)\n",
    "\n",
    "train_pred = rfc.predict(train_tf)\n",
    "test_pred = rfc.predict(test_tf)\n",
    "\n",
    "print(f'Train Accuracy: {accuracy_score(y_train, train_pred)}')\n",
    "print(f'Test Accuracy: {accuracy_score(y_test, test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "result['model'] = 'Random Forest'\n",
    "result['acc_train'] = accuracy_score(y_train, train_predictions)\n",
    "result['acc_test'] = accuracy_score(y_test, test_predictions)\n",
    "result['vect_type'] = 'Tfidf'\n",
    "\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_test</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>model</th>\n",
       "      <th>vect_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.88</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.9950</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>Logistic</td>\n",
       "      <td>Tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.86</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Logistic</td>\n",
       "      <td>Tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Tfidf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc_test  acc_train                model vect_type\n",
       "0      0.88     1.0000  Logistic Regression     Count\n",
       "1      0.84     0.9950        Random Forest     Count\n",
       "2      0.84     0.9100        Random Forest     Count\n",
       "3      0.87     0.9550        Random Forest     Count\n",
       "4      0.84     0.9800             Logistic     Tfidf\n",
       "5      0.87     0.9475        Random Forest     Tfidf\n",
       "6      0.86     1.0000             Logistic     Tfidf\n",
       "7      0.87     0.9475        Random Forest     Tfidf"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vlclSdSSveq-"
   },
   "source": [
    "# Stretch Goals\n",
    "\n",
    "- Try some agglomerative clustering using cosine-similarity-distance! (works better with high dimensional spaces) robust clustering - Agglomerative clustering like Ward would be cool. Try and create an awesome Dendrogram of the most important terms from the dataset.\n",
    "\n",
    "- Awesome resource for clustering stretch goals: \n",
    " - Agglomerative Clustering with Scipy: <https://joernhees.de/blog/2015/08/26/scipy-hierarchical-clustering-and-dendrogram-tutorial/>\n",
    " - Agglomerative Clustering for NLP: <http://brandonrose.org/clustering>\n",
    " \n",
    "- Use Latent Dirichlet Allocation (LDA) to perform topic modeling on the dataset: \n",
    " - Topic Modeling and LDA in Python: <https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24>\n",
    " - Topic Modeling and LDA using Gensim: <https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_423_Document_Classification_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "US4-S1-NLP (Python 3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
