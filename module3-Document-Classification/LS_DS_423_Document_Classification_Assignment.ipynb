{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_423_Document_Classification_Assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cocoisland/DS-Unit-4-Sprint-2-NLP/blob/master/module3-Document-Classification/LS_DS_423_Document_Classification_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "-OJHr-tbuSuI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Now it's your turn!\n",
        "\n",
        "Use the following dataset of scraped \"Data Scientist\" and \"Data Analyst\" job listings to create your own Document Classification Models.\n",
        "\n",
        "<https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-2-NLP/master/module3-Document-Classification/job_listings.csv>\n",
        "\n",
        "Requirements:\n",
        "\n",
        "- Apply both CountVectorizer and TfidfVectorizer methods to this data and compare results\n",
        "- Use at least two different classification models to compare differences in model accuracy\n",
        "- Try to \"Hyperparameter Tune\" your model by using different n_gram ranges, max_results, and data cleaning methods\n",
        "- Try and get the highest accuracy possible!"
      ]
    },
    {
      "metadata": {
        "id": "MFreAPN3uGgz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "07f982f6-9147-4b36-9cbf-d29ced644008"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-2-NLP/master/module3-Document-Classification/job_listings.csv\"\n",
        "\n",
        "df = pd.read_csv(url, encoding=\"ISO-8859-1\")\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(500, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>description</th>\n",
              "      <th>title</th>\n",
              "      <th>job</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n",
              "      <td>Data scientistÂ</td>\n",
              "      <td>Data Scientist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n",
              "      <td>Data Scientist I</td>\n",
              "      <td>Data Scientist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n",
              "      <td>Data Scientist - Entry Level</td>\n",
              "      <td>Data Scientist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Data Scientist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Data Scientist</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         description  \\\n",
              "0  b\"<div><div>Job Requirements:</div><ul><li><p>...   \n",
              "1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...   \n",
              "2  b'<div><p>As a Data Scientist you will be work...   \n",
              "3  b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n",
              "4  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...   \n",
              "\n",
              "                          title             job  \n",
              "0              Data scientistÂ   Data Scientist  \n",
              "1              Data Scientist I  Data Scientist  \n",
              "2  Data Scientist - Entry Level  Data Scientist  \n",
              "3                Data Scientist  Data Scientist  \n",
              "4                Data Scientist  Data Scientist  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "9hqZl1Jsj3A0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "caa58d18-c12a-4d08-f270-a046174ba7cc"
      },
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', 200)\n",
        "df = df.drop(['title','job'], axis=1)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;\\nConceptual understanding in Machine Learning models like Nai\\xc2\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random For...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Data Scientist 1, you will help us build machine learning models, data pipelines, and micro-services to help our clients navigate their healthcare journ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be working on consulting side of our business. You will be responsible for analyzing large, complex datasets and identify meaningful patterns that lead to ac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-u-xs-mb--md\"&gt;&lt;div class=\"jobsearch-JobMetadataHeader-item \"&gt;&lt;span class=\"icl-u-xs-mr--xs\"&gt;$4,969 - $6,756 a month&lt;/span&gt;&lt;/div&gt;&lt;div class=\"jobsearch-Jo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple locations&lt;/li&gt;\\n&lt;li&gt;2+ years of Analytics experience&lt;/li&gt;\\n&lt;li&gt;Understand business requirements and technical requirements&lt;/li&gt;\\n&lt;li&gt;Can handle data e...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                               description\n",
              "0  b\"<div><div>Job Requirements:</div><ul><li><p>\\nConceptual understanding in Machine Learning models like Nai\\xc2\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random For...\n",
              "1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Data Scientist 1, you will help us build machine learning models, data pipelines, and micro-services to help our clients navigate their healthcare journ...\n",
              "2  b'<div><p>As a Data Scientist you will be working on consulting side of our business. You will be responsible for analyzing large, complex datasets and identify meaningful patterns that lead to ac...\n",
              "3  b'<div class=\"jobsearch-JobMetadataHeader icl-u-xs-mb--md\"><div class=\"jobsearch-JobMetadataHeader-item \"><span class=\"icl-u-xs-mr--xs\">$4,969 - $6,756 a month</span></div><div class=\"jobsearch-Jo...\n",
              "4  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple locations</li>\\n<li>2+ years of Analytics experience</li>\\n<li>Understand business requirements and technical requirements</li>\\n<li>Can handle data e..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "eA51G4EQkYkO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U nltk\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5_AxR35Qk53-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.description.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iRSVAsGBki9e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import string, re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize # Sentence Tokenizer\n",
        "from nltk.tokenize import word_tokenize # Word Tokenizer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "# Remove extra quatation marks and a leading b from each string\n",
        "job_listings = [str(x)[2:-1] for x in df.description.tolist()]\n",
        "\n",
        "#table = str.maketrans(string.punctuation,' '*32)\n",
        "table = str.maketrans('', '', string.punctuation)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "cleaned_listings = []\n",
        "\n",
        "for listing in job_listings:\n",
        "    # Remove HTML tags and paragraph breaks (\\\\n)\n",
        "    listing = re.sub(pattern=r'\\\\n|<[\\w/]+>', repl='', string=listing)\n",
        "   \n",
        "    #print(listing)\n",
        "\n",
        "    # Strip punctuation everywhere,\n",
        "    # replacing it with spaces so that words separated only\n",
        "    # by punctuation don't get smooshed together\n",
        "    no_punctuation = listing.translate(table)\n",
        "#     print(\"No Punctuation:\", no_punctuation)\n",
        "#     print('------------------------------------------')\n",
        "    \n",
        "    # Tokenize by word\n",
        "    tokens = word_tokenize(no_punctuation)\n",
        "#     print(\"Tokens:\", tokens)\n",
        "#     print('------------------------------------------')\n",
        "\n",
        "    \n",
        "    # Make all words lowercase\n",
        "    lowercase_tokens = [w.lower() for w in tokens]\n",
        "#     print(\"Lowercase:\", lowercase_tokens)\n",
        "#     print('------------------------------------------')\n",
        "    \n",
        "      # Remove words that aren't alphabetic\n",
        "    alphabetic = [w for w in lowercase_tokens if w.isalpha()]\n",
        "#     print(\"Alphabetic:\", alphabetic)\n",
        "#     print('------------------------------------------')\n",
        "    \n",
        "    # Remove stopwords\n",
        "    words = [w for w in alphabetic if not w in stop_words]\n",
        "#     print(\"Cleaned Words:\", words)\n",
        "#     print(\"--------------------------------\")\n",
        "    \n",
        "    # lemmatize!\n",
        "    lemmas = [lemmatizer.lemmatize(w) for w in words]\n",
        "    # Append to list\n",
        "    cleaned_listings.append(words)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vWCfa7eGllgC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "153033fa-ce2f-47ba-f5d1-918449fdcee0"
      },
      "cell_type": "code",
      "source": [
        "len(cleaned_listings)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "kxfn50KOoAVp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=None, ngram_range=(1,1), stop_words='english')\n",
        "\n",
        "vectorizer.fit(X_train)\n",
        "\n",
        "print(vectorizer.vocabulary_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vlclSdSSveq-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Stretch Goals\n",
        "\n",
        "- Try some agglomerative clustering using cosine-similarity-distance! (works better with high dimensional spaces) robust clustering - Agglomerative clustering like Ward would be cool. Try and create an awesome Dendrogram of the most important terms from the dataset.\n",
        "\n",
        "- Awesome resource for clustering stretch goals: \n",
        " - Agglomerative Clustering with Scipy: <https://joernhees.de/blog/2015/08/26/scipy-hierarchical-clustering-and-dendrogram-tutorial/>\n",
        " - Agglomerative Clustering for NLP: <http://brandonrose.org/clustering>\n",
        " \n",
        "- Use Latent Dirichlet Allocation (LDA) to perform topic modeling on the dataset: \n",
        " - Topic Modeling and LDA in Python: <https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24>\n",
        " - Topic Modeling and LDA using Gensim: <https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/>\n"
      ]
    }
  ]
}