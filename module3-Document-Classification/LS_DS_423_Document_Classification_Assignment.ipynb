{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_423_Document_Classification_Assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cocoisland/DS-Unit-4-Sprint-2-NLP/blob/master/module3-Document-Classification/LS_DS_423_Document_Classification_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "-OJHr-tbuSuI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Now it's your turn!\n",
        "\n",
        "Use the following dataset of scraped \"Data Scientist\" and \"Data Analyst\" job listings to create your own Document Classification Models.\n",
        "\n",
        "<https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-2-NLP/master/module3-Document-Classification/job_listings.csv>\n",
        "\n",
        "Requirements:\n",
        "\n",
        "- Apply both CountVectorizer and TfidfVectorizer methods to this data and compare results\n",
        "- Use at least two different classification models to compare differences in model accuracy\n",
        "- Try to \"Hyperparameter Tune\" your model by using different n_gram ranges, max_results, and data cleaning methods\n",
        "- Try and get the highest accuracy possible!"
      ]
    },
    {
      "metadata": {
        "id": "MFreAPN3uGgz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "e01cd32e-bf61-4e94-b6e2-5c72f62dc3fb"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-2-NLP/master/module3-Document-Classification/job_listings.csv\"\n",
        "\n",
        "df = pd.read_csv(url, encoding=\"ISO-8859-1\")\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(500, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>description</th>\n",
              "      <th>title</th>\n",
              "      <th>job</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n",
              "      <td>Data scientistÂ</td>\n",
              "      <td>Data Scientist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n",
              "      <td>Data Scientist I</td>\n",
              "      <td>Data Scientist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n",
              "      <td>Data Scientist - Entry Level</td>\n",
              "      <td>Data Scientist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Data Scientist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Data Scientist</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         description  \\\n",
              "0  b\"<div><div>Job Requirements:</div><ul><li><p>...   \n",
              "1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...   \n",
              "2  b'<div><p>As a Data Scientist you will be work...   \n",
              "3  b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n",
              "4  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...   \n",
              "\n",
              "                          title             job  \n",
              "0              Data scientistÂ   Data Scientist  \n",
              "1              Data Scientist I  Data Scientist  \n",
              "2  Data Scientist - Entry Level  Data Scientist  \n",
              "3                Data Scientist  Data Scientist  \n",
              "4                Data Scientist  Data Scientist  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "1RQGKFfxzlB6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2680b37c-8c1f-4772-e60a-c5c8498a9c52"
      },
      "cell_type": "code",
      "source": [
        "df.job.value_counts()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data Scientist    250\n",
              "Data Analyst      250\n",
              "Name: job, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "9hqZl1Jsj3A0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', 200)\n",
        "##df = df.drop(['title','job'], axis=1)\n",
        "\n",
        "#df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5_AxR35Qk53-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "2d0dd233-f680-4910-db25-d843076092d5"
      },
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "def clean_html_with_bs4(string):\n",
        "    soup = BeautifulSoup(string)\n",
        "    string = soup.get_text()\n",
        "    return string\n",
        "\n",
        "listings = []\n",
        "for x in df['description']:\n",
        "    # Remove extra quotation marks\n",
        "    x = str(x)[2:-1]\n",
        "    # Clean out HTML\n",
        "    x = clean_html_with_bs4(x)\n",
        "    # Remove line breaks\n",
        "    x = x.replace('\\\\n',' ')\n",
        "    # Translate unicode characters to ASCII\n",
        "#     x = unidecode(x)\n",
        "    listings.append(x)\n",
        "    \n",
        "df['description'] = listings\n",
        "\n",
        "# Create a numerical label column\n",
        "df['label_num'] = df.job.map({'Data Analyst': 0, 'Data Scientist': 1})\n",
        "df.head()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>description</th>\n",
              "      <th>title</th>\n",
              "      <th>job</th>\n",
              "      <th>label_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Job Requirements: Conceptual understanding in Machine Learning models like Nai\\xc2\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN alo...</td>\n",
              "      <td>Data scientistÂ</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Job Description  As a Data Scientist 1, you will help us build machine learning models, data pipelines, and micro-services to help our clients navigate their healthcare journey. You will do so by ...</td>\n",
              "      <td>Data Scientist I</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>As a Data Scientist you will be working on consulting side of our business. You will be responsible for analyzing large, complex datasets and identify meaningful patterns that lead to actionable r...</td>\n",
              "      <td>Data Scientist - Entry Level</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>$4,969 - $6,756 a monthContractUnder the general supervision of Professors Dana Mukamel and Kai Zheng, the incumbent will join the CalMHSA Mental Health Tech Suite Innovation (INN) Evaluation Team...</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Location: USA \\xe2\\x80\\x93 multiple locations 2+ years of Analytics experience Understand business requirements and technical requirements Can handle data extraction, preparation and transformatio...</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                               description  \\\n",
              "0  Job Requirements: Conceptual understanding in Machine Learning models like Nai\\xc2\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN alo...   \n",
              "1  Job Description  As a Data Scientist 1, you will help us build machine learning models, data pipelines, and micro-services to help our clients navigate their healthcare journey. You will do so by ...   \n",
              "2  As a Data Scientist you will be working on consulting side of our business. You will be responsible for analyzing large, complex datasets and identify meaningful patterns that lead to actionable r...   \n",
              "3  $4,969 - $6,756 a monthContractUnder the general supervision of Professors Dana Mukamel and Kai Zheng, the incumbent will join the CalMHSA Mental Health Tech Suite Innovation (INN) Evaluation Team...   \n",
              "4  Location: USA \\xe2\\x80\\x93 multiple locations 2+ years of Analytics experience Understand business requirements and technical requirements Can handle data extraction, preparation and transformatio...   \n",
              "\n",
              "                          title             job  label_num  \n",
              "0              Data scientistÂ   Data Scientist          1  \n",
              "1              Data Scientist I  Data Scientist          1  \n",
              "2  Data Scientist - Entry Level  Data Scientist          1  \n",
              "3                Data Scientist  Data Scientist          1  \n",
              "4                Data Scientist  Data Scientist          1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "7qWLIRHm35Qd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "670881c0-3eaf-4814-ee6b-f435f28789d5"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(max_features=None, \n",
        "                             ngram_range=(1,1), \n",
        "                             stop_words='english')\n",
        "\n",
        "word_counts = vectorizer.fit_transform(df.description)\n",
        "\n",
        "vect_count = pd.DataFrame(\n",
        "            word_counts.toarray(), \n",
        "                columns=vectorizer.get_feature_names())\n",
        "\n",
        "print(word_counts.shape)\n",
        "vect_count.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(500, 9514)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>00011236</th>\n",
              "      <th>00079</th>\n",
              "      <th>00805</th>\n",
              "      <th>00am</th>\n",
              "      <th>00pm</th>\n",
              "      <th>01</th>\n",
              "      <th>02115</th>\n",
              "      <th>03</th>\n",
              "      <th>...</th>\n",
              "      <th>zetahub</th>\n",
              "      <th>zeus</th>\n",
              "      <th>zheng</th>\n",
              "      <th>zillow</th>\n",
              "      <th>zogsports</th>\n",
              "      <th>zoho</th>\n",
              "      <th>zone</th>\n",
              "      <th>zones</th>\n",
              "      <th>zoom</th>\n",
              "      <th>zywave</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 9514 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   00  000  00011236  00079  00805  00am  00pm  01  02115  03   ...    \\\n",
              "0   0    0         0      0      0     0     0   0      0   0   ...     \n",
              "1   0    0         0      0      0     0     0   0      0   0   ...     \n",
              "2   0    0         0      0      0     0     0   0      0   0   ...     \n",
              "3   0    0         0      0      0     0     0   0      0   0   ...     \n",
              "4   0    0         0      0      0     0     0   0      0   0   ...     \n",
              "\n",
              "   zetahub  zeus  zheng  zillow  zogsports  zoho  zone  zones  zoom  zywave  \n",
              "0        0     0      0       0          0     0     0      0     0       0  \n",
              "1        0     0      0       0          0     0     0      0     0       0  \n",
              "2        0     0      0       0          0     0     0      0     0       0  \n",
              "3        0     0      1       0          0     0     0      0     0       0  \n",
              "4        0     0      0       0          0     0     0      0     0       0  \n",
              "\n",
              "[5 rows x 9514 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "wn50193A3_vp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "c04a5d78-e99c-44c8-9c1c-cf670efae0ec"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=None, \n",
        "                             ngram_range=(1,1), \n",
        "                             stop_words='english')\n",
        "\n",
        "word_counts = vectorizer.fit_transform(df.description)\n",
        "\n",
        "vect_tfidf = pd.DataFrame(\n",
        "            word_counts.toarray(), \n",
        "                columns=vectorizer.get_feature_names())\n",
        "\n",
        "print(word_counts.shape)\n",
        "vect_tfidf.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(500, 9514)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>00011236</th>\n",
              "      <th>00079</th>\n",
              "      <th>00805</th>\n",
              "      <th>00am</th>\n",
              "      <th>00pm</th>\n",
              "      <th>01</th>\n",
              "      <th>02115</th>\n",
              "      <th>03</th>\n",
              "      <th>...</th>\n",
              "      <th>zetahub</th>\n",
              "      <th>zeus</th>\n",
              "      <th>zheng</th>\n",
              "      <th>zillow</th>\n",
              "      <th>zogsports</th>\n",
              "      <th>zoho</th>\n",
              "      <th>zone</th>\n",
              "      <th>zones</th>\n",
              "      <th>zoom</th>\n",
              "      <th>zywave</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.109323</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 9514 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    00  000  00011236  00079  00805  00am  00pm   01  02115   03   ...    \\\n",
              "0  0.0  0.0       0.0    0.0    0.0   0.0   0.0  0.0    0.0  0.0   ...     \n",
              "1  0.0  0.0       0.0    0.0    0.0   0.0   0.0  0.0    0.0  0.0   ...     \n",
              "2  0.0  0.0       0.0    0.0    0.0   0.0   0.0  0.0    0.0  0.0   ...     \n",
              "3  0.0  0.0       0.0    0.0    0.0   0.0   0.0  0.0    0.0  0.0   ...     \n",
              "4  0.0  0.0       0.0    0.0    0.0   0.0   0.0  0.0    0.0  0.0   ...     \n",
              "\n",
              "   zetahub  zeus     zheng  zillow  zogsports  zoho  zone  zones  zoom  zywave  \n",
              "0      0.0   0.0  0.000000     0.0        0.0   0.0   0.0    0.0   0.0     0.0  \n",
              "1      0.0   0.0  0.000000     0.0        0.0   0.0   0.0    0.0   0.0     0.0  \n",
              "2      0.0   0.0  0.000000     0.0        0.0   0.0   0.0    0.0   0.0     0.0  \n",
              "3      0.0   0.0  0.109323     0.0        0.0   0.0   0.0    0.0   0.0     0.0  \n",
              "4      0.0   0.0  0.000000     0.0        0.0   0.0   0.0    0.0   0.0     0.0  \n",
              "\n",
              "[5 rows x 9514 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "l2UzduKN4zqP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3_kIyjwY42-e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vectorizers = [\n",
        "    TfidfVectorizer(stop_words='english',\n",
        "                    max_features=None),\n",
        "    CountVectorizer(stop_words='english',\n",
        "                   max_features=None)\n",
        "]\n",
        "\n",
        "classifiers = [\n",
        "    MultinomialNB(),\n",
        "    LinearSVC(),\n",
        "    LogisticRegression(),\n",
        "    RandomForestClassifier()\n",
        "]\n",
        "\n",
        "clf_names = [\n",
        "         \"Naive Bayes\",\n",
        "         \"Linear SVM\",\n",
        "         \"Logistic Regression\",\n",
        "         \"Random Forest\"\n",
        "        ]\n",
        "\n",
        "vect_names = [\n",
        "    \"TfidfVectorizer\",\n",
        "    \"CountVectorizer\"\n",
        "]\n",
        "clf_params = [\n",
        "              {'vect__ngram_range': [(1, 1), (1, 2)],\n",
        "              'clf__alpha': (1e-2, 1e-3)},\n",
        "              {'vect__ngram_range': [(1, 1), (1, 2)],\n",
        "              'clf__C': (np.logspace(-5, 1, 5))},\n",
        "              {'vect__ngram_range': [(1, 1), (1, 2)],\n",
        "              'clf__C': (np.logspace(-5, 1, 5))},\n",
        "              {'vect__ngram_range': [(1, 1), (1, 2)],\n",
        "              'clf__max_depth': (1, 2)},\n",
        "             ]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_F-1cQ8h5kju",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2506
        },
        "outputId": "8da043ba-84d5-406b-ab51-9a9415e6ddad"
      },
      "cell_type": "code",
      "source": [
        "for classifier, clf_name, params in zip(classifiers, \n",
        "                                        clf_names, \n",
        "                                        clf_params):\n",
        "    for vectorizer, vect_name in zip(vectorizers, \n",
        "                                     vect_names):\n",
        "        pipe = Pipeline([\n",
        "            ('vect', vectorizer),\n",
        "            ('clf', classifier),\n",
        "        ])\n",
        "        gs = GridSearchCV(pipe, \n",
        "                          param_grid=params, \n",
        "                          n_jobs=-1,\n",
        "                          scoring='roc_auc',\n",
        "                          cv=5,\n",
        "                          verbose=10)\n",
        "        \n",
        "        gs.fit(df.description, df.label_num)\n",
        "        score = gs.best_score_\n",
        "        print(f'''\n",
        "Classifier: {clf_name}\n",
        "Vectorizer: {vect_name}\n",
        "Score: {gs.best_score_:.4f}\n",
        "Params: {gs.best_params_}\n",
        "------------------------------\n",
        "            ''')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    3.3s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    6.4s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    8.0s\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   11.8s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   11.8s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Classifier: Naive Bayes\n",
            "Vectorizer: TfidfVectorizer\n",
            "Score: 0.9155\n",
            "Params: {'clf__alpha': 0.01, 'vect__ngram_range': (1, 2)}\n",
            "------------------------------\n",
            "            \n",
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    1.1s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    4.2s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    5.7s\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    9.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    9.3s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Classifier: Naive Bayes\n",
            "Vectorizer: CountVectorizer\n",
            "Score: 0.8989\n",
            "Params: {'clf__alpha': 0.01, 'vect__ngram_range': (1, 1)}\n",
            "------------------------------\n",
            "            \n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.6s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    1.1s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    4.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    5.9s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    9.8s\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   13.3s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   17.0s\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   22.4s\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   26.6s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Classifier: Linear SVM\n",
            "Vectorizer: TfidfVectorizer\n",
            "Score: 0.9602\n",
            "Params: {'clf__C': 0.31622776601683794, 'vect__ngram_range': (1, 2)}\n",
            "------------------------------\n",
            "            \n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    1.1s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    4.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    6.0s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   10.2s\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   14.5s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   20.2s\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   27.0s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   30.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Classifier: Linear SVM\n",
            "Vectorizer: CountVectorizer\n",
            "Score: 0.9761\n",
            "Params: {'clf__C': 0.01, 'vect__ngram_range': (1, 2)}\n",
            "------------------------------\n",
            "            \n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    1.1s\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    5.9s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    7.1s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   11.3s\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   14.8s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   18.8s\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   23.6s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   26.4s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Classifier: Logistic Regression\n",
            "Vectorizer: TfidfVectorizer\n",
            "Score: 0.9603\n",
            "Params: {'clf__C': 10.0, 'vect__ngram_range': (1, 2)}\n",
            "------------------------------\n",
            "            \n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.6s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    1.2s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    4.6s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    6.2s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   10.5s\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   14.1s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   18.4s\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   23.7s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   26.8s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Classifier: Logistic Regression\n",
            "Vectorizer: CountVectorizer\n",
            "Score: 0.9748\n",
            "Params: {'clf__C': 0.31622776601683794, 'vect__ngram_range': (1, 2)}\n",
            "------------------------------\n",
            "            \n",
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.6s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    1.2s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    4.7s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    6.4s\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   10.5s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   10.5s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Classifier: Random Forest\n",
            "Vectorizer: TfidfVectorizer\n",
            "Score: 0.8444\n",
            "Params: {'clf__max_depth': 2, 'vect__ngram_range': (1, 1)}\n",
            "------------------------------\n",
            "            \n",
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.6s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    1.1s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    4.4s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    6.1s\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   10.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   10.1s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Classifier: Random Forest\n",
            "Vectorizer: CountVectorizer\n",
            "Score: 0.8536\n",
            "Params: {'clf__max_depth': 2, 'vect__ngram_range': (1, 1)}\n",
            "------------------------------\n",
            "            \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vlclSdSSveq-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Stretch Goals\n",
        "\n",
        "- Try some agglomerative clustering using cosine-similarity-distance! (works better with high dimensional spaces) robust clustering - Agglomerative clustering like Ward would be cool. Try and create an awesome Dendrogram of the most important terms from the dataset.\n",
        "\n",
        "- Awesome resource for clustering stretch goals: \n",
        " - Agglomerative Clustering with Scipy: <https://joernhees.de/blog/2015/08/26/scipy-hierarchical-clustering-and-dendrogram-tutorial/>\n",
        " - Agglomerative Clustering for NLP: <http://brandonrose.org/clustering>\n",
        " \n",
        "- Use Latent Dirichlet Allocation (LDA) to perform topic modeling on the dataset: \n",
        " - Topic Modeling and LDA in Python: <https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24>\n",
        " - Topic Modeling and LDA using Gensim: <https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/>\n"
      ]
    }
  ]
}