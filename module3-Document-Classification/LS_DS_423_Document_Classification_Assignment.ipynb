{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-OJHr-tbuSuI"
   },
   "source": [
    "# Now it's your turn!\n",
    "\n",
    "Use the following dataset of scraped \"Data Scientist\" and \"Data Analyst\" job listings to create your own Document Classification Models.\n",
    "\n",
    "<https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-2-NLP/master/module3-Document-Classification/job_listings.csv>\n",
    "\n",
    "Requirements:\n",
    "\n",
    "- Apply both CountVectorizer and TfidfVectorizer methods to this data and compare results\n",
    "- Use at least two different classification models to compare differences in model accuracy\n",
    "- Try to \"Hyperparameter Tune\" your model by using different n_gram ranges, max_results, and data cleaning methods\n",
    "- Try and get the highest accuracy possible!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MFreAPN3uGgz"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "df = pd.read_csv(\"job_listings.csv\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>job</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0  b\"<div><div>Job Requirements:</div><ul><li><p>...   \n",
       "1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...   \n",
       "2  b'<div><p>As a Data Scientist you will be work...   \n",
       "3  b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n",
       "4  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...   \n",
       "\n",
       "                          title             job  \n",
       "0               Data scientist   Data Scientist  \n",
       "1              Data Scientist I  Data Scientist  \n",
       "2  Data Scientist - Entry Level  Data Scientist  \n",
       "3                Data Scientist  Data Scientist  \n",
       "4                Data Scientist  Data Scientist  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "def clean_words(l):\n",
    "    \n",
    "    l2 = re.sub(r'<.*?>',\" \", l)\n",
    "    l2 = l2.lower()\n",
    "    l2 = re.sub(r'\\\\xc2\\\\xa8',r'',l2)\n",
    "    l2 = re.sub(r'\\\\n',r'',l2)\n",
    "    l2 = re.sub(r'/',' ', l2)\n",
    "    l2 = re.sub(r'^b\\'','',l2)\n",
    "    l2 = re.sub(r'^b\\\"','',l2)\n",
    "    l2 = re.sub(r\"\\\\'\", ' ', l2)\n",
    "    \n",
    "    return l2\n",
    "df[\"clean_words\"] = df[\"description\"].apply(lambda x: clean_words(str(x)))\n",
    "\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from nltk.corpus import stopwords\n",
    "# stop_words = stopwords.words('english')\n",
    "\n",
    "# df[\"nltk_token\"] = df[\"clean_words\"].apply(lambda x : word_tokenize(x))\n",
    "# df[\"nltk_token\"] = df[\"nltk_token\"].apply(lambda x: [word for word in x if word.isalpha()])\n",
    "# df[\"nltk_token\"] = df[\"nltk_token\"].apply(lambda x : [word for word in x if not word in stop_words])\n",
    "# nltk.download('wordnet')\n",
    "# from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# def get_lemmas(word_list):\n",
    "#     lemmas = [lemmatizer.lemmatize(word) for word in word_list]\n",
    "    \n",
    "#     return lemmas\n",
    "# df[\"word_lemmas\"] = df[\"nltk_token\"].apply(lambda x : get_lemmas(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>job</th>\n",
       "      <th>clean_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>job requirements:    conceptual understandin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>job description   as a data scientist 1, you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>as a data scientist you will be working on c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>$4,969 - $6,756 a month   contract   under ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>location: usa \\xe2\\x80\\x93 multiple location...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0  b\"<div><div>Job Requirements:</div><ul><li><p>...   \n",
       "1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...   \n",
       "2  b'<div><p>As a Data Scientist you will be work...   \n",
       "3  b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n",
       "4  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...   \n",
       "\n",
       "                          title             job  \\\n",
       "0               Data scientist   Data Scientist   \n",
       "1              Data Scientist I  Data Scientist   \n",
       "2  Data Scientist - Entry Level  Data Scientist   \n",
       "3                Data Scientist  Data Scientist   \n",
       "4                Data Scientist  Data Scientist   \n",
       "\n",
       "                                         clean_words  \n",
       "0    job requirements:    conceptual understandin...  \n",
       "1   job description   as a data scientist 1, you ...  \n",
       "2    as a data scientist you will be working on c...  \n",
       "3     $4,969 - $6,756 a month   contract   under ...  \n",
       "4    location: usa \\xe2\\x80\\x93 multiple location...  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data Analyst      250\n",
       "Data Scientist    250\n",
       "Name: job, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"job\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"job\"]=df[\"job\"].replace(\"Data Analyst\", 0)\n",
    "df[\"job\"]=df[\"job\"].replace(\"Data Scientist\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    250\n",
       "0    250\n",
       "Name: job, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"job\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[\"clean_words\"]\n",
    "y = df[\"job\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' job description   as a data scientist 1, you will help us build machine learning models, data pipelines, and micro-services to help our clients navigate their healthcare journey. you will do so by empowering and improving the next generation of accolade applications and user experiences.   a day in the life\\\\xe2\\\\x80\\\\xa6    work with a small agile team to design and develop mobile applications in an iterative fashion.  work with a tight-knit group of development team members in seattle.  contribute to best practices and help guide the future of our applications.  operates effectively as a collaborative member of the development team.  operates effectively as an individual for quick turnaround of enhancements and fixes.  responsible for meeting expectations and deliverables on time with high quality.  drive and implement new features within our mobile applications.  perform thorough manual testing and writing test cases that cover all areas.  identify new development tools approaches that will increase code quality, efficiency, and best practices.  develop and champion the the development processes, coding style guidelines, and architectural designs necessary to innovate and maintain great product quality.  effectively turns design documents and graphics into performant, usable ui.  demonstrates creative, technical, and analytical skills.  demonstrates ability to communicate effectively in both technical and business environments     qualifications    what we are looking for\\\\xe2\\\\x80\\\\xa6    master\\\\xe2\\\\x80\\\\x99s degree in computer science, math, or related field.  computer science fundamentals, as illustrated through algorithm design, problem solving, and complexity analysis.  must have 1+ year real-world experience developing and deploying micro-services or data pipelines  must have a fundamental understanding of key machine learning concepts, such as accuracy measures, cross-validation, and open source machine learning libraries  fluent in python and sql  proficient with writing unit functional tests and familiar with automation frameworks  experience with cloud infrastructure, such as aws or azure, is a plus.  experience with distributed data pipelines, such as a spark, is a plus.  strong written and oral communication skills.  desire and willingness to work in an agile, collaborative, innovative, flexible, and team-oriented environment  hands-on, detail-oriented, methodical &amp; inquisitive  a motivated self-starter with a solid level of experience that quickly grasps complex challenges  a skillful communicator with experience working with technical management teams   a service oriented person who thinks \"customer first\"  fast fail entrepreneurial spirit  thrives in a fast-paced environment where continuous improvement is the norm and the bar for quality is extremely high  excited by the challenges of working in a product team undergoing rapid, international growth   additional information    what is important to us   creating an enduring company that is hyper-focused on our culture and making a meaningful impact in the lives of our employees, members and customers. the secret to our success is:   we find joy and purpose in serving others   making a difference in our members\\\\xe2\\\\x80\\\\x99 and customers\\\\xe2\\\\x80\\\\x99 lives is what we do. even when it\\\\xe2\\\\x80\\\\x99s hard, we do the right thing for the right reasons.   we are strong individually and together, we\\\\xe2\\\\x80\\\\x99re powerful   trusting in our colleagues and embracing their different backgrounds and experiences enable us to solve tough problems in creative ways, having fun along the way.   we roll up our sleeves and get stuff done   results motivate us. and we aren t afraid of the hard work or tough decisions needed to get us there.   we\\\\xe2\\\\x80\\\\x99re boldly and relentlessly reinventing healthcare   we re curious and act big - not afraid to knock down barriers or take calculated risks to change the world, one person at a time.  all your information will be kept confidential according to eeo guidelines.  \\''"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=None, ngram_range=(1,1), stop_words='english')\n",
    "\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "train_word_counts = vectorizer.transform(X_train)\n",
    "\n",
    "X_train_vectorized = pd.DataFrame(train_word_counts.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "\n",
    "test_word_counts = vectorizer.transform(X_test)\n",
    "\n",
    "X_test_vectorized = pd.DataFrame(test_word_counts.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -i https://test.pypi.org/simple/lambdata-crawftv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9925\n",
      "Test Accuracy: 0.92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92        54\n",
      "           1       0.90      0.93      0.91        46\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       100\n",
      "   macro avg       0.92      0.92      0.92       100\n",
      "weighted avg       0.92      0.92      0.92       100\n",
      "\n",
      "AxesSubplot(0.241667,0.125;0.503333x0.755)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cwcol\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR = LogisticRegression(random_state=42).fit(X_train_vectorized, y_train)\n",
    "\n",
    "train_predictions = LR.predict(X_train_vectorized)\n",
    "test_predictions = LR.predict(X_test_vectorized)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(f'Train Accuracy: {accuracy_score(y_train, train_predictions)}')\n",
    "print(f'Test Accuracy: {accuracy_score(y_test, test_predictions)}')\n",
    "\n",
    "from lambdata_crawftv.ClassificationVisualization import classification_visualization\n",
    "classification_visualization(y_test,test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vlclSdSSveq-"
   },
   "source": [
    "# Stretch Goals\n",
    "\n",
    "- Try some agglomerative clustering using cosine-similarity-distance! (works better with high dimensional spaces) robust clustering - Agglomerative clustering like Ward would be cool. Try and create an awesome Dendrogram of the most important terms from the dataset.\n",
    "\n",
    "- Awesome resource for clustering stretch goals: \n",
    " - Agglomerative Clustering with Scipy: <https://joernhees.de/blog/2015/08/26/scipy-hierarchical-clustering-and-dendrogram-tutorial/>\n",
    " - Agglomerative Clustering for NLP: <http://brandonrose.org/clustering>\n",
    " \n",
    "- Use Latent Dirichlet Allocation (LDA) to perform topic modeling on the dataset: \n",
    " - Topic Modeling and LDA in Python: <https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24>\n",
    " - Topic Modeling and LDA using Gensim: <https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_423_Document_Classification_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
