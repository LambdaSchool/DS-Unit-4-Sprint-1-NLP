{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of LS_DS_422_BOW_Assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python",
      "version": "3.7.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danhorsley/DS-Unit-4-Sprint-1-NLP/blob/master/Copy_of_LS_DS_422_BOW_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euGcbkghJaPh",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 2*\n",
        "\n",
        "# Document Representations: Bag-Of-Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hyj-f9FDcVFp",
        "outputId": "c2b17b24-b163-4855-f808-708ceaea61d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "!pip install -U nltk\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import sent_tokenize # Sentence Tokenizer\n",
        "from nltk.tokenize import word_tokenize # Word Tokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nltk\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/16/4d247e27c55a7b6412e7c4c86f2500ae61afcbf5932b9e3491f8462f8d9e/nltk-3.4.4.zip (1.5MB)\n",
            "\r\u001b[K     |▎                               | 10kB 13.4MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 3.3MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 4.7MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 3.8MB/s eta 0:00:01\r\u001b[K     |█▍                              | 61kB 4.5MB/s eta 0:00:01\r\u001b[K     |█▋                              | 71kB 5.1MB/s eta 0:00:01\r\u001b[K     |█▉                              | 81kB 5.8MB/s eta 0:00:01\r\u001b[K     |██                              | 92kB 6.4MB/s eta 0:00:01\r\u001b[K     |██▎                             | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |██▌                             | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |██▊                             | 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |███                             | 133kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▏                            | 143kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▍                            | 153kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 163kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▉                            | 174kB 4.9MB/s eta 0:00:01\r\u001b[K     |████                            | 184kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▎                           | 194kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▌                           | 204kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▊                           | 215kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 225kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 235kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 245kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 256kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 266kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 276kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 286kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 296kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 307kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 317kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 327kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 337kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 348kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 358kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 368kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 378kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 389kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 399kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 409kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 419kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 430kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 440kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 450kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 460kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 471kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 481kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 491kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 501kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 512kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 522kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 532kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 542kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 552kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 563kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 573kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 583kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 593kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 604kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 614kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 624kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 634kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 645kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 655kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 665kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 675kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 686kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 696kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 706kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 716kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 727kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 737kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 747kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 757kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 768kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 778kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 788kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 798kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 808kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 819kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 829kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 839kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 849kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 860kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 870kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 880kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 890kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 901kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 911kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 921kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 931kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 942kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 952kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 962kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 972kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 983kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 993kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5MB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/c8/31/48ace4468e236e0e8435f30d33e43df48594e4d53e367cf061\n",
            "Successfully built nltk\n",
            "Installing collected packages: nltk\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nltk-3.4.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M7bcmqfGXrFG"
      },
      "source": [
        "# 1) (optional) Scrape 100 Job Listings that contain the title \"Data Scientist\" from indeed.com\n",
        "\n",
        "At a minimum your final dataframe of job listings should contain\n",
        "- Job Title\n",
        "- Job Description\n",
        "\n",
        "If you choose to not to scrape the data, there is a CSV with outdated data in the directory. Remeber, if you scrape Indeed, you're helping yourself find a job. ;)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KcYlc1URXhlC",
        "colab": {}
      },
      "source": [
        "##### Your Code Here #####\n",
        "raise Exception(\"\\nThis task is not complete. \\nReplace this line with your code for the task.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5C4xFZNtX1m2"
      },
      "source": [
        "## 2) Use Spacy to tokenize / clean the listings "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndLm9Ok9J5Rz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-1-NLP/master/module2-vector-representations/job_listings.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dhUHuMr-X-II",
        "colab": {}
      },
      "source": [
        "##### Your Code Here #####\n",
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = Tokenizer(nlp.vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhhsPIMEKLhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens = []\n",
        "\n",
        "for doc in tokenizer.pipe(df['description'], batch_size=500):\n",
        "    \n",
        "    doc_tokens = []\n",
        "    \n",
        "    for token in doc: \n",
        "      if (token.is_stop == False) and (token.is_punct==False) and (token.is_space==False) and \"<\" not in token.text\\\n",
        "      and \"\\\\\" not in token.text and \"=\" not in token.text:\n",
        "        doc_tokens.append(token.text.lower())\n",
        "   \n",
        "    tokens.append(doc_tokens)\n",
        "    \n",
        "df['tokens'] = tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQt59s0nJ8e3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "ee0b4851-6989-4c04-8a08-63f3dea3f586"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>description</th>\n",
              "      <th>title</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n",
              "      <td>Data scientist</td>\n",
              "      <td>[understanding, machine, learning, models, lik...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n",
              "      <td>Data Scientist I</td>\n",
              "      <td>[data, scientist, 1,, help, build, machine, le...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n",
              "      <td>Data Scientist - Entry Level</td>\n",
              "      <td>[data, scientist, working, consulting, busines...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>[$6,756, general, supervision, professors, dan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>[usa, multiple, years, analytics, business, re...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                             tokens\n",
              "0           0  ...  [understanding, machine, learning, models, lik...\n",
              "1           1  ...  [data, scientist, 1,, help, build, machine, le...\n",
              "2           2  ...  [data, scientist, working, consulting, busines...\n",
              "3           3  ...  [$6,756, general, supervision, professors, dan...\n",
              "4           4  ...  [usa, multiple, years, analytics, business, re...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-lgCZNL_YycP"
      },
      "source": [
        "# 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X2PZ8Pj_YxcF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "0c8fa575-1a98-4e13-ad6e-2a3dec3d6476"
      },
      "source": [
        "##### Your Code Here #####\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(tokenizer=lambda doc: doc, lowercase=False, stop_words='english')\n",
        "dtm = vectorizer.fit_transform(df['tokens'])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_qQi1itOcCX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "5d242949-d9ea-4dbb-9d33-c2081a8d08ad"
      },
      "source": [
        "dtm = pd.DataFrame(dtm.todense(), columns = vectorizer.get_feature_names())\n",
        "dtm.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>\"ability</th>\n",
              "      <th>\"apply\"</th>\n",
              "      <th>\"best</th>\n",
              "      <th>\"big</th>\n",
              "      <th>\"can</th>\n",
              "      <th>\"can-do\"</th>\n",
              "      <th>\"completeness</th>\n",
              "      <th>\"customer</th>\n",
              "      <th>\"engineering</th>\n",
              "      <th>\"fintech\"</th>\n",
              "      <th>\"full-stack</th>\n",
              "      <th>\"get</th>\n",
              "      <th>\"hands-on\"</th>\n",
              "      <th>\"helio\"</th>\n",
              "      <th>\"my</th>\n",
              "      <th>\"no</th>\n",
              "      <th>\"numbers-based\"</th>\n",
              "      <th>\"open-sourcing\"</th>\n",
              "      <th>\"pillar</th>\n",
              "      <th>\"saas\"</th>\n",
              "      <th>\"storytelling\"</th>\n",
              "      <th>\"success\"</th>\n",
              "      <th>\"tmus\")</th>\n",
              "      <th>\"transforming</th>\n",
              "      <th>\"view</th>\n",
              "      <th>#1</th>\n",
              "      <th>#8954,</th>\n",
              "      <th>#autodeskinterns</th>\n",
              "      <th>#hcdagile,</th>\n",
              "      <th>$1,000</th>\n",
              "      <th>$1.66</th>\n",
              "      <th>$10</th>\n",
              "      <th>$100,000</th>\n",
              "      <th>$100,908</th>\n",
              "      <th>$10b</th>\n",
              "      <th>$110k</th>\n",
              "      <th>$125,000</th>\n",
              "      <th>$126,062</th>\n",
              "      <th>$14.4</th>\n",
              "      <th>$15</th>\n",
              "      <th>...</th>\n",
              "      <th>yes</th>\n",
              "      <th>yes,</th>\n",
              "      <th>yet,</th>\n",
              "      <th>yeti</th>\n",
              "      <th>yeti,</th>\n",
              "      <th>yield</th>\n",
              "      <th>york</th>\n",
              "      <th>york,</th>\n",
              "      <th>york.</th>\n",
              "      <th>you!</th>\n",
              "      <th>you!\"</th>\n",
              "      <th>you'd</th>\n",
              "      <th>you'll</th>\n",
              "      <th>you're</th>\n",
              "      <th>you've</th>\n",
              "      <th>you,</th>\n",
              "      <th>you.</th>\n",
              "      <th>you:</th>\n",
              "      <th>you?</th>\n",
              "      <th>young</th>\n",
              "      <th>young,</th>\n",
              "      <th>yourself),</th>\n",
              "      <th>yourself.</th>\n",
              "      <th>youtube,</th>\n",
              "      <th>yrs</th>\n",
              "      <th>yrs,</th>\n",
              "      <th>yrs.</th>\n",
              "      <th>zenreach</th>\n",
              "      <th>zero.</th>\n",
              "      <th>zeus</th>\n",
              "      <th>zf</th>\n",
              "      <th>zheng,</th>\n",
              "      <th>zillow</th>\n",
              "      <th>zoom</th>\n",
              "      <th>zuckerberg</th>\n",
              "      <th>zurich</th>\n",
              "      <th>|</th>\n",
              "      <th>||</th>\n",
              "      <th>~$70</th>\n",
              "      <th>~4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 12860 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   \"ability  \"apply\"  \"best  \"big  \"can  ...  zurich  |  ||  ~$70  ~4\n",
              "0         0        0      0     0     0  ...       0  0   0     0   0\n",
              "1         0        0      0     0     0  ...       0  0   0     0   0\n",
              "2         0        0      0     0     0  ...       0  0   0     0   0\n",
              "3         0        0      0     0     0  ...       0  0   0     0   0\n",
              "4         0        0      0     0     0  ...       0  0   0     0   0\n",
              "\n",
              "[5 rows x 12860 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Zo1iH_UeY7_n"
      },
      "source": [
        "# 4) Visualize the most common word counts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M5LB00uyZKV5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "efdbf3de-cf6a-48cd-f9d2-d48752c4d786"
      },
      "source": [
        "##### Your Code Here #####\n",
        "import matplotlib.pyplot as plt\n",
        "common20 = dtm.sum().sort_values(ascending=False)[:20]\n",
        "plt.barh(common20.index,list(common20))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 20 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAD8CAYAAACo9anUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfpyWTe0Y2g4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bwFsTqrVZMYi"
      },
      "source": [
        " # 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmhCAuz6RZb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mystrings = [' '.join(x) for x in list(df['tokens'])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-gx2gZCbl5Np",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "66766f01-9e57-40ce-dd74-46dc03eb8ed4"
      },
      "source": [
        "##### Your Code Here #####\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(max_features = 20)\n",
        "\n",
        "dtm = tfidf.fit_transform(mystrings)\n",
        "docs = pd.DataFrame(dtm.todense(), columns = tfidf.get_feature_names())\n",
        "docs.head()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>analysis</th>\n",
              "      <th>analytics</th>\n",
              "      <th>business</th>\n",
              "      <th>data</th>\n",
              "      <th>experience</th>\n",
              "      <th>help</th>\n",
              "      <th>insights</th>\n",
              "      <th>learning</th>\n",
              "      <th>machine</th>\n",
              "      <th>models</th>\n",
              "      <th>new</th>\n",
              "      <th>product</th>\n",
              "      <th>science</th>\n",
              "      <th>scientist</th>\n",
              "      <th>skills</th>\n",
              "      <th>solutions</th>\n",
              "      <th>statistical</th>\n",
              "      <th>team</th>\n",
              "      <th>technical</th>\n",
              "      <th>work</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.184901</td>\n",
              "      <td>0.427867</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.247839</td>\n",
              "      <td>0.263777</td>\n",
              "      <td>0.292570</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.229826</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.282707</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.617726</td>\n",
              "      <td>0.227625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.097013</td>\n",
              "      <td>0.302537</td>\n",
              "      <td>0.262530</td>\n",
              "      <td>0.359029</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.304137</td>\n",
              "      <td>0.323696</td>\n",
              "      <td>0.119676</td>\n",
              "      <td>0.232497</td>\n",
              "      <td>0.25909</td>\n",
              "      <td>0.188021</td>\n",
              "      <td>0.106281</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.378772</td>\n",
              "      <td>0.379023</td>\n",
              "      <td>0.186221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.527941</td>\n",
              "      <td>0.411599</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.183900</td>\n",
              "      <td>0.195727</td>\n",
              "      <td>0.434183</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.170535</td>\n",
              "      <td>0.385587</td>\n",
              "      <td>0.209773</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.202309</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.168902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.388282</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.298392</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.729187</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.478002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.481366</td>\n",
              "      <td>0.387095</td>\n",
              "      <td>0.603581</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.504118</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   analysis  analytics  business  ...      team  technical      work\n",
              "0       0.0   0.000000  0.000000  ...  0.000000   0.617726  0.227625\n",
              "1       0.0   0.000000  0.097013  ...  0.378772   0.379023  0.186221\n",
              "2       0.0   0.000000  0.527941  ...  0.000000   0.000000  0.168902\n",
              "3       0.0   0.000000  0.000000  ...  0.729187   0.000000  0.478002\n",
              "4       0.0   0.481366  0.387095  ...  0.000000   0.504118  0.000000\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcS14dhZJaQr",
        "colab_type": "text"
      },
      "source": [
        " # 6) Create a NearestNeighbor Model. Write the description of your ideal datascience job and query your job listings. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputHidden": false,
        "inputHidden": false,
        "id": "aUn3gd8lJaQt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "5a332100-62b2-4650-c728-f672689cec6c"
      },
      "source": [
        "##### Your Code Here #####\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "nn = NearestNeighbors(n_neighbors=5,algorithm='ball_tree')\n",
        "\n",
        "nn.fit(dtm.todense())"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NearestNeighbors(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
              "                 metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                 radius=1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx6tuordR0oC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "dde75943-772f-46fd-c71f-a2c85a50058c"
      },
      "source": [
        "ideal_job = ['amazon','blockchain','mathematics']\n",
        "job_squish =[ ' '.join(ideal_job)]\n",
        "job_squish"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['amazon blockchain mathematics']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhumlDHwSPCj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "46696dec-1678-4a8d-b612-7757b35669e0"
      },
      "source": [
        "new = tfidf.transform(job_squish)\n",
        "\n",
        "nn.kneighbors(new.todense())"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[1., 1., 1., 1., 1.]]), array([[278, 287, 289,  34, 325]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRIzY9MzSjSp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "5cf29c1c-9f78-4059-ab14-cdd6562e87a4"
      },
      "source": [
        "print(mystrings[278])\n",
        "print(mystrings[287])\n",
        "print(mystrings[289])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "icl-u-xs-mt--xs\">temporary, marketing world leading team data scientists developing cutting edge solutions help customers entire buying journey enterprise offerings. team seeking build generation data science critical team marketing analytics, data, &amp; media organization. team builds first-of-a-kind capabilities advanced statistical modeling techniques scale business units geographies. team positioned bring marketing science level, substantial revenue outcomes data scientist interns work alongside marketing analytics experts develop scalable analytical solutions provide data-driven optimization insights ibm. interns work large, complex data sets extract knowledge insights solve difficult, non-routine analysis problems, applying advanced analytical methods needed. interns conduct end-to-end analysis includes industry research, data gathering requirements specification, processing, analysis, ongoing deliverables, marketing data scientist intern, work collaboratively, team, project addresses strategic ibm marketing business challenge. highly visible intern program leadership exposure summer. opportunity showcase final outcomes large audience marketing leaders practitioners organization. addition project, internship includes educational networking candidates formal graduate-level training statistics, machine learning, applied mathematics, and/or operations research passion learn deploy leading technologies drive business marketing data scientist intern positions primarily based new york, new technical professional pursuing graduate degree quantitative discipline (e.g., statistics, data science, computer science, behavioral science, applied mathematics, operations research) discipline involving experimental design quantitative analysis technology work datasets scripting, python, statistical software (spss, sas, r, statistical analysis linear models, multivariate analysis, clustering, time series, mixed model, bayesian knowledge marketing work full-time 12-14 tech prof pursuing phd quantitative discipline (e.g., statistics, data science, computer science, behavioral science, applied mathematics, operations research) discipline involving experimental design quantitative analysis knowledge experience working large data sets apply data mining predictive modeling techniques extract meaningful track record developing intellectual capital published works. basic knowledge digital advancements data science predictive committed creating diverse environment proud equal opportunity employer. qualified applicants receive consideration employment regard race, color, religion, gender, gender identity expression, sexual orientation, national origin, genetics, disability, age, veteran status. ibm committed compliance fair employment practices citizenship immigration\n",
            "b\":who are: sixleaf leading marketing platform party sellers amazon.com variety marketplaces. offer suite complete software solutions brands, big small, selling online. solutions significantly improve marketplace performance profit mission help brands possible scale point household names. goal best it. helping quality brands grow, assist clients achieve dreams, market better place consumers. member team shares joy responsibility making ecommerce world better looking for: love data? love experiment? love looking passionate things. who, fervor investigative reporter, wants inner workings thing. care hype concerned passion research technical writing, perfect position work us?we startup, job demanding times. operate competitive fast moving industry, lots excitement surrounding it, tons things learn. benefits new: unlikely worked project like this. exposed fascinating challenging new world learning incredibly exciting industry money: bluntly; generous. startup, benchmark determines bonus structures pay increases set stone yet, consistently extremely giving. given bonus year season. given raises 90-day probationary period. regularly increase pay based exemplary skillset: exposed people world bring unique set skills table. learning intricacies relatively new industry saas space, require expansion current knowledge. overall, walk away job capable productive job summary::sixleaf looking hire data scientist join fast growth startup! sixleaf established market trusted leader provides content regularly based exciting experiments helpful data. critical present facts, unique combinations aggregated data illustrate important helpful data points online responsible creating experiments finding right data combinations draw logical educated conclusions. outlining parallels correlations, you'll shining light dimly lit world ecommerce, specifically amazon, qualifications: graduate degree computer science, engineering, business information systems, mathematics, statistics, data science related track record delivering highly-scalable reliable data science solutions multiple ability communicate insights analysis appropriate visualization tools, methods information management skills (architecture, design, development support) etl, database, edw, reporting &amp; big data experience 2-3 different technology stacks etl, dw, reporting &amp; big data written oral communication skills, particularly ability synthesize complex issues/scenarios easy-to-understand concepts detail self-discipline, strong ownership accountability drive ability work ambiguous situations influence organizational essential duties responsibilities* tasked steward company data provide novel strategies ideas leveraging new data sources, development custom analytics uncover valuable opportunities insights, spearhead rapid approach problems multiple angles develop test complex models enhance, track, drive client technical skills set r, python, machine learning key role, strong business acumen e-commerce search optimization, price elasticity, psychology sales demand equally thought leader organization branch new e-commerce spaces, new ways approach data operational business aspects data streams machine learning applications enhance proprietary marketing analytics software services agile update business intelligence systems research new information industry drive creation, prototyping, iteration novel business analytics\n",
            "leading software platform digital assets. offering largest production blockchain platform world, share passion code, create, ultimately build open, accessible fair financial future, piece software time. looking add data scientist | analyst growth team expand tens millions users statistical techniques complex data sets understand users geographies engagement analyze, interpret trends patterns provide ongoing reports data visualisations, order recommendations wider internal stakeholders external business partners ensure accurate collection logging data needed provide insights user engagement help drive business performance marketing campaigns customer referral programs. build data pipelines import traffic data daily machine learning models email targeting, content recommendation algorithms, delivery &amp; targeting infrastructure, in-product notification experience ios, android degree mathematics, statistics, economics, cs, engineering hard years professional working experiment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FiDfTWceoRkH"
      },
      "source": [
        "## Stretch Goals\n",
        "\n",
        " - Try different visualizations for words and frequencies - what story do you want to tell with the data?\n",
        " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
        " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
        " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
        "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTAVE7zESPiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}