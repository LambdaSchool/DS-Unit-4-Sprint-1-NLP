{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Sprint Challenge\n",
    "## *Data Science Unit 4 Sprint 1*\n",
    "\n",
    "After a week of Natural Language Processing, you've learned some cool new stuff: how to process text, how turn text into vectors, and how to model topics from documents. Apply your newly acquired skills to one of the most famous NLP datasets out there: [Yelp](https://www.yelp.com/dataset/challenge). As part of the job selection process, some of my friends have been asked to create analysis of this dataset, so I want to empower you to have a head start.  \n",
    "\n",
    "The real dataset is massive (almost 8 gigs uncompressed). I've sampled the data for you to something more managable for the Sprint Challenge. You can analyze the full dataset as a stretch goal or after the sprint challenge. As you work on the challenge, I suggest adding notes about your findings and things you want to analyze in the future.\n",
    "\n",
    "## Challenge Objectives\n",
    "*Successfully complete these all these objectives to earn a 2. There are more details on each objective further down in the notebook.*\n",
    "* <a href=\"#p1\">Part 1</a>: Write a function to tokenize the yelp reviews\n",
    "* <a href=\"#p2\">Part 2</a>: Create a vector representation of those tokens\n",
    "* <a href=\"#p3\">Part 3</a>: Use your tokens in a classification model on yelp rating\n",
    "* <a href=\"#p4\">Part 4</a>: Estimate & Interpret a topic model of the Yelp reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "yelp = pd.read_json('./data/review_sample.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nDuEqIyRc8YKS1q1fX0CZg</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-03-31 16:50:30</td>\n",
       "      <td>0</td>\n",
       "      <td>eZs2tpEJtXPwawvHnHZIgQ</td>\n",
       "      <td>1</td>\n",
       "      <td>BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...</td>\n",
       "      <td>10</td>\n",
       "      <td>n1LM36qNg4rqGXIcvVXv8w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eMYeEapscbKNqUDCx705hg</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-16 05:31:03</td>\n",
       "      <td>0</td>\n",
       "      <td>DoQDWJsNbU0KL1O29l_Xug</td>\n",
       "      <td>4</td>\n",
       "      <td>Came here for lunch Togo. Service was quick. S...</td>\n",
       "      <td>0</td>\n",
       "      <td>5CgjjDAic2-FAvCtiHpytA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6Q7-wkCPc1KF75jZLOTcMw</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-06-20 19:14:48</td>\n",
       "      <td>1</td>\n",
       "      <td>DDOdGU7zh56yQHmUnL1idQ</td>\n",
       "      <td>3</td>\n",
       "      <td>I've been to Vegas dozens of times and had nev...</td>\n",
       "      <td>2</td>\n",
       "      <td>BdV-cf3LScmb8kZ7iiBcMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k3zrItO4l9hwfLRwHBDc9w</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-07-13 00:33:45</td>\n",
       "      <td>4</td>\n",
       "      <td>LfTMUWnfGFMOfOIyJcwLVA</td>\n",
       "      <td>1</td>\n",
       "      <td>We went here on a night where they closed off ...</td>\n",
       "      <td>5</td>\n",
       "      <td>cZZnBqh4gAEy4CdNvJailQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6hpfRwGlOzbNv7k5eP9rsQ</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-30 02:30:01</td>\n",
       "      <td>0</td>\n",
       "      <td>zJSUdI7bJ8PNJAg4lnl_Gg</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5 to 4 stars\\n\\nNot bad for the price, $12.9...</td>\n",
       "      <td>5</td>\n",
       "      <td>n9QO4ClYAS7h9fpQwa5bhA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool                date  funny  \\\n",
       "0  nDuEqIyRc8YKS1q1fX0CZg     1 2015-03-31 16:50:30      0   \n",
       "1  eMYeEapscbKNqUDCx705hg     0 2015-12-16 05:31:03      0   \n",
       "2  6Q7-wkCPc1KF75jZLOTcMw     1 2010-06-20 19:14:48      1   \n",
       "3  k3zrItO4l9hwfLRwHBDc9w     3 2010-07-13 00:33:45      4   \n",
       "4  6hpfRwGlOzbNv7k5eP9rsQ     1 2018-06-30 02:30:01      0   \n",
       "\n",
       "                review_id  stars  \\\n",
       "0  eZs2tpEJtXPwawvHnHZIgQ      1   \n",
       "1  DoQDWJsNbU0KL1O29l_Xug      4   \n",
       "2  DDOdGU7zh56yQHmUnL1idQ      3   \n",
       "3  LfTMUWnfGFMOfOIyJcwLVA      1   \n",
       "4  zJSUdI7bJ8PNJAg4lnl_Gg      4   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...      10   \n",
       "1  Came here for lunch Togo. Service was quick. S...       0   \n",
       "2  I've been to Vegas dozens of times and had nev...       2   \n",
       "3  We went here on a night where they closed off ...       5   \n",
       "4  3.5 to 4 stars\\n\\nNot bad for the price, $12.9...       5   \n",
       "\n",
       "                  user_id  \n",
       "0  n1LM36qNg4rqGXIcvVXv8w  \n",
       "1  5CgjjDAic2-FAvCtiHpytA  \n",
       "2  BdV-cf3LScmb8kZ7iiBcMA  \n",
       "3  cZZnBqh4gAEy4CdNvJailQ  \n",
       "4  n9QO4ClYAS7h9fpQwa5bhA  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...\n",
       "1       Came here for lunch Togo. Service was quick. S...\n",
       "2       I've been to Vegas dozens of times and had nev...\n",
       "3       We went here on a night where they closed off ...\n",
       "4       3.5 to 4 stars\\n\\nNot bad for the price, $12.9...\n",
       "                              ...                        \n",
       "9995    My family and I were hungry and this Subway is...\n",
       "9996    My wife and I came here with a a couple of fri...\n",
       "9997    The food was just OK and not anything to brag ...\n",
       "9998    Today's visit is great!! Love and enjoy Town S...\n",
       "9999    This is the absolute worst place I have ever s...\n",
       "Name: text, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Tokenize Function\n",
    "<a id=\"#p1\"></a>\n",
    "\n",
    "Complete the function `tokenize`. Your function should\n",
    "- accept one document at a time\n",
    "- return a list of tokens\n",
    "\n",
    "You are free to use any method you have learned this week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I chose to use SpaCy!\n",
    "\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "tokenizer = nlp.Defaults.create_tokenizer(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = nlp.Defaults.stop_words.union(['\\n\\n', '\\n', ' ', 'service', 'good', 'food', 'place', 'like', 'just', 'really', 'got', 'don', 've', 'did', 'didn', 'great', 'time', '$', 'little', 'come', 'came', 'best', 'nice', 'love', 'order', 'ordered'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    tokens_new = []\n",
    "    tokens = tokenizer(doc)\n",
    "    for token in tokens:\n",
    "        if (token.is_punct == False) and (token.text.lower() not in STOP_WORDS):\n",
    "            tokens_new.append(token.text.lower())\n",
    "    return tokens_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokens = yelp['text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp['text_tokens'] = text_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [beware, fake, fake, fake, small, business, lo...\n",
       "1     [lunch, togo, quick, staff, friendly, complain...\n",
       "2     [vegas, dozens, times, stepped, foot, circus, ...\n",
       "3     [went, night, closed, street, party, actually,...\n",
       "4     [3.5, 4, stars, bad, price, 12.99, lunch, seni...\n",
       "5     [tasty, fast, casual, latin, street, menu, ove...\n",
       "6     [absolutely, amazing, incredible, production, ...\n",
       "7     [pho, enjoyed, 9:00pm, busy, served, right, aw...\n",
       "8     [absolutely, unique, experience, nail, shop, f...\n",
       "9     [wow, walked, sat, bar, 10, minutes, bartender...\n",
       "10    [popped, dinner, yesterday, reservation, despi...\n",
       "11    [thw, worst, stay, ended, paying, 700, 800, 2,...\n",
       "12    [friendly, customer, quality, waitress, checke...\n",
       "13    [super, busy, server, attentive, try, bacon, f...\n",
       "14    [talk, getting, ripped, charged, 420, shut, va...\n",
       "15    [girls, night, tonight, kid, decided, drive, h...\n",
       "16    [stopped, drinks, flying, charlotte, weeks, ba...\n",
       "17    [excellent, restaurant, encourage, visiting, m...\n",
       "18    [purchased, groupon, massage, maryann, massage...\n",
       "19    [previous, review, stands, 2, years, later, oa...\n",
       "Name: text_tokens, dtype: object"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp['text_tokens'].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Vector Representation\n",
    "<a id=\"#p2\"></a>\n",
    "1. Create a vector representation of the reviews\n",
    "2. Write a fake review and query for the 10 most similiar reviews, print the text of the reviews. Do you notice any patterns?\n",
    "    - Given the size of the dataset, it will probably be best to use a `NearestNeighbors` model for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting with a little exploration...\n",
    "\n",
    "vect = CountVectorizer(stop_words='english')\n",
    "\n",
    "vect.fit(yelp['text'])\n",
    "\n",
    "dtm = vect.transform(yelp['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_top20 = pd.DataFrame(dtm.sum().sort_values(ascending=False).head(20),\n",
    "                       columns=['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>5070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place</th>\n",
       "      <td>4832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>4806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>4297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>service</th>\n",
       "      <td>3695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>3558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>3553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>3449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really</th>\n",
       "      <td>2692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>got</th>\n",
       "      <td>2070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>don</th>\n",
       "      <td>1925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ve</th>\n",
       "      <td>1924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nice</th>\n",
       "      <td>1748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best</th>\n",
       "      <td>1746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>did</th>\n",
       "      <td>1737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>1685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>staff</th>\n",
       "      <td>1597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order</th>\n",
       "      <td>1575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>didn</th>\n",
       "      <td>1564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>came</th>\n",
       "      <td>1553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count\n",
       "food      5070\n",
       "place     4832\n",
       "good      4806\n",
       "great     4297\n",
       "service   3695\n",
       "like      3558\n",
       "just      3553\n",
       "time      3449\n",
       "really    2692\n",
       "got       2070\n",
       "don       1925\n",
       "ve        1924\n",
       "nice      1748\n",
       "best      1746\n",
       "did       1737\n",
       "love      1685\n",
       "staff     1597\n",
       "order     1575\n",
       "didn      1564\n",
       "came      1553"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc_top20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use TF-IDF to vectorize my words..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "\n",
    "dtm = tfidf.fit_transform(yelp['text'])\n",
    "\n",
    "dtm = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=10000,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=<spacy.tokenizer.Tokenizer object at 0x0000024EE44DAD68>,\n",
       "                use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>00pm</th>\n",
       "      <th>07</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>101</th>\n",
       "      <th>10pm</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>yuck</th>\n",
       "      <th>yuk</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "      <th>yup</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>était</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  00pm   07   10  100  1000  101  10pm   11  ...  yuck  yuk  yum  \\\n",
       "0  0.0  0.0   0.0  0.0  0.0  0.0   0.0  0.0   0.0  0.0  ...   0.0  0.0  0.0   \n",
       "1  0.0  0.0   0.0  0.0  0.0  0.0   0.0  0.0   0.0  0.0  ...   0.0  0.0  0.0   \n",
       "2  0.0  0.0   0.0  0.0  0.0  0.0   0.0  0.0   0.0  0.0  ...   0.0  0.0  0.0   \n",
       "3  0.0  0.0   0.0  0.0  0.0  0.0   0.0  0.0   0.0  0.0  ...   0.0  0.0  0.0   \n",
       "4  0.0  0.0   0.0  0.0  0.0  0.0   0.0  0.0   0.0  0.0  ...   0.0  0.0  0.0   \n",
       "\n",
       "   yummy  yup  zero  zone  zoo  zucchini  était  \n",
       "0    0.0  0.0   0.0   0.0  0.0       0.0    0.0  \n",
       "1    0.0  0.0   0.0   0.0  0.0       0.0    0.0  \n",
       "2    0.0  0.0   0.0   0.0  0.0       0.0    0.0  \n",
       "3    0.0  0.0   0.0   0.0  0.0       0.0    0.0  \n",
       "4    0.0  0.0   0.0   0.0  0.0       0.0    0.0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a NearestNeighbors model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "                 metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NearestNeighbors(n_neighbors=5, algorithm='kd_tree')\n",
    "nn.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = ['Wonderful burrito, great coffee, nice owner, convenient parking.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = tfidf.transform(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find matching reviews!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = nn.kneighbors(new.todense(), n_neighbors=10)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6311    天氣很熱吃不下東西，今天我點了一個韓國冷面湯、餐後點了甜點，冰沙系列不會太甜膩，覺得店家很用...\n",
      "6204    旅行でラスベガスに来ましたがネイルがはげてるのが気になり、探したお店でした。\\n質問にも丁寧...\n",
      "6029    Just discovered this place, a hidden treasure ...\n",
      "4867    The ambiance of this place is a 4 or a 5- it's...\n",
      "4536    Burritos are on the \"smaller\" side but still g...\n",
      "5784    This is a great location. It's not as packed a...\n",
      "6290    Great place for a decent burrito.\\nLove the ca...\n",
      "721     ordered a spicy bbq steak burrito. add topping...\n",
      "4094    It's wonderful to find a coffee shop that care...\n",
      "822     Bomb tacos! Menu is simplistic, but food is al...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for match in matches:\n",
    "    print(yelp['text'][match])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, I truly don't know why these reviews in Japanese and Chinese are matching at the top there, but the rest of the reviews seem to match my contrived sample pretty well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Classification\n",
    "<a id=\"#p3\"></a>\n",
    "Your goal in this section will be to predict `stars` from the review dataset. \n",
    "\n",
    "1. Create a piepline object with a sklearn `CountVectorizer` or `TfidfVector` and any sklearn classifier. Use that pipeline to estimate a model to predict `stars`. Use the Pipeline to predict a star rating for your fake review from Part 2. \n",
    "2. Tune the entire pipeline with a GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words='english')\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "pipe = Pipeline([('vect', vect), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['business_id', 'cool', 'date', 'funny', 'review_id', 'stars', 'text',\n",
       "       'useful', 'user_id', 'text_tokens'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words='english', strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_patte...\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=None, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(yelp['text'], yelp['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_review = ['This place stinks, plain and simple. Worst calamari ever.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5], dtype=int64)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(bad_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictor seems to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   49.9s\n",
      "[Parallel(n_jobs=4)]: Done 162 out of 162 | elapsed:  5.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words='english',\n",
       "                                                        strip...\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n_estimators=100,\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=4,\n",
       "             param_grid={'clf__max_depth': (20, 100, 200),\n",
       "                         'clf__n_estimators': (50, 100),\n",
       "                         'vect__max_df': (0.8, 0.9, 1.0),\n",
       "                         'vect__min_df': (0.02, 0.05, 0.1)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': (0.8, 0.9, 1.0),\n",
    "    'vect__min_df': (.02, .05, .1),\n",
    "#     'vect__max_features': (500,5000),\n",
    "    'clf__n_estimators': (50, 100),\n",
    "    'clf__max_depth': (20, 100, 200)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=3, n_jobs=4, verbose=1)\n",
    "grid_search.fit(yelp['text'], yelp['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__max_depth': 100,\n",
       " 'clf__n_estimators': 100,\n",
       " 'vect__max_df': 0.8,\n",
       " 'vect__min_df': 0.02}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5], dtype=int64)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.predict(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.predict(bad_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Topic Modeling\n",
    "\n",
    "Let's find out what those yelp reviews are saying! :D\n",
    "\n",
    "1. Estimate a LDA topic model of the review text\n",
    "    - Keep the `iterations` parameter at or below 5 to reduce run time\n",
    "    - The `workers` parameter should match the number of physical cores on your machine.\n",
    "2. Create 1-2 visualizations of the results\n",
    "    - You can use the most important 3 words of a topic in relevant visualizations. Refer to yesterday's notebook to extract. \n",
    "3. In markdown, write 1-2 paragraphs of analysis on the results of your topic model\n",
    "\n",
    "__*Note*__: You can pass the DataFrame column of text reviews to gensim. You do not have to use a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import LdaMulticore\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn the vocubalary of the yelp data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = Dictionary(yelp['text_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29025"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id2word.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word.filter_extremes(no_below=5, no_above=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7706"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id2word.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a bag of words representation of the entire corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "corpus = [id2word.doc2bow(tokens) for tokens in text_tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your LDA model should be ready for estimation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "lda = LdaMulticore(corpus=corpus,\n",
    "                   id2word=id2word,\n",
    "                   iterations=5,\n",
    "                   workers=4,\n",
    "                   num_topics = 3 # You can change this parameter\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.004*\"staff\" + 0.004*\"people\" + 0.003*\"pretty\" + 0.003*\"definitely\" + 0.003*\"day\" + 0.003*\"restaurant\" + 0.003*\"way\" + 0.003*\"recommend\" + 0.003*\"friendly\" + 0.003*\"went\"'),\n",
       " (1,\n",
       "  '0.005*\"definitely\" + 0.004*\"know\" + 0.004*\"amazing\" + 0.004*\"staff\" + 0.004*\"menu\" + 0.004*\"friendly\" + 0.004*\"try\" + 0.004*\"experience\" + 0.004*\"restaurant\" + 0.004*\"people\"'),\n",
       " (2,\n",
       "  '0.004*\"went\" + 0.004*\"try\" + 0.004*\"chicken\" + 0.004*\"said\" + 0.004*\"delicious\" + 0.003*\"staff\" + 0.003*\"experience\" + 0.003*\"restaurant\" + 0.003*\"people\" + 0.003*\"friendly\"')]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 1-2 visualizations of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "words = [re.findall(r'\"([^\"]*)\"',t[1]) for t in lda.print_topics()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [' '.join(t[0:3]) for t in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['staff people pretty', 'definitely know amazing', 'went try chicken']"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1494825380634907688074278432\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1494825380634907688074278432_data = {\"mdsDat\": {\"x\": [-0.005100265008956635, 0.0033050882417600866, 0.0017951767671965482], \"y\": [-0.0008348953678140317, -0.0038127880309048075, 0.004647683398718839], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [33.49742889404297, 33.45417785644531, 33.04838562011719]}, \"tinfo\": {\"Term\": [\"know\", \"bad\", \"try\", \"said\", \"menu\", \"places\", \"pretty\", \"amazing\", \"definitely\", \"cheese\", \"2\", \"coffee\", \"took\", \"think\", \"dessert\", \"quality\", \"went\", \"meal\", \"right\", \"dish\", \"excellent\", \"wait\", \"super\", \"comes\", \"wanted\", \"tasty\", \"  \", \"selection\", \"hour\", \"experience\", \"zach\", \"roach\", \"everybody\", \"frites\", \"ginger\", \"rob\", \"samosa\", \"dessert\", \"inspired\", \"terrific\", \"ranges\", \"tj\", \"know\", \"bc\", \"yonge\", \"pepsi\", \"installed\", \"whites\", \"mart\", \"timely\", \"lukewarm\", \"turkey\", \"purchased\", \"immediate\", \"reflexology\", \"lets\", \"coffee\", \"pure\", \"clearing\", \"adjustment\", \"generous\", \"zero\", \"menu\", \"meal\", \"  \", \"amazing\", \"breakfast\", \"2\", \"definitely\", \"right\", \"cold\", \"excellent\", \"busy\", \"worth\", \"took\", \"going\", \"review\", \"saturday\", \"friendly\", \"visit\", \"tasty\", \"couple\", \"experience\", \"table\", \"find\", \"coming\", \"ok\", \"soup\", \"day\", \"try\", \"staff\", \"restaurant\", \"better\", \"area\", \"chicken\", \"people\", \"way\", \"went\", \"small\", \"recommend\", \"said\", \"asked\", \"new\", \"delicious\", \"eat\", \"work\", \"told\", \"want\", \"revisit\", \"therapists\", \"europe\", \"places\", \"southwestern\", \"rapide\", \"carte\", \"girlfriends\", \"benefits\", \"ribs\", \"donuts\", \"goat\", \"brooklyn\", \"lies\", \"smash\", \"socializing\", \"bad\", \"dish\", \"rocks\", \"timers\", \"ahwatukee\", \"piss\", \"groups\", \"skeptical\", \"pristine\", \"scale\", \"tremendous\", \"sunset\", \"soothing\", \"services\", \"yesterday\", \"quality\", \"hour\", \"said\", \"frozen\", \"previous\", \"money\", \"reservations\", \"super\", \"buffets\", \"car\", \"went\", \"bite\", \"wait\", \"try\", \"1\", \"portions\", \"making\", \"room\", \"pay\", \"variety\", \"pizza\", \"delicious\", \"chicken\", \"store\", \"loved\", \"wanted\", \"sauce\", \"tacos\", \"bit\", \"vegas\", \"new\", \"long\", \"cheese\", \"looking\", \"experience\", \"times\", \"want\", \"took\", \"restaurant\", \"bar\", \"staff\", \"friendly\", \"people\", \"amazing\", \"recommend\", \"price\", \"fresh\", \"told\", \"right\", \"going\", \"better\", \"definitely\", \"pretty\", \"sure\", \"menu\", \"yikes\", \"smoking\", \"alterations\", \"jammed\", \"racist\", \"chore\", \"plumber\", \"wind\", \"imo\", \"worthy\", \"asu\", \"guaranteed\", \"jessica\", \"cared\", \"scoop\", \"vast\", \"reaching\", \"trap\", \"quesadillas\", \"bon\", \"physicians\", \"bday\", \"aggressive\", \"gamble\", \"blvd\", \"quirky\", \"drive\", \"raised\", \"lashes\", \"flops\", \"jewelry\", \"curry\", \"wine\", \"selection\", \"buy\", \"young\", \"pretty\", \"terrible\", \"seen\", \"bag\", \"looks\", \"think\", \"hours\", \"friday\", \"cash\", \"later\", \"check\", \"toppings\", \"phoenix\", \"property\", \"owner\", \"thanks\", \"found\", \"cheese\", \"server\", \"received\", \"3\", \"sushi\", \"night\", \"big\", \"having\", \"way\", \"minutes\", \"bar\", \"day\", \"people\", \"let\", \"times\", \"staff\", \"drinks\", \"recommend\", \"years\", \"sure\", \" \\n\\n\", \"restaurant\", \"better\", \"definitely\", \"want\", \"work\", \"new\", \"vegas\", \"friendly\", \"delicious\", \"2\", \"went\", \"wait\", \"told\", \"chicken\", \"menu\", \"fresh\", \"amazing\", \"going\", \"experience\", \"try\"], \"Freq\": [1208.0, 827.0, 1437.0, 1194.0, 1222.0, 475.0, 1064.0, 1346.0, 1441.0, 818.0, 1045.0, 630.0, 907.0, 878.0, 364.0, 665.0, 1477.0, 727.0, 1084.0, 440.0, 659.0, 970.0, 673.0, 350.0, 652.0, 486.0, 434.0, 477.0, 586.0, 1286.0, 3.838987112045288, 6.783689975738525, 13.385632514953613, 11.835906982421875, 18.760587692260742, 7.279029846191406, 5.11309289932251, 184.75936889648438, 10.826295852661133, 19.870853424072266, 7.743249416351318, 4.415006160736084, 595.9595947265625, 16.898000717163086, 8.793270111083984, 2.812730312347412, 24.429332733154297, 7.80804967880249, 6.393239498138428, 19.189451217651367, 5.646677494049072, 34.35403060913086, 56.80638885498047, 7.6446051597595215, 4.9847211837768555, 10.788473129272461, 304.9387512207031, 18.977619171142578, 6.534919261932373, 4.7444233894348145, 44.91389465332031, 35.588016510009766, 554.9915161132812, 331.3962707519531, 198.1890869140625, 589.0894775390625, 209.82159423828125, 458.6009521484375, 622.8324584960938, 459.8625183105469, 177.3126983642578, 283.2729797363281, 218.3240966796875, 269.6902160644531, 373.93060302734375, 464.1135559082031, 205.06138610839844, 97.73725128173828, 540.0641479492188, 230.7797393798828, 203.80833435058594, 174.43460083007812, 500.7721252441406, 322.7549133300781, 321.90802001953125, 240.1523895263672, 201.3858184814453, 198.39791870117188, 445.29248046875, 520.5711059570312, 556.5066528320312, 491.2366027832031, 417.5203857421875, 289.0960388183594, 469.6958923339844, 484.6669616699219, 390.350830078125, 458.2422790527344, 293.8830261230469, 377.0169677734375, 377.8138122558594, 302.8295593261719, 358.5431823730469, 368.65496826171875, 302.66656494140625, 310.13214111328125, 311.9041748046875, 316.2874450683594, 5.406114101409912, 4.886428356170654, 6.006808757781982, 245.47097778320312, 3.74587082862854, 4.170828819274902, 11.966238975524902, 11.315332412719727, 5.842154026031494, 53.55199432373047, 60.68253707885742, 24.622730255126953, 5.387869834899902, 3.9788918495178223, 6.824587345123291, 4.30591344833374, 403.9460144042969, 214.981201171875, 21.804107666015625, 5.1733551025390625, 2.453453302383423, 4.251492500305176, 22.174388885498047, 16.919137954711914, 2.4513869285583496, 6.788434982299805, 6.516043663024902, 9.689784049987793, 4.545078754425049, 70.30524444580078, 44.611183166503906, 307.4476623535156, 268.8460693359375, 533.7875366210938, 57.7642822265625, 48.51737594604492, 216.34136962890625, 41.92205047607422, 293.3866271972656, 26.410709381103516, 265.5491638183594, 617.0914916992188, 96.90644836425781, 408.90350341796875, 591.97802734375, 215.7781524658203, 112.90454864501953, 136.02481079101562, 391.56048583984375, 183.89044189453125, 124.806884765625, 322.212890625, 487.7486267089844, 539.8361206054688, 285.7032165527344, 203.53689575195312, 266.1838684082031, 323.8334045410156, 143.18145751953125, 323.92340087890625, 352.7518310546875, 429.9908752441406, 291.5179443359375, 314.85736083984375, 273.0609130859375, 457.985107421875, 321.2018127441406, 372.2623596191406, 332.35992431640625, 440.9333801269531, 356.4837341308594, 472.3713684082031, 434.14141845703125, 436.8076477050781, 415.4623718261719, 378.61273193359375, 326.4609069824219, 332.5293273925781, 336.6530456542969, 353.2456970214844, 356.851806640625, 352.8062438964844, 373.5277099609375, 337.7886962890625, 325.7038879394531, 327.9120788574219, 4.457597255706787, 16.472911834716797, 5.764987468719482, 3.8931636810302734, 6.5318474769592285, 3.3965070247650146, 12.504308700561523, 7.526309013366699, 7.76163911819458, 15.11111068725586, 7.611025333404541, 5.393525123596191, 10.182280540466309, 11.09611701965332, 16.31220054626465, 7.455438613891602, 5.756219863891602, 3.5759150981903076, 5.0703020095825195, 9.654159545898438, 5.454047203063965, 7.775185585021973, 5.209640979766846, 11.981267929077148, 5.532003879547119, 3.1328861713409424, 150.79708862304688, 10.225030899047852, 13.437179565429688, 3.5324556827545166, 16.565654754638672, 62.960548400878906, 184.3783721923828, 221.1074981689453, 112.89643096923828, 60.12162780761719, 466.0009460449219, 96.79998016357422, 106.01213836669922, 47.431617736816406, 105.63529968261719, 376.44354248046875, 183.64572143554688, 84.27804565429688, 70.00231170654297, 161.21543884277344, 262.45904541015625, 63.04766845703125, 74.0507583618164, 36.4205322265625, 183.1779327392578, 101.84101867675781, 276.5073547363281, 329.28228759765625, 275.9316711425781, 100.97565460205078, 349.47247314453125, 222.63658142089844, 378.26190185546875, 258.54827880859375, 185.80409240722656, 415.9522705078125, 342.46453857421875, 379.0004577636719, 440.951416015625, 512.4212646484375, 207.58273315429688, 318.82861328125, 525.5473022460938, 277.7275390625, 407.96954345703125, 245.18785095214844, 340.87664794921875, 231.77587890625, 438.1514587402344, 382.2271728515625, 444.86773681640625, 342.80596923828125, 319.3533020019531, 365.5959777832031, 308.5460510253906, 404.8039245605469, 369.8769836425781, 331.666015625, 401.71209716796875, 315.7275695800781, 313.4426574707031, 368.4976806640625, 339.47393798828125, 306.2351379394531, 341.59234619140625, 321.0325927734375, 327.4345397949219, 325.09271240234375], \"Total\": [1208.0, 827.0, 1437.0, 1194.0, 1222.0, 475.0, 1064.0, 1346.0, 1441.0, 818.0, 1045.0, 630.0, 907.0, 878.0, 364.0, 665.0, 1477.0, 727.0, 1084.0, 440.0, 659.0, 970.0, 673.0, 350.0, 652.0, 486.0, 434.0, 477.0, 586.0, 1286.0, 7.241946220397949, 12.985931396484375, 25.785287857055664, 22.928815841674805, 36.34721374511719, 14.146477699279785, 10.078487396240234, 364.33843994140625, 21.492820739746094, 39.48784637451172, 15.502191543579102, 8.911172866821289, 1208.5574951171875, 34.27880859375, 17.852819442749023, 5.714555263519287, 49.699092864990234, 15.890848159790039, 13.01533031463623, 39.09977722167969, 11.51909065246582, 70.093994140625, 116.13147735595703, 15.71982192993164, 10.25399398803711, 22.20050811767578, 630.408203125, 39.304290771484375, 13.679965019226074, 9.976258277893066, 94.59989929199219, 75.53561401367188, 1222.37744140625, 727.8172607421875, 434.78936767578125, 1346.144287109375, 466.42681884765625, 1045.1064453125, 1441.2279052734375, 1084.7767333984375, 403.8650817871094, 659.5322875976562, 505.9620361328125, 638.2457275390625, 907.0697021484375, 1141.9979248046875, 480.1112060546875, 219.71194458007812, 1379.009521484375, 555.5164184570312, 486.31243896484375, 412.9364013671875, 1286.1917724609375, 804.3724365234375, 809.4369506835938, 591.4091186523438, 489.59234619140625, 485.9463806152344, 1203.350341796875, 1437.641845703125, 1554.42529296875, 1370.3214111328125, 1152.5538330078125, 750.8363037109375, 1378.0296630859375, 1433.8958740234375, 1110.47265625, 1477.0458984375, 792.66552734375, 1163.5992431640625, 1194.697265625, 837.277099609375, 1154.1300048828125, 1226.280517578125, 856.28857421875, 938.05126953125, 961.9998779296875, 1031.355712890625, 10.288811683654785, 9.426216125488281, 11.615583419799805, 475.1177978515625, 7.265933036804199, 8.098800659179688, 23.321847915649414, 22.25945281982422, 11.49738883972168, 105.65557861328125, 120.51579284667969, 48.98529052734375, 10.965204238891602, 8.100716590881348, 13.905672073364258, 8.775496482849121, 827.2496948242188, 440.6601257324219, 44.71510696411133, 10.626121520996094, 5.052740573883057, 8.76910400390625, 45.77510070800781, 34.972625732421875, 5.072647571563721, 14.068950653076172, 13.54055404663086, 20.158409118652344, 9.461426734924316, 147.57472229003906, 93.92478942871094, 665.8828125, 586.4061279296875, 1194.697265625, 123.64910125732422, 104.12751770019531, 482.6549377441406, 90.56100463867188, 673.175048828125, 56.31134796142578, 612.5629272460938, 1477.0458984375, 216.1281280517578, 970.1619873046875, 1437.641845703125, 499.69683837890625, 254.3339080810547, 309.7250061035156, 953.023681640625, 431.3848571777344, 285.96990966796875, 785.469482421875, 1226.280517578125, 1378.0296630859375, 696.276611328125, 486.74365234375, 652.4435424804688, 813.7682495117188, 333.70172119140625, 827.0324096679688, 910.311279296875, 1154.1300048828125, 747.978759765625, 818.90283203125, 696.076904296875, 1286.1917724609375, 856.78271484375, 1031.355712890625, 907.0697021484375, 1370.3214111328125, 1016.3267822265625, 1554.42529296875, 1379.009521484375, 1433.8958740234375, 1346.144287109375, 1163.5992431640625, 902.1044311523438, 935.551025390625, 961.9998779296875, 1084.7767333984375, 1141.9979248046875, 1152.5538330078125, 1441.2279052734375, 1064.773193359375, 955.3391723632812, 1222.37744140625, 8.61135482788086, 31.885028839111328, 11.17304515838623, 7.558173656463623, 12.730491638183594, 6.696262359619141, 24.790407180786133, 14.985010147094727, 15.474802017211914, 30.15899085998535, 15.310728073120117, 10.991454124450684, 20.787799835205078, 22.687942504882812, 33.40829086303711, 15.301294326782227, 11.841442108154297, 7.3751678466796875, 10.464154243469238, 19.972959518432617, 11.310937881469727, 16.149311065673828, 10.827058792114258, 24.904544830322266, 11.513352394104004, 6.521049976348877, 314.2893371582031, 21.330432891845703, 28.043800354003906, 7.373889446258545, 34.74964904785156, 133.99932861328125, 397.275146484375, 477.7230224609375, 247.25997924804688, 130.20980834960938, 1064.773193359375, 212.73983764648438, 234.92398071289062, 102.61458587646484, 235.0738525390625, 878.9874267578125, 420.6531066894531, 187.43096923828125, 154.63442993164062, 372.1879577636719, 626.2706909179688, 140.05960083007812, 166.65066528320312, 79.24308013916016, 433.98529052734375, 234.09231567382812, 679.3380126953125, 818.90283203125, 682.4095458984375, 234.27230834960938, 892.6386108398438, 550.1685791015625, 973.8533325195312, 651.6212768554688, 455.6187744140625, 1110.47265625, 901.1825561523438, 1016.3267822265625, 1203.350341796875, 1433.8958740234375, 521.8651123046875, 856.78271484375, 1554.42529296875, 740.4833374023438, 1163.5992431640625, 641.7554931640625, 955.3391723632812, 602.515625, 1370.3214111328125, 1152.5538330078125, 1441.2279052734375, 1031.355712890625, 938.05126953125, 1154.1300048828125, 910.311279296875, 1379.009521484375, 1226.280517578125, 1045.1064453125, 1477.0458984375, 970.1619873046875, 961.9998779296875, 1378.0296630859375, 1222.37744140625, 935.551025390625, 1346.144287109375, 1141.9979248046875, 1286.1917724609375, 1437.641845703125], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -10.48639965057373, -9.917099952697754, -9.23740005493164, -9.36050033569336, -8.899800300598145, -9.846599578857422, -10.199799537658691, -6.612500190734863, -9.449600219726562, -8.842300415039062, -9.784799575805664, -10.346599578857422, -5.441400051116943, -9.004400253295898, -9.657600402832031, -10.79740047454834, -8.6358003616333, -9.776399612426758, -9.976400375366211, -8.87720012664795, -10.100500106811523, -8.294899940490723, -7.791999816894531, -9.797599792480469, -10.225199699401855, -9.453100204467773, -6.111499786376953, -8.888299942016602, -9.954400062561035, -10.2746000289917, -8.026900291442871, -8.259599685668945, -5.512599945068359, -6.028299808502197, -6.542399883270264, -5.453000068664551, -6.485300064086914, -5.703400135040283, -5.397299766540527, -5.700699806213379, -6.65369987487793, -6.185200214385986, -6.4456000328063965, -6.234300136566162, -5.90749979019165, -5.691500186920166, -6.508299827575684, -7.249300003051758, -5.539899826049805, -6.390100002288818, -6.514400005340576, -6.670000076293945, -5.6153998374938965, -6.054699897766113, -6.057300090789795, -6.350299835205078, -6.526400089263916, -6.541299819946289, -5.732900142669678, -5.576700210571289, -5.509900093078613, -5.634699821472168, -5.797299861907959, -6.16480016708374, -5.679500102996826, -5.648099899291992, -5.86460018157959, -5.70419979095459, -6.148399829864502, -5.8993000984191895, -5.897200107574463, -6.1184000968933105, -5.9496002197265625, -5.9217000007629395, -6.11899995803833, -6.094600200653076, -6.088900089263916, -6.074900150299072, -10.142800331115723, -10.243800163269043, -10.037400245666504, -6.327099800109863, -10.509699821472168, -10.402199745178223, -9.348199844360352, -9.40410041809082, -10.065199851989746, -7.849699974060059, -7.724699974060059, -8.62660026550293, -10.146200180053711, -10.449299812316895, -9.909799575805664, -10.37030029296875, -5.828999996185303, -6.459799766540527, -8.748200416564941, -10.186800003051758, -10.93280029296875, -10.383000373840332, -8.731399536132812, -9.001899719238281, -10.933699607849121, -9.91510009765625, -9.956000328063965, -9.559200286865234, -10.316300392150879, -7.577499866485596, -8.032299995422363, -6.1020002365112305, -6.236199855804443, -5.550300121307373, -7.773900032043457, -7.948400020599365, -6.453400135040283, -8.094499588012695, -6.148799896240234, -8.556500434875488, -6.248499870300293, -5.405300140380859, -7.2565999031066895, -5.816800117492676, -5.446800231933594, -6.456099987030029, -7.103799819946289, -6.917500019073486, -5.860199928283691, -6.616000175476074, -7.003499984741211, -6.055099964141846, -5.640500068664551, -5.539000034332275, -6.1753997802734375, -6.514500141143799, -6.246099948883057, -6.050099849700928, -6.866199970245361, -6.049799919128418, -5.9644999504089355, -5.766499996185303, -6.155200004577637, -6.078199863433838, -6.220600128173828, -5.703499794006348, -6.058199882507324, -5.910699844360352, -6.024099826812744, -5.741399765014648, -5.953999996185303, -5.672500133514404, -5.756899833679199, -5.750800132751465, -5.800899982452393, -5.893799781799316, -6.041999816894531, -6.023600101470947, -6.011300086975098, -5.963099956512451, -5.953000068664551, -5.964399814605713, -5.907299995422363, -6.007900238037109, -6.044300079345703, -6.037600040435791, -10.32349967956543, -9.016400337219238, -10.066300392150879, -10.458900451660156, -9.941399574279785, -10.595399856567383, -9.291999816894531, -9.799699783325195, -9.768899917602539, -9.102700233459473, -9.78849983215332, -10.13290023803711, -9.4975004196167, -9.411499977111816, -9.026200294494629, -9.809200286865234, -10.06779956817627, -10.543899536132812, -10.194700241088867, -9.550700187683105, -10.121700286865234, -9.767200469970703, -10.16759967803955, -9.334799766540527, -10.107600212097168, -10.67609977722168, -6.802199840545654, -9.493300437927246, -9.220100402832031, -10.556099891662598, -9.0108003616333, -7.675600051879883, -6.601099967956543, -6.41949987411499, -7.091599941253662, -7.721700191497803, -5.673900127410889, -7.245500087738037, -7.1545000076293945, -7.958799839019775, -7.158100128173828, -5.88730001449585, -6.605100154876709, -7.383999824523926, -7.5696001052856445, -6.735400199890137, -6.248000144958496, -7.674200057983398, -7.513400077819824, -8.222999572753906, -6.607600212097168, -7.194699764251709, -6.195899963378906, -6.021200180053711, -6.197999954223633, -7.203199863433838, -5.961699962615967, -6.412600040435791, -5.882500171661377, -6.263000011444092, -6.593400001525879, -5.787499904632568, -5.981900215148926, -5.8805999755859375, -5.7291998863220215, -5.578999996185303, -6.482600212097168, -6.053400039672852, -5.553699970245361, -6.191500186920166, -5.8069000244140625, -6.316100120544434, -5.986599922180176, -6.372300148010254, -5.735499858856201, -5.872099876403809, -5.720300197601318, -5.980899810791016, -6.051799774169922, -5.916600227355957, -6.08620023727417, -5.814700126647949, -5.904900074005127, -6.013999938964844, -5.822400093078613, -6.063199996948242, -6.070499897003174, -5.908699989318848, -5.990699768066406, -6.093800067901611, -5.984499931335449, -6.046599864959717, -6.026800155639648, -6.033999919891357], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.45899999141693115, 0.44440001249313354, 0.43810001015663147, 0.4323999881744385, 0.43230000138282776, 0.4291999936103821, 0.41510000824928284, 0.4147000014781952, 0.40799999237060547, 0.40700000524520874, 0.3995000123977661, 0.391400009393692, 0.38670000433921814, 0.3864000141620636, 0.3855000138282776, 0.384799987077713, 0.38350000977516174, 0.3831000030040741, 0.38280001282691956, 0.38190001249313354, 0.3808000087738037, 0.3806000053882599, 0.37860000133514404, 0.37279999256134033, 0.3723999857902527, 0.37209999561309814, 0.36739999055862427, 0.36559998989105225, 0.3549000024795532, 0.3504999876022339, 0.34880000352859497, 0.3411000072956085, 0.30410000681877136, 0.3070000112056732, 0.30809998512268066, 0.267300009727478, 0.29490000009536743, 0.27000001072883606, 0.2547000050544739, 0.23549999296665192, 0.2705000042915344, 0.24860000610351562, 0.2531999945640564, 0.23229999840259552, 0.20759999752044678, 0.19329999387264252, 0.24300000071525574, 0.28369998931884766, 0.15629999339580536, 0.21529999375343323, 0.2240000069141388, 0.23199999332427979, 0.15039999783039093, 0.18050000071525574, 0.17159999907016754, 0.19249999523162842, 0.2054000049829483, 0.19789999723434448, 0.09960000216960907, 0.0778999999165535, 0.06650000065565109, 0.06780000030994415, 0.07829999923706055, 0.13930000364780426, 0.017400000244379044, 0.008999999612569809, 0.04820000007748604, -0.07670000195503235, 0.1014999970793724, -0.0333000011742115, -0.057500001043081284, 0.07670000195503235, -0.07540000230073929, -0.10819999873638153, 0.053700000047683716, -0.013100000098347664, -0.032600000500679016, -0.08829999715089798, 0.4514999985694885, 0.43799999356269836, 0.43549999594688416, 0.43459999561309814, 0.4325000047683716, 0.43140000104904175, 0.427700012922287, 0.41839998960494995, 0.4180000126361847, 0.4154999852180481, 0.4088999927043915, 0.40709999203681946, 0.38440001010894775, 0.3840000033378601, 0.3831999897956848, 0.382999986410141, 0.3781999945640564, 0.3772999942302704, 0.376800000667572, 0.3752000033855438, 0.3725999891757965, 0.3709999918937683, 0.3702000081539154, 0.36890000104904175, 0.3677999973297119, 0.3662000000476837, 0.3635999858379364, 0.36239999532699585, 0.3617999851703644, 0.35350000858306885, 0.3504999876022339, 0.3222000002861023, 0.3151000142097473, 0.28929999470710754, 0.33390000462532043, 0.3312999904155731, 0.29249998927116394, 0.3248000144958496, 0.2644999921321869, 0.3379000127315521, 0.2590999901294708, 0.22220000624656677, 0.2928999960422516, 0.23100000619888306, 0.2076999992132187, 0.25519999861717224, 0.28290000557899475, 0.2721000015735626, 0.20550000667572021, 0.24230000376701355, 0.26589998602867126, 0.20389999449253082, 0.17309999465942383, 0.15780000388622284, 0.20419999957084656, 0.22310000658035278, 0.19850000739097595, 0.17350000143051147, 0.24889999628067017, 0.15770000219345093, 0.1469999998807907, 0.10769999772310257, 0.1527000069618225, 0.13910000026226044, 0.15919999778270721, 0.06239999830722809, 0.11389999836683273, 0.07599999755620956, 0.09099999815225601, -0.03889999911189079, 0.04729999974370003, -0.09610000252723694, -0.06080000102519989, -0.09369999915361404, -0.08060000091791153, -0.027799999341368675, 0.07859999686479568, 0.060600001364946365, 0.04500000178813934, -0.027000000700354576, -0.0681999996304512, -0.08879999816417694, -0.25529998540878296, -0.05310000106692314, 0.01889999955892563, -0.2207999974489212, 0.4487000107765198, 0.44679999351501465, 0.445499986410141, 0.4438000023365021, 0.4399000108242035, 0.4284000098705292, 0.4228000044822693, 0.4185999929904938, 0.4171999990940094, 0.41609999537467957, 0.4081999957561493, 0.3953000009059906, 0.3935000002384186, 0.3919999897480011, 0.3903000056743622, 0.3882000148296356, 0.38589999079704285, 0.3833000063896179, 0.38260000944137573, 0.38019999861717224, 0.37779998779296875, 0.37630000710487366, 0.3756999969482422, 0.37549999356269836, 0.3741999864578247, 0.374099999666214, 0.37279999256134033, 0.3718999922275543, 0.3714999854564667, 0.37119999527931213, 0.36640000343322754, 0.35190001130104065, 0.33959999680519104, 0.3368000090122223, 0.323199987411499, 0.3343999981880188, 0.2809000015258789, 0.3197999894618988, 0.31150001287460327, 0.33550000190734863, 0.30730000138282776, 0.25920000672340393, 0.2784000039100647, 0.30790001153945923, 0.31470000743865967, 0.2705000042915344, 0.23749999701976776, 0.3089999854564667, 0.29600000381469727, 0.329800009727478, 0.24459999799728394, 0.27489998936653137, 0.20829999446868896, 0.19609999656677246, 0.20170000195503235, 0.2655999958515167, 0.16940000653266907, 0.20250000059604645, 0.1615000069141388, 0.18279999494552612, 0.2101999968290329, 0.12520000338554382, 0.1396999955177307, 0.12080000340938568, 0.10329999774694443, 0.07819999754428864, 0.18529999256134033, 0.11869999766349792, 0.02280000038444996, 0.1264999955892563, 0.05909999832510948, 0.14499999582767487, 0.07670000195503235, 0.15189999341964722, -0.032999999821186066, 0.0035000001080334187, -0.06830000132322311, 0.00570000009611249, 0.02969999983906746, -0.042399998754262924, 0.025299999862909317, -0.1185000017285347, -0.09139999747276306, -0.04050000011920929, -0.1949000060558319, -0.015399999916553497, -0.0142000000923872, -0.2117999941110611, -0.17399999499320984, -0.009600000455975533, -0.26420000195503235, -0.16179999709129333, -0.26100000739097595, -0.37950000166893005]}, \"token.table\": {\"Topic\": [1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3], \"Freq\": [0.33360129594802856, 0.28215035796165466, 0.38505226373672485, 0.4553929269313812, 0.3357947766780853, 0.20699678361415863, 0.3041844367980957, 0.4322620928287506, 0.26416015625, 0.43918970227241516, 0.24399428069591522, 0.317671000957489, 0.26886579394340515, 0.3394430875778198, 0.390975683927536, 0.5011898875236511, 0.20047596096992493, 0.3007139563560486, 0.27708354592323303, 0.27708354592323303, 0.46180593967437744, 0.19791239500045776, 0.3958247900009155, 0.19791239500045776, 0.268503338098526, 0.17900222539901733, 0.537006676197052, 0.4375459551811218, 0.3082878887653351, 0.25405895709991455, 0.384904146194458, 0.2943384647369385, 0.3209754228591919, 0.3618873655796051, 0.29380953311920166, 0.34516650438308716, 0.2612547278404236, 0.2612547278404236, 0.5225094556808472, 0.22242377698421478, 0.4883652329444885, 0.2889091372489929, 0.26312050223350525, 0.2728656828403473, 0.4580245614051819, 0.2764858901500702, 0.3502810299396515, 0.3729115426540375, 0.4959332346916199, 0.2625528872013092, 0.23338033258914948, 0.18576644361019135, 0.3096107244491577, 0.49537718296051025, 0.26092880964279175, 0.5218576192855835, 0.26092880964279175, 0.3626728653907776, 0.3062763810157776, 0.331437885761261, 0.33608478307724, 0.26702627539634705, 0.3974701464176178, 0.34944218397140503, 0.3917621672153473, 0.25875648856163025, 0.28223997354507446, 0.44880783557891846, 0.26835933327674866, 0.2605670392513275, 0.2605670392513275, 0.521134078502655, 0.20027077198028564, 0.3504738509654999, 0.5006769299507141, 0.4502314031124115, 0.2637069523334503, 0.285146564245224, 0.2735927104949951, 0.4559878706932068, 0.2735927104949951, 0.2486177384853363, 0.4617186486721039, 0.28413456678390503, 0.4308623671531677, 0.33401715755462646, 0.23519551753997803, 0.20221631228923798, 0.3397234082221985, 0.45700886845588684, 0.3069072365760803, 0.43424108624458313, 0.25956517457962036, 0.3085339367389679, 0.22038137912750244, 0.4848390221595764, 0.2572695016860962, 0.5145390033721924, 0.21439124643802643, 0.2457408756017685, 0.29747578501701355, 0.4526805579662323, 0.2810286283493042, 0.30018967390060425, 0.4183494448661804, 0.2137005627155304, 0.3846610188484192, 0.40175706148147583, 0.3410666882991791, 0.3918638527393341, 0.2670479416847229, 0.298674076795578, 0.298674076795578, 0.4480111300945282, 0.5116972327232361, 0.2923984229564667, 0.2923984229564667, 0.48381349444389343, 0.27283909916877747, 0.24269989132881165, 0.4382651746273041, 0.31446143984794617, 0.24513137340545654, 0.39996081590652466, 0.4228157103061676, 0.1771254986524582, 0.4058104455471039, 0.3178848624229431, 0.2773038148880005, 0.4213723838329315, 0.3317702114582062, 0.24458971619606018, 0.27612078189849854, 0.2537326216697693, 0.4701516032218933, 0.369800865650177, 0.263431191444397, 0.36647680401802063, 0.4322702884674072, 0.2595009505748749, 0.3087644875049591, 0.30090993642807007, 0.3979513645172119, 0.3017254173755646, 0.5077696442604065, 0.21683135628700256, 0.27721476554870605, 0.24962548911571503, 0.4879043698310852, 0.26097211241722107, 0.2738230228424072, 0.5061577558517456, 0.21573935449123383, 0.3281640410423279, 0.29710325598716736, 0.37543046474456787, 0.2577243149280548, 0.26090607047080994, 0.48044902086257935, 0.35385265946388245, 0.3211534023284912, 0.3246569037437439, 0.258273720741272, 0.516547441482544, 0.17218248546123505, 0.5041634440422058, 0.27147263288497925, 0.19390901923179626, 0.4290919601917267, 0.35024821758270264, 0.22136899828910828, 0.3895220160484314, 0.3560899794101715, 0.25423890352249146, 0.39780738949775696, 0.3175046443939209, 0.28538355231285095, 0.27122727036476135, 0.27122727036476135, 0.5424545407295227, 0.28704413771629333, 0.3061804175376892, 0.40774989128112793, 0.31745997071266174, 0.35593995451927185, 0.32707998156547546, 0.24542368948459625, 0.30411195755004883, 0.44816499948501587, 0.39158540964126587, 0.314718633890152, 0.2936890423297882, 0.5233588814735413, 0.26167944073677063, 0.21806621551513672, 0.3234960734844208, 0.46906933188438416, 0.21027246117591858, 0.3212265074253082, 0.20076656341552734, 0.48183977603912354, 0.4756876230239868, 0.2959834039211273, 0.23255838453769684, 0.5227360725402832, 0.24761182069778442, 0.24761182069778442, 0.17969892919063568, 0.494172066450119, 0.31447315216064453, 0.2858000695705414, 0.5103572607040405, 0.20414291322231293, 0.4063054621219635, 0.31261003017425537, 0.2810863256454468, 0.26215124130249023, 0.4806106388568878, 0.26215124130249023, 0.2729393243789673, 0.18195953965187073, 0.454898864030838, 0.3226381540298462, 0.2699625492095947, 0.408236026763916, 0.2660272419452667, 0.4587264358997345, 0.27455374598503113, 0.2234620302915573, 0.33994758129119873, 0.43741506338119507, 0.5089116096496582, 0.2544558048248291, 0.2544558048248291, 0.25848472118377686, 0.25848472118377686, 0.5169694423675537, 0.5117987990379333, 0.23263582587242126, 0.2791629731655121, 0.48290619254112244, 0.20121091604232788, 0.3018163740634918, 0.26461419463157654, 0.26461419463157654, 0.5292283892631531, 0.2886308431625366, 0.24052569270133972, 0.48105138540267944, 0.172663614153862, 0.345327228307724, 0.48921358585357666, 0.49314990639686584, 0.2507120966911316, 0.2565041482448578, 0.21395103633403778, 0.3209265470504761, 0.4635605812072754, 0.3197309374809265, 0.24718692898750305, 0.43257713317871094, 0.367911159992218, 0.23377688229084015, 0.3985704183578491, 0.4954841434955597, 0.22522006928920746, 0.3153080940246582, 0.24689173698425293, 0.49378347396850586, 0.24689173698425293, 0.2941260039806366, 0.3903854191303253, 0.31551697850227356, 0.36202895641326904, 0.3921980559825897, 0.24566251039505005, 0.3360646069049835, 0.21269911527633667, 0.4509221315383911, 0.3492598235607147, 0.41911178827285767, 0.23215505480766296, 0.5208744406700134, 0.17362481355667114, 0.3472496271133423, 0.27443698048591614, 0.43909919261932373, 0.28735166788101196, 0.4609948396682739, 0.23049741983413696, 0.3073298931121826, 0.45478448271751404, 0.29128190875053406, 0.2528107166290283, 0.4540332555770874, 0.26832956075668335, 0.27732840180397034, 0.3173607885837555, 0.30293530225753784, 0.3795013427734375, 0.32321226596832275, 0.44752469658851624, 0.22790609300136566, 0.31105682253837585, 0.3725750148296356, 0.3171219825744629, 0.3049740493297577, 0.30702775716781616, 0.38814878463745117, 0.4105456471443176, 0.2839096784591675, 0.304334819316864, 0.331808477640152, 0.2442479133605957, 0.4216732680797577, 0.2920825779438019, 0.4265332818031311, 0.28049200773239136, 0.3382393419742584, 0.30476412177085876, 0.3570691645145416, 0.5249752402305603, 0.34998348355293274, 0.17499174177646637, 0.27002593874931335, 0.28202706575393677, 0.4440426230430603, 0.35363999009132385, 0.17681999504566193, 0.4420499801635742, 0.22807347774505615, 0.4561469554901123, 0.22807347774505615, 0.3195541203022003, 0.40994590520858765, 0.2711753845214844, 0.21889308094978333, 0.5156615972518921, 0.26519739627838135, 0.2420291006565094, 0.2823672890663147, 0.5243963599205017, 0.3263426423072815, 0.44429782032966614, 0.23197850584983826, 0.24512262642383575, 0.3174384832382202, 0.4376519024372101, 0.2785046696662903, 0.47057685256004333, 0.2496938407421112, 0.3126024007797241, 0.3613772392272949, 0.32590460777282715, 0.19713571667671204, 0.3942714333534241, 0.19713571667671204, 0.23976856470108032, 0.30286556482315063, 0.45429834723472595, 0.49082300066947937, 0.26693883538246155, 0.2411060333251953, 0.48340779542922974, 0.22898262739181519, 0.27986764907836914, 0.26280900835990906, 0.4610420763492584, 0.27632489800453186, 0.2866930365562439, 0.2866930365562439, 0.4778217077255249, 0.30669906735420227, 0.30669906735420227, 0.4600486159324646, 0.23565468192100525, 0.31420624256134033, 0.549860954284668, 0.23440687358379364, 0.2812882363796234, 0.4688137471675873, 0.5160560607910156, 0.2580280303955078, 0.19352102279663086, 0.2469501495361328, 0.4939002990722656, 0.2469501495361328, 0.337796688079834, 0.2533475160598755, 0.506695032119751, 0.29026052355766296, 0.2817234396934509, 0.4311222434043884, 0.3239946961402893, 0.32571351528167725, 0.35063618421554565, 0.48761487007141113, 0.2925689220428467, 0.19504594802856445, 0.26501473784446716, 0.46377578377723694, 0.26501473784446716, 0.35831010341644287, 0.32182231545448303, 0.31963303685188293, 0.42698439955711365, 0.26868775486946106, 0.3040962219238281, 0.19438590109348297, 0.4859647750854492, 0.19438590109348297, 0.25554731488227844, 0.5110946297645569, 0.23661789298057556, 0.42405039072036743, 0.3254125714302063, 0.2507428526878357, 0.5390449166297913, 0.23101924359798431, 0.23101924359798431, 0.49482282996177673, 0.28275591135025024, 0.2120669186115265, 0.31309330463409424, 0.49200373888015747, 0.20127426087856293, 0.2812102138996124, 0.4113224148750305, 0.3074425160884857, 0.31639814376831055, 0.4469751715660095, 0.2368800938129425, 0.49610617756843567, 0.29766371846199036, 0.1984424740076065, 0.4460385739803314, 0.24577635526657104, 0.309496134519577, 0.29615309834480286, 0.3981477618217468, 0.30598393082618713, 0.2132355123758316, 0.49754953384399414, 0.28431403636932373, 0.2693942189216614, 0.2394615113735199, 0.4789230227470398, 0.2426316738128662, 0.30648213624954224, 0.45120978355407715, 0.2553780972957611, 0.2825905382633209, 0.4626111686229706, 0.29747530817985535, 0.2989407181739807, 0.4044491946697235, 0.20328684151172638, 0.4743359684944153, 0.31848272681236267, 0.2287503331899643, 0.48609447479248047, 0.28593793511390686, 0.3709004521369934, 0.339361310005188, 0.290160208940506, 0.21573930978775024, 0.503391683101654, 0.2876524031162262, 0.250901460647583, 0.250901460647583, 0.501802921295166, 0.22790732979774475, 0.4558146595954895, 0.22790732979774475, 0.2113846093416214, 0.5284615159034729, 0.2113846093416214, 0.40745237469673157, 0.3271965980529785, 0.2634035348892212, 0.2752571403980255, 0.550514280796051, 0.2752571403980255, 0.3583317995071411, 0.3036492168903351, 0.33838874101638794, 0.25851795077323914, 0.41075628995895386, 0.33176469802856445, 0.24803544580936432, 0.49607089161872864, 0.2976425290107727, 0.3357224762439728, 0.43525081872940063, 0.22876664996147156, 0.3025103509426117, 0.3412400782108307, 0.356941282749176, 0.23629121482372284, 0.35807207226753235, 0.4053303003311157, 0.40155526995658875, 0.2884235978126526, 0.31080129742622375, 0.22175492346286774, 0.4285264015197754, 0.3476158380508423, 0.4194834232330322, 0.2076854109764099, 0.3721887171268463, 0.16922077536582947, 0.37604615092277527, 0.45595598220825195, 0.5064849257469177, 0.20259398221969604, 0.27856671810150146, 0.29902732372283936, 0.2648527920246124, 0.43572553992271423, 0.3182613253593445, 0.5304355621337891, 0.2121742069721222, 0.24687497317790985, 0.32537439465522766, 0.4277649223804474, 0.4859362840652466, 0.23018033802509308, 0.28133153915405273, 0.2823231518268585, 0.47053855657577515, 0.18821541965007782, 0.253273069858551, 0.37465742230415344, 0.37232309579849243, 0.44887468218803406, 0.22443734109401703, 0.22443734109401703, 0.324324369430542, 0.35031190514564514, 0.3253638744354248, 0.4123167097568512, 0.366013765335083, 0.22159267961978912, 0.22847415506839752, 0.32129180431365967, 0.4498085081577301, 0.27118027210235596, 0.27118027210235596, 0.5423605442047119, 0.2215566635131836, 0.5169655680656433, 0.29540887475013733, 0.36239901185035706, 0.41178545355796814, 0.22606465220451355, 0.48506295680999756, 0.21399836242198944, 0.29959771037101746, 0.3077246844768524, 0.43710893392562866, 0.2552716135978699, 0.1960618495941162, 0.2614157795906067, 0.4574776291847229, 0.27353280782699585, 0.38777944445610046, 0.3394443392753601, 0.41582930088043213, 0.293420672416687, 0.2898204028606415, 0.2535659074783325, 0.4215790927410126, 0.32571879029273987, 0.3063928484916687, 0.36069029569625854, 0.33257198333740234, 0.22377415001392365, 0.4076981246471405, 0.3693806231021881, 0.3512018024921417, 0.27375730872154236, 0.37461525201797485, 0.31007838249206543, 0.41772568225860596, 0.27216488122940063, 0.503434419631958, 0.251717209815979, 0.251717209815979, 0.20020006597042084, 0.266933411359787, 0.533866822719574, 0.25171470642089844, 0.2844376266002655, 0.463155061006546, 0.33047235012054443, 0.3294062912464142, 0.34006670117378235, 0.42303454875946045, 0.319626122713089, 0.25852110981941223, 0.19894564151763916, 0.29841846227645874, 0.4973641335964203, 0.29450467228889465, 0.3241109848022461, 0.38176533579826355, 0.25552359223365784, 0.47910675406455994, 0.2768172323703766, 0.3483772277832031, 0.23225149512290955, 0.4645029902458191, 0.5041220784187317, 0.2800678014755249, 0.2240542471408844, 0.3071965277194977, 0.23039738833904266, 0.4607947766780853, 0.5523377060890198, 0.2761688530445099, 0.2761688530445099, 0.4765963852405548, 0.2515369653701782, 0.27801454067230225], \"Term\": [\" \\n\\n\", \" \\n\\n\", \" \\n\\n\", \"  \", \"  \", \"  \", \"1\", \"1\", \"1\", \"2\", \"2\", \"2\", \"3\", \"3\", \"3\", \"adjustment\", \"adjustment\", \"adjustment\", \"aggressive\", \"aggressive\", \"aggressive\", \"ahwatukee\", \"ahwatukee\", \"ahwatukee\", \"alterations\", \"alterations\", \"alterations\", \"amazing\", \"amazing\", \"amazing\", \"area\", \"area\", \"area\", \"asked\", \"asked\", \"asked\", \"asu\", \"asu\", \"asu\", \"bad\", \"bad\", \"bad\", \"bag\", \"bag\", \"bag\", \"bar\", \"bar\", \"bar\", \"bc\", \"bc\", \"bc\", \"bday\", \"bday\", \"bday\", \"benefits\", \"benefits\", \"benefits\", \"better\", \"better\", \"better\", \"big\", \"big\", \"big\", \"bit\", \"bit\", \"bit\", \"bite\", \"bite\", \"bite\", \"blvd\", \"blvd\", \"blvd\", \"bon\", \"bon\", \"bon\", \"breakfast\", \"breakfast\", \"breakfast\", \"brooklyn\", \"brooklyn\", \"brooklyn\", \"buffets\", \"buffets\", \"buffets\", \"busy\", \"busy\", \"busy\", \"buy\", \"buy\", \"buy\", \"car\", \"car\", \"car\", \"cared\", \"cared\", \"cared\", \"carte\", \"carte\", \"carte\", \"cash\", \"cash\", \"cash\", \"check\", \"check\", \"check\", \"cheese\", \"cheese\", \"cheese\", \"chicken\", \"chicken\", \"chicken\", \"chore\", \"chore\", \"chore\", \"clearing\", \"clearing\", \"clearing\", \"coffee\", \"coffee\", \"coffee\", \"cold\", \"cold\", \"cold\", \"comes\", \"comes\", \"comes\", \"coming\", \"coming\", \"coming\", \"couple\", \"couple\", \"couple\", \"curry\", \"curry\", \"curry\", \"day\", \"day\", \"day\", \"definitely\", \"definitely\", \"definitely\", \"delicious\", \"delicious\", \"delicious\", \"dessert\", \"dessert\", \"dessert\", \"dish\", \"dish\", \"dish\", \"donuts\", \"donuts\", \"donuts\", \"drinks\", \"drinks\", \"drinks\", \"drive\", \"drive\", \"drive\", \"eat\", \"eat\", \"eat\", \"europe\", \"europe\", \"europe\", \"everybody\", \"everybody\", \"everybody\", \"excellent\", \"excellent\", \"excellent\", \"experience\", \"experience\", \"experience\", \"find\", \"find\", \"find\", \"flops\", \"flops\", \"flops\", \"found\", \"found\", \"found\", \"fresh\", \"fresh\", \"fresh\", \"friday\", \"friday\", \"friday\", \"friendly\", \"friendly\", \"friendly\", \"frites\", \"frites\", \"frites\", \"frozen\", \"frozen\", \"frozen\", \"gamble\", \"gamble\", \"gamble\", \"generous\", \"generous\", \"generous\", \"ginger\", \"ginger\", \"ginger\", \"girlfriends\", \"girlfriends\", \"girlfriends\", \"goat\", \"goat\", \"goat\", \"going\", \"going\", \"going\", \"groups\", \"groups\", \"groups\", \"guaranteed\", \"guaranteed\", \"guaranteed\", \"having\", \"having\", \"having\", \"hour\", \"hour\", \"hour\", \"hours\", \"hours\", \"hours\", \"immediate\", \"immediate\", \"immediate\", \"imo\", \"imo\", \"imo\", \"inspired\", \"inspired\", \"inspired\", \"installed\", \"installed\", \"installed\", \"jammed\", \"jammed\", \"jammed\", \"jessica\", \"jessica\", \"jessica\", \"jewelry\", \"jewelry\", \"jewelry\", \"know\", \"know\", \"know\", \"lashes\", \"lashes\", \"lashes\", \"later\", \"later\", \"later\", \"let\", \"let\", \"let\", \"lets\", \"lets\", \"lets\", \"lies\", \"lies\", \"lies\", \"long\", \"long\", \"long\", \"looking\", \"looking\", \"looking\", \"looks\", \"looks\", \"looks\", \"loved\", \"loved\", \"loved\", \"lukewarm\", \"lukewarm\", \"lukewarm\", \"making\", \"making\", \"making\", \"mart\", \"mart\", \"mart\", \"meal\", \"meal\", \"meal\", \"menu\", \"menu\", \"menu\", \"minutes\", \"minutes\", \"minutes\", \"money\", \"money\", \"money\", \"new\", \"new\", \"new\", \"night\", \"night\", \"night\", \"ok\", \"ok\", \"ok\", \"owner\", \"owner\", \"owner\", \"pay\", \"pay\", \"pay\", \"people\", \"people\", \"people\", \"pepsi\", \"pepsi\", \"pepsi\", \"phoenix\", \"phoenix\", \"phoenix\", \"physicians\", \"physicians\", \"physicians\", \"piss\", \"piss\", \"piss\", \"pizza\", \"pizza\", \"pizza\", \"places\", \"places\", \"places\", \"plumber\", \"plumber\", \"plumber\", \"portions\", \"portions\", \"portions\", \"pretty\", \"pretty\", \"pretty\", \"previous\", \"previous\", \"previous\", \"price\", \"price\", \"price\", \"pristine\", \"pristine\", \"pristine\", \"property\", \"property\", \"property\", \"purchased\", \"purchased\", \"purchased\", \"pure\", \"pure\", \"pure\", \"quality\", \"quality\", \"quality\", \"quesadillas\", \"quesadillas\", \"quesadillas\", \"quirky\", \"quirky\", \"quirky\", \"racist\", \"racist\", \"racist\", \"raised\", \"raised\", \"raised\", \"ranges\", \"ranges\", \"ranges\", \"rapide\", \"rapide\", \"rapide\", \"reaching\", \"reaching\", \"reaching\", \"received\", \"received\", \"received\", \"recommend\", \"recommend\", \"recommend\", \"reflexology\", \"reflexology\", \"reflexology\", \"reservations\", \"reservations\", \"reservations\", \"restaurant\", \"restaurant\", \"restaurant\", \"review\", \"review\", \"review\", \"revisit\", \"revisit\", \"revisit\", \"ribs\", \"ribs\", \"ribs\", \"right\", \"right\", \"right\", \"roach\", \"roach\", \"roach\", \"rob\", \"rob\", \"rob\", \"rocks\", \"rocks\", \"rocks\", \"room\", \"room\", \"room\", \"said\", \"said\", \"said\", \"samosa\", \"samosa\", \"samosa\", \"saturday\", \"saturday\", \"saturday\", \"sauce\", \"sauce\", \"sauce\", \"scale\", \"scale\", \"scale\", \"scoop\", \"scoop\", \"scoop\", \"seen\", \"seen\", \"seen\", \"selection\", \"selection\", \"selection\", \"server\", \"server\", \"server\", \"services\", \"services\", \"services\", \"skeptical\", \"skeptical\", \"skeptical\", \"small\", \"small\", \"small\", \"smash\", \"smash\", \"smash\", \"smoking\", \"smoking\", \"smoking\", \"socializing\", \"socializing\", \"socializing\", \"soothing\", \"soothing\", \"soothing\", \"soup\", \"soup\", \"soup\", \"southwestern\", \"southwestern\", \"southwestern\", \"staff\", \"staff\", \"staff\", \"store\", \"store\", \"store\", \"sunset\", \"sunset\", \"sunset\", \"super\", \"super\", \"super\", \"sure\", \"sure\", \"sure\", \"sushi\", \"sushi\", \"sushi\", \"table\", \"table\", \"table\", \"tacos\", \"tacos\", \"tacos\", \"tasty\", \"tasty\", \"tasty\", \"terrible\", \"terrible\", \"terrible\", \"terrific\", \"terrific\", \"terrific\", \"thanks\", \"thanks\", \"thanks\", \"therapists\", \"therapists\", \"therapists\", \"think\", \"think\", \"think\", \"timely\", \"timely\", \"timely\", \"timers\", \"timers\", \"timers\", \"times\", \"times\", \"times\", \"tj\", \"tj\", \"tj\", \"told\", \"told\", \"told\", \"took\", \"took\", \"took\", \"toppings\", \"toppings\", \"toppings\", \"trap\", \"trap\", \"trap\", \"tremendous\", \"tremendous\", \"tremendous\", \"try\", \"try\", \"try\", \"turkey\", \"turkey\", \"turkey\", \"variety\", \"variety\", \"variety\", \"vast\", \"vast\", \"vast\", \"vegas\", \"vegas\", \"vegas\", \"visit\", \"visit\", \"visit\", \"wait\", \"wait\", \"wait\", \"want\", \"want\", \"want\", \"wanted\", \"wanted\", \"wanted\", \"way\", \"way\", \"way\", \"went\", \"went\", \"went\", \"whites\", \"whites\", \"whites\", \"wind\", \"wind\", \"wind\", \"wine\", \"wine\", \"wine\", \"work\", \"work\", \"work\", \"worth\", \"worth\", \"worth\", \"worthy\", \"worthy\", \"worthy\", \"years\", \"years\", \"years\", \"yesterday\", \"yesterday\", \"yesterday\", \"yikes\", \"yikes\", \"yikes\", \"yonge\", \"yonge\", \"yonge\", \"young\", \"young\", \"young\", \"zach\", \"zach\", \"zach\", \"zero\", \"zero\", \"zero\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 3, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1494825380634907688074278432\", ldavis_el1494825380634907688074278432_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1494825380634907688074278432\", ldavis_el1494825380634907688074278432_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1494825380634907688074278432\", ldavis_el1494825380634907688074278432_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "1     -0.005100 -0.000835       1        1  33.497429\n",
       "2      0.003305 -0.003813       2        1  33.454178\n",
       "0      0.001795  0.004648       3        1  33.048386, topic_info=           Term         Freq        Total Category  logprob  loglift\n",
       "453        know  1208.000000  1208.000000  Default  30.0000  30.0000\n",
       "125         bad   827.000000   827.000000  Default  29.0000  29.0000\n",
       "289         try  1437.000000  1437.000000  Default  28.0000  28.0000\n",
       "30         said  1194.000000  1194.000000  Default  27.0000  27.0000\n",
       "167        menu  1222.000000  1222.000000  Default  26.0000  26.0000\n",
       "..          ...          ...          ...      ...      ...      ...\n",
       "347       fresh   306.235138   935.551025   Topic3  -6.0938  -0.0096\n",
       "180     amazing   341.592346  1346.144287   Topic3  -5.9845  -0.2642\n",
       "192       going   321.032593  1141.997925   Topic3  -6.0466  -0.1618\n",
       "245  experience   327.434540  1286.191772   Topic3  -6.0268  -0.2610\n",
       "289         try   325.092712  1437.641846   Topic3  -6.0340  -0.3795\n",
       "\n",
       "[288 rows x 6 columns], token_table=      Topic      Freq   Term\n",
       "term                        \n",
       "1046      1  0.333601   \\n\\n\n",
       "1046      2  0.282150   \\n\\n\n",
       "1046      3  0.385052   \\n\\n\n",
       "1147      1  0.455393       \n",
       "1147      2  0.335795       \n",
       "...     ...       ...    ...\n",
       "7388      2  0.276169   zach\n",
       "7388      3  0.276169   zach\n",
       "2558      1  0.476596   zero\n",
       "2558      2  0.251537   zero\n",
       "2558      3  0.278015   zero\n",
       "\n",
       "[624 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 3, 1])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.gensim.prepare(lda, corpus, id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "The tokens seem to split pretty well into 3 or 4 groups. I see topics for the overall experience a restaurant offers, the service, and the food. It would be interesting to get user ratings of each of those subcategories and then train a model specifically to predict food rating for a review. The other thing I notice from these visualizations is that people really like mentioning the chicken in their yelp reviews, for whatever reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stretch Goals\n",
    "\n",
    "Complete one of more of these to push your score towards a three: \n",
    "* Incorporate named entity recognition into your analysis\n",
    "* Compare vectorization methods in the classification section\n",
    "* Analyze more (or all) of the yelp dataset - this one is v. hard. \n",
    "* Use a generator object on the reviews file - this would help you with the analyzing the whole dataset.\n",
    "* Incorporate any of the other yelp dataset entities in your analysis (business, users, etc.)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "u4-s1-nlp"
  },
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "0.14.5"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
