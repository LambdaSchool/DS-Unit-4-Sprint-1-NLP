{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Sprint Challenge\n",
    "## *Data Science Unit 4 Sprint 1*\n",
    "\n",
    "After a week of Natural Language Processing, you've learned some cool new stuff: how to process text, how turn text into vectors, and how to model topics from documents. Apply your newly acquired skills to one of the most famous NLP datasets out there: [Yelp](https://www.yelp.com/dataset/challenge). As part of the job selection process, some of my friends have been asked to create analysis of this dataset, so I want to empower you to have a head start.  \n",
    "\n",
    "The real dataset is massive (almost 8 gigs uncompressed). I've sampled the data for you to something more managable for the Sprint Challenge. You can analyze the full dataset as a stretch goal or after the sprint challenge. As you work on the challenge, I suggest adding notes about your findings and things you want to analyze in the future.\n",
    "\n",
    "## Challenge Objectives\n",
    "*Successfully complete these all these objectives to earn a 2. There are more details on each objective further down in the notebook.*\n",
    "* <a href=\"#p1\">Part 1</a>: Write a function to tokenize the yelp reviews\n",
    "* <a href=\"#p2\">Part 2</a>: Create a vector representation of those tokens\n",
    "* <a href=\"#p3\">Part 3</a>: Use your tokens in a classification model on yelp rating\n",
    "* <a href=\"#p4\">Part 4</a>: Estimate & Interpret a topic model of the Yelp reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed',)).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "yelp = pd.read_json('./data/review_sample.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nDuEqIyRc8YKS1q1fX0CZg</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-03-31 16:50:30</td>\n",
       "      <td>0</td>\n",
       "      <td>eZs2tpEJtXPwawvHnHZIgQ</td>\n",
       "      <td>1</td>\n",
       "      <td>BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...</td>\n",
       "      <td>10</td>\n",
       "      <td>n1LM36qNg4rqGXIcvVXv8w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eMYeEapscbKNqUDCx705hg</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-16 05:31:03</td>\n",
       "      <td>0</td>\n",
       "      <td>DoQDWJsNbU0KL1O29l_Xug</td>\n",
       "      <td>4</td>\n",
       "      <td>Came here for lunch Togo. Service was quick. S...</td>\n",
       "      <td>0</td>\n",
       "      <td>5CgjjDAic2-FAvCtiHpytA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6Q7-wkCPc1KF75jZLOTcMw</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-06-20 19:14:48</td>\n",
       "      <td>1</td>\n",
       "      <td>DDOdGU7zh56yQHmUnL1idQ</td>\n",
       "      <td>3</td>\n",
       "      <td>I've been to Vegas dozens of times and had nev...</td>\n",
       "      <td>2</td>\n",
       "      <td>BdV-cf3LScmb8kZ7iiBcMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k3zrItO4l9hwfLRwHBDc9w</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-07-13 00:33:45</td>\n",
       "      <td>4</td>\n",
       "      <td>LfTMUWnfGFMOfOIyJcwLVA</td>\n",
       "      <td>1</td>\n",
       "      <td>We went here on a night where they closed off ...</td>\n",
       "      <td>5</td>\n",
       "      <td>cZZnBqh4gAEy4CdNvJailQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6hpfRwGlOzbNv7k5eP9rsQ</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-30 02:30:01</td>\n",
       "      <td>0</td>\n",
       "      <td>zJSUdI7bJ8PNJAg4lnl_Gg</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5 to 4 stars\\n\\nNot bad for the price, $12.9...</td>\n",
       "      <td>5</td>\n",
       "      <td>n9QO4ClYAS7h9fpQwa5bhA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool                date  funny  \\\n",
       "0  nDuEqIyRc8YKS1q1fX0CZg     1 2015-03-31 16:50:30      0   \n",
       "1  eMYeEapscbKNqUDCx705hg     0 2015-12-16 05:31:03      0   \n",
       "2  6Q7-wkCPc1KF75jZLOTcMw     1 2010-06-20 19:14:48      1   \n",
       "3  k3zrItO4l9hwfLRwHBDc9w     3 2010-07-13 00:33:45      4   \n",
       "4  6hpfRwGlOzbNv7k5eP9rsQ     1 2018-06-30 02:30:01      0   \n",
       "\n",
       "                review_id  stars  \\\n",
       "0  eZs2tpEJtXPwawvHnHZIgQ      1   \n",
       "1  DoQDWJsNbU0KL1O29l_Xug      4   \n",
       "2  DDOdGU7zh56yQHmUnL1idQ      3   \n",
       "3  LfTMUWnfGFMOfOIyJcwLVA      1   \n",
       "4  zJSUdI7bJ8PNJAg4lnl_Gg      4   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...      10   \n",
       "1  Came here for lunch Togo. Service was quick. S...       0   \n",
       "2  I've been to Vegas dozens of times and had nev...       2   \n",
       "3  We went here on a night where they closed off ...       5   \n",
       "4  3.5 to 4 stars\\n\\nNot bad for the price, $12.9...       5   \n",
       "\n",
       "                  user_id  \n",
       "0  n1LM36qNg4rqGXIcvVXv8w  \n",
       "1  5CgjjDAic2-FAvCtiHpytA  \n",
       "2  BdV-cf3LScmb8kZ7iiBcMA  \n",
       "3  cZZnBqh4gAEy4CdNvJailQ  \n",
       "4  n9QO4ClYAS7h9fpQwa5bhA  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Tokenize Function\n",
    "<a id=\"#p1\"></a>\n",
    "\n",
    "Complete the function `tokenize`. Your function should\n",
    "- accept one document at a time\n",
    "- return a list of tokens\n",
    "\n",
    "You are free to use any method you have learned this week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    \n",
    "    tokens = re.sub(r'[^a-zA-Z ^0-9]', '', doc)\n",
    "    tokens = tokens.lower().split()\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Vector Representation\n",
    "<a id=\"#p2\"></a>\n",
    "1. Create a vector representation of the reviews\n",
    "2. Write a fake review and query for the 10 most similiar reviews, print the text of the reviews. Do you notice any patterns?\n",
    "    - Given the size of the dataset, it will probably be best to use a `NearestNeighbors` model for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_soup(df_column, spec_chars_remove = []):\n",
    "    \"\"\"\n",
    "    Input: dataframe column and list of specific characters to remove, \n",
    "    \n",
    "    Output: List of cleaned observations\n",
    "    \"\"\"\n",
    "    \n",
    "    soupy = [BeautifulSoup(df_column[ii], 'lxml').get_text() \n",
    "             for ii in range(df_column.shape[0])\n",
    "            ]\n",
    "    \n",
    "    for char in spec_chars_remove:\n",
    "        soupy = [soupy[ii].replace(char, ' ') \n",
    "                 for ii in range(len(soupy))\n",
    "                ]\n",
    "        \n",
    "    to_clean = ['[^A-Za-z ]+', '   ', '  ']\n",
    "    \n",
    "    for char in to_clean:\n",
    "        soupy = [re.sub(char, ' ', soupy[ii]) \n",
    "                 for ii in range(len(soupy))\n",
    "                ]\n",
    "        \n",
    "    df_feature = pd.Series([nlp(soupy[ii].lower().strip()) \n",
    "                            for ii in range(len(soupy))\n",
    "                           ])\n",
    "        \n",
    "    for row in range(df_feature.shape[0]):\n",
    "        df_feature[row] = \" \".join([token.lemma_ \n",
    "                                    for token in df_feature[row]\n",
    "                                    if len(str(token)) > 2\n",
    "                                   ])\n",
    "         \n",
    "    return df_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp['text_cleaned'] = clean_soup(yelp['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    beware fake fake fake also own small business ...\n",
       "1    come here for lunch togo service be quick staf...\n",
       "2    be vegas dozen time and have never step foot i...\n",
       "3    go here night where -PRON- close off part the ...\n",
       "4    star not bad for the price for lunch senior ge...\n",
       "Name: text_cleaned, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp['text_cleaned'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abc</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abordable</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>absinthe</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>...</th>\n",
       "      <th>zip</th>\n",
       "      <th>ziti</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zroif</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>zumba</th>\n",
       "      <th>zuzana</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaa  abandon  abc  ability  able  abordable  abruptly  absinthe  absolute  \\\n",
       "0  0.0      0.0  0.0      0.0   0.0        0.0       0.0       0.0       0.0   \n",
       "1  0.0      0.0  0.0      0.0   0.0        0.0       0.0       0.0       0.0   \n",
       "2  0.0      0.0  0.0      0.0   0.0        0.0       0.0       0.0       0.0   \n",
       "3  0.0      0.0  0.0      0.0   0.0        0.0       0.0       0.0       0.0   \n",
       "4  0.0      0.0  0.0      0.0   0.0        0.0       0.0       0.0       0.0   \n",
       "\n",
       "   absolutely  ...  zip  ziti  zombie  zone  zoo  zoom  zroif  zucchini  \\\n",
       "0         0.0  ...  0.0   0.0     0.0   0.0  0.0   0.0    0.0       0.0   \n",
       "1         0.0  ...  0.0   0.0     0.0   0.0  0.0   0.0    0.0       0.0   \n",
       "2         0.0  ...  0.0   0.0     0.0   0.0  0.0   0.0    0.0       0.0   \n",
       "3         0.0  ...  0.0   0.0     0.0   0.0  0.0   0.0    0.0       0.0   \n",
       "4         0.0  ...  0.0   0.0     0.0   0.0  0.0   0.0    0.0       0.0   \n",
       "\n",
       "   zumba  zuzana  \n",
       "0    0.0     0.0  \n",
       "1    0.0     0.0  \n",
       "2    0.0     0.0  \n",
       "3    0.0     0.0  \n",
       "4    0.0     0.0  \n",
       "\n",
       "[5 rows x 8000 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vectorize cleaned text\n",
    "stop_words = nlp.Defaults.stop_words.union(['-PRON-', 'review', 'pron', 'star', 'll','ve'])\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words = stop_words, max_features = 8000)\n",
    "\n",
    "dtm = tfidf.fit_transform(yelp['text_cleaned'])\n",
    "\n",
    "dtm = pd.DataFrame(dtm.todense(), columns = tfidf.get_feature_names())\n",
    "\n",
    "dtm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=None, n_neighbors=10, p=2, radius=1.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NearestNeighbors(n_neighbors=10, algorithm='kd_tree')\n",
    "nn.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_review = [\"\"\"This was the greatest place to have lunch, \n",
    "                    the atmosphere was great, food was great, \n",
    "                    service was outstanding. Cheap prices, \n",
    "                    great lunch deals\"\"\"]\n",
    "\n",
    "fake = tfidf.transform(fake_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stars:\n",
      " 6625    3\n",
      "6204    5\n",
      "469     4\n",
      "6311    5\n",
      "1192    5\n",
      "7594    5\n",
      "2199    3\n",
      "7486    4\n",
      "1522    5\n",
      "555     3\n",
      "Name: stars, dtype: int64\n",
      "\n",
      "                Review:\n",
      " 6625    Food and service are ok. There are much better...\n",
      "6204    旅行でラスベガスに来ましたがネイルがはげてるのが気になり、探したお店でした。\\n質問にも丁寧...\n",
      "469     O  o  thenk 6nnn  .b  cgv  xx TV cvg  9 nvehxc...\n",
      "6311    天氣很熱吃不下東西，今天我點了一個韓國冷面湯、餐後點了甜點，冰沙系列不會太甜膩，覺得店家很用...\n",
      "1192    This place is so cute! It has a great atmosphe...\n",
      "7594    Great place to hang out SteveO is awesome and ...\n",
      "2199    Came for lunch and didn't see much of a crowd ...\n",
      "7486    Their view is amazing. Go there for LUNCH TIME...\n",
      "1522    This is a great Asian food place. Great sushi,...\n",
      "555     Chingu Korean BBQ's Lunch Specials for $5.99! ...\n",
      "Name: text, dtype: object\n",
      "                Review Cleaned:\n",
      " 6625    food and service be there be much well place f...\n",
      "6204                                                     \n",
      "469     thenk nnn cgv cvg nvehxcfvvv and the vghvhridd...\n",
      "6311                                                     \n",
      "1192    this place cute have great atmosphere the staf...\n",
      "7594    great place hang out steveo awesome and make -...\n",
      "2199    come for lunch and didn see much crowd and asi...\n",
      "7486    -PRON- view amazing there for lunch time becau...\n",
      "1522    this great asian food place great sushi great ...\n",
      "555     chingu korean bbq lunch special for choice for...\n",
      "Name: text_cleaned, dtype: object\n"
     ]
    }
   ],
   "source": [
    "nearest_vectors, nearest_loc = nn.kneighbors(fake.todense())\n",
    "\n",
    "for neighbor in list(nearest_loc):\n",
    "    print(f\"\"\"Stars:\\n {yelp['stars'].iloc[neighbor]}\\n\n",
    "                Review:\\n {yelp['text'].iloc[neighbor][0:300]}\n",
    "                Review Cleaned:\\n {yelp['text_cleaned'].iloc[neighbor][0:300]}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reviews found by nearest neighbors model are all rated with 3 and higher stars, \n",
    "and they mostly use similar language to which I used in the fake review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Classification\n",
    "<a id=\"#p3\"></a>\n",
    "Your goal in this section will be to predict `stars` from the review dataset. \n",
    "\n",
    "1. Create a piepline object with a sklearn `CountVectorizer` or `TfidfVector` and any sklearn classifier. Use that pipeline to estimate a model to predict `stars`. Use the Pipeline to predict a star rating for your fake review from Part 2. \n",
    "2. Tune the entire pipeline with a GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.stats import randint, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000,), (2000,), (8000,), (2000,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(yelp['text_cleaned'], yelp['stars'],\n",
    "                                                  test_size=0.20, random_state=42, stratify = yelp['stars'])\n",
    "\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words=stop_words)\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "svd = TruncatedSVD(algorithm='randomized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:   27.4s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:   59.5s\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of  48 | elapsed:  2.9min remaining:   25.1s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.554125\n",
      "\n",
      "Best hyperparameters: \n",
      "{'clf__class_weight': 'balanced', 'clf__n_estimators': 100, 'lsi__svd__n_components': 30, 'lsi__vect__max_df': 0.85, 'lsi__vect__max_features': 5000, 'lsi__vect__min_df': 0.01, 'lsi__vect__ngram_range': (1, 2)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pipline using latent semantic indexing\n",
    "\n",
    "lsi = Pipeline([('vect', vect), \n",
    "                ('svd', svd)])\n",
    "\n",
    "pipeline = Pipeline([('lsi', lsi),\n",
    "                 ('clf', rfc)])\n",
    "\n",
    "# The pipeline puts together a bunch fit then transform,fit then predict.\n",
    "parameters = {\n",
    "    'lsi__vect__ngram_range': [(1,2)],\n",
    "    'lsi__vect__max_df': [.85, .95],\n",
    "    'lsi__vect__min_df': [.01, .1],\n",
    "    'lsi__vect__max_features': [500, 5000],\n",
    "    'lsi__svd__n_components': [30],\n",
    "    'clf__n_estimators': [ 100, 500],\n",
    "    'clf__class_weight': ['balanced'] \n",
    "}\n",
    "\n",
    "search = GridSearchCV(\n",
    "    pipeline, \n",
    "    parameters,  \n",
    "    cv=3, \n",
    "    verbose = 10,\n",
    "    n_jobs = -1\n",
    ")\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best score: {search.best_score_}\\n')\n",
    "print(f'Best hyperparameters: \\n{search.best_params_}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: \n",
      "0.5455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_pipeline = search.best_estimator_\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(f'Validation Accuracy:\\n{best_pipeline.score(X_val, y_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The model predicts my fake review would give\n",
      "the location a rating of 5 stars.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fake_review_pred = best_pipeline.predict(fake_review)\n",
    "\n",
    "print(f\"\"\"\n",
    "The model predicts my fake review would give\n",
    "the location a rating of {fake_review_pred[0]} stars.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Topic Modeling\n",
    "\n",
    "Let's find out what those yelp reviews are saying! :D\n",
    "\n",
    "1. Estimate a LDA topic model of the review text\n",
    "    - Keep the `iterations` parameter at or below 5 to reduce run time\n",
    "    - The `workers` parameter should match the number of physical cores on your machine.\n",
    "2. Create 1-2 visualizations of the results\n",
    "    - You can use the most important 3 words of a topic in relevant visualizations. Refer to yesterday's notebook to extract. \n",
    "3. In markdown, write 1-2 paragraphs of analysis on the results of your topic model\n",
    "\n",
    "__*Note*__: You can pass the DataFrame column of text reviews to gensim. You do not have to use a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import LdaMulticore\n",
    "from gensim.corpora import Dictionary\n",
    "from spacy.tokenizer import Tokenize\n",
    "import pyLDAvis.gensim\n",
    "import warnings #for LDA warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn the vocubalary of the yelp data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tokens(df_feature, addl_stop_words = ['-PRON-']):\n",
    "    \"\"\"\n",
    "    Input: Column of a dataframe/ Pandas Series, \n",
    "    stop words you'd like to add to nlp's defaults\n",
    "    \n",
    "    Output: List consisting of tokens for each observation\n",
    "    \n",
    "    Assumes: nlp object initialized as nlp\n",
    "    \"\"\"\n",
    "    \n",
    "    tokens = []\n",
    "    tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "    STOP_WORDS = nlp.Defaults.stop_words.union(addl_stop_words)\n",
    "\n",
    "    for doc in tokenizer.pipe(df_feature, batch_size=500):\n",
    "\n",
    "        doc_tokens = []\n",
    "\n",
    "        for token in doc: \n",
    "            if token.text not in STOP_WORDS:\n",
    "                doc_tokens.append(token.text.lower())\n",
    "\n",
    "        tokens.append(doc_tokens)\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [beware, fake, fake, fake, small, business, lo...\n",
       "1    [come, lunch, togo, service, quick, staff, fri...\n",
       "2    [vegas, dozen, time, step, foot, circus, circu...\n",
       "3    [night, close, street, party, good, actually, ...\n",
       "4    [bad, price, lunch, senior, pay, eat, hot, foo...\n",
       "Name: text_tokens, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp['text_tokens'] = make_tokens(yelp['text_cleaned'], stop_words)\n",
    "yelp['text_tokens'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = Dictionary(yelp['text_tokens'])\n",
    "id2word.filter_extremes(no_below=5, no_above=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a bag of words representation of the entire corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "corpus = [id2word.doc2bow(text) for text in yelp['text_tokens']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your LDA model should be ready for estimation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "lda = LdaMulticore(corpus=corpus,\n",
    "                   id2word=id2word,\n",
    "                   iterations=3,\n",
    "                   workers=6,\n",
    "                   num_topics = 3 # tuned after initial results of pyLDAvis\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Topic 0 ------\n",
      "place good food\n",
      "\n",
      "------ Topic 1 ------\n",
      "good place food\n",
      "\n",
      "------ Topic 2 ------\n",
      "good place food\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = [re.findall(r'\"([^\"]*)\"',t[1]) for t in lda.print_topics()]\n",
    "\n",
    "topics = [' '.join(t[0:3]) for t in words]\n",
    "\n",
    "for id, t in enumerate(topics): \n",
    "    print(f\"------ Topic {id} ------\")\n",
    "    print(t, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 1-2 visualizations of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el48891406055289315682781328556\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el48891406055289315682781328556_data = {\"mdsDat\": {\"x\": [0.004120621355752693, -0.0006237168839186892, -0.0034969044718340015], \"y\": [0.0014725697599807326, -0.0039041440338795585, 0.0024315742738988265], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [33.39412307739258, 33.31450271606445, 33.291378021240234]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"Freq\": [3451.0, 6467.0, 2555.0, 3801.0, 3885.0, 661.0, 2283.0, 1548.0, 1201.0, 1562.0, 1412.0, 1448.0, 1653.0, 4274.0, 895.0, 1592.0, 1600.0, 937.0, 1558.0, 1723.0, 468.0, 355.0, 1164.0, 1118.0, 667.0, 1212.0, 782.0, 1115.0, 1074.0, 1981.0, 3.6468887329101562, 21.367948532104492, 2.9459495544433594, 175.87355041503906, 31.010984420776367, 36.286617279052734, 77.4321517944336, 4.316063404083252, 8.626720428466797, 4.292764186859131, 28.090131759643555, 7.146342754364014, 3.311140775680542, 4.689244747161865, 5.6082892417907715, 4.199576377868652, 4.201315402984619, 13.491401672363281, 11.16091537475586, 6.041051864624023, 114.94087982177734, 35.22714614868164, 75.71758270263672, 22.60309410095215, 3.6711599826812744, 21.53997039794922, 10.532166481018066, 15.565113067626953, 29.764795303344727, 10.05447769165039, 218.16371154785156, 55.15988540649414, 91.302978515625, 670.1598510742188, 343.2371520996094, 62.92841339111328, 40.54092025756836, 131.98355102539062, 515.9764404296875, 248.41281127929688, 182.33924865722656, 217.2115478515625, 380.4581604003906, 656.0020751953125, 2512.344970703125, 199.4091796875, 595.0450439453125, 357.6057434082031, 290.0345458984375, 458.1833190917969, 789.8945922851562, 299.6006164550781, 625.57763671875, 623.3170776367188, 651.610595703125, 673.3081665039062, 388.5380859375, 191.3580322265625, 1505.2000732421875, 557.0149536132812, 261.3383483886719, 1300.7877197265625, 463.97930908203125, 474.1864013671875, 402.599609375, 1394.0823974609375, 1241.4034423828125, 646.494140625, 1626.226318359375, 1519.4820556640625, 635.6473388671875, 507.15313720703125, 638.30126953125, 1065.06689453125, 973.1989135742188, 713.4561157226562, 547.2227172851562, 584.7599487304688, 557.8412475585938, 653.4993896484375, 505.665771484375, 482.1914367675781, 6.888660430908203, 16.6679630279541, 2.9138402938842773, 15.540261268615723, 6.27091121673584, 23.44646644592285, 7.168842792510986, 6.66076135635376, 39.76302719116211, 8.933921813964844, 9.405203819274902, 11.746942520141602, 6.059379577636719, 17.228158950805664, 30.221349716186523, 10.678590774536133, 12.025390625, 4.166925430297852, 5.542903900146484, 22.564382553100586, 3.2129862308502197, 97.81901550292969, 7.3041815757751465, 5.920212745666504, 56.78522872924805, 8.173456192016602, 12.703740119934082, 33.96218490600586, 49.88772201538086, 35.94890213012695, 278.48291015625, 1468.21728515625, 610.3252563476562, 80.55056762695312, 73.4732894897461, 1068.3074951171875, 285.7262268066406, 200.8422393798828, 87.73082733154297, 165.1619415283203, 279.84063720703125, 198.69984436035156, 104.04047393798828, 116.49127960205078, 60.63547897338867, 615.47802734375, 1635.6180419921875, 641.3338623046875, 256.31903076171875, 92.64448547363281, 280.9515075683594, 203.1058349609375, 380.6488342285156, 1825.896484375, 1882.574951171875, 432.6921691894531, 574.8972778320312, 347.76446533203125, 1477.5621337890625, 527.2416381835938, 2135.516357421875, 1339.302001953125, 654.9249877929688, 578.0316772460938, 590.1491088867188, 1235.1375732421875, 661.0797729492188, 443.3554992675781, 471.5268859863281, 627.674560546875, 493.227783203125, 524.5059814453125, 503.7088623046875, 595.5473022460938, 1037.92041015625, 493.6923522949219, 518.3763427734375, 587.1087646484375, 632.288330078125, 533.1600952148438, 24.403972625732422, 7.30819034576416, 118.7813720703125, 9.971643447875977, 3.310579776763916, 7.046093940734863, 54.4709587097168, 221.1162567138672, 21.274545669555664, 4.163329601287842, 17.15107536315918, 4.6197428703308105, 7.37999963760376, 7.366945743560791, 177.87254333496094, 71.41650390625, 2.743771553039551, 9.134001731872559, 4.558220386505127, 59.18518829345703, 2.7274739742279053, 6.35017204284668, 7.267787456512451, 35.627197265625, 11.764266014099121, 2.703338623046875, 28.37953758239746, 5.850289821624756, 3.1386349201202393, 5.8181471824646, 298.5184631347656, 61.822837829589844, 82.6427001953125, 46.05070114135742, 21.818437576293945, 410.0171813964844, 243.3368682861328, 246.49945068359375, 227.77304077148438, 100.58260345458984, 173.11248779296875, 68.28789520263672, 938.1624145507812, 244.00550842285156, 174.28070068359375, 1521.919921875, 56.00056838989258, 372.902587890625, 187.71728515625, 387.4449462890625, 438.3340759277344, 455.00811767578125, 1481.533447265625, 230.25709533691406, 244.0402069091797, 467.5279541015625, 525.4269409179688, 487.2477111816406, 1769.4202880859375, 1844.6549072265625, 275.803955078125, 440.30963134765625, 1309.88623046875, 581.629638671875, 516.583251953125, 320.5284118652344, 559.0791625976562, 1286.8001708984375, 1819.2940673828125, 833.7418823242188, 616.5540771484375, 594.0083618164062, 1244.76025390625, 606.3723754882812, 1009.6937866210938, 429.53094482421875, 485.56536865234375, 602.1935424804688, 590.3549194335938, 521.720703125, 604.2618408203125, 558.35595703125, 481.4041748046875, 478.6372375488281, 477.0400085449219, 471.8243408203125, 472.3033447265625], \"Term\": [\"order\", \"good\", \"try\", \"service\", \"come\", \"stay\", \"love\", \"didn\", \"customer\", \"ask\", \"people\", \"definitely\", \"know\", \"great\", \"walk\", \"find\", \"staff\", \"small\", \"day\", \"wait\", \"steak\", \"wrong\", \"fry\", \"room\", \"quality\", \"bad\", \"sit\", \"use\", \"pretty\", \"look\", \"bouncy\", \"cart\", \"drastically\", \"wrong\", \"accept\", \"carpet\", \"afternoon\", \"dvd\", \"rotation\", \"useful\", \"sadly\", \"gabe\", \"kong\", \"tick\", \"pupusa\", \"americano\", \"granite\", \"remodel\", \"cracker\", \"pleasing\", \"sell\", \"pro\", \"rock\", \"trim\", \"strap\", \"shoot\", \"chew\", \"flag\", \"safe\", \"exam\", \"manager\", \"tire\", \"haven\", \"didn\", \"sit\", \"salt\", \"tech\", \"lady\", \"customer\", \"expect\", \"company\", \"actually\", \"walk\", \"find\", \"good\", \"cut\", \"definitely\", \"bit\", \"guy\", \"use\", \"look\", \"different\", \"day\", \"ask\", \"know\", \"wait\", \"sure\", \"inside\", \"time\", \"experience\", \"week\", \"like\", \"bad\", \"delicious\", \"minute\", \"great\", \"service\", \"nice\", \"place\", \"food\", \"want\", \"chicken\", \"don\", \"come\", \"order\", \"love\", \"staff\", \"price\", \"restaurant\", \"try\", \"tell\", \"drink\", \"johnny\", \"relaxing\", \"sentence\", \"poach\", \"singe\", \"risotto\", \"packaging\", \"colorful\", \"test\", \"scam\", \"pollo\", \"entertain\", \"bro\", \"chorizo\", \"slider\", \"diverse\", \"berry\", \"shadyside\", \"sever\", \"knock\", \"jumper\", \"evening\", \"mule\", \"cast\", \"email\", \"dense\", \"character\", \"honey\", \"true\", \"properly\", \"thank\", \"order\", \"people\", \"lobster\", \"crowd\", \"try\", \"worth\", \"live\", \"fall\", \"pork\", \"stay\", \"drive\", \"bean\", \"explain\", \"airport\", \"work\", \"great\", \"staff\", \"beer\", \"patio\", \"car\", \"fun\", \"location\", \"food\", \"place\", \"friend\", \"think\", \"meal\", \"time\", \"friendly\", \"good\", \"come\", \"restaurant\", \"eat\", \"know\", \"like\", \"don\", \"bad\", \"amazing\", \"want\", \"chicken\", \"tell\", \"drink\", \"price\", \"service\", \"definitely\", \"find\", \"look\", \"love\", \"nice\", \"creative\", \"task\", \"past\", \"ideal\", \"cramp\", \"addict\", \"brand\", \"steak\", \"shred\", \"ending\", \"pic\", \"peter\", \"chilli\", \"izakaya\", \"dog\", \"prefer\", \"bok\", \"udon\", \"soir\", \"vegetable\", \"crow\", \"dispenser\", \"brussel\", \"push\", \"david\", \"intrusive\", \"patty\", \"perk\", \"canopy\", \"bark\", \"quality\", \"fruit\", \"cup\", \"mango\", \"sprout\", \"small\", \"cream\", \"large\", \"spot\", \"believe\", \"outside\", \"aren\", \"love\", \"roll\", \"talk\", \"service\", \"credit\", \"vegas\", \"husband\", \"check\", \"pretty\", \"room\", \"come\", \"selection\", \"sandwich\", \"fry\", \"menu\", \"thing\", \"food\", \"place\", \"excellent\", \"table\", \"like\", \"eat\", \"recommend\", \"wasn\", \"ask\", \"time\", \"good\", \"try\", \"price\", \"wait\", \"great\", \"nice\", \"order\", \"feel\", \"need\", \"don\", \"want\", \"day\", \"look\", \"restaurant\", \"little\", \"tell\", \"think\", \"experience\", \"work\"], \"Total\": [3451.0, 6467.0, 2555.0, 3801.0, 3885.0, 661.0, 2283.0, 1548.0, 1201.0, 1562.0, 1412.0, 1448.0, 1653.0, 4274.0, 895.0, 1592.0, 1600.0, 937.0, 1558.0, 1723.0, 468.0, 355.0, 1164.0, 1118.0, 667.0, 1212.0, 782.0, 1115.0, 1074.0, 1981.0, 6.94256067276001, 41.644012451171875, 5.947044849395752, 355.77191162109375, 63.4128303527832, 74.31144714355469, 159.50070190429688, 8.912948608398438, 17.83722686767578, 8.913497924804688, 58.41912841796875, 14.864620208740234, 6.9364213943481445, 9.903800964355469, 11.884794235229492, 8.91319751739502, 8.917978286743164, 28.730655670166016, 23.777511596679688, 12.875818252563477, 245.59129333496094, 75.2795181274414, 162.346923828125, 48.54258728027344, 7.923637866973877, 46.561241149902344, 22.769025802612305, 33.66036605834961, 64.38008880615234, 21.78838539123535, 480.2772216796875, 119.82861328125, 201.13381958007812, 1548.497314453125, 782.9153442382812, 139.60739135742188, 89.15287780761719, 297.9041442871094, 1201.6829833984375, 569.0897216796875, 415.6405944824219, 499.80157470703125, 895.7830810546875, 1592.722412109375, 6467.1552734375, 461.958740234375, 1448.127685546875, 855.5174560546875, 690.517578125, 1115.14013671875, 1981.2652587890625, 716.268310546875, 1558.70849609375, 1562.89501953125, 1653.85400390625, 1723.464599609375, 962.9150390625, 450.17315673828125, 4269.5625, 1452.904296875, 633.572265625, 3845.8115234375, 1212.8165283203125, 1243.9366455078125, 1034.7501220703125, 4274.4609375, 3801.24365234375, 1786.026611328125, 5353.4560546875, 5114.798828125, 1853.6767578125, 1397.083740234375, 1901.57470703125, 3885.90234375, 3451.110107421875, 2283.90673828125, 1600.964599609375, 1796.861328125, 1771.1221923828125, 2555.548828125, 1508.8089599609375, 1446.575927734375, 13.762065887451172, 33.46087646484375, 5.900166034698486, 31.475744247436523, 12.785101890563965, 48.18559265136719, 14.750864028930664, 13.780271530151367, 82.69208526611328, 18.674840927124023, 19.680583953857422, 24.625473022460938, 12.791495323181152, 36.38399124145508, 64.0235595703125, 22.628803253173828, 25.537857055664062, 8.860118865966797, 11.805309295654297, 48.27244186401367, 6.883191108703613, 209.68634033203125, 15.764697074890137, 12.800436019897461, 122.8808364868164, 17.718612670898438, 27.564197540283203, 73.7674331665039, 109.29153442382812, 78.81123352050781, 631.911376953125, 3451.110107421875, 1412.2930908203125, 180.5133056640625, 164.55899047851562, 2555.548828125, 664.4536743164062, 463.02667236328125, 198.3677978515625, 381.0328063964844, 661.4796142578125, 464.05712890625, 236.63833618164062, 268.2402038574219, 135.95013427734375, 1526.1236572265625, 4274.4609375, 1600.964599609375, 613.3571166992188, 211.9696044921875, 686.6580810546875, 487.200927734375, 952.6136474609375, 5114.798828125, 5353.4560546875, 1109.6748046875, 1510.2415771484375, 879.27685546875, 4269.5625, 1396.9576416015625, 6467.1552734375, 3885.90234375, 1771.1221923828125, 1582.1810302734375, 1653.85400390625, 3845.8115234375, 1901.57470703125, 1212.8165283203125, 1314.53515625, 1853.6767578125, 1397.083740234375, 1508.8089599609375, 1446.575927734375, 1796.861328125, 3801.24365234375, 1448.127685546875, 1592.722412109375, 1981.2652587890625, 2283.90673828125, 1786.026611328125, 49.346466064453125, 14.78635025024414, 245.17478942871094, 20.721630096435547, 6.900609016418457, 14.790399551391602, 115.15774536132812, 468.98046875, 45.31389236450195, 8.873916625976562, 36.557376861572266, 9.860933303833008, 15.756292343139648, 15.780094146728516, 382.3770446777344, 153.82386779785156, 5.927098751068115, 19.734493255615234, 9.881406784057617, 128.5311737060547, 5.923705101013184, 13.791964530944824, 15.789499282836914, 77.75476837158203, 25.695125579833984, 5.91273307800293, 62.07362365722656, 12.82999038696289, 6.904758453369141, 12.821732521057129, 667.8923950195312, 137.16246032714844, 184.49644470214844, 102.60719299316406, 48.253883361816406, 937.608642578125, 554.550048828125, 562.5958251953125, 521.4148559570312, 227.77725219726562, 396.489990234375, 154.10302734375, 2283.90673828125, 570.8806762695312, 405.74468994140625, 3801.24365234375, 126.37565612792969, 901.77587890625, 441.750732421875, 940.2914428710938, 1074.5174560546875, 1118.306884765625, 3885.90234375, 550.3382568359375, 586.6728515625, 1164.5023193359375, 1324.1766357421875, 1235.5455322265625, 5114.798828125, 5353.4560546875, 686.8857421875, 1153.09619140625, 3845.8115234375, 1582.1810302734375, 1394.20849609375, 816.318603515625, 1562.89501953125, 4269.5625, 6467.1552734375, 2555.548828125, 1796.861328125, 1723.464599609375, 4274.4609375, 1786.026611328125, 3451.110107421875, 1171.4075927734375, 1388.53271484375, 1901.57470703125, 1853.6767578125, 1558.70849609375, 1981.2652587890625, 1771.1221923828125, 1391.9014892578125, 1508.8089599609375, 1510.2415771484375, 1452.904296875, 1526.1236572265625], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.453000009059906, 0.429500013589859, 0.39430001378059387, 0.392300009727478, 0.3815000057220459, 0.3799999952316284, 0.374099999666214, 0.3716000020503998, 0.37040001153945923, 0.3662000000476837, 0.3646000027656555, 0.3643999993801117, 0.3573000133037567, 0.3490999937057495, 0.3458000123500824, 0.3441999852657318, 0.3440999984741211, 0.3409000039100647, 0.34049999713897705, 0.3400000035762787, 0.3375000059604645, 0.33739998936653137, 0.33410000801086426, 0.33239999413490295, 0.32739999890327454, 0.32589998841285706, 0.32580000162124634, 0.3255000114440918, 0.325300008058548, 0.32339999079704285, 0.3077000081539154, 0.32100000977516174, 0.3070000112056732, 0.25929999351501465, 0.27219998836517334, 0.30000001192092896, 0.30869999527931213, 0.2827000021934509, 0.2513999938964844, 0.2678000032901764, 0.2727999985218048, 0.26350000500679016, 0.24050000309944153, 0.20980000495910645, 0.15129999816417694, 0.2567000091075897, 0.20739999413490295, 0.22450000047683716, 0.22930000722408295, 0.20730000734329224, 0.17720000445842743, 0.22519999742507935, 0.18389999866485596, 0.17759999632835388, 0.16539999842643738, 0.15690000355243683, 0.1891999989748001, 0.24130000174045563, 0.05420000106096268, 0.13809999823570251, 0.21119999885559082, 0.012799999676644802, 0.13590000569820404, 0.1324000060558319, 0.15279999375343323, -0.023600000888109207, -0.022299999371170998, 0.08060000091791153, -0.09470000118017197, -0.11699999868869781, 0.026499999687075615, 0.08349999785423279, 0.005200000014156103, -0.19750000536441803, -0.16910000145435333, -0.06669999659061432, 0.02329999953508377, -0.025800000876188278, -0.05849999934434891, -0.2669000029563904, 0.003599999938160181, -0.0017999999690800905, 0.40709999203681946, 0.40230000019073486, 0.3937000036239624, 0.39340001344680786, 0.38679999113082886, 0.37880000472068787, 0.3776000142097473, 0.37220001220703125, 0.367000013589859, 0.3619000017642975, 0.36079999804496765, 0.35899999737739563, 0.35199999809265137, 0.3515999913215637, 0.34850001335144043, 0.3481999933719635, 0.34599998593330383, 0.3447999954223633, 0.34310001134872437, 0.33869999647140503, 0.33730000257492065, 0.3366999924182892, 0.32989999651908875, 0.3280999958515167, 0.3271999955177307, 0.3255000114440918, 0.3246000111103058, 0.32350000739097595, 0.3149000108242035, 0.3142000138759613, 0.2797999978065491, 0.24449999630451202, 0.26019999384880066, 0.2922999858856201, 0.29280000925064087, 0.22699999809265137, 0.25519999861717224, 0.2639000117778778, 0.2833000123500824, 0.2632000148296356, 0.23890000581741333, 0.25099998712539673, 0.2773999869823456, 0.26510000228881836, 0.29179999232292175, 0.19110000133514404, 0.13850000500679016, 0.18440000712871552, 0.22669999301433563, 0.27149999141693115, 0.20550000667572021, 0.22419999539852142, 0.1817999929189682, 0.06909999996423721, 0.054099999368190765, 0.1573999971151352, 0.13330000638961792, 0.17159999907016754, 0.038100000470876694, 0.12479999661445618, -0.008899999782443047, 0.03400000184774399, 0.10429999977350235, 0.09220000356435776, 0.06870000064373016, -0.03660000115633011, 0.04259999841451645, 0.09279999881982803, 0.0738999992609024, 0.016300000250339508, 0.057999998331069946, 0.04259999841451645, 0.044199999421834946, -0.005100000184029341, -0.1988999992609024, 0.023099999874830246, -0.02329999953508377, -0.11710000038146973, -0.1851000040769577, -0.10970000177621841, 0.39579999446868896, 0.3952000141143799, 0.3752000033855438, 0.3684000074863434, 0.3653999865055084, 0.35839998722076416, 0.35120001435279846, 0.3479999899864197, 0.34380000829696655, 0.34310001134872437, 0.34299999475479126, 0.3416000008583069, 0.34139999747276306, 0.33809998631477356, 0.3345000147819519, 0.3325999975204468, 0.3296999931335449, 0.3294999897480011, 0.3260999917984009, 0.32440000772476196, 0.32429999113082886, 0.32429999113082886, 0.3240000009536743, 0.31940001249313354, 0.31859999895095825, 0.3172999918460846, 0.3172000050544739, 0.31459999084472656, 0.31139999628067017, 0.30970001220703125, 0.2946000099182129, 0.30300000309944153, 0.29679998755455017, 0.2987000048160553, 0.3061999976634979, 0.2727000117301941, 0.27619999647140503, 0.27469998598098755, 0.271699994802475, 0.2824999988079071, 0.2712000012397766, 0.28600001335144043, 0.2101999968290329, 0.2498999983072281, 0.2547999918460846, 0.18449999392032623, 0.28600001335144043, 0.2168000042438507, 0.24410000443458557, 0.21330000460147858, 0.20319999754428864, 0.20059999823570251, 0.1356000006198883, 0.22849999368190765, 0.22269999980926514, 0.18729999661445618, 0.17550000548362732, 0.16940000653266907, 0.03840000182390213, 0.03440000116825104, 0.1873999983072281, 0.1370999962091446, 0.02280000038444996, 0.09910000115633011, 0.10700000077486038, 0.16500000655651093, 0.07190000265836716, -0.09950000047683716, -0.16840000450611115, -0.02019999921321869, 0.03020000085234642, 0.034699998795986176, -0.13379999995231628, 0.019600000232458115, -0.12919999659061432, 0.0966000035405159, 0.04919999837875366, -0.05000000074505806, -0.04430000111460686, 0.005400000140070915, -0.08760000020265579, -0.054499998688697815, 0.03819999843835831, -0.04830000177025795, -0.05260000005364418, -0.024800000712275505, -0.0729999989271164], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -10.593099594116211, -8.82509994506836, -10.806599617004395, -6.717199802398682, -8.45259952545166, -8.295499801635742, -7.537600040435791, -10.424599647521973, -9.732099533081055, -10.430100440979004, -8.551600456237793, -9.92039966583252, -10.68970012664795, -10.341699600219727, -10.162699699401855, -10.45199966430664, -10.451600074768066, -9.284899711608887, -9.474599838256836, -10.088399887084961, -7.142600059509277, -8.325200080871582, -7.559999942779541, -8.768899917602539, -10.58650016784668, -8.817099571228027, -9.532600402832031, -9.142000198364258, -8.49370002746582, -9.579000473022461, -6.501699924468994, -7.876800060272217, -7.372799873352051, -5.379499912261963, -6.048600196838379, -7.744999885559082, -8.184700012207031, -7.004300117492676, -5.640900135040283, -6.3719000816345215, -6.681099891662598, -6.506100177764893, -5.9456000328063965, -5.4008002281188965, -4.058000087738037, -6.591599941253662, -5.4984002113342285, -6.007599830627441, -6.2170000076293945, -5.759699821472168, -5.215099811553955, -6.184500217437744, -5.448299884796143, -5.451900005340576, -5.40749979019165, -5.374800205230713, -5.924600124359131, -6.632800102233887, -4.570300102233887, -5.5644001960754395, -6.321199893951416, -4.716300010681152, -5.747099876403809, -5.725399971008301, -5.888999938964844, -4.646999835968018, -4.763000011444092, -5.41540002822876, -4.493000030517578, -4.5609002113342285, -5.432300090789795, -5.658199787139893, -5.428199768066406, -4.916200160980225, -5.006400108337402, -5.31689977645874, -5.582099914550781, -5.5157999992370605, -5.562900066375732, -5.404600143432617, -5.661099910736084, -5.708600044250488, -9.954700469970703, -9.071100234985352, -10.815099716186523, -9.141200065612793, -10.048700332641602, -8.729900360107422, -9.914899826049805, -9.98840045928955, -8.201700210571289, -9.694700241088867, -9.64330005645752, -9.420999526977539, -10.083000183105469, -9.038100242614746, -8.476099967956543, -9.516400337219238, -9.397600173950195, -10.45740032196045, -10.172100067138672, -8.768199920654297, -10.717399597167969, -7.301499843597412, -9.896200180053711, -10.106200218200684, -7.845300197601318, -9.783699989318848, -9.342700004577637, -8.359399795532227, -7.974800109863281, -8.302499771118164, -6.255199909210205, -4.592800140380859, -5.470600128173828, -7.495699882507324, -7.587699890136719, -4.910799980163574, -6.229599952697754, -6.582099914550781, -7.410299777984619, -6.777699947357178, -6.250400066375732, -6.592800140380859, -7.239799976348877, -7.126800060272217, -7.779699802398682, -5.462200164794922, -4.484799861907959, -5.421000003814697, -6.338200092315674, -7.355800151824951, -6.246399879455566, -6.570899963378906, -5.942699909210205, -4.374800205230713, -4.344200134277344, -5.814599990844727, -5.530399799346924, -6.033100128173828, -4.58650016784668, -5.6168999671936035, -4.218100070953369, -4.684700012207031, -5.400100231170654, -5.525000095367432, -5.504199981689453, -4.765699863433838, -5.390699863433838, -5.790200233459473, -5.728600025177002, -5.442599773406982, -5.683599948883057, -5.622099876403809, -5.662600040435791, -5.495100021362305, -4.939599990844727, -5.682700157165527, -5.633900165557861, -5.509399890899658, -5.435299873352051, -5.605800151824951, -8.689200401306152, -9.89490032196045, -7.106599807739258, -9.584199905395508, -10.686800003051758, -9.931400299072266, -7.886199951171875, -6.485199928283691, -8.826399803161621, -10.457599639892578, -9.041799545288086, -10.353599548339844, -9.885100364685059, -9.886899948120117, -6.7027997970581055, -7.6153998374938965, -10.874600410461426, -9.671899795532227, -10.366999626159668, -7.803199768066406, -10.880499839782715, -10.035400390625, -9.900500297546387, -8.310799598693848, -9.418800354003906, -10.889399528503418, -8.538200378417969, -10.117400169372559, -10.740099906921387, -10.122900009155273, -6.185100078582764, -7.7596001625061035, -7.469399929046631, -8.054200172424316, -8.801199913024902, -5.867700099945068, -6.389500141143799, -6.376500129699707, -6.455599784851074, -7.272900104522705, -6.730000019073486, -7.660200119018555, -5.039999961853027, -6.38670015335083, -6.723199844360352, -4.55620002746582, -7.858500003814697, -5.962600231170654, -6.64900016784668, -5.924300193786621, -5.800899982452393, -5.763599872589111, -4.583099842071533, -6.444699764251709, -6.386600017547607, -5.736400127410889, -5.619699954986572, -5.695099830627441, -4.4054999351501465, -4.363900184631348, -6.264200210571289, -5.79640007019043, -4.706200122833252, -5.518099784851074, -5.63670015335083, -6.113900184631348, -5.557600021362305, -4.723999977111816, -4.377699851989746, -5.1579999923706055, -5.459799766540527, -5.497000217437744, -4.757199764251709, -5.476399898529053, -4.9664998054504395, -5.821199893951416, -5.698599815368652, -5.48330020904541, -5.503200054168701, -5.626800060272217, -5.479899883270264, -5.558899879455566, -5.707200050354004, -5.7129998207092285, -5.716300010681152, -5.72730016708374, -5.72629976272583]}, \"token.table\": {\"Topic\": [1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3], \"Freq\": [0.4888600707054138, 0.2680845558643341, 0.23654519021511078, 0.43417230248451233, 0.2681064009666443, 0.29811832308769226, 0.27044570446014404, 0.27044570446014404, 0.4732799828052521, 0.48275649547576904, 0.2821304202079773, 0.2382434606552124, 0.30158117413520813, 0.4486939311027527, 0.25009170174598694, 0.3096151649951935, 0.3590622842311859, 0.331676185131073, 0.44877272844314575, 0.3365795612335205, 0.22438636422157288, 0.3309474289417267, 0.2271207869052887, 0.44126322865486145, 0.39861923456192017, 0.24313853681087494, 0.35766956210136414, 0.38258054852485657, 0.36526545882225037, 0.25148072838783264, 0.3119703233242035, 0.23397773504257202, 0.46795547008514404, 0.3380686342716217, 0.4394892156124115, 0.21974460780620575, 0.33422616124153137, 0.4173751175403595, 0.24781647324562073, 0.2721957564353943, 0.2853665053844452, 0.44341567158699036, 0.19578777253627777, 0.46989065408706665, 0.3524179756641388, 0.4184601902961731, 0.2992340922355652, 0.28286972641944885, 0.33743321895599365, 0.16871660947799683, 0.5061498284339905, 0.5761563181877136, 0.2880781590938568, 0.2880781590938568, 0.20840977132320404, 0.32129842042922974, 0.4689219892024994, 0.23453082144260406, 0.46906164288520813, 0.23453082144260406, 0.3166661560535431, 0.2533329129219055, 0.44333261251449585, 0.28965532779693604, 0.28965532779693604, 0.43448296189308167, 0.28689679503440857, 0.4092284142971039, 0.30437272787094116, 0.48444756865501404, 0.26913753151893616, 0.24222378432750702, 0.5042741894721985, 0.26414361596107483, 0.24013055860996246, 0.3124893605709076, 0.4687340259552002, 0.2343670129776001, 0.2902315557003021, 0.47162628173828125, 0.25395262241363525, 0.30097052454948425, 0.2860815227031708, 0.41157451272010803, 0.4831124544143677, 0.30743521451950073, 0.21959656476974487, 0.3628987967967987, 0.3528779149055481, 0.28416335582733154, 0.2538668215274811, 0.31733354926109314, 0.4442669451236725, 0.21987691521644592, 0.4672384560108185, 0.30233076214790344, 0.29027003049850464, 0.5079725980758667, 0.21770253777503967, 0.27406761050224304, 0.34457892179489136, 0.3813785910606384, 0.4378783106803894, 0.2863050401210785, 0.2766813337802887, 0.4626219868659973, 0.25233927369117737, 0.2943958044052124, 0.2898294925689697, 0.2898294925689697, 0.4347442388534546, 0.23983408510684967, 0.3227842152118683, 0.43819308280944824, 0.28370827436447144, 0.22291363775730133, 0.4863570034503937, 0.3086037337779999, 0.24530041217803955, 0.44312331080436707, 0.33762651681900024, 0.16881325840950012, 0.5064398050308228, 0.31599611043930054, 0.44360992312431335, 0.2369970828294754, 0.28726840019226074, 0.26558777689933777, 0.4498731791973114, 0.4293977618217468, 0.24132820963859558, 0.32953783869743347, 0.43077439069747925, 0.31171613931655884, 0.2554340660572052, 0.35026097297668457, 0.19458943605422974, 0.4670146405696869, 0.40161454677581787, 0.2636798322200775, 0.3348926305770874, 0.4108753800392151, 0.3411301374435425, 0.24790631234645844, 0.3810483515262604, 0.3215597867965698, 0.29744279384613037, 0.28218913078308105, 0.45150262117385864, 0.28218913078308105, 0.4326775372028351, 0.2893127501010895, 0.27768856287002563, 0.41883745789527893, 0.27084821462631226, 0.3099397122859955, 0.21751795709133148, 0.29002395272254944, 0.43503591418266296, 0.265148788690567, 0.48610612750053406, 0.265148788690567, 0.24844588339328766, 0.2876741588115692, 0.4655091166496277, 0.3355114161968231, 0.3476066291332245, 0.3165797293186188, 0.5044522285461426, 0.16815073788166046, 0.3363014757633209, 0.3332006335258484, 0.34840893745422363, 0.31868359446525574, 0.29953208565711975, 0.4288265109062195, 0.2715182900428772, 0.44878527522087097, 0.33658894896507263, 0.22439263761043549, 0.26735246181488037, 0.36531850695610046, 0.36784666776657104, 0.2115871012210846, 0.4638640284538269, 0.3255186080932617, 0.22537963092327118, 0.22537963092327118, 0.45075926184654236, 0.3248668611049652, 0.4873002767562866, 0.20304179191589355, 0.2766036093235016, 0.46736472845077515, 0.2527584731578827, 0.4589601159095764, 0.2753760814666748, 0.2753760814666748, 0.3130069375038147, 0.28680169582366943, 0.4018135666847229, 0.43578365445137024, 0.270607590675354, 0.29345110058784485, 0.383370041847229, 0.29182925820350647, 0.32486653327941895, 0.3467041850090027, 0.43244823813438416, 0.21995212137699127, 0.38312670588493347, 0.44362038373947144, 0.17643992602825165, 0.3218350410461426, 0.31159093976020813, 0.3670797348022461, 0.41187340021133423, 0.32522931694984436, 0.2624437212944031, 0.475336492061615, 0.29708531498908997, 0.2376682460308075, 0.2969813644886017, 0.3570033013820648, 0.3458591401576996, 0.29377976059913635, 0.39020439982414246, 0.3163088858127594, 0.3049483895301819, 0.3772483766078949, 0.3178335428237915, 0.2916249930858612, 0.25517186522483826, 0.45201870799064636, 0.25762078166007996, 0.3409181833267212, 0.4018884301185608, 0.2463049441576004, 0.4166658818721771, 0.33661675453186035, 0.47091683745384216, 0.2690953314304352, 0.2690953314304352, 0.38842424750328064, 0.33028432726860046, 0.2812674045562744, 0.4485321640968323, 0.22426608204841614, 0.336399108171463, 0.3261229991912842, 0.382738322019577, 0.2912648022174835, 0.41997483372688293, 0.27950048446655273, 0.3012233376502991, 0.45243510603904724, 0.19887256622314453, 0.34802699089050293, 0.2304539978504181, 0.4609079957008362, 0.29823458194732666, 0.2784375548362732, 0.2965473234653473, 0.42557936906814575, 0.2895525097846985, 0.2412937581539154, 0.4825875163078308, 0.42428117990493774, 0.27989229559898376, 0.2954418659210205, 0.16912652552127838, 0.33825305104255676, 0.5073795914649963, 0.25348392128944397, 0.25348392128944397, 0.44359683990478516, 0.21799053251743317, 0.5086445808410645, 0.2906540334224701, 0.2905628979206085, 0.435844361782074, 0.2905628979206085, 0.3107362985610962, 0.47646233439445496, 0.2278732806444168, 0.3942306935787201, 0.3567425012588501, 0.24911509454250336, 0.4324996769428253, 0.28833311796188354, 0.28833311796188354, 0.44309553503990173, 0.28532668948173523, 0.271899551153183, 0.24884650111198425, 0.31283560395240784, 0.43725883960723877, 0.33829009532928467, 0.32112857699394226, 0.34063032269477844, 0.31539589166641235, 0.33838602900505066, 0.34557044506073, 0.2980389893054962, 0.43410027027130127, 0.2678031325340271, 0.36008426547050476, 0.44872039556503296, 0.1938915252685547, 0.28028151392936707, 0.3999522924423218, 0.3201717734336853, 0.3987351059913635, 0.2962753176689148, 0.30485570430755615, 0.3121843636035919, 0.2767188251018524, 0.4106997847557068, 0.45390450954437256, 0.25401994585990906, 0.2914983034133911, 0.29237717390060425, 0.2631394565105438, 0.4483116567134857, 0.2558920979499817, 0.3957797884941101, 0.34915053844451904, 0.2839500308036804, 0.31868860125541687, 0.3964727818965912, 0.3894660174846649, 0.3111862540245056, 0.29958924651145935, 0.3171643614768982, 0.44403010606765747, 0.19029861688613892, 0.32768404483795166, 0.3226427435874939, 0.3500097692012787, 0.3616967499256134, 0.2984277904033661, 0.33930066227912903, 0.28193825483322144, 0.42537036538124084, 0.2926594614982605, 0.2824787497520447, 0.2824787497520447, 0.43632879853248596, 0.27117055654525757, 0.47454845905303955, 0.27117055654525757, 0.21209359169006348, 0.30182549357414246, 0.485368013381958, 0.3349536955356598, 0.43874216079711914, 0.23116521537303925, 0.24164852499961853, 0.3060881495475769, 0.45107725262641907, 0.2832273244857788, 0.43192169070243835, 0.2846434712409973, 0.3117695152759552, 0.233827143907547, 0.467654287815094, 0.30423083901405334, 0.30423083901405334, 0.507051408290863, 0.3282511234283447, 0.19147981703281403, 0.46502241492271423, 0.30372902750968933, 0.3517354130744934, 0.3446371853351593, 0.4659897983074188, 0.2329948991537094, 0.2329948991537094, 0.2541639804840088, 0.5083279609680176, 0.2541639804840088, 0.25405749678611755, 0.4573034942150116, 0.25405749678611755, 0.270317941904068, 0.4330335855484009, 0.29656240344047546, 0.2665386199951172, 0.2730395495891571, 0.46156686544418335, 0.3331727981567383, 0.2587207853794098, 0.40762484073638916, 0.32556769251823425, 0.3316894769668579, 0.3433765172958374, 0.4649339020252228, 0.2523926794528961, 0.27896034717559814, 0.30452510714530945, 0.45678767561912537, 0.24108238518238068, 0.5048467516899109, 0.25242337584495544, 0.25242337584495544, 0.2057751566171646, 0.33438464999198914, 0.4629940986633301, 0.2859742045402527, 0.266510009765625, 0.4476768970489502, 0.3155912458896637, 0.31415674090385437, 0.37081971764564514, 0.2689708471298218, 0.5080560445785522, 0.20919954776763916, 0.4524783492088318, 0.243642196059227, 0.278448224067688, 0.3150544762611389, 0.36982202529907227, 0.3150544762611389, 0.22828400135040283, 0.4773210883140564, 0.2697901725769043, 0.4681333005428314, 0.3141420781612396, 0.21558770537376404, 0.27501368522644043, 0.29778552055358887, 0.4274097979068756, 0.25842636823654175, 0.3344341516494751, 0.40686506032943726, 0.5045627355575562, 0.22425010800361633, 0.2803126275539398, 0.4792950749397278, 0.32523593306541443, 0.18829448521137238, 0.465982586145401, 0.2485240399837494, 0.27958956360816956, 0.45126551389694214, 0.2578659951686859, 0.28651776909828186, 0.33238285779953003, 0.25227007269859314, 0.415904700756073, 0.21419191360473633, 0.48193180561065674, 0.3212878704071045, 0.22895009815692902, 0.3525104820728302, 0.41792479157447815, 0.4682576358318329, 0.28095459938049316, 0.2483801394701004, 0.16948676109313965, 0.508460283279419, 0.3389735221862793, 0.32647210359573364, 0.27306851744651794, 0.4003952741622925, 0.25412294268608093, 0.5082458853721619, 0.25412294268608093, 0.22573061287403107, 0.45146122574806213, 0.22573061287403107, 0.47249600291252136, 0.23624800145626068, 0.3006792664527893, 0.24275116622447968, 0.3089560270309448, 0.46343404054641724, 0.23464810848236084, 0.4692962169647217, 0.23464810848236084, 0.43810611963272095, 0.2682282328605652, 0.2924965023994446, 0.3123849928379059, 0.46857750415802, 0.21866950392723083, 0.26983538269996643, 0.2932993471622467, 0.43728265166282654, 0.3036004900932312, 0.2024003267288208, 0.506000816822052, 0.3222002685070038, 0.24165019392967224, 0.43727177381515503, 0.22796092927455902, 0.31085580587387085, 0.45592185854911804, 0.3416690230369568, 0.4003836214542389, 0.2573448419570923, 0.39154645800590515, 0.42329347133636475, 0.18443500995635986, 0.23668363690376282, 0.29212304949760437, 0.4712349772453308, 0.5048186182975769, 0.25240930914878845, 0.25240930914878845, 0.40398165583610535, 0.31051546335220337, 0.28559112548828125, 0.3295475244522095, 0.28878769278526306, 0.3815813362598419, 0.3130047023296356, 0.2563188076019287, 0.42884111404418945, 0.27051976323127747, 0.27051976323127747, 0.47340959310531616, 0.4598841965198517, 0.2243337631225586, 0.325283944606781, 0.33536386489868164, 0.3479565680027008, 0.31746894121170044, 0.2902333438396454, 0.4837222397327423, 0.2297680526971817, 0.25953006744384766, 0.4399351179599762, 0.299092561006546, 0.28813183307647705, 0.3180781304836273, 0.39415788650512695, 0.30326274037361145, 0.38073378801345825, 0.31584352254867554, 0.5048566460609436, 0.30291399359703064, 0.20194266736507416, 0.35249513387680054, 0.3461712896823883, 0.30143603682518005, 0.45898887515068054, 0.25870281457901, 0.2753933370113373, 0.47381076216697693, 0.24720561504364014, 0.2884065508842468, 0.28364503383636475, 0.4574919641017914, 0.26534533500671387, 0.25552240014076233, 0.41791415214538574, 0.3263486921787262, 0.3040361702442169, 0.2533634901046753, 0.4560542702674866, 0.41071072220802307, 0.3291066288948059, 0.2600570023059845, 0.4487576186656952, 0.3365682065486908, 0.2243788093328476, 0.2650325894355774, 0.3215876519680023, 0.4136282801628113, 0.35010960698127747, 0.18672512471675873, 0.4590325951576233, 0.3904924988746643, 0.2645833194255829, 0.3446545898914337, 0.4242098331451416, 0.3471822738647461, 0.22885005176067352, 0.3431018888950348, 0.33878615498542786, 0.31828635931015015, 0.35892847180366516, 0.24867741763591766, 0.39322882890701294, 0.41194984316825867, 0.3519724905490875, 0.23517443239688873, 0.2870016396045685, 0.4029817581176758, 0.30928030610084534, 0.3280890882015228, 0.43042880296707153, 0.24230432510375977, 0.49469897150993347, 0.26702502369880676, 0.23891711235046387], \"Term\": [\"accept\", \"accept\", \"accept\", \"actually\", \"actually\", \"actually\", \"addict\", \"addict\", \"addict\", \"afternoon\", \"afternoon\", \"afternoon\", \"airport\", \"airport\", \"airport\", \"amazing\", \"amazing\", \"amazing\", \"americano\", \"americano\", \"americano\", \"aren\", \"aren\", \"aren\", \"ask\", \"ask\", \"ask\", \"bad\", \"bad\", \"bad\", \"bark\", \"bark\", \"bark\", \"bean\", \"bean\", \"bean\", \"beer\", \"beer\", \"beer\", \"believe\", \"believe\", \"believe\", \"berry\", \"berry\", \"berry\", \"bit\", \"bit\", \"bit\", \"bok\", \"bok\", \"bok\", \"bouncy\", \"bouncy\", \"bouncy\", \"brand\", \"brand\", \"brand\", \"bro\", \"bro\", \"bro\", \"brussel\", \"brussel\", \"brussel\", \"canopy\", \"canopy\", \"canopy\", \"car\", \"car\", \"car\", \"carpet\", \"carpet\", \"carpet\", \"cart\", \"cart\", \"cart\", \"cast\", \"cast\", \"cast\", \"character\", \"character\", \"character\", \"check\", \"check\", \"check\", \"chew\", \"chew\", \"chew\", \"chicken\", \"chicken\", \"chicken\", \"chilli\", \"chilli\", \"chilli\", \"chorizo\", \"chorizo\", \"chorizo\", \"colorful\", \"colorful\", \"colorful\", \"come\", \"come\", \"come\", \"company\", \"company\", \"company\", \"cracker\", \"cracker\", \"cracker\", \"cramp\", \"cramp\", \"cramp\", \"cream\", \"cream\", \"cream\", \"creative\", \"creative\", \"creative\", \"credit\", \"credit\", \"credit\", \"crow\", \"crow\", \"crow\", \"crowd\", \"crowd\", \"crowd\", \"cup\", \"cup\", \"cup\", \"customer\", \"customer\", \"customer\", \"cut\", \"cut\", \"cut\", \"david\", \"david\", \"david\", \"day\", \"day\", \"day\", \"definitely\", \"definitely\", \"definitely\", \"delicious\", \"delicious\", \"delicious\", \"dense\", \"dense\", \"dense\", \"didn\", \"didn\", \"didn\", \"different\", \"different\", \"different\", \"dispenser\", \"dispenser\", \"dispenser\", \"diverse\", \"diverse\", \"diverse\", \"dog\", \"dog\", \"dog\", \"don\", \"don\", \"don\", \"drastically\", \"drastically\", \"drastically\", \"drink\", \"drink\", \"drink\", \"drive\", \"drive\", \"drive\", \"dvd\", \"dvd\", \"dvd\", \"eat\", \"eat\", \"eat\", \"email\", \"email\", \"email\", \"ending\", \"ending\", \"ending\", \"entertain\", \"entertain\", \"entertain\", \"evening\", \"evening\", \"evening\", \"exam\", \"exam\", \"exam\", \"excellent\", \"excellent\", \"excellent\", \"expect\", \"expect\", \"expect\", \"experience\", \"experience\", \"experience\", \"explain\", \"explain\", \"explain\", \"fall\", \"fall\", \"fall\", \"feel\", \"feel\", \"feel\", \"find\", \"find\", \"find\", \"flag\", \"flag\", \"flag\", \"food\", \"food\", \"food\", \"friend\", \"friend\", \"friend\", \"friendly\", \"friendly\", \"friendly\", \"fruit\", \"fruit\", \"fruit\", \"fry\", \"fry\", \"fry\", \"fun\", \"fun\", \"fun\", \"gabe\", \"gabe\", \"gabe\", \"good\", \"good\", \"good\", \"granite\", \"granite\", \"granite\", \"great\", \"great\", \"great\", \"guy\", \"guy\", \"guy\", \"haven\", \"haven\", \"haven\", \"honey\", \"honey\", \"honey\", \"husband\", \"husband\", \"husband\", \"ideal\", \"ideal\", \"ideal\", \"inside\", \"inside\", \"inside\", \"intrusive\", \"intrusive\", \"intrusive\", \"izakaya\", \"izakaya\", \"izakaya\", \"johnny\", \"johnny\", \"johnny\", \"jumper\", \"jumper\", \"jumper\", \"knock\", \"knock\", \"knock\", \"know\", \"know\", \"know\", \"kong\", \"kong\", \"kong\", \"lady\", \"lady\", \"lady\", \"large\", \"large\", \"large\", \"like\", \"like\", \"like\", \"little\", \"little\", \"little\", \"live\", \"live\", \"live\", \"lobster\", \"lobster\", \"lobster\", \"location\", \"location\", \"location\", \"look\", \"look\", \"look\", \"love\", \"love\", \"love\", \"manager\", \"manager\", \"manager\", \"mango\", \"mango\", \"mango\", \"meal\", \"meal\", \"meal\", \"menu\", \"menu\", \"menu\", \"minute\", \"minute\", \"minute\", \"mule\", \"mule\", \"mule\", \"need\", \"need\", \"need\", \"nice\", \"nice\", \"nice\", \"order\", \"order\", \"order\", \"outside\", \"outside\", \"outside\", \"packaging\", \"packaging\", \"packaging\", \"past\", \"past\", \"past\", \"patio\", \"patio\", \"patio\", \"patty\", \"patty\", \"patty\", \"people\", \"people\", \"people\", \"perk\", \"perk\", \"perk\", \"peter\", \"peter\", \"peter\", \"pic\", \"pic\", \"pic\", \"place\", \"place\", \"place\", \"pleasing\", \"pleasing\", \"pleasing\", \"poach\", \"poach\", \"poach\", \"pollo\", \"pollo\", \"pollo\", \"pork\", \"pork\", \"pork\", \"prefer\", \"prefer\", \"prefer\", \"pretty\", \"pretty\", \"pretty\", \"price\", \"price\", \"price\", \"pro\", \"pro\", \"pro\", \"properly\", \"properly\", \"properly\", \"pupusa\", \"pupusa\", \"pupusa\", \"push\", \"push\", \"push\", \"quality\", \"quality\", \"quality\", \"recommend\", \"recommend\", \"recommend\", \"relaxing\", \"relaxing\", \"relaxing\", \"remodel\", \"remodel\", \"remodel\", \"restaurant\", \"restaurant\", \"restaurant\", \"risotto\", \"risotto\", \"risotto\", \"rock\", \"rock\", \"rock\", \"roll\", \"roll\", \"roll\", \"room\", \"room\", \"room\", \"rotation\", \"rotation\", \"rotation\", \"sadly\", \"sadly\", \"sadly\", \"safe\", \"safe\", \"safe\", \"salt\", \"salt\", \"salt\", \"sandwich\", \"sandwich\", \"sandwich\", \"scam\", \"scam\", \"scam\", \"selection\", \"selection\", \"selection\", \"sell\", \"sell\", \"sell\", \"sentence\", \"sentence\", \"sentence\", \"service\", \"service\", \"service\", \"sever\", \"sever\", \"sever\", \"shadyside\", \"shadyside\", \"shadyside\", \"shoot\", \"shoot\", \"shoot\", \"shred\", \"shred\", \"shred\", \"singe\", \"singe\", \"singe\", \"sit\", \"sit\", \"sit\", \"slider\", \"slider\", \"slider\", \"small\", \"small\", \"small\", \"soir\", \"soir\", \"soir\", \"spot\", \"spot\", \"spot\", \"sprout\", \"sprout\", \"sprout\", \"staff\", \"staff\", \"staff\", \"stay\", \"stay\", \"stay\", \"steak\", \"steak\", \"steak\", \"strap\", \"strap\", \"strap\", \"sure\", \"sure\", \"sure\", \"table\", \"table\", \"table\", \"talk\", \"talk\", \"talk\", \"task\", \"task\", \"task\", \"tech\", \"tech\", \"tech\", \"tell\", \"tell\", \"tell\", \"test\", \"test\", \"test\", \"thank\", \"thank\", \"thank\", \"thing\", \"thing\", \"thing\", \"think\", \"think\", \"think\", \"tick\", \"tick\", \"tick\", \"time\", \"time\", \"time\", \"tire\", \"tire\", \"tire\", \"trim\", \"trim\", \"trim\", \"true\", \"true\", \"true\", \"try\", \"try\", \"try\", \"udon\", \"udon\", \"udon\", \"use\", \"use\", \"use\", \"useful\", \"useful\", \"useful\", \"vegas\", \"vegas\", \"vegas\", \"vegetable\", \"vegetable\", \"vegetable\", \"wait\", \"wait\", \"wait\", \"walk\", \"walk\", \"walk\", \"want\", \"want\", \"want\", \"wasn\", \"wasn\", \"wasn\", \"week\", \"week\", \"week\", \"work\", \"work\", \"work\", \"worth\", \"worth\", \"worth\", \"wrong\", \"wrong\", \"wrong\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 3, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el48891406055289315682781328556\", ldavis_el48891406055289315682781328556_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el48891406055289315682781328556\", ldavis_el48891406055289315682781328556_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el48891406055289315682781328556\", ldavis_el48891406055289315682781328556_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "1      0.004121  0.001473       1        1  33.394123\n",
       "2     -0.000624 -0.003904       2        1  33.314503\n",
       "0     -0.003497  0.002432       3        1  33.291378, topic_info=    Category         Freq        Term        Total  loglift  logprob\n",
       "329  Default  3451.000000       order  3451.000000  30.0000  30.0000\n",
       "36   Default  6467.000000        good  6467.000000  29.0000  29.0000\n",
       "31   Default  2555.000000         try  2555.000000  28.0000  28.0000\n",
       "41   Default  3801.000000     service  3801.000000  27.0000  27.0000\n",
       "33   Default  3885.000000        come  3885.000000  26.0000  26.0000\n",
       "..       ...          ...         ...          ...      ...      ...\n",
       "323   Topic3   481.404175      little  1391.901489   0.0382  -5.7072\n",
       "429   Topic3   478.637238        tell  1508.808960  -0.0483  -5.7130\n",
       "142   Topic3   477.040009       think  1510.241577  -0.0526  -5.7163\n",
       "231   Topic3   471.824341  experience  1452.904297  -0.0248  -5.7273\n",
       "280   Topic3   472.303345        work  1526.123657  -0.0730  -5.7263\n",
       "\n",
       "[279 rows x 6 columns], token_table=      Topic      Freq      Term\n",
       "term                           \n",
       "1975      1  0.488860    accept\n",
       "1975      2  0.268085    accept\n",
       "1975      3  0.236545    accept\n",
       "105       1  0.434172  actually\n",
       "105       2  0.268106  actually\n",
       "...     ...       ...       ...\n",
       "602       2  0.430429     worth\n",
       "602       3  0.242304     worth\n",
       "640       1  0.494699     wrong\n",
       "640       2  0.267025     wrong\n",
       "640       3  0.238917     wrong\n",
       "\n",
       "[597 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 3, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "pyLDAvis.gensim.prepare(lda, corpus, id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stretch Goals\n",
    "\n",
    "Complete one of more of these to push your score towards a three: \n",
    "* Incorporate named entity recognition into your analysis\n",
    "* Compare vectorization methods in the classification section\n",
    "* Analyze more (or all) of the yelp dataset - this one is v. hard. \n",
    "* Use a generator object on the reviews file - this would help you with the analyzing the whole dataset.\n",
    "* Incorporate any of the other yelp dataset entities in your analysis (business, users, etc.)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "u4-s1-nlp"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "0.14.5"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
