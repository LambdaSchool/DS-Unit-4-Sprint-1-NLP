{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS42SC.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tesseract314/DS-Unit-4-Sprint-2-NLP/blob/master/DS42SC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QpPcbYew_ttN"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Sprint Challenge*\n",
        "\n",
        "# Natural Language Processing\n",
        "\n",
        "**Part 1 - Working with Text Data**\n",
        "Use Python string methods remove irregular whitespace from the following string:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWipfE7GPGhz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0b82b236-c817-4dce-f333-27050a669f8f"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "\n",
        "pd.set_option('max_colwidth', 800)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dtotEnsStY5o",
        "outputId": "5b54b8a6-e939-4cac-c2f3-758061ad0032",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "whitespace_string = \"\\n\\n  This is a    string   that has  \\n a lot of  extra \\n   whitespace.   \"\n",
        "\n",
        "print(whitespace_string)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  This is a    string   that has  \n",
            " a lot of  extra \n",
            "   whitespace.   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G9-MkBwasXx8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "328024f6-c642-422e-b501-8d6f13708787"
      },
      "source": [
        "# remove whitespace\n",
        "\" \".join(whitespace_string.split())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is a string that has a lot of extra whitespace.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vg1-d2aAsXLn"
      },
      "source": [
        "### Use Regular Expressions to take the dates in the following .txt file and put them into a dataframe with columns for:\n",
        "\n",
        "[RegEx dates.txt](https://raw.githubusercontent.com/ryanleeallred/datasets/master/dates.txt)\n",
        "\n",
        "- Day\n",
        "- Month\n",
        "- Year\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KWDiN4C9_0sq",
        "colab": {}
      },
      "source": [
        "# put text in string variable\n",
        "dates_text = '''\n",
        "March 8, 2015\n",
        "March 15, 2015\n",
        "March 22, 2015\n",
        "March 29, 2015\n",
        "April 5, 2015\n",
        "April 12, 2015\n",
        "April 19, 2015\n",
        "April 26, 2015\n",
        "May 3, 2015\n",
        "May 10, 2015\n",
        "May 17, 2015\n",
        "May 24, 2015\n",
        "May 31, 2015\n",
        "June 7, 2015\n",
        "June 14, 2015\n",
        "June 21, 2015\n",
        "June 28, 2015\n",
        "July 5, 2015\n",
        "July 12, 2015\n",
        "July 19, 2015\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqKsavDnPpFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# regex to extract month and day\n",
        "regex = r\"([a-zA-Z]+) (\\d+)\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaqcJjkgQNGu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "d3f27d15-bb1b-402f-904c-6c5cc1301fc4"
      },
      "source": [
        "# find all matching regex\n",
        "result = re.findall(regex, dates_text)\n",
        "result"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('March', '8'),\n",
              " ('March', '15'),\n",
              " ('March', '22'),\n",
              " ('March', '29'),\n",
              " ('April', '5'),\n",
              " ('April', '12'),\n",
              " ('April', '19'),\n",
              " ('April', '26'),\n",
              " ('May', '3'),\n",
              " ('May', '10'),\n",
              " ('May', '17'),\n",
              " ('May', '24'),\n",
              " ('May', '31'),\n",
              " ('June', '7'),\n",
              " ('June', '14'),\n",
              " ('June', '21'),\n",
              " ('June', '28'),\n",
              " ('July', '5'),\n",
              " ('July', '12'),\n",
              " ('July', '19')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCp7b5CDTKls",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "eda90575-f7b6-436f-b8aa-a3a9d08bee0e"
      },
      "source": [
        "# make dataframe\n",
        "df = pd.DataFrame(result, columns=['Month', 'Day'])\n",
        "df.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>March</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>March</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>March</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>March</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>April</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Month Day\n",
              "0  March   8\n",
              "1  March  15\n",
              "2  March  22\n",
              "3  March  29\n",
              "4  April   5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9eYOuKjSlyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# regex to find year\n",
        "regex2 = r\"\\b[0-9]{4}\\b\"\n",
        "result2 = re.findall(regex2, dates_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emKQzCJ_S5od",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "outputId": "97d1daa5-dc46-445f-b3a5-af8730e14676"
      },
      "source": [
        "# add year column and show all results in df\n",
        "df['Year'] = result2\n",
        "df"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>March</td>\n",
              "      <td>8</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>March</td>\n",
              "      <td>15</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>March</td>\n",
              "      <td>22</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>March</td>\n",
              "      <td>29</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>April</td>\n",
              "      <td>5</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>April</td>\n",
              "      <td>12</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>April</td>\n",
              "      <td>19</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>April</td>\n",
              "      <td>26</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>May</td>\n",
              "      <td>3</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>May</td>\n",
              "      <td>10</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>May</td>\n",
              "      <td>17</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>May</td>\n",
              "      <td>24</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>May</td>\n",
              "      <td>31</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>June</td>\n",
              "      <td>7</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>June</td>\n",
              "      <td>14</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>June</td>\n",
              "      <td>21</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>June</td>\n",
              "      <td>28</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>July</td>\n",
              "      <td>5</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>July</td>\n",
              "      <td>12</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>July</td>\n",
              "      <td>19</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Month Day  Year\n",
              "0   March   8  2015\n",
              "1   March  15  2015\n",
              "2   March  22  2015\n",
              "3   March  29  2015\n",
              "4   April   5  2015\n",
              "5   April  12  2015\n",
              "6   April  19  2015\n",
              "7   April  26  2015\n",
              "8     May   3  2015\n",
              "9     May  10  2015\n",
              "10    May  17  2015\n",
              "11    May  24  2015\n",
              "12    May  31  2015\n",
              "13   June   7  2015\n",
              "14   June  14  2015\n",
              "15   June  21  2015\n",
              "16   June  28  2015\n",
              "17   July   5  2015\n",
              "18   July  12  2015\n",
              "19   July  19  2015"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s4Q0dgoe_uBW"
      },
      "source": [
        "# Part 2 - Bag of Words \n",
        "\n",
        "### Use the twitter sentiment analysis dataset found at this link for the remainder of the Sprint Challenge:\n",
        "\n",
        "[Twitter Sentiment Analysis Dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/twitter_sentiment_binary.csv)\n",
        "\n",
        " ### Clean and tokenize the documents ensuring the following properties of the text:\n",
        "\n",
        "1) Text should be lowercase.\n",
        "\n",
        "2) Stopwords should be removed.\n",
        "\n",
        "3) Punctuation should be removed.\n",
        "\n",
        "4) Tweets should be tokenized at the word level. \n",
        "\n",
        "(The above don't necessarily need to be completed in that specific order.)\n",
        "\n",
        "### Output some cleaned tweets so that we can see that you made all of the above changes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xzdhyTS_3F9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "51a7994c-15ed-43ee-cac1-4c25f6ea3a59"
      },
      "source": [
        "# read data\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/twitter_sentiment_binary.csv')\n",
        "df.head()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>SentimentText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>is so sad for my APL friend.............</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>I missed the New Moon trailer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>omg its already 7:30 :O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>.. Omgaga. Im sooo  im gunna CRy. I've been at this dentist since 11.. I was suposed 2 just get a crown put on (30mins)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>i think mi bf is cheating on me!!!       T_T</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sentiment  \\\n",
              "0          0   \n",
              "1          0   \n",
              "2          1   \n",
              "3          0   \n",
              "4          0   \n",
              "\n",
              "                                                                                                                          SentimentText  \n",
              "0                                                                                              is so sad for my APL friend.............  \n",
              "1                                                                                                      I missed the New Moon trailer...  \n",
              "2                                                                                                               omg its already 7:30 :O  \n",
              "3            .. Omgaga. Im sooo  im gunna CRy. I've been at this dentist since 11.. I was suposed 2 just get a crown put on (30mins)...  \n",
              "4                                                                                          i think mi bf is cheating on me!!!       T_T  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iofDzkhqWlAx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "991dfab4-a735-484c-df1b-1c8aa61a6812"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(99989, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbxvMATbUyZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to tokenize and clean\n",
        "def tokenize_clean(doc):\n",
        "    # make tokens with split\n",
        "    tokens = doc.split()\n",
        "    # remove punctuation\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    tokens = [w.translate(table) for w in tokens]\n",
        "    # remove non-alphabetic tokens\n",
        "    tokens = [word for word in tokens if word.isalpha()]\n",
        "    # remove stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [w for w in tokens if not w in stop_words]\n",
        "    # remove short tokens and make all words lower\n",
        "    tokens = [word.lower() for word in tokens if len(word) > 2]\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TL3ErfqyUyXF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "c9fee509-a198-4c4e-e89a-029c10c612b8"
      },
      "source": [
        "# apply above function to sentiment text\n",
        "df['SentimentText'] = df['SentimentText'].apply(tokenize_clean)\n",
        "# show clean tweets\n",
        "df.head(10)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>SentimentText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[sad, apl, friend]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>[missed, new, moon, trailer]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>[omg, already]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>[omgaga, sooo, gunna, cry, ive, dentist, since, suposed, get, crown, put]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>[think, cheating]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>[worry, much]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>[juuuuuuuuuuuuuuuuussssst, chillin]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>[sunny, again, work, tomorrow, tonight]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>[handed, uniform, today, miss, already]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>[hmmmm, wonder, number]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sentiment  \\\n",
              "0          0   \n",
              "1          0   \n",
              "2          1   \n",
              "3          0   \n",
              "4          0   \n",
              "5          0   \n",
              "6          1   \n",
              "7          0   \n",
              "8          1   \n",
              "9          1   \n",
              "\n",
              "                                                               SentimentText  \n",
              "0                                                         [sad, apl, friend]  \n",
              "1                                               [missed, new, moon, trailer]  \n",
              "2                                                             [omg, already]  \n",
              "3  [omgaga, sooo, gunna, cry, ive, dentist, since, suposed, get, crown, put]  \n",
              "4                                                          [think, cheating]  \n",
              "5                                                              [worry, much]  \n",
              "6                                        [juuuuuuuuuuuuuuuuussssst, chillin]  \n",
              "7                                    [sunny, again, work, tomorrow, tonight]  \n",
              "8                                    [handed, uniform, today, miss, already]  \n",
              "9                                                    [hmmmm, wonder, number]  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q764vszGqiUh"
      },
      "source": [
        "### How should TF-IDF scores be interpreted? How are they calculated?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e2Ji7BMhqs3M"
      },
      "source": [
        "#### Your Answer Here #####\n",
        "\n",
        "The TF-IDF score accounts for the frequency of a word as it appears in a single document AND across all documents. The term frequency (tf) is equal to the number of times a specific word appears in a document divided by the total number of words in that document. The inverse document frequency (idf) is equal to the log of total documents divided by the number of times a specific word appears in all the documents. The TF-IDF score is term frequency multiplied by inverse document frequency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3iUeBKtG_uEK"
      },
      "source": [
        "# Part 3 - Document Classification\n",
        "\n",
        "1) Use Train_Test_Split to create train and test datasets.\n",
        "\n",
        "2) Vectorize the tokenized documents using your choice of vectorization method. \n",
        "\n",
        " - Stretch goal: Use both of the methods that we talked about in class.\n",
        "\n",
        "3) Create a vocabulary using the X_train dataset and transform both your X_train and X_test data using that vocabulary.\n",
        "\n",
        "4) Use your choice of binary classification algorithm to train and evaluate your model's accuracy. Report both train and test accuracies.\n",
        "\n",
        " - Stretch goal: Use an error metric other than accuracy and implement/evaluate multiple classifiers.\n",
        " - Stretch goal: Track your results in a DataFrmae and produce a visualization of the results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSUZLhmWbfUc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9202dfa6-5269-4edd-c660-c587b431b865"
      },
      "source": [
        "# make text data sklearn compatible\n",
        "documents = []\n",
        "for text in df['SentimentText'].tolist():\n",
        "  text = \" \".join(text)\n",
        "  documents.append(text)\n",
        "  \n",
        "len(documents) == len(df['SentimentText'])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGtCiO_jcHZH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "cf4e8a7d-315b-4021-fcba-dc02069eed7a"
      },
      "source": [
        "# insert compatible data into df\n",
        "df['SentimentText'] = documents\n",
        "df.head()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>SentimentText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>sad apl friend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>missed new moon trailer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>omg already</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>omgaga sooo gunna cry ive dentist since suposed get crown put</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>think cheating</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sentiment                                                  SentimentText\n",
              "0          0                                                 sad apl friend\n",
              "1          0                                        missed new moon trailer\n",
              "2          1                                                    omg already\n",
              "3          0  omgaga sooo gunna cry ive dentist since suposed get crown put\n",
              "4          0                                                 think cheating"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TX8OEgUP_3ee",
        "colab": {}
      },
      "source": [
        "# split into independent and dependent variables\n",
        "X = df['SentimentText']\n",
        "y = df['Sentiment']\n",
        "\n",
        "# train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0LrTUTodJW3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "09106ab2-1249-432d-a5fa-d4dc75238b40"
      },
      "source": [
        "# model instance\n",
        "vectorizer = CountVectorizer(min_df=.001)\n",
        "\n",
        "# fit model\n",
        "vectorizer.fit(X_train)\n",
        "\n",
        "# print feature list\n",
        "print(vectorizer.get_feature_names())"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['able', 'absolutely', 'account', 'actually', 'add', 'afternoon', 'ago', 'agree', 'ahh', 'ahhh', 'aint', 'air', 'album', 'alex', 'alexalltimelow', 'all', 'almost', 'alone', 'along', 'alot', 'already', 'alright', 'also', 'although', 'always', 'alyssamilano', 'amazing', 'amp', 'and', 'andyclemmensen', 'annoying', 'another', 'answer', 'anymore', 'anyone', 'anything', 'anyway', 'aplusk', 'app', 'apparently', 'apple', 'appreciate', 'are', 'arent', 'around', 'art', 'ashleytisdale', 'ask', 'asked', 'asking', 'asleep', 'ass', 'ate', 'aubreyoday', 'awake', 'away', 'awesome', 'awful', 'aww', 'awww', 'awwww', 'babe', 'baby', 'babygirlparis', 'back', 'backstreetboys', 'bad', 'band', 'bday', 'beach', 'beat', 'beautiful', 'bed', 'beer', 'behind', 'believe', 'best', 'bet', 'better', 'bgt', 'big', 'billyraycyrus', 'birthday', 'bit', 'bitch', 'black', 'blog', 'blue', 'body', 'boo', 'book', 'books', 'bored', 'boring', 'bought', 'bout', 'box', 'boy', 'boys', 'bradiewebbstack', 'break', 'breakfast', 'bring', 'bro', 'broke', 'broken', 'brother', 'btw', 'bummer', 'business', 'busy', 'but', 'buy', 'bye', 'cake', 'call', 'called', 'came', 'camera', 'can', 'cannot', 'cant', 'car', 'card', 'care', 'case', 'cat', 'catch', 'caught', 'cause', 'chance', 'change', 'chat', 'check', 'cheers', 'chicken', 'chocolate', 'choice', 'chris', 'city', 'class', 'clean', 'close', 'closed', 'club', 'coffee', 'cold', 'come', 'comes', 'coming', 'comment', 'company', 'completely', 'computer', 'concert', 'congrats', 'congratulations', 'cool', 'cos', 'could', 'couldnt', 'country', 'couple', 'course', 'coz', 'crap', 'crazy', 'crc', 'cream', 'cry', 'crying', 'cut', 'cute', 'cuz', 'dad', 'damn', 'dance', 'date', 'day', 'days', 'dead', 'deal', 'dear', 'decided', 'def', 'definitely', 'did', 'didnt', 'die', 'died', 'different', 'dinner', 'disappointed', 'doesnt', 'dog', 'done', 'dont', 'doubt', 'download', 'dream', 'dreams', 'dress', 'drink', 'drive', 'driving', 'drunk', 'dude', 'due', 'dunno', 'earlier', 'early', 'easy', 'eat', 'eating', 'either', 'else', 'email', 'end', 'english', 'enjoy', 'enjoyed', 'enjoying', 'enough', 'episode', 'especially', 'etc', 'even', 'evening', 'event', 'ever', 'every', 'everyone', 'everything', 'exactly', 'exam', 'exams', 'except', 'excited', 'exciting', 'experience', 'extra', 'eye', 'eyes', 'face', 'facebook', 'fact', 'fail', 'fair', 'fall', 'family', 'fan', 'fans', 'fantastic', 'far', 'fast', 'fav', 'favorite', 'feel', 'feeling', 'feels', 'fell', 'felt', 'figure', 'film', 'final', 'finally', 'find', 'fine', 'fingers', 'finish', 'finished', 'first', 'fix', 'flight', 'flu', 'fly', 'follow', 'followers', 'followfriday', 'following', 'food', 'for', 'forever', 'forget', 'forgot', 'forward', 'found', 'free', 'friday', 'friend', 'friends', 'front', 'fuck', 'fucking', 'full', 'fun', 'funny', 'future', 'game', 'games', 'gave', 'get', 'gets', 'getting', 'girl', 'girls', 'give', 'giving', 'glad', 'god', 'goes', 'goin', 'going', 'gone', 'gonna', 'good', 'goodnight', 'google', 'gorgeous', 'got', 'gotta', 'great', 'green', 'group', 'guess', 'guy', 'guys', 'had', 'haha', 'hahah', 'hahaha', 'hahahaha', 'hair', 'half', 'hand', 'hands', 'hang', 'happen', 'happened', 'happens', 'happy', 'hard', 'hasnt', 'hate', 'have', 'havent', 'haveyouever', 'head', 'hear', 'heard', 'heart', 'hehe', 'hell', 'hello', 'help', 'hes', 'hey', 'high', 'hilarious', 'hit', 'hmm', 'hold', 'home', 'hope', 'hopefully', 'hoping', 'horrible', 'hot', 'hour', 'hours', 'house', 'how', 'hows', 'hug', 'huge', 'hugs', 'huh', 'hun', 'hungry', 'hurt', 'hurts', 'ice', 'idea', 'idk', 'ill', 'imagine', 'inaperfectworld', 'indeed', 'info', 'inside', 'instead', 'interesting', 'internet', 'interview', 'invite', 'iphone', 'ipod', 'iremember', 'isnt', 'itll', 'its', 'itunes', 'ive', 'jealous', 'job', 'join', 'july', 'june', 'just', 'keep', 'keeps', 'kick', 'kid', 'kidding', 'kids', 'kill', 'kind', 'kinda', 'knew', 'kno', 'know', 'knows', 'lady', 'lame', 'laptop', 'last', 'late', 'lately', 'later', 'laugh', 'learn', 'least', 'leave', 'leaving', 'left', 'less', 'let', 'lets', 'life', 'like', 'liked', 'lil', 'line', 'link', 'list', 'listen', 'listening', 'little', 'live', 'living', 'lmao', 'lol', 'london', 'long', 'longer', 'look', 'looked', 'looking', 'looks', 'lose', 'lost', 'lot', 'lots', 'love', 'loved', 'lovely', 'loves', 'loving', 'luck', 'lucky', 'lunch', 'luv', 'mac', 'mad', 'made', 'mail', 'make', 'makes', 'making', 'man', 'many', 'mate', 'matter', 'may', 'maybe', 'mean', 'means', 'meant', 'meet', 'meeting', 'mention', 'message', 'met', 'might', 'mind', 'mine', 'minute', 'minutes', 'miss', 'missed', 'missing', 'mom', 'moment', 'monday', 'money', 'month', 'months', 'mood', 'morning', 'mothers', 'move', 'movie', 'movies', 'moving', 'much', 'mum', 'music', 'musicmonday', 'must', 'myspace', 'myweakness', 'nah', 'name', 'near', 'need', 'needed', 'needs', 'never', 'new', 'news', 'next', 'nice', 'night', 'nite', 'nobody', 'nope', 'not', 'note', 'nothing', 'now', 'number', 'office', 'ohh', 'okay', 'old', 'omg', 'once', 'one', 'ones', 'online', 'only', 'ooh', 'open', 'order', 'others', 'ouch', 'outside', 'page', 'pain', 'parents', 'part', 'party', 'pass', 'past', 'pay', 'people', 'perfect', 'person', 'phone', 'photo', 'photos', 'pic', 'pick', 'pics', 'picture', 'pictures', 'place', 'plan', 'plans', 'play', 'played', 'playing', 'please', 'pleasure', 'plus', 'point', 'pool', 'poor', 'post', 'posted', 'ppl', 'pretty', 'prob', 'probably', 'problem', 'profile', 'proud', 'put', 'question', 'quick', 'quite', 'quot', 'quoti', 'quotthe', 'quotyou', 'radio', 'rain', 'raining', 'random', 'rather', 'read', 'reading', 'ready', 'real', 'really', 'reason', 'record', 'red', 'remember', 'reply', 'rest', 'ride', 'right', 'rock', 'room', 'run', 'running', 'sad', 'sadly', 'safe', 'said', 'sat', 'saturday', 'save', 'saw', 'say', 'saying', 'says', 'scared', 'scary', 'school', 'season', 'second', 'see', 'seeing', 'seem', 'seems', 'seen', 'self', 'send', 'sending', 'sense', 'sent', 'serious', 'seriously', 'service', 'set', 'sexy', 'shall', 'shame', 'share', 'sharing', 'she', 'shes', 'shirt', 'shit', 'shop', 'shopping', 'short', 'shot', 'shouldnt', 'show', 'shows', 'shut', 'sick', 'side', 'sigh', 'sign', 'silly', 'since', 'sing', 'single', 'sir', 'sis', 'sister', 'site', 'sitting', 'sleep', 'sleeping', 'slow', 'small', 'smile', 'sold', 'someone', 'something', 'sometimes', 'somewhere', 'son', 'song', 'songs', 'soo', 'soon', 'sooo', 'soooo', 'sorry', 'sort', 'sound', 'sounds', 'speak', 'special', 'spend', 'squarespace', 'star', 'start', 'started', 'starting', 'stay', 'still', 'stop', 'store', 'story', 'stuck', 'study', 'studying', 'stuff', 'stupid', 'suck', 'sucks', 'summer', 'sun', 'sunday', 'sunny', 'sunshine', 'super', 'support', 'supposed', 'sure', 'sweet', 'sweetie', 'take', 'taken', 'takes', 'taking', 'talk', 'talking', 'tea', 'team', 'tell', 'test', 'text', 'thank', 'thanks', 'that', 'thats', 'the', 'then', 'there', 'theres', 'they', 'theyre', 'thing', 'things', 'think', 'thinking', 'this', 'tho', 'though', 'thought', 'three', 'thursday', 'thx', 'ticket', 'tickets', 'til', 'till', 'time', 'times', 'tired', 'today', 'together', 'told', 'tomorrow', 'tonight', 'too', 'took', 'top', 'totally', 'touch', 'tour', 'town', 'train', 'tried', 'trip', 'true', 'try', 'trying', 'tuesday', 'turn', 'tweet', 'tweeting', 'tweets', 'twitter', 'two', 'type', 'ugh', 'understand', 'unfortunately', 'unless', 'update', 'updates', 'upset', 'use', 'used', 'using', 'usually', 'vegas', 'version', 'very', 'via', 'video', 'vip', 'visit', 'voice', 'vote', 'wait', 'waiting', 'wake', 'walk', 'wanna', 'want', 'wanted', 'wants', 'warm', 'was', 'wasnt', 'watch', 'watched', 'watching', 'water', 'way', 'wear', 'weather', 'web', 'website', 'wedding', 'wednesday', 'week', 'weekend', 'weeks', 'weird', 'welcome', 'well', 'went', 'were', 'weve', 'what', 'whatever', 'whats', 'when', 'where', 'white', 'who', 'whole', 'why', 'wife', 'will', 'win', 'wine', 'wish', 'wit', 'with', 'without', 'woke', 'woman', 'wonder', 'wonderful', 'wondering', 'wont', 'word', 'words', 'work', 'worked', 'working', 'works', 'world', 'worries', 'worry', 'worse', 'worst', 'worth', 'would', 'wouldnt', 'wow', 'write', 'writing', 'wrong', 'wtf', 'xoxo', 'xxx', 'yall', 'yay', 'yea', 'yeah', 'year', 'years', 'yep', 'yes', 'yesterday', 'yet', 'you', 'youd', 'youll', 'young', 'youquot', 'your', 'youre', 'youtube', 'youve', 'yummy', 'yup']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNm08EMqfQxW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "ed796cf3-5a9d-4906-e470-1196c1415f2d"
      },
      "source": [
        "# transform train data\n",
        "train_counts = vectorizer.transform(X_train)\n",
        "\n",
        "# create dataframe with vectors\n",
        "X_train_vec = pd.DataFrame(train_counts.toarray(), columns=vectorizer.get_feature_names())\n",
        "\n",
        "# see dataframe\n",
        "print(X_train_vec.shape)\n",
        "X_train_vec.head()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(79991, 920)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>able</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>account</th>\n",
              "      <th>actually</th>\n",
              "      <th>add</th>\n",
              "      <th>afternoon</th>\n",
              "      <th>ago</th>\n",
              "      <th>agree</th>\n",
              "      <th>ahh</th>\n",
              "      <th>ahhh</th>\n",
              "      <th>...</th>\n",
              "      <th>youd</th>\n",
              "      <th>youll</th>\n",
              "      <th>young</th>\n",
              "      <th>youquot</th>\n",
              "      <th>your</th>\n",
              "      <th>youre</th>\n",
              "      <th>youtube</th>\n",
              "      <th>youve</th>\n",
              "      <th>yummy</th>\n",
              "      <th>yup</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 920 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   able  absolutely  account  actually  add  afternoon  ago  agree  ahh  ahhh  \\\n",
              "0     0           0        0         0    0          0    0      0    0     0   \n",
              "1     0           0        0         0    0          0    0      0    0     0   \n",
              "2     0           0        0         0    0          0    0      0    0     0   \n",
              "3     0           0        0         0    0          0    0      0    0     0   \n",
              "4     0           0        0         0    0          0    0      0    0     0   \n",
              "\n",
              "   ...  youd  youll  young  youquot  your  youre  youtube  youve  yummy  yup  \n",
              "0  ...     0      0      0        0     0      0        0      0      0    0  \n",
              "1  ...     0      0      0        0     0      0        0      0      0    0  \n",
              "2  ...     0      0      0        0     0      0        0      0      0    0  \n",
              "3  ...     0      0      0        0     0      0        0      0      0    0  \n",
              "4  ...     0      0      0        0     0      0        0      0      0    0  \n",
              "\n",
              "[5 rows x 920 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrXyL2wVgEG7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "2cbcdd6e-e228-48e6-e1bd-716019be9a14"
      },
      "source": [
        "# transform test data\n",
        "test_counts = vectorizer.transform(X_test)\n",
        "\n",
        "# create df with vecs\n",
        "X_test_vec = pd.DataFrame(test_counts.toarray(), columns=vectorizer.get_feature_names())\n",
        "\n",
        "# see dataframe\n",
        "print(X_test_vec.shape)\n",
        "X_test_vec.head()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(19998, 920)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>able</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>account</th>\n",
              "      <th>actually</th>\n",
              "      <th>add</th>\n",
              "      <th>afternoon</th>\n",
              "      <th>ago</th>\n",
              "      <th>agree</th>\n",
              "      <th>ahh</th>\n",
              "      <th>ahhh</th>\n",
              "      <th>...</th>\n",
              "      <th>youd</th>\n",
              "      <th>youll</th>\n",
              "      <th>young</th>\n",
              "      <th>youquot</th>\n",
              "      <th>your</th>\n",
              "      <th>youre</th>\n",
              "      <th>youtube</th>\n",
              "      <th>youve</th>\n",
              "      <th>yummy</th>\n",
              "      <th>yup</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 920 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   able  absolutely  account  actually  add  afternoon  ago  agree  ahh  ahhh  \\\n",
              "0     0           0        0         0    0          0    0      0    0     0   \n",
              "1     0           0        0         0    0          0    0      0    0     0   \n",
              "2     0           0        0         0    0          0    0      0    0     0   \n",
              "3     0           0        0         0    0          0    0      0    0     0   \n",
              "4     0           0        0         0    0          0    0      0    0     0   \n",
              "\n",
              "   ...  youd  youll  young  youquot  your  youre  youtube  youve  yummy  yup  \n",
              "0  ...     0      0      0        0     0      0        0      0      0    0  \n",
              "1  ...     0      0      0        0     0      0        0      0      0    0  \n",
              "2  ...     0      0      0        0     0      0        0      0      0    0  \n",
              "3  ...     0      0      0        0     0      0        0      0      0    0  \n",
              "4  ...     0      0      0        0     0      0        0      0      0    0  \n",
              "\n",
              "[5 rows x 920 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwG6XjloggMv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d5e75e87-7079-4ab2-c56e-8f8cd1539050"
      },
      "source": [
        "# make and fit model\n",
        "mnb = MultinomialNB().fit(X_train_vec, y_train)\n",
        "\n",
        "# get train and test predictions\n",
        "train_preds = mnb.predict(X_train_vec)\n",
        "test_preds = mnb.predict(X_test_vec)\n",
        "\n",
        "train_acc = accuracy_score(y_train, train_preds)\n",
        "test_acc = accuracy_score(y_test, test_preds)\n",
        "\n",
        "print('Train Accuracy:', train_acc)\n",
        "print('Test Accuracy:', test_acc)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.734895175707267\n",
            "Test Accuracy: 0.7282228222822282\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sorF95UO_uGx"
      },
      "source": [
        "# Part 4 -  Word2Vec\n",
        "\n",
        "1) Fit a Word2Vec model on your cleaned/tokenized twitter dataset. \n",
        "\n",
        "2) Display the 10 words that are most similar to the word \"twitter\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DYno4d4N-LHR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "baef10fb-336a-43cb-a79b-ce420645135d"
      },
      "source": [
        "# put data back in tokenized and list form\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/twitter_sentiment_binary.csv')\n",
        "\n",
        "def tokenize_clean(doc):\n",
        "    # make tokens with split\n",
        "    tokens = doc.split()\n",
        "    # remove punctuation\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    tokens = [w.translate(table) for w in tokens]\n",
        "    # remove non-alphabetic tokens\n",
        "    tokens = [word for word in tokens if word.isalpha()]\n",
        "    # remove stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [w for w in tokens if not w in stop_words]\n",
        "    # remove short tokens and make all words lower\n",
        "    tokens = [word.lower() for word in tokens if len(word) > 2]\n",
        "    return tokens\n",
        "  \n",
        "df['SentimentText'] = df['SentimentText'].apply(tokenize_clean)\n",
        "df.head(10)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>SentimentText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[sad, apl, friend]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>[missed, new, moon, trailer]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>[omg, already]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>[omgaga, sooo, gunna, cry, ive, dentist, since, suposed, get, crown, put]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>[think, cheating]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>[worry, much]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>[juuuuuuuuuuuuuuuuussssst, chillin]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>[sunny, again, work, tomorrow, tonight]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>[handed, uniform, today, miss, already]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>[hmmmm, wonder, number]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sentiment  \\\n",
              "0          0   \n",
              "1          0   \n",
              "2          1   \n",
              "3          0   \n",
              "4          0   \n",
              "5          0   \n",
              "6          1   \n",
              "7          0   \n",
              "8          1   \n",
              "9          1   \n",
              "\n",
              "                                                               SentimentText  \n",
              "0                                                         [sad, apl, friend]  \n",
              "1                                               [missed, new, moon, trailer]  \n",
              "2                                                             [omg, already]  \n",
              "3  [omgaga, sooo, gunna, cry, ive, dentist, since, suposed, get, crown, put]  \n",
              "4                                                          [think, cheating]  \n",
              "5                                                              [worry, much]  \n",
              "6                                        [juuuuuuuuuuuuuuuuussssst, chillin]  \n",
              "7                                    [sunny, again, work, tomorrow, tonight]  \n",
              "8                                    [handed, uniform, today, miss, already]  \n",
              "9                                                    [hmmmm, wonder, number]  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YO4d0TI4jVgW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model instance\n",
        "wv_model = Word2Vec(df['SentimentText'], min_count=5, size=300, window=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChV76LYQjftu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "e1fba28e-d29b-4508-9a99-6a6460cf8bed"
      },
      "source": [
        "# 10 words most similar to 'twitter'\n",
        "wv_model.wv.most_similar('twitter')"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('awalliewall', 0.8500722646713257),\n",
              " ('grats', 0.8236775398254395),\n",
              " ('list', 0.8124279379844666),\n",
              " ('aboard', 0.8105133175849915),\n",
              " ('peterfacinelli', 0.8083851337432861),\n",
              " ('bonniestwit', 0.8045743107795715),\n",
              " ('world', 0.8033061623573303),\n",
              " ('brittanyasnow', 0.8031395673751831),\n",
              " ('updates', 0.8026084899902344),\n",
              " ('facebook', 0.7961694598197937)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GehBGlqpj6Mj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}