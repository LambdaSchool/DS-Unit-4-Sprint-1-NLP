{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS42SC.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ruwai/DS-Unit-4-Sprint-2-NLP/blob/master/DS42SC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QpPcbYew_ttN"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Sprint Challenge*\n",
        "\n",
        "# Natural Language Processing\n",
        "\n",
        "**Part 1 - Working with Text Data**\n",
        "Use Python string methods remove irregular whitespace from the following string:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dtotEnsStY5o",
        "outputId": "00edf2eb-3fa8-4417-c8d6-408aa5697438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "whitespace_string = \"\\n\\n  This is a    string   that has  \\n a lot of  extra \\n   whitespace.   \"\n",
        "\n",
        "print(whitespace_string)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  This is a    string   that has  \n",
            " a lot of  extra \n",
            "   whitespace.   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G9-MkBwasXx8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1eecdf3-2bd2-4c2d-a5cd-af0890996f61"
      },
      "source": [
        "##### Your Code Here #####\n",
        "\n",
        "new_string = \" \".join(whitespace_string.split())\n",
        "print(new_string)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is a string that has a lot of extra whitespace.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vg1-d2aAsXLn"
      },
      "source": [
        "### Use Regular Expressions to take the dates in the following .txt file and put them into a dataframe with columns for:\n",
        "\n",
        "[RegEx dates.txt](https://raw.githubusercontent.com/ryanleeallred/datasets/master/dates.txt)\n",
        "\n",
        "- Day\n",
        "- Month\n",
        "- Year\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KWDiN4C9_0sq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9abbc40c-a06e-4b37-b62f-6929cdc845dd"
      },
      "source": [
        "##### Your Code Here #####\n",
        "import re\n",
        "\n",
        "dates = \"\"\"\n",
        "March 8, 2015\n",
        "March 15, 2015\n",
        "March 22, 2015\n",
        "March 29, 2015\n",
        "April 5, 2015\n",
        "April 12, 2015\n",
        "April 19, 2015\n",
        "April 26, 2015\n",
        "May 3, 2015\n",
        "May 10, 2015\n",
        "May 17, 2015\n",
        "May 24, 2015\n",
        "May 31, 2015\n",
        "June 7, 2015\n",
        "June 14, 2015\n",
        "June 21, 2015\n",
        "June 28, 2015\n",
        "July 5, 2015\n",
        "July 12, 2015\n",
        "July 19, 2015\n",
        "\"\"\"\n",
        "\n",
        "regex = r\"([a-zA-Z]+) (\\d+)(..)(\\d+)\"\n",
        "search_result = re.findall(regex, dates)\n",
        "print(search_result)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('March', '8', ', ', '2015'), ('March', '15', ', ', '2015'), ('March', '22', ', ', '2015'), ('March', '29', ', ', '2015'), ('April', '5', ', ', '2015'), ('April', '12', ', ', '2015'), ('April', '19', ', ', '2015'), ('April', '26', ', ', '2015'), ('May', '3', ', ', '2015'), ('May', '10', ', ', '2015'), ('May', '17', ', ', '2015'), ('May', '24', ', ', '2015'), ('May', '31', ', ', '2015'), ('June', '7', ', ', '2015'), ('June', '14', ', ', '2015'), ('June', '21', ', ', '2015'), ('June', '28', ', ', '2015'), ('July', '5', ', ', '2015'), ('July', '12', ', ', '2015'), ('July', '19', ', ', '2015')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqE3RkFmSeMX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "df129bd5-3539-45fe-bc1e-22cbadc6cf6e"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(search_result, columns=['Month', 'Day', 'Commas', 'Year'])\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Commas</th>\n",
              "      <th>Year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>March</td>\n",
              "      <td>8</td>\n",
              "      <td>,</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>March</td>\n",
              "      <td>15</td>\n",
              "      <td>,</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>March</td>\n",
              "      <td>22</td>\n",
              "      <td>,</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>March</td>\n",
              "      <td>29</td>\n",
              "      <td>,</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>April</td>\n",
              "      <td>5</td>\n",
              "      <td>,</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Month Day Commas  Year\n",
              "0  March   8     ,   2015\n",
              "1  March  15     ,   2015\n",
              "2  March  22     ,   2015\n",
              "3  March  29     ,   2015\n",
              "4  April   5     ,   2015"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UevfiHx7SeMZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "235fd824-b89a-45f9-952a-49b31a8056c3"
      },
      "source": [
        "df.drop(columns=['Commas'],inplace=True)\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>March</td>\n",
              "      <td>8</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>March</td>\n",
              "      <td>15</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>March</td>\n",
              "      <td>22</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>March</td>\n",
              "      <td>29</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>April</td>\n",
              "      <td>5</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Month Day  Year\n",
              "0  March   8  2015\n",
              "1  March  15  2015\n",
              "2  March  22  2015\n",
              "3  March  29  2015\n",
              "4  April   5  2015"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s4Q0dgoe_uBW"
      },
      "source": [
        "# Part 2 - Bag of Words \n",
        "\n",
        "### Use the twitter sentiment analysis dataset found at this link for the remainder of the Sprint Challenge:\n",
        "\n",
        "[Twitter Sentiment Analysis Dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/twitter_sentiment_binary.csv)\n",
        "\n",
        " ### Clean and tokenize the documents ensuring the following properties of the text:\n",
        "\n",
        "1) Text should be lowercase.\n",
        "\n",
        "2) Stopwords should be removed.\n",
        "\n",
        "3) Punctuation should be removed.\n",
        "\n",
        "4) Tweets should be tokenized at the word level. \n",
        "\n",
        "(The above don't necessarily need to be completed in that specific order.)\n",
        "\n",
        "### Output some cleaned tweets so that we can see that you made all of the above changes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xzdhyTS_3F9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c542e989-ba51-4af8-b73b-6a1cbd08f441"
      },
      "source": [
        "##### Your Code Here #####\n",
        "url = 'https://raw.githubusercontent.com/ryanleeallred/datasets/master/twitter_sentiment_binary.csv'\n",
        "\n",
        "df = pd.read_csv(url)\n",
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>SentimentText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>is so sad for my APL frie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>I missed the New Moon trail...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>omg its already 7:30 :O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sentiment                                      SentimentText\n",
              "0          0                       is so sad for my APL frie...\n",
              "1          0                     I missed the New Moon trail...\n",
              "2          1                            omg its already 7:30 :O\n",
              "3          0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
              "4          0           i think mi bf is cheating on me!!!   ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pnim01RoSeMf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "61e85482-9ff4-474a-e8d3-2a2c6cddaa6e"
      },
      "source": [
        "# wow that is messy\n",
        "\n",
        "df['SentimentText'][3]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"          .. Omgaga. Im sooo  im gunna CRy. I've been at this dentist since 11.. I was suposed 2 just get a crown put on (30mins)...\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tdcy9DOSeMi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6be17cda-21af-419d-d3c5-088ec2545f4d"
      },
      "source": [
        "import string\n",
        "\n",
        "def apply_changes(ugly_string):\n",
        "    \n",
        "    new_string = ugly_string.lower()\n",
        "    new_string = \" \".join(new_string.split())\n",
        "    for p in string.punctuation:\n",
        "        new_string = new_string.replace(p, '')\n",
        "\n",
        "    return new_string\n",
        "\n",
        "df['SentimentText'] = df['SentimentText'].apply(apply_changes)\n",
        "df['SentimentText'][3]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' omgaga im sooo im gunna cry ive been at this dentist since 11 i was suposed 2 just get a crown put on 30mins'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7QTal0iSeMl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "21da7e7d-50fe-4723-a0b9-5a380f0dfe87"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>SentimentText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>is so sad for my apl friend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>i missed the new moon trailer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>omg its already 730 o</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>omgaga im sooo im gunna cry ive been at this ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>i think mi bf is cheating on me tt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sentiment                                      SentimentText\n",
              "0          0                        is so sad for my apl friend\n",
              "1          0                      i missed the new moon trailer\n",
              "2          1                              omg its already 730 o\n",
              "3          0   omgaga im sooo im gunna cry ive been at this ...\n",
              "4          0                 i think mi bf is cheating on me tt"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYhhwHngSeMn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a1b1febd-249c-455e-e690-30cdc8a7f403"
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLrVtgjASeMp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b3ed4563-7d3e-4c2c-fe3f-5a9a84b37def"
      },
      "source": [
        "#it's ready\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop = stopwords.words('english')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1HVhnYEVG3P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "98ac0087-6fe1-4e5c-84c6-8ce0cf229970"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvt47oozSeMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['SentimentTextTokens'] = df.apply(lambda x: nltk.word_tokenize(x['SentimentText']), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orduMezYVA52",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "0d0f8189-df12-46ac-eed6-d74992393295"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>SentimentText</th>\n",
              "      <th>SentimentTextTokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>is so sad for my apl friend</td>\n",
              "      <td>[is, so, sad, for, my, apl, friend]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>i missed the new moon trailer</td>\n",
              "      <td>[i, missed, the, new, moon, trailer]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>omg its already 730 o</td>\n",
              "      <td>[omg, its, already, 730, o]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>omgaga im sooo im gunna cry ive been at this ...</td>\n",
              "      <td>[omgaga, im, sooo, im, gunna, cry, ive, been, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>i think mi bf is cheating on me tt</td>\n",
              "      <td>[i, think, mi, bf, is, cheating, on, me, tt]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sentiment                                      SentimentText  \\\n",
              "0          0                        is so sad for my apl friend   \n",
              "1          0                      i missed the new moon trailer   \n",
              "2          1                              omg its already 730 o   \n",
              "3          0   omgaga im sooo im gunna cry ive been at this ...   \n",
              "4          0                 i think mi bf is cheating on me tt   \n",
              "\n",
              "                                 SentimentTextTokens  \n",
              "0                [is, so, sad, for, my, apl, friend]  \n",
              "1               [i, missed, the, new, moon, trailer]  \n",
              "2                        [omg, its, already, 730, o]  \n",
              "3  [omgaga, im, sooo, im, gunna, cry, ive, been, ...  \n",
              "4       [i, think, mi, bf, is, cheating, on, me, tt]  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBgi2OXTVPcE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "cf3b3cfe-8921-48a3-aac4-56e9a9a1eb23"
      },
      "source": [
        "df['SentimentTextStrTokens'] = df['SentimentTextTokens'].astype('str')\n",
        "df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>SentimentText</th>\n",
              "      <th>SentimentTextTokens</th>\n",
              "      <th>SentimentTextStrTokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>is so sad for my apl friend</td>\n",
              "      <td>[is, so, sad, for, my, apl, friend]</td>\n",
              "      <td>['is', 'so', 'sad', 'for', 'my', 'apl', 'friend']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>i missed the new moon trailer</td>\n",
              "      <td>[i, missed, the, new, moon, trailer]</td>\n",
              "      <td>['i', 'missed', 'the', 'new', 'moon', 'trailer']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>omg its already 730 o</td>\n",
              "      <td>[omg, its, already, 730, o]</td>\n",
              "      <td>['omg', 'its', 'already', '730', 'o']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>omgaga im sooo im gunna cry ive been at this ...</td>\n",
              "      <td>[omgaga, im, sooo, im, gunna, cry, ive, been, ...</td>\n",
              "      <td>['omgaga', 'im', 'sooo', 'im', 'gunna', 'cry',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>i think mi bf is cheating on me tt</td>\n",
              "      <td>[i, think, mi, bf, is, cheating, on, me, tt]</td>\n",
              "      <td>['i', 'think', 'mi', 'bf', 'is', 'cheating', '...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sentiment                                      SentimentText  \\\n",
              "0          0                        is so sad for my apl friend   \n",
              "1          0                      i missed the new moon trailer   \n",
              "2          1                              omg its already 730 o   \n",
              "3          0   omgaga im sooo im gunna cry ive been at this ...   \n",
              "4          0                 i think mi bf is cheating on me tt   \n",
              "\n",
              "                                 SentimentTextTokens  \\\n",
              "0                [is, so, sad, for, my, apl, friend]   \n",
              "1               [i, missed, the, new, moon, trailer]   \n",
              "2                        [omg, its, already, 730, o]   \n",
              "3  [omgaga, im, sooo, im, gunna, cry, ive, been, ...   \n",
              "4       [i, think, mi, bf, is, cheating, on, me, tt]   \n",
              "\n",
              "                              SentimentTextStrTokens  \n",
              "0  ['is', 'so', 'sad', 'for', 'my', 'apl', 'friend']  \n",
              "1   ['i', 'missed', 'the', 'new', 'moon', 'trailer']  \n",
              "2              ['omg', 'its', 'already', '730', 'o']  \n",
              "3  ['omgaga', 'im', 'sooo', 'im', 'gunna', 'cry',...  \n",
              "4  ['i', 'think', 'mi', 'bf', 'is', 'cheating', '...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q764vszGqiUh"
      },
      "source": [
        "### How should TF-IDF scores be interpreted? How are they calculated?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e2Ji7BMhqs3M"
      },
      "source": [
        "#### Your Answer Here #####\n",
        "\n",
        "Term Frequency - Inverse Document Frequency scores should be interpreted in descending order where the top scores are the most important words in a specific document, with or without context."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3iUeBKtG_uEK"
      },
      "source": [
        "# Part 3 - Document Classification\n",
        "\n",
        "1) Use Train_Test_Split to create train and test datasets.\n",
        "\n",
        "2) Vectorize the tokenized documents using your choice of vectorization method. \n",
        "\n",
        " - Stretch goal: Use both of the methods that we talked about in class.\n",
        "\n",
        "3) Create a vocabulary using the X_train dataset and transform both your X_train and X_test data using that vocabulary.\n",
        "\n",
        "4) Use your choice of binary classification algorithm to train and evaluate your model's accuracy. Report both train and test accuracies.\n",
        "\n",
        " - Stretch goal: Use an error metric other than accuracy and implement/evaluate multiple classifiers.\n",
        " - Stretch goal: Track your results in a DataFrmae and produce a visualization of the results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TX8OEgUP_3ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d38bebd2-e139-44cb-a1f9-c004485174a2"
      },
      "source": [
        "##### Your Code Here #####\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "X = df['SentimentTextStrTokens']\n",
        "y = df['Sentiment']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=420)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(79991,)\n",
            "(19998,)\n",
            "(79991,)\n",
            "(19998,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEOZWirhaMIo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "e6972ab6-5440-4234-de55-dab107f15d74"
      },
      "source": [
        "vectorizer=CountVectorizer(max_features=None,ngram_range=(1,1),stop_words='english')\n",
        "\n",
        "vectorizer.fit(X_train)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
              "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "        tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGue2sHFaVVP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ff7fe22a-2a18-4296-92a7-7a549dff2aa5"
      },
      "source": [
        "train_words_count = vectorizer.transform(X_train)\n",
        "test_words_count = vectorizer.transform(X_test)\n",
        "\n",
        "print(train_words_count.shape)\n",
        "print(test_words_count.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(79991, 102266)\n",
            "(19998, 102266)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKyAGx9bcOB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train_v = pd.DataFrame(train_words_count.toarray(), columns=vectorizer.get_feature_names())\n",
        "\n",
        "# print(X_train_v.shape)\n",
        "# X_train_v.head()\n",
        "\n",
        "# can't do this method Colab ran out of RAM..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zq4Hv-VcZeA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_test_v = pd.DataFrame(test_words_count.toarray(),columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcF4Rot6a95M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "216e23ec-8d9c-4bd9-92cc-4fd1bd9bedb3"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "LR = LogisticRegression(random_state=42).fit(train_words_count,y_train)\n",
        "MNB = MultinomialNB().fit(train_words_count,y_train)\n",
        "RF = RandomForestClassifier().fit(train_words_count,y_train)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0fptFIzdDn6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d0b1df73-9a0e-4931-ec07-338e4823bf82"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#LR \n",
        "train_preds = LR.predict(train_words_count)\n",
        "test_preds = LR.predict(test_words_count)\n",
        "\n",
        "print(f'Train Accuracy for LR: {accuracy_score(y_train,train_preds)}')\n",
        "print(f'Test Accuracy for LR: {accuracy_score(y_test,test_preds)}')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy for LR: 0.9056643872435649\n",
            "Test Accuracy for LR: 0.7477747774777478\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBCNg00mdl_h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cedf2e50-0bcd-4795-a51c-3a37d10f9fb2"
      },
      "source": [
        "train_preds = MNB.predict(train_words_count)\n",
        "test_preds = MNB.predict(test_words_count)\n",
        "\n",
        "print(f'Train Accuracy for MNB: {accuracy_score(y_train,train_preds)}')\n",
        "print(f'Test Accuracy for MNB: {accuracy_score(y_test,test_preds)}')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy for MNB: 0.8960383043092348\n",
            "Test Accuracy for MNB: 0.7438243824382438\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JXf9TXJd0SE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0830ec05-45e6-4155-e3c3-1311f31fb082"
      },
      "source": [
        "train_preds = RF.predict(train_words_count)\n",
        "test_preds = RF.predict(test_words_count)\n",
        "\n",
        "print(f'Train Accuracy for RF: {accuracy_score(y_train,train_preds)}')\n",
        "print(f'Test Accuracy for RF: {accuracy_score(y_test,test_preds)}')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy for RF: 0.9822480029003263\n",
            "Test Accuracy for RF: 0.698019801980198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sorF95UO_uGx"
      },
      "source": [
        "# Part 4 -  Word2Vec\n",
        "\n",
        "1) Fit a Word2Vec model on your cleaned/tokenized twitter dataset. \n",
        "\n",
        "2) Display the 10 words that are most similar to the word \"twitter\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DYno4d4N-LHR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "137c8c2e-51a1-4d02-d351-24929bbcbe78"
      },
      "source": [
        "##### Your Code Here #####\n",
        "!pip install gensim\n",
        "import gensim"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.8.3)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.2.1)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.138)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.21.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.138 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.138)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2019.3.9)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.2)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.8)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.138->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.138->boto3->smart-open>=1.2.1->gensim) (0.14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eBRAp9WeENL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b426ab6e-f197-4d2c-c18d-c19b5106c4b8"
      },
      "source": [
        "from gensim.models.word2vec import Word2Vec\n",
        "\n",
        "model = Word2Vec(df['SentimentTextTokens'], min_count=3, size=420)\n",
        "print(model)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=22146, size=420, alpha=0.025)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q99lndPewWa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "c0ea50ab-2b30-46c0-d1fe-f001bfe9a273"
      },
      "source": [
        "model.wv.most_similar('twitter')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('facebook', 0.7981023788452148),\n",
              " ('myspace', 0.7290792465209961),\n",
              " ('everyone', 0.703342616558075),\n",
              " ('youtube', 0.6812082529067993),\n",
              " ('fb', 0.6777151823043823),\n",
              " ('tweets', 0.6717411279678345),\n",
              " ('updates', 0.6678978204727173),\n",
              " ('someone', 0.6608356237411499),\n",
              " ('blog', 0.6430208683013916),\n",
              " ('list', 0.6429527401924133)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgYN8Bz4e0Os",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#is that it?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVI9oGtne1Ks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}