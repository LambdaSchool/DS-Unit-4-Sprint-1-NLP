{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_422_BOW_Assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "hyj-f9FDcVFp",
        "colab_type": "code",
        "outputId": "75777175-2790-43b6-e986-f269c0ba8cbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "!pip install -U nltk\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import sent_tokenize # Sentence Tokenizer\n",
        "from nltk.tokenize import word_tokenize # Word Tokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: nltk in /usr/local/lib/python3.6/dist-packages (3.4)\n",
            "Requirement already satisfied, skipping upgrade: singledispatch in /usr/local/lib/python3.6/dist-packages (from nltk) (3.4.0.3)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.11.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "M7bcmqfGXrFG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 1) (optional) Scrape 100 Job Listings that contain the title \"Data Scientist\" from indeed.com\n",
        "\n",
        "At a minimum your final dataframe of job listings should contain\n",
        "- Job Title\n",
        "- Job Description"
      ]
    },
    {
      "metadata": {
        "id": "KcYlc1URXhlC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### Your Code Here #####\n",
        "from urllib.request import urlopen\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "postings = []\n",
        "\n",
        "scraped_url = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-2-NLP/master/module2-Bag-of-Words/job_listings.csv'\n",
        "\n",
        "data = urlopen(scraped_url)\n",
        "for line in data:\n",
        "    html_doc = line\n",
        "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
        "    postings.append(soup.get_text())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4thPjvRikUDA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H-mr3PIVb7M1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73c0f492-9fa2-40b8-ae8e-22b5bb34a1a4"
      },
      "cell_type": "code",
      "source": [
        "# Deleting first item in list\n",
        "postings.pop(0)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "',description,title\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "metadata": {
        "id": "W_4cp_osVykS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dictionary of job descriptions and job titles\n",
        "post_dict = {'description': [], 'title': []}\n",
        "for posting in postings:\n",
        "    description = re.split(r'\",|\\',', posting)[0]\n",
        "    post_dict['description'].append(description)\n",
        "    \n",
        "    title = re.split(r'\",|\\',', posting)[1]\n",
        "    post_dict['title'].append(title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dATXiCTFbQNU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(post_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uhkTR5AhikJ1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.description = df.description.str.lstrip('1234567890,\"b\\\\')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6N5U17JlioVn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "fcf66ec4-333e-40b2-bb0a-4106275d7c1c"
      },
      "cell_type": "code",
      "source": [
        "df.description[0]"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Job Requirements:\\\\nConceptual understanding in Machine Learning models like Nai\\\\xc2\\\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them\\\\nIntermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role)\\\\nExposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R\\\\nAbility to communicate Model findings to both Technical and Non-Technical stake holders\\\\nHands on experience in SQL/Hive or similar programming language\\\\nMust show past work via GitHub, Kaggle or any other published article\\\\nMaster\\'s degree in Statistics/Mathematics/Computer Science or any other quant specific field.\\\\nApply Now\"\"'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "metadata": {
        "id": "oPuhtM0h91_K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "17adefac-1297-4d36-ec0a-b04f758fc132"
      },
      "cell_type": "code",
      "source": [
        "df.description.head(25)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     Job Requirements:\\nConceptual understanding in...\n",
              "1     'Job Description\\n\\nAs a Data Scientist 1, you...\n",
              "2     'As a Data Scientist you will be working on co...\n",
              "3     '$4,969 - $6,756 a monthContractUnder the gene...\n",
              "4     'Location: USA \\xe2\\x80\\x93 multiple locations...\n",
              "5     'Create various Business Intelligence Analytic...\n",
              "6     'As Spotify Premium swells to over 96M subscri...\n",
              "7     Everytown for Gun Safety, the nation's largest...\n",
              "8     MS in a quantitative discipline such as Statis...\n",
              "9     'Slack is hiring experienced data scientists t...\n",
              "10    'Who We Are\\nBlackThorn Therapeutics is a comp...\n",
              "11    'Part-timeAbout The Opportunity\\nHere at Grubh...\n",
              "12    nfosys\\xe2\\x80\\x93 Data & Analytics \\xe2\\x80\\x...\n",
              "13    'As Spotify Premium swells to over 96M subscri...\n",
              "14    'Experience with guiding R&D strategy for your...\n",
              "15    'The Atlantic is seeking a Data Scientist to h...\n",
              "16    'THE CHALLENGE\\nEventbrite is big, bustling ma...\n",
              "17    'ContractWe are looking to hire for a Data Sci...\n",
              "18    Everytown for Gun Safety, the nation's largest...\n",
              "19    '$70,000 - $100,000 a yearTitle: Data Analyst/...\n",
              "20    '$45,000 a yearWorking under direction of the ...\n",
              "21    'The Challenge:\\nAre you excited at the prospe...\n",
              "22    'We are seeking a Data Scientist to join our P...\n",
              "23    'Motiion is a technology and data company for ...\n",
              "24    'The Scientist is responsible for the scientif...\n",
              "Name: description, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "metadata": {
        "id": "5C4xFZNtX1m2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 2) Use NLTK to tokenize / clean the listings "
      ]
    },
    {
      "metadata": {
        "id": "dhUHuMr-X-II",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### Your Code Here #####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-lgCZNL_YycP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
      ]
    },
    {
      "metadata": {
        "id": "X2PZ8Pj_YxcF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### Your Code Here #####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zo1iH_UeY7_n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 4) Visualize the most common word counts"
      ]
    },
    {
      "metadata": {
        "id": "M5LB00uyZKV5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### Your Code Here #####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bwFsTqrVZMYi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " # 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
      ]
    },
    {
      "metadata": {
        "id": "-gx2gZCbl5Np",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### Your Code Here #####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FiDfTWceoRkH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Stretch Goals\n",
        "\n",
        " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
        " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
        " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
        "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data."
      ]
    }
  ]
}