{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "hyj-f9FDcVFp",
    "outputId": "5dd045fe-6e4c-458c-e2fc-253c3da9c805"
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import requests\n",
    "import string\n",
    "\n",
    "from bs4 import BeautifulSoup, Comment, NavigableString, SoupStrainer\n",
    "from nltk.tokenize import sent_tokenize # Sentence Tokenizer\n",
    "from nltk.tokenize import word_tokenize # Word Tokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7bcmqfGXrFG"
   },
   "source": [
    "# 1) (optional) Scrape 100 Job Listings that contain the title \"Data Scientist\" from indeed.com\n",
    "\n",
    "At a minimum your final dataframe of job listings should contain\n",
    "- Job Title\n",
    "- Job Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.indeed.com/jobs?as_and=tensorflow&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&sr=directhire&as_src=&salary=&radius=50&l=21044&fromage=any&sort=&psf=advsrch\n",
      "230\n",
      "237\n"
     ]
    }
   ],
   "source": [
    "class IndeedScraper:\n",
    "    \"\"\" Class meant for scraping Indeed.com for specified job keywords and job locations\"\"\"\n",
    "\n",
    "    def query_generator(self, keyword, location):\n",
    "        \"\"\"A function that takes a search keyword (or keywords) and a city and returns the resulting query url\"\"\"\n",
    "\n",
    "        string1 = f\"https://www.indeed.com/jobs?as_and={keyword}&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&\"\n",
    "        string2 = f\"sr=directhire&as_src=&salary=&radius=50&l={location}&fromage=any&sort=&psf=advsrch\"\n",
    "        query = string1 + string2\n",
    "\n",
    "        return query\n",
    "\n",
    "    def search_results_numeric(self, query):\n",
    "        '''A function that takes a search query url and returns the number of search results'''\n",
    "\n",
    "        search_count = SoupStrainer(id=\"searchCount\")\n",
    "        page = requests.get(query)\n",
    "        soup = BeautifulSoup(page.text, \"html.parser\", parse_only=search_count)\n",
    "        s = soup.get_text()\n",
    "        num_search_results = [int(item) for item in s.split(' ') if item.isdigit()][-1]\n",
    "        result = \"Number of job results:\" + str(num_search_results)\n",
    "        return num_search_results\n",
    "\n",
    "\n",
    "    def search_page_generator(self, query, num_search_results, limit=50):\n",
    "        '''A function that takes a query url and the number of search results corresponding that query, \n",
    "        and returns a list of urls to be scraped.'''\n",
    "\n",
    "        urls_to_scrape = []\n",
    "        converted_search_results = int(num_search_results)\n",
    "        i = int(converted_search_results / 50)\n",
    "        \n",
    "        for page_number in range(i + 1):\n",
    "            \n",
    "            url_suffix = f'&limit={limit}&start={str(page_number * 50)}'\n",
    "            url = f'{query}{url_suffix}'\n",
    "            urls_to_scrape.append(url)\n",
    "            \n",
    "        return urls_to_scrape\n",
    "\n",
    "    def make_soup(self, query, parser='html.parser'):\n",
    "\n",
    "        '''A function that takes a query url and returns a BeautifulSoup object. html.parser is passed in as default parser'''\n",
    "\n",
    "        page = requests.get(query)\n",
    "        soup = BeautifulSoup(page.text, parser)\n",
    "\n",
    "        return soup\n",
    "    \n",
    "\n",
    "    # Map iterables in urls_to_scrape into soup_generator()\n",
    "    def extract_job_postings(self, url_list):\n",
    "        \"\"\"A function that takes a list of urls from search_page_generator() \n",
    "         and returns a list of BeautifulSoup objects corresponding to each job posting in the list of urls\"\"\"\n",
    "    \n",
    "        job_postings = []\n",
    "        \n",
    "        for url in url_list:\n",
    "            \n",
    "            soup = scraper.make_soup(url)\n",
    "            for result in soup.find_all('div', attrs={'data-tn-component': 'organicJob'}):\n",
    "                job_postings.append(result)\n",
    "            \n",
    "        return job_postings\n",
    "    \n",
    "    def process_job_posting(self, job):\n",
    "        \"\"\"\n",
    "        Function that parses through html elements of indeed job postings and prints them in a prettified string output\n",
    "        \"\"\"\n",
    "        \n",
    "        # job id\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            job_id = job.find('h2', attrs={\"class\": \"jobtitle\"})['id']\n",
    "            #print(\"Job ID:\", job_id)\n",
    "        except AttributeError:\n",
    "            job_id = 'NA'\n",
    "        \n",
    "\n",
    "        # job title\n",
    "        \n",
    "        job_title = job.find('a', attrs={'data-tn-element':\"jobTitle\"}).text.strip().capitalize()\n",
    "\n",
    "        #print(\"Job Title:\", job_title)\n",
    "\n",
    "        # * company\n",
    "\n",
    "        company = job.find('span', class_='company').text.strip()\n",
    "\n",
    "        #print(\"Company:\", company)\n",
    "\n",
    "        # location\n",
    "\n",
    "        location = job.find('span', class_='location').get_text()\n",
    "        #print(\"Location:\", location)\n",
    "        \n",
    "        # date_posting\n",
    "\n",
    "        post_date = job.find('span', class_='date').get_text()\n",
    "        #print(\"Date Posted:\", post_date)\n",
    "        \n",
    "        \n",
    "        # salary_range\n",
    "\n",
    "        try:\n",
    "            salary = job.find('span', class_='salary no-wrap').text.strip()\n",
    "            #print(\"Salary:\" , salary)\n",
    "        except AttributeError:\n",
    "            salary = 'NA'\n",
    "\n",
    "        # job_summary\n",
    "\n",
    "        summary = job.find('span', class_='summary').text.strip()\n",
    "        #print(\"Job Summary:\", summary)\n",
    "\n",
    "        # job_link\n",
    "\n",
    "        job_link = \"https://www.indeed.com\" + job.find('h2', attrs={\"class\": \"jobtitle\"}).find('a')['href']\n",
    "        #print(\"Job_link:\", job_link)\n",
    "        \n",
    "        # full description\n",
    "        \n",
    "        request = requests.get(job_link)\n",
    "        request_soup = BeautifulSoup(request.text, \"html.parser\")\n",
    "        description = request_soup.find('div', attrs={\"class\": \"jobsearch-JobComponent-description\"})\n",
    "        description = description.text.strip()\n",
    "        \n",
    "        #print(description)\n",
    "        return [job_id, job_title, company, location, post_date, salary, summary, job_link, description]\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jl_51b0735e7d2e01d8', 'Geospatial data scientist', 'Chesapeake Conservancy Inc', 'Annapolis, MD 21401', '1 day ago', '$100,000 - $125,000 a year', 'Experience with CNTK, Tensorflow, Keras. Chesapeake Conservancy, a nonprofit organization based in Annapolis, Maryland is seeking a Geospatial Data Scientist...', 'https://www.indeed.com/rc/clk?jk=51b0735e7d2e01d8&fccid=51c576784f5d7c9d&vjs=3', '$100,000 - $125,000 a yearDescription:\\nChesapeake Conservancy, a nonprofit organization based in Annapolis, Maryland is seeking a Geospatial Data Scientist with experience leveraging machine learning and large and complex data sets in the environmental world.\\n\\nABOUT THE CONSERVANCY\\nChesapeake Conservancy is a non-profit organization based in Annapolis, Maryland, dedicated to ensuring a healthier Chesapeake Bay watershed where fish and wildlife thrive, with healthy waters and abundant forests, wetlands, shorelines, and open spaces. With the human population in the Chesapeake watershed approaching 18 million and growing and tens of thousands of acres of open space vanishing each year, the Conservancy works to connect people with the Chesapeake’s wildlife and history; conserve landscapes and rivers; and restore the region’s natural resources. The Conservancy works in close partnership with the National Park Service Chesapeake Bay Office, the United States Fish and Wildlife Service, as well as other federal, state and local agencies, private foundations, and corporations to advance conservation.\\n\\nWithin the Conservancy, the Conservation Innovation Center (CIC) group has become a globally recognized leader in producing data, analyses, and web applications to advance precision conservation and restoration. We partner with industry-leading organizations like Microsoft and Esri to help define the next generation of environmental data and work with partners on the ground to make sure it is useful. The CIC has recognized the potential of machine learning to dramatically improve the analysis of large and complex datasets to improve environmental decision making.\\n\\nPOSITION DESCRIPTION\\nThe Geospatial Data Scientist, working within the CIC, will be responsible for the development and management of a variety of pilot projects both inside and outside the Chesapeake Bay watershed that demonstrate the role that AI and “big data” can play in environmental decision making. The successful candidate will have a unique opportunity to build a data science program within the CIC that works to address global challenges while getting to work at the cutting edge of data science and collaborating with other leading organizations.\\n\\nReporting directly to the Director of Conservation Technology, the successful candidate for this position will be involved in all aspects of projects from scoping, data evaluation, and project execution. This position will take the lead on creating a portfolio of projects leveraging machine learning and will work with the CIC’s team to identify opportunities to improve existing workflows. Experience with environmental issues, including water quality and quantity management, ecosystem and habitat modeling, and land management is highly desired.\\n\\nEssential functions include:\\n1. Create machine learning solutions, including artificial intelligence, for a diverse set of problems.\\n2. Employ structured approaches to leveraging large data sets to uncover new insights.\\n3. Work closely with the team within the CIC to incorporate their expertise into new data science solutions that improve workflows and outcomes.\\n4. Drive acquisition of new data sources as needed with governance on license, terms of use, compliance, quality, and high availability.\\n5. Represent the CIC’s capabilities and product offerings to internal and external audiences, both technical and non-technical, at conferences and meetings.\\n6. Overseeing and collaborating with team members as well as other project managers. Candidates must be able to work within the CIC’s structure to add additional capabilities. This includes working with peers and supervisors in problem solving, and providing constructive feedback on ideas and problems. The CIC team is a highly collaborative and innovative group. Ideal candidates will participate in brainstorming and discussions.\\n7. Obtaining, organizing, and processing component datasets. The Geospatial Data Scientistwill be working with a variety of spatial data, including satellite and aerial imagery; LiDAR; national, state, and local vector data; and ecological models. Organization and attention to detail are key skills in working across projects with high volumes of complex data.\\n8. Working independently to solve problems and errors. Much of the CIC’s work involves finding unique, customized solutions to partners’ challenges. Errors and unknowns will be encountered. This position will be required to handle a range of technical challenges and to devise solutions based on available resources. While this position will be the only data scientist within the CIC, this position will work closely with partners with strong data science programs.\\n9. Compiling deliverables and writing grant reports. Project deliverables may include maps, memos, short or long reports, slide decks, datasets, or grant reports. Applicants should be able to write concisely and effectively, design impactful products, and communicate progress to funders.\\n\\nRequirements:\\nKEY QUALIFICATIONS\\nThe Geospatial Data Scientist should be an organized, dependable, and goal-driven leader with a passion for the mission of the Chesapeake Conservancy – public access, conservation, and education and stewardship of the Bay and its resources. Candidates must be able to challenge conventions, to thrive independently as well as on a team in a relaxed, dynamic office culture, and to think creatively. Other essential skills include adaptability, independence in problem solving, strong oral and written communication, and an ability to teach others technical material.\\n\\nJob Requirements:\\n\\nMaster’s in a quantitative field. Ph.D. preferred.\\nExperience in delivering insights and capabilities through data science, AI or machine learning techniques. E.g., neural networks for NLP, computer vision, etc., random forests and other supervised methods, clustering, PCA, etc.\\nExperience with a numerical programming language such as Python/Numpy/Scipy, R, Matlab, or similar\\nFamiliarity with SQL or similar.\\nResearch or strong experience in computational aspects of one or more of the following, or highly related, areas preferred: Bayesian modeling, causal inference methods, finite mixture models, generalized linear models, joint modeling, nonlinear mixed models\\nComfort manipulating and analyzing complex, high-dimensionality from varying sources to solve difficult problems\\nAbility to communicate complex quantitative analysis in a clear, precise, and actionable manner\\nExperience framing and participating in data-driven business decisions, including measuring and evaluating outcomes.\\nExcellent oral and written communication skills.\\nThe ability to translate data science to non-technical people at all levels.\\nTeam player with proven ability to build trusted relationships.\\nDemonstrated ability to work efficiently, prioritize workflow, and meet demanding deadlines.\\n\\nSkills/Experience nice to have\\n\\n\\nExperience with CNTK, Tensorflow, Keras\\nExperience with cloud based architectures such as Azure or AWS\\n\\nLOCATION\\nThis position will be based in Annapolis, Maryland, however travel throughout the United States for meetings with partners may be required.\\n\\nChesapeake Conservancy is an equal opportunity employer. Salary and benefits are commensurate with the candidate’s relevant professional experience and/or education with an expected salary range between $100,000-125,000.\\n\\nThe Conservancy offers a competitive employee benefits package that includes health and dental insurance, life insurance, disability insurance, paid vacation and sick leave, and participation in a retirement savings plan. Opportunities for advancement and professional development are available.\\n\\nApplications will be reviewed as their materials arrive, with an anticipated start date in May or early June 2019.']\n"
     ]
    }
   ],
   "source": [
    "        \n",
    "# =========================== EXAMPLE USAGE ==============================================\n",
    "# init class object\n",
    "scraper = IndeedScraper()\n",
    "# define query with keyword/keywords and location\n",
    "test_query = scraper.query_generator(\"tensorflow\", \"21044\")\n",
    "# store the amount of search results\n",
    "num_search_results = scraper.search_results_numeric(test_query)\n",
    "# create urls from query and associated number of jobs\n",
    "urls = scraper.search_page_generator(test_query, num_search_results)\n",
    "\n",
    "# you can skip this step, it's built into IndeedScraper.extract_job_postings(), just testing functionality\n",
    "#soup = scraper.make_soup(test_query) \n",
    "\n",
    "# this opens all the links from the pages and stores their full text description for later use\n",
    "job_postings = scraper.extract_job_postings(urls)\n",
    "\n",
    "#============================================== debug ==============================================\n",
    "#print(test_query)\n",
    "#print(number_of_jobs)\n",
    "#print(urls)\n",
    "#print(soup)\n",
    "#print(len(job_postings))\n",
    "#============================================== debug ==============================================\n",
    "\n",
    "# verifying all is working\n",
    "test = scraper.process_job_posting(job_postings[0])\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move data to dataframe for processing\n",
    "\n",
    " This may take a bit to run depending on your query, try to narrow down what you want or you might be here a while.  \n",
    " If you get NA values, it's because i added in some ugly handling of getting past search limits with Indeed that stops the\n",
    " code from breaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['ID', 'Title', 'Company', 'Location', 'Date', 'Salary', 'Summary', 'Link', 'FullText']\n",
    "dataframe = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for job_number in range(0, number_of_jobs - 1):\n",
    "    dataframe.loc[len(dataframe)] = (scraper.process_job_posting(job_postings[job_number]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcYlc1URXhlC"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Date</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Link</th>\n",
       "      <th>FullText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jl_51b0735e7d2e01d8</td>\n",
       "      <td>Geospatial data scientist</td>\n",
       "      <td>Chesapeake Conservancy Inc</td>\n",
       "      <td>Annapolis, MD 21401</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>$100,000 - $125,000 a year</td>\n",
       "      <td>Experience with CNTK, Tensorflow, Keras. Chesa...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=51b0735e7d2e0...</td>\n",
       "      <td>$100,000 - $125,000 a yearDescription:\\nChesap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jl_a276ea2539679009</td>\n",
       "      <td>Yolo developer</td>\n",
       "      <td>K&amp;M Systems</td>\n",
       "      <td>Tysons Corner, VA</td>\n",
       "      <td>14 hours ago</td>\n",
       "      <td>NA</td>\n",
       "      <td>Job Description K&amp;M Systems, Inc. is looking f...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=a276ea2539679...</td>\n",
       "      <td>ContractJob Description\\nK&amp;M Systems, Inc. is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jl_ffecc05983f8169b</td>\n",
       "      <td>Summer intern - big data &amp; machine learning</td>\n",
       "      <td>Intelligent Automation</td>\n",
       "      <td>Rockville, MD 20855</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>NA</td>\n",
       "      <td>Intelligent Automation, Inc. (IAI) is seeking ...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=ffecc05983f81...</td>\n",
       "      <td>Temporary, InternshipIntelligent Automation, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jl_f790b176479fd4e4</td>\n",
       "      <td>Senior python developer - data engineering and...</td>\n",
       "      <td>B23 LLC</td>\n",
       "      <td>McLean, VA</td>\n",
       "      <td>30+ days ago</td>\n",
       "      <td>$85,000 - $175,000 a year</td>\n",
       "      <td>Working knowledge of TensorFlow, TensorFLow Li...</td>\n",
       "      <td>https://www.indeed.com/company/B23/jobs/Senior...</td>\n",
       "      <td>$85,000 - $175,000 a yearB23 is a software com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jl_52ad992137a033cf</td>\n",
       "      <td>Intern - artificial intelligence</td>\n",
       "      <td>Alion Science and Technology</td>\n",
       "      <td>Annapolis Junction, MD 20701</td>\n",
       "      <td>30+ days ago</td>\n",
       "      <td>NA</td>\n",
       "      <td>Experience with deep learning frameworks and l...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=52ad992137a03...</td>\n",
       "      <td>Part-time, Temporary, InternshipResponsibiliti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                                              Title  \\\n",
       "0  jl_51b0735e7d2e01d8                          Geospatial data scientist   \n",
       "1  jl_a276ea2539679009                                     Yolo developer   \n",
       "2  jl_ffecc05983f8169b        Summer intern - big data & machine learning   \n",
       "3  jl_f790b176479fd4e4  Senior python developer - data engineering and...   \n",
       "4  jl_52ad992137a033cf                   Intern - artificial intelligence   \n",
       "\n",
       "                        Company                      Location          Date  \\\n",
       "0    Chesapeake Conservancy Inc           Annapolis, MD 21401     1 day ago   \n",
       "1                   K&M Systems             Tysons Corner, VA  14 hours ago   \n",
       "2        Intelligent Automation           Rockville, MD 20855   6 hours ago   \n",
       "3                       B23 LLC                    McLean, VA  30+ days ago   \n",
       "4  Alion Science and Technology  Annapolis Junction, MD 20701  30+ days ago   \n",
       "\n",
       "                       Salary  \\\n",
       "0  $100,000 - $125,000 a year   \n",
       "1                          NA   \n",
       "2                          NA   \n",
       "3   $85,000 - $175,000 a year   \n",
       "4                          NA   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  Experience with CNTK, Tensorflow, Keras. Chesa...   \n",
       "1  Job Description K&M Systems, Inc. is looking f...   \n",
       "2  Intelligent Automation, Inc. (IAI) is seeking ...   \n",
       "3  Working knowledge of TensorFlow, TensorFLow Li...   \n",
       "4  Experience with deep learning frameworks and l...   \n",
       "\n",
       "                                                Link  \\\n",
       "0  https://www.indeed.com/rc/clk?jk=51b0735e7d2e0...   \n",
       "1  https://www.indeed.com/rc/clk?jk=a276ea2539679...   \n",
       "2  https://www.indeed.com/rc/clk?jk=ffecc05983f81...   \n",
       "3  https://www.indeed.com/company/B23/jobs/Senior...   \n",
       "4  https://www.indeed.com/rc/clk?jk=52ad992137a03...   \n",
       "\n",
       "                                            FullText  \n",
       "0  $100,000 - $125,000 a yearDescription:\\nChesap...  \n",
       "1  ContractJob Description\\nK&M Systems, Inc. is ...  \n",
       "2  Temporary, InternshipIntelligent Automation, I...  \n",
       "3  $85,000 - $175,000 a yearB23 is a software com...  \n",
       "4  Part-time, Temporary, InternshipResponsibiliti...  "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhUHuMr-X-II"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lgCZNL_YycP"
   },
   "source": [
    "# 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2PZ8Pj_YxcF"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zo1iH_UeY7_n"
   },
   "source": [
    "# 4) Visualize the most common word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5LB00uyZKV5"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwFsTqrVZMYi"
   },
   "source": [
    " # 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gx2gZCbl5Np"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiDfTWceoRkH"
   },
   "source": [
    "## Stretch Goals\n",
    "\n",
    " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
    " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
    " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
    "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_422_BOW_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
