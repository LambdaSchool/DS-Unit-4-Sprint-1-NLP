{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# You may need to change the path\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1321</td>\n",
       "      <td>\\nSometimes, when whisky is batched, a few lef...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3861</td>\n",
       "      <td>\\nAn uncommon exclusive bottling of a 6 year o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655</td>\n",
       "      <td>\\nThis release is a port version of Amrut’s In...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>555</td>\n",
       "      <td>\\nThis 41 year old single cask was aged in a s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1965</td>\n",
       "      <td>\\nQuite herbal on the nose, with aromas of dri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3190</td>\n",
       "      <td>\\nCooley produced some great Irish single malt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3736</td>\n",
       "      <td>\\nThis year’s Ardbeg Day bottling is named in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2643</td>\n",
       "      <td>\\nAs part of a rebranding of the entire Talisk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4817</td>\n",
       "      <td>\\nMacQueen’s has an impressive range of age st...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4528</td>\n",
       "      <td>\\nFull gold color. Layers of citrus fruit on t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>418</td>\n",
       "      <td>\\nThis has the classic sweetish, oily, floral,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4495</td>\n",
       "      <td>\\nFolklore tells of the Silkies, whose siren v...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>670</td>\n",
       "      <td>\\nA high-strength blend that takes no prisoner...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1554</td>\n",
       "      <td>\\nSweet and lightly smoky on the nose: toasted...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1663</td>\n",
       "      <td>\\nBunnahabhain has been marketing batches of p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2119</td>\n",
       "      <td>\\nVery fragrant. Spicy too, with notes of hone...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3901</td>\n",
       "      <td>\\nMore widely available than Buffalo Trace’s a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4486</td>\n",
       "      <td>\\nSomewhat forgotten, this table bourbon is ri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2189</td>\n",
       "      <td>\\nLike its Ledaig stablemate, this Tobermory i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2996</td>\n",
       "      <td>\\nThe official Fèis Ìle  2016 bottling. This i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                        description  ratingCategory\n",
       "0   1321  \\nSometimes, when whisky is batched, a few lef...               1\n",
       "1   3861  \\nAn uncommon exclusive bottling of a 6 year o...               0\n",
       "2    655  \\nThis release is a port version of Amrut’s In...               1\n",
       "3    555  \\nThis 41 year old single cask was aged in a s...               1\n",
       "4   1965  \\nQuite herbal on the nose, with aromas of dri...               1\n",
       "5   3190  \\nCooley produced some great Irish single malt...               1\n",
       "6   3736  \\nThis year’s Ardbeg Day bottling is named in ...               0\n",
       "7   2643  \\nAs part of a rebranding of the entire Talisk...               1\n",
       "8   4817  \\nMacQueen’s has an impressive range of age st...               0\n",
       "9   4528  \\nFull gold color. Layers of citrus fruit on t...               0\n",
       "10   418  \\nThis has the classic sweetish, oily, floral,...               1\n",
       "11  4495  \\nFolklore tells of the Silkies, whose siren v...               0\n",
       "12   670  \\nA high-strength blend that takes no prisoner...               1\n",
       "13  1554  \\nSweet and lightly smoky on the nose: toasted...               1\n",
       "14  1663  \\nBunnahabhain has been marketing batches of p...               1\n",
       "15  2119  \\nVery fragrant. Spicy too, with notes of hone...               1\n",
       "16  3901  \\nMore widely available than Buffalo Trace’s a...               0\n",
       "17  4486  \\nSomewhat forgotten, this table bourbon is ri...               0\n",
       "18  2189  \\nLike its Ledaig stablemate, this Tobermory i...               1\n",
       "19  2996  \\nThe official Fèis Ìle  2016 bottling. This i...               1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSometimes, when whisky is batched, a few leftover barrels are returned to the warehouse. Canadian Club recently pulled and vatted several of these from the 1970s. Acetone, Granny Smith apples, and fresh-cut white cedar showcase this long age. Complex and spicy, yet reserved, this dram is ripe with strawberries, canned pears, cloves, pepper, and faint flowers, then slightly pulling oak tannins. Distinct, elegant, and remarkably vibrant, this ancient Canadian Club is anything but tired. (Australia only)\\xa0A$133'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['description'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(x=train['ratingCategory']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2881\n",
       "0    1141\n",
       "2      65\n",
       "Name: ratingCategory, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['ratingCategory'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       \\nSometimes, when whisky is batched, a few lef...\n",
       "1       \\nAn uncommon exclusive bottling of a 6 year o...\n",
       "2       \\nThis release is a port version of Amrut’s In...\n",
       "3       \\nThis 41 year old single cask was aged in a s...\n",
       "4       \\nQuite herbal on the nose, with aromas of dri...\n",
       "                              ...                        \n",
       "4082    \\nWhat lies beneath the surface of Dewar’s? He...\n",
       "4083    \\nAfter 6 to 7 years of maturation in bourbon ...\n",
       "4084    \\nBright, delicate, and approachable. While no...\n",
       "4085    \\nI’m calling this the pitmaster’s dram: the n...\n",
       "4086    \\nSpicy sultanas, greengage plums, toffee, and...\n",
       "Name: description, Length: 4087, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "##stripping the \\n from test and train sets\n",
    "\n",
    "train['description'] = train['description'].str.strip()\n",
    "test['description'] = test['description'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Sometimes, when whisky is batched, a few lefto...\n",
       "1       An uncommon exclusive bottling of a 6 year old...\n",
       "2       This release is a port version of Amrut’s Inte...\n",
       "3       This 41 year old single cask was aged in a she...\n",
       "4       Quite herbal on the nose, with aromas of dried...\n",
       "                              ...                        \n",
       "4082    What lies beneath the surface of Dewar’s? Here...\n",
       "4083    After 6 to 7 years of maturation in bourbon ca...\n",
       "4084    Bright, delicate, and approachable. While not ...\n",
       "4085    I’m calling this the pitmaster’s dram: the nos...\n",
       "4086    Spicy sultanas, greengage plums, toffee, and n...\n",
       "Name: description, Length: 4087, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### pipeline components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1 = nlp(train['description'][10])\n",
    "len(doc1)\n",
    "#\n",
    "#for token in doc:\n",
    " #   print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1 = nlp(train['description'][10])\n",
    "len(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "tokens = []\n",
    "\n",
    "for doc in tokenizer.pipe(train['description'], batch_size=500):\n",
    "    doc_tokens = [token.lemma_ for token in doc if (token.is_stop != True) and (token.is_punct != True)]\n",
    "    tokens.append(doc_tokens)\n",
    "\n",
    "train['tokens'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sometimes,',\n",
       " 'whisky',\n",
       " 'batched,',\n",
       " 'leftover',\n",
       " 'barrel',\n",
       " 'return',\n",
       " 'warehouse.',\n",
       " 'Canadian',\n",
       " 'Club',\n",
       " 'recently',\n",
       " 'pull',\n",
       " 'vatted',\n",
       " '1970s.',\n",
       " 'Acetone,',\n",
       " 'Granny',\n",
       " 'Smith',\n",
       " 'apples,',\n",
       " 'fresh-cut',\n",
       " 'white',\n",
       " 'cedar',\n",
       " 'showcase',\n",
       " 'long',\n",
       " 'age.',\n",
       " 'Complex',\n",
       " 'spicy,',\n",
       " 'reserved,',\n",
       " 'dram',\n",
       " 'ripe',\n",
       " 'strawberries,',\n",
       " 'can',\n",
       " 'pears,',\n",
       " 'cloves,',\n",
       " 'pepper,',\n",
       " 'faint',\n",
       " 'flowers,',\n",
       " 'slightly',\n",
       " 'pull',\n",
       " 'oak',\n",
       " 'tannins.',\n",
       " 'Distinct,',\n",
       " 'elegant,',\n",
       " 'remarkably',\n",
       " 'vibrant,',\n",
       " 'ancient',\n",
       " 'Canadian',\n",
       " 'Club',\n",
       " 'tired.',\n",
       " '(Australia',\n",
       " 'only)',\n",
       " '\\xa0',\n",
       " 'A$133']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tokens'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "tokens = []\n",
    "\n",
    "for doc in tokenizer.pipe(test['description'], batch_size=500):\n",
    "    doc_tokens = [token.lemma_ for token in doc if (token.is_stop != True) and (token.is_punct != True)]\n",
    "    tokens.append(doc_tokens)\n",
    "\n",
    "test['tokens'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_data=train['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['tokens'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(desc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = vect.transform(desc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4087x12974 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 230675 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1321</td>\n",
       "      <td>Sometimes, when whisky is batched, a few lefto...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Sometimes,, whisky, batched,, leftover, barre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3861</td>\n",
       "      <td>An uncommon exclusive bottling of a 6 year old...</td>\n",
       "      <td>0</td>\n",
       "      <td>[uncommon, exclusive, bottle, 6, year, old, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655</td>\n",
       "      <td>This release is a port version of Amrut’s Inte...</td>\n",
       "      <td>1</td>\n",
       "      <td>[release, port, version, Amrut’s, Intermediate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>555</td>\n",
       "      <td>This 41 year old single cask was aged in a she...</td>\n",
       "      <td>1</td>\n",
       "      <td>[41, year, old, single, cask, age, sherry, but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1965</td>\n",
       "      <td>Quite herbal on the nose, with aromas of dried...</td>\n",
       "      <td>1</td>\n",
       "      <td>[herbal, nose,, aroma, dry, tarragon,, parsley...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4082</th>\n",
       "      <td>3342</td>\n",
       "      <td>What lies beneath the surface of Dewar’s? Here...</td>\n",
       "      <td>1</td>\n",
       "      <td>[lie, beneath, surface, Dewar’s?, Here,, blend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4083</th>\n",
       "      <td>3130</td>\n",
       "      <td>After 6 to 7 years of maturation in bourbon ca...</td>\n",
       "      <td>1</td>\n",
       "      <td>[6, 7, year, maturation, bourbon, casks,, spen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084</th>\n",
       "      <td>2811</td>\n",
       "      <td>Bright, delicate, and approachable. While not ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Bright,, delicate,, approachable., showstoppe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4085</th>\n",
       "      <td>478</td>\n",
       "      <td>I’m calling this the pitmaster’s dram: the nos...</td>\n",
       "      <td>1</td>\n",
       "      <td>[I’m, call, pitmaster’s, dram:, nose, muscular...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4086</th>\n",
       "      <td>1209</td>\n",
       "      <td>Spicy sultanas, greengage plums, toffee, and n...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Spicy, sultanas,, greengage, plums,, toffee,,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4087 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                        description  ratingCategory  \\\n",
       "0     1321  Sometimes, when whisky is batched, a few lefto...               1   \n",
       "1     3861  An uncommon exclusive bottling of a 6 year old...               0   \n",
       "2      655  This release is a port version of Amrut’s Inte...               1   \n",
       "3      555  This 41 year old single cask was aged in a she...               1   \n",
       "4     1965  Quite herbal on the nose, with aromas of dried...               1   \n",
       "...    ...                                                ...             ...   \n",
       "4082  3342  What lies beneath the surface of Dewar’s? Here...               1   \n",
       "4083  3130  After 6 to 7 years of maturation in bourbon ca...               1   \n",
       "4084  2811  Bright, delicate, and approachable. While not ...               1   \n",
       "4085   478  I’m calling this the pitmaster’s dram: the nos...               1   \n",
       "4086  1209  Spicy sultanas, greengage plums, toffee, and n...               1   \n",
       "\n",
       "                                                 tokens  \n",
       "0     [Sometimes,, whisky, batched,, leftover, barre...  \n",
       "1     [uncommon, exclusive, bottle, 6, year, old, ca...  \n",
       "2     [release, port, version, Amrut’s, Intermediate...  \n",
       "3     [41, year, old, single, cask, age, sherry, but...  \n",
       "4     [herbal, nose,, aroma, dry, tarragon,, parsley...  \n",
       "...                                                 ...  \n",
       "4082  [lie, beneath, surface, Dewar’s?, Here,, blend...  \n",
       "4083  [6, 7, year, maturation, bourbon, casks,, spen...  \n",
       "4084  [Bright,, delicate,, approachable., showstoppe...  \n",
       "4085  [I’m, call, pitmaster’s, dram:, nose, muscular...  \n",
       "4086  [Spicy, sultanas,, greengage, plums,, toffee,,...  \n",
       "\n",
       "[4087 rows x 4 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>005</th>\n",
       "      <th>006</th>\n",
       "      <th>011</th>\n",
       "      <th>020</th>\n",
       "      <th>028</th>\n",
       "      <th>035</th>\n",
       "      <th>0473</th>\n",
       "      <th>048</th>\n",
       "      <th>...</th>\n",
       "      <th>zings</th>\n",
       "      <th>zingy</th>\n",
       "      <th>zip</th>\n",
       "      <th>zipping</th>\n",
       "      <th>zippy</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zone</th>\n",
       "      <th>zuidam</th>\n",
       "      <th>ànima</th>\n",
       "      <th>ìle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4082</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4083</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4085</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4086</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4087 rows × 12974 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      00  000  005  006  011  020  028  035  0473  048  ...  zings  zingy  \\\n",
       "0      0    0    0    0    0    0    0    0     0    0  ...      0      0   \n",
       "1      0    0    0    0    0    0    0    0     0    0  ...      0      0   \n",
       "2      0    0    0    0    0    0    0    0     0    0  ...      0      0   \n",
       "3      0    0    0    0    0    0    0    0     0    0  ...      0      0   \n",
       "4      0    0    0    0    0    0    0    0     0    0  ...      0      0   \n",
       "...   ..  ...  ...  ...  ...  ...  ...  ...   ...  ...  ...    ...    ...   \n",
       "4082   0    0    0    0    0    0    0    0     0    0  ...      0      0   \n",
       "4083   0    0    0    0    0    0    0    0     0    0  ...      0      0   \n",
       "4084   0    0    0    0    0    0    0    0     0    0  ...      0      0   \n",
       "4085   0    0    0    0    0    0    0    0     0    0  ...      0      0   \n",
       "4086   0    0    0    0    0    0    0    0     0    0  ...      0      0   \n",
       "\n",
       "      zip  zipping  zippy  zombies  zone  zuidam  ànima  ìle  \n",
       "0       0        0      0        0     0       0      0    0  \n",
       "1       0        0      0        0     0       0      0    0  \n",
       "2       0        0      0        0     0       0      0    0  \n",
       "3       0        0      0        0     0       0      0    0  \n",
       "4       0        0      0        0     0       0      0    0  \n",
       "...   ...      ...    ...      ...   ...     ...    ...  ...  \n",
       "4082    0        0      0        0     0       0      0    0  \n",
       "4083    0        0      0        0     0       0      0    0  \n",
       "4084    0        0      0        0     0       0      0    0  \n",
       "4085    0        0      0        0     0       0      0    0  \n",
       "4086    0        0      0        0     0       0      0    0  \n",
       "\n",
       "[4087 rows x 12974 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names())\n",
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "and        15817\n",
       "the        13767\n",
       "of          8126\n",
       "with        6394\n",
       "in          4692\n",
       "is          4212\n",
       "this        3243\n",
       "to          3009\n",
       "on          2955\n",
       "it          2894\n",
       "finish      2598\n",
       "oak         2175\n",
       "palate      2028\n",
       "nose        1871\n",
       "sweet       1804\n",
       "but         1774\n",
       "notes       1757\n",
       "vanilla     1743\n",
       "whisky      1487\n",
       "fruit       1459\n",
       "dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_20_words = dtm.sum().sort_values(ascending=False).head(20)\n",
    "top_20_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['description'] = train['description'].str.replace('a', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sometimes, when whisky is batched, a few leftover barrels are returned to the warehouse. Canadian Club recently pulled and vatted several of these from the 1970s. Acetone, Granny Smith apples, and fresh-cut white cedar showcase this long age. Complex and spicy, yet reserved, this dram is ripe with strawberries, canned pears, cloves, pepper, and faint flowers, then slightly pulling oak tannins. Distinct, elegant, and remarkably vibrant, this ancient Canadian Club is anything but tired. (Australia only)\\xa0A$133'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['description'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [Sometimes,, whisky, batched,, leftover, barre...\n",
       "1       [uncommon, exclusive, bottle, 6, year, old, ca...\n",
       "2       [release, port, version, Amrut’s, Intermediate...\n",
       "3       [41, year, old, single, cask, age, sherry, but...\n",
       "4       [herbal, nose,, aroma, dry, tarragon,, parsley...\n",
       "                              ...                        \n",
       "4082    [lie, beneath, surface, Dewar’s?, Here,, blend...\n",
       "4083    [6, 7, year, maturation, bourbon, casks,, spen...\n",
       "4084    [Bright,, delicate,, approachable., showstoppe...\n",
       "4085    [I’m, call, pitmaster’s, dram:, nose, muscular...\n",
       "4086    [Spicy, sultanas,, greengage, plums,, toffee,,...\n",
       "Name: tokens, Length: 4087, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [Style:, Speyside, single, malt, scotch, Color...\n",
       "1       [bright, lively,, nice, balance, flavors., Zes...\n",
       "2       [new, oloroso-forward, Chivas, position, split...\n",
       "3       [Aged, bourbon, cask, enhance, Rioja, wine, ca...\n",
       "4       [freshness, wood, nose,, lace, caramel, delica...\n",
       "                              ...                        \n",
       "1017    [Care, small, batch,, bourbon-matured, blend, ...\n",
       "1018    [pick, bunch,, whisky, equivalent, Fountains, ...\n",
       "1019    [Port, Ellen,, sure!, old-fashioned, nature:, ...\n",
       "1020    [Youthful, lively., Bold,, crisp,, spice, (min...\n",
       "1021    [mashbill, 60/20/10/10, corn/wheat/rye/malt,, ...\n",
       "Name: tokens, Length: 1022, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vectors(docs):\n",
    "    return [nlp(doc).vector for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_word_vectors(docs):\n",
    "   # return [nlp(doc).vector for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train['tokens'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condense(text):\n",
    "    string1 = \"\"\n",
    "    for x in text:\n",
    "        string1 = string1 + \" \" + x\n",
    "    return string1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Sometimes, whisky batched, leftover barrel return warehouse. Canadian Club recently pull vatted 1970s. Acetone, Granny Smith apples, fresh-cut white cedar showcase long age. Complex spicy, reserved, dram ripe strawberries, can pears, cloves, pepper, faint flowers, slightly pull oak tannins. Distinct, elegant, remarkably vibrant, ancient Canadian Club tired. (Australia only) \\xa0 A$133'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condense(train['tokens'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#string1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tokens'] = train['tokens'].apply(condense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['tokens'] = test['tokens'].apply(condense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Sometimes, whisky batched, leftover barrel re...\n",
       "1        uncommon exclusive bottle 6 year old cask str...\n",
       "2        release port version Amrut’s Intermediate She...\n",
       "3        41 year old single cask age sherry butt inter...\n",
       "4        herbal nose, aroma dry tarragon, parsley, dil...\n",
       "                              ...                        \n",
       "4082     lie beneath surface Dewar’s? Here, blend fini...\n",
       "4083     6 7 year maturation bourbon casks, spend mont...\n",
       "4084     Bright, delicate, approachable. showstopper, ...\n",
       "4085     I’m call pitmaster’s dram: nose muscular peat...\n",
       "4086     Spicy sultanas, greengage plums, toffee, new ...\n",
       "Name: tokens, Length: 4087, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Style: Speyside single malt scotch Color: Wal...\n",
       "1        bright lively, nice balance flavors. Zesty fr...\n",
       "2        new oloroso-forward Chivas position split 12 ...\n",
       "3        Aged bourbon cask enhance Rioja wine casks. m...\n",
       "4        freshness wood nose, lace caramel delicate mi...\n",
       "                              ...                        \n",
       "1017     Care small batch, bourbon-matured blend 20% m...\n",
       "1018     pick bunch, whisky equivalent Fountains Wayne...\n",
       "1019     Port Ellen, sure! old-fashioned nature: inter...\n",
       "1020     Youthful lively. Bold, crisp, spice (mint, ci...\n",
       "1021     mashbill 60/20/10/10 corn/wheat/rye/malt, age...\n",
       "Name: tokens, Length: 1022, dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_word_vectors(train['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4087"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = get_word_vectors(train['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4087"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4087"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = get_word_vectors(test['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)==len(test['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "#clf = XGBClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4087,)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['ratingCategory'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X, train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now doing doing a grid search to optimize hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([('clf', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    #'vect__max_df': ( 0.75, 1.0),\n",
    "    #'vect__min_df': (.02, .05),\n",
    "    #'vect__max_features': (500,1000),\n",
    "    #'clf__max_depth':(10,15,20),\n",
    "    'clf__max_depth':(5,10,15,20),\n",
    "    'clf__min_samples_leaf':(1,2,3),\n",
    "    'clf__n_estimators':(100,200)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 4.77 µs\n",
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   43.1s\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=10, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X, train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_estimator\n",
    "'''\n",
    "bootstrap=True, ccp_alpha=0.0,\n",
    "                                        class_weight=None, criterion='gini',\n",
    "                                        max_depth=None, max_features='auto',\n",
    "                                        max_leaf_nodes=None, max_samples=None,\n",
    "                                        min_impurity_decrease=0.0,\n",
    "                                        min_impurity_split=None,\n",
    "                                        min_samples_leaf=1, min_samples_split=2,\n",
    "                                        min_weight_fraction_leaf=0.0,\n",
    "                                        n_estimators=200, n_jobs=None,\n",
    "                                        oob_score=False, random_state=None,\n",
    "                                        verbose=0, warm_start=False))],\n",
    "                                        \n",
    "                                        \n",
    "                                        \n",
    "                                        \n",
    "                                        \n",
    "                                        \n",
    "                                        \n",
    "                                        ipeline(memory=None,\n",
    "         steps=[('clf',\n",
    "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
    "                                        class_weight=None, criterion='gini',\n",
    "                                        max_depth=20, max_features='auto',\n",
    "                                        max_leaf_nodes=None, max_samples=None,\n",
    "                                        min_impurity_decrease=0.0,\n",
    "                                        min_impurity_split=None,\n",
    "                                        min_samples_leaf=2, min_samples_split=2,\n",
    "                                        min_weight_fraction_leaf=0.0,\n",
    "                                        n_estimators=100, n_jobs=None,\n",
    "                                        oob_score=False, random_state=None,\n",
    "                                        verbose=0, warm_start=False))],\n",
    "         verbose=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(grid_search.best_score_*100).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Record of best scores\n",
    "#0.7359915966638038\n",
    "#73.62\n",
    "#73.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This exports to a kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['ratingCategory'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subNumber = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Do some exploratory visualizations to see what stop words I could add to my tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practice Problems\n",
    "Use your own Data Set\n",
    "\n",
    "Analyze the corpus of text using text visualizations of token frequency. Try cleaning the data as much as possible. Try the following techniques:\n",
    "\n",
    "Lemmatization Custom stopword removal Keep in mind the attributes of good tokens. Once you have a solid baseline, layer in the star rating in your visualization(s). Key part of this assignment - produce a write-up of the attributes of the best and worst coffee shops. Based on your analysis, what makes the best the best and the worst the worst. Use graphs and numbesr from your analysis to support your conclusions.\n",
    "\n",
    "Overall Word / Token Count View Counts by Rating\n",
    "\n",
    "[ ]\n",
    "Can visualize the words with the greatest difference in counts between 'good' & 'bad'?\n",
    "\n",
    "[ ]\n",
    "Use Spacy to tokenize the listings\n",
    "\n",
    "[ ]\n",
    "Use Scikit-Learn's CountVectorizer to get word counts\n",
    "\n",
    "[ ]\n",
    "Visualize the most common word counts\n",
    "\n",
    "[ ]\n",
    "Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix\n",
    "\n",
    "[ ]\n",
    "Create a NearestNeighbor Model.\n",
    "\n",
    "[ ]\n",
    "Try different visualizations for words and frequencies\n",
    "\n",
    "[ ]\n",
    "Fit a Gensim LDA topic model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
