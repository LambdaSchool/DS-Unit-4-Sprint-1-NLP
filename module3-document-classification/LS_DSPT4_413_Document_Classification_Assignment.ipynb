{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 4, Sprint 1, Module 3*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification (Assignment)\n",
    "\n",
    "This notebook is for you to practice skills during lecture.\n",
    "\n",
    "Today's guided module project and assignment will be different. You already know how to do classification. You ready know how to extract features from documents. So? That means you're ready to combine and practice those skills in a kaggle competition. We we will open with a five minute sprint explaining the competition, and then give you 25 minutes to work. After those twenty five minutes are up, I will give a 5-minute demo an NLP technique that will help you with document classification (*and **maybe** the competition*).\n",
    "\n",
    "Today's all about having fun and practicing your skills.\n",
    "\n",
    "## Sections\n",
    "* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n",
    "* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n",
    "* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy\n",
    "* <a href=\"#p4\">Part 4</a>: Post Lecture Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Feature Extraction & Classification Pipelines (Learn)\n",
    "<a id=\"p1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along \n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model (try using the pipe method I just demoed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Competition Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_Train = os.path.join(os.path.curdir,  \"data\", \"train.csv\")\n",
    "PATH_TEST = os.path.join(os.path.curdir,  \"data\", \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'.'"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "os.path.curdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(4087, 3) (1022, 2)\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# You may need to change the path\n",
    "train = pd.read_csv(PATH_Train)\n",
    "test = pd.read_csv(PATH_TEST)\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     id                                        description  ratingCategory\n0  1321  \\nSometimes, when whisky is batched, a few lef...               1\n1  3861  \\nAn uncommon exclusive bottling of a 6 year o...               0\n2   655  \\nThis release is a port version of Amrut’s In...               1\n3   555  \\nThis 41 year old single cask was aged in a s...               1\n4  1965  \\nQuite herbal on the nose, with aromas of dri...               1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>description</th>\n      <th>ratingCategory</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1321</td>\n      <td>\\nSometimes, when whisky is batched, a few lef...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3861</td>\n      <td>\\nAn uncommon exclusive bottling of a 6 year o...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>655</td>\n      <td>\\nThis release is a port version of Amrut’s In...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>555</td>\n      <td>\\nThis 41 year old single cask was aged in a s...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1965</td>\n      <td>\\nQuite herbal on the nose, with aromas of dri...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1    2881\n0    1141\n2      65\nName: ratingCategory, dtype: int64"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# Distribution of ratingCategory: 0 (Excellent), 1 (Good), 2 (Poor)\n",
    "train.ratingCategory.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        id  \\\n2073  4274   \n2799  53     \n3965  3930   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                description  \\\n2073  \\nThe first release from Wolfburn distillery is 3 years old. Matured in a mix of Spanish and American oak quarter casks previously used by an Islay distillery. The nose is soft and belies its youth, offering vanilla, lemon, ginger, and light smoke. The early palate is grassy. Sweeter fruit notes soon develop with more vanilla and ginger, plus white pepper. The finish is quite long and slightly smoky. Much to look forward to as this ages!               \n2799  \\nIf Canada made bourbon (it doesn’t), it would taste like this massive dram. The mashbill of 60% corn, 36% rye, and 4% malted barley is identical to that used for Crown Royal Hand Selected Barrel Coffey rye. Beer still distillation and virgin oak barrels yield huge vanillas, rye spices, barrel tones, cherries, dark fruits, soaring floral esters, and gingery, peppery spices. Strong woodiness, slightly pulling tannins, and something almost chocolaty.   \n3965  \\nA very different whisky to its unaged namesake, and most unlike any of the other blends tasted for this issue. That’s no bad thing.\\r\\nThis is less sweet than most blends, with tobacco leaf and ashtray to the fore, and a dusty, grainy note with a touch of oak, grape skin, and sweet heather. That said, not a lot of evidence of the 12 years in cask.                                                                                                         \n\n      ratingCategory  \n2073  0               \n2799  0               \n3965  0               ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>description</th>\n      <th>ratingCategory</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2073</th>\n      <td>4274</td>\n      <td>\\nThe first release from Wolfburn distillery is 3 years old. Matured in a mix of Spanish and American oak quarter casks previously used by an Islay distillery. The nose is soft and belies its youth, offering vanilla, lemon, ginger, and light smoke. The early palate is grassy. Sweeter fruit notes soon develop with more vanilla and ginger, plus white pepper. The finish is quite long and slightly smoky. Much to look forward to as this ages!</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2799</th>\n      <td>53</td>\n      <td>\\nIf Canada made bourbon (it doesn’t), it would taste like this massive dram. The mashbill of 60% corn, 36% rye, and 4% malted barley is identical to that used for Crown Royal Hand Selected Barrel Coffey rye. Beer still distillation and virgin oak barrels yield huge vanillas, rye spices, barrel tones, cherries, dark fruits, soaring floral esters, and gingery, peppery spices. Strong woodiness, slightly pulling tannins, and something almost chocolaty.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3965</th>\n      <td>3930</td>\n      <td>\\nA very different whisky to its unaged namesake, and most unlike any of the other blends tasted for this issue. That’s no bad thing.\\r\\nThis is less sweet than most blends, with tobacco leaf and ashtray to the fore, and a dusty, grainy note with a touch of oak, grape skin, and sweet heather. That said, not a lot of evidence of the 12 years in cask.</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# Read a few reviews from the \"Excellent\" category\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "train[train.ratingCategory == 0].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        id  \\\n2990  5105   \n2606  5074   \n3508  5099   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                       description  \\\n2990  \\nWith its overt floral perfume notes and the scent of children’s powdered candy, this whisky is difficult to enjoy. Its unctuous artificial flavors are equally unsuitable for cocktails, mixing, or sipping. Fruity, winey, lavender notes duke it out with baby cereal and artificial coconut. The saving graces? A late lovely bitterness, long gingery burn, and creamy body. But then jujubes, grape gum and artificial bananas kick in and it’s over.   \n2606  \\nPerhaps my least favorite of all the Experimental Collection releases to date. The nose shows nicely, but it comes across as rather aggressive and harsh on the palate toward the finish, which the label describes as being “earthy.” Otherwise, the whiskey is pleasantly sweet, with molasses, date, and fig, plus charcoal, leather, and bitter resin in the mix. Price is per 375 ml.                                                                   \n3508  \\nReal maple syrup has an earthy, woodsy aroma; maple flavoring has strong overtones of coconut, and so does Cabin Fever. The nose evokes dried, sweetened baking coconut, while the sweet and spicy palate is a hot, liquid, coconut macaroon. Peppery notes suggest that it’s whisky, but without any traces of barrel aging that’s as close as you get. Best part? The long, spicy finish with its confection-sweet coconut.                                \n\n      ratingCategory  \n2990  2               \n2606  2               \n3508  2               ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>description</th>\n      <th>ratingCategory</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2990</th>\n      <td>5105</td>\n      <td>\\nWith its overt floral perfume notes and the scent of children’s powdered candy, this whisky is difficult to enjoy. Its unctuous artificial flavors are equally unsuitable for cocktails, mixing, or sipping. Fruity, winey, lavender notes duke it out with baby cereal and artificial coconut. The saving graces? A late lovely bitterness, long gingery burn, and creamy body. But then jujubes, grape gum and artificial bananas kick in and it’s over.</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2606</th>\n      <td>5074</td>\n      <td>\\nPerhaps my least favorite of all the Experimental Collection releases to date. The nose shows nicely, but it comes across as rather aggressive and harsh on the palate toward the finish, which the label describes as being “earthy.” Otherwise, the whiskey is pleasantly sweet, with molasses, date, and fig, plus charcoal, leather, and bitter resin in the mix. Price is per 375 ml.</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3508</th>\n      <td>5099</td>\n      <td>\\nReal maple syrup has an earthy, woodsy aroma; maple flavoring has strong overtones of coconut, and so does Cabin Fever. The nose evokes dried, sweetened baking coconut, while the sweet and spicy palate is a hot, liquid, coconut macaroon. Peppery notes suggest that it’s whisky, but without any traces of barrel aging that’s as close as you get. Best part? The long, spicy finish with its confection-sweet coconut.</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# Read a few reviews from the \"Poor\" category\n",
    "train[train.ratingCategory == 2].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Training Set into Train/Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(3269,) (818,) (3269,) (818,)\n"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Doing a train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train['description'], \n",
    "                                                    train['ratingCategory'], \n",
    "                                                    test_size=0.2, \n",
    "                                                    stratify=train['ratingCategory'],\n",
    "                                                    random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing some imports for the Random forrest classifier a\n",
    "# and the tfidf vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words=\"english\", ngram_range=(1,2))\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "pipe = Pipeline([('vect', vect), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   32.6s\n[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  2.4min\n[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  4.7min\n[Parallel(n_jobs=4)]: Done 720 out of 720 | elapsed: 12.7min finished\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GridSearchCV(cv=5, error_score=nan,\n             estimator=Pipeline(memory=None,\n                                steps=[('vect',\n                                        TfidfVectorizer(analyzer='word',\n                                                        binary=False,\n                                                        decode_error='strict',\n                                                        dtype=<class 'numpy.float64'>,\n                                                        encoding='utf-8',\n                                                        input='content',\n                                                        lowercase=True,\n                                                        max_df=1.0,\n                                                        max_features=None,\n                                                        min_df=1,\n                                                        ngram_range=(1, 2),\n                                                        norm='l2',\n                                                        preprocessor=None,\n                                                        smooth_idf=True,\n                                                        stop_words='english',\n                                                        strip...\n                                                               oob_score=False,\n                                                               random_state=None,\n                                                               verbose=0,\n                                                               warm_start=False))],\n                                verbose=False),\n             iid='deprecated', n_jobs=4,\n             param_grid={'clf__max_depth': (5, 10, 15, None),\n                         'clf__n_estimators': (100, 500),\n                         'vect__max_df': (0.75, 1.0),\n                         'vect__max_features': (5000, 10000, 7000),\n                         'vect__min_df': (2, 5, 10)},\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring=None, verbose=1)"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': (0.75, 1.0),\n",
    "    'clf__max_depth':(5,10,15,None),\n",
    "    'vect__min_df': (2,5,10),\n",
    "    'vect__max_features': (5000, 10000, 7000),\n",
    "    'clf__n_estimators': (100, 500)\n",
    "\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=5, n_jobs=4, verbose=1)\n",
    "grid_search.fit(X_train, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7421283092384712"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'clf__max_depth': None,\n 'clf__n_estimators': 100,\n 'vect__max_df': 1.0,\n 'vect__max_features': 5000,\n 'vect__min_df': 2}"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File\n",
    "*Note:* In a typical Kaggle competition, you are only allowed two submissions a day, so you only submit if you feel you cannot achieve higher test accuracy. For this competition the max daily submissions are capped at **20**. Submit for each demo and for your assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = grid_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     id  ratingCategory\n0  3461  1             \n1  2604  1             \n2  3341  1             \n3  3764  1             \n4  2306  1             ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>ratingCategory</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3461</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2604</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3341</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3764</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2306</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "subNumber = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You're trying to achieve a minimum of 70% Accuracy on your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Indexing (Learn)\n",
    "<a id=\"p2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "4. Make a submission to Kaggle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing some imports for the Laten semantic indexing\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the best parameters for the model from\n",
    "# the grid search.(up above)\n",
    "#{'clf__max_depth': None,\n",
    "# 'clf__n_estimators': 100,\n",
    "# 'vect__max_df': 1.0,\n",
    "# 'vect__max_features': 5000,\n",
    "# 'vect__min_df': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=100, algorithm=\"randomized\",\n",
    "n_iter=10,\n",
    "random_state=49)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to add some of the param for the vectorizer\n",
    "vect = TfidfVectorizer(stop_words=\"english\", ngram_range=(1,2), min_df=2, max_features=5000)\n",
    "clf = RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the parameters for the next pipeline\n",
    "params = {\n",
    "    \"lsi__svd__n_components\": [65, 100, 250 ],\n",
    "    \"lsi__vect__max_df\" : [.9, .95, 1.0],\n",
    "    \"clf__n_estimators\": [5, 10,  20, 100]\n",
    "\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "parameters = {\n",
    "    'lsi__svd__n_components': [10,100,250],\n",
    "    'lsi__vect__max_df': (0.75, 1.0),\n",
    "    'clf__max_depth':(5,10,15,20)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi = Pipeline([(\"vect\", vect), (\"svd\", svd)])\n",
    "\n",
    "\n",
    "\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:   43.4s\n[Parallel(n_jobs=3)]: Done 120 out of 120 | elapsed:  2.4min finished\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GridSearchCV(cv=5, error_score=nan,\n             estimator=Pipeline(memory=None,\n                                steps=[('lsi',\n                                        Pipeline(memory=None,\n                                                 steps=[('vect',\n                                                         TfidfVectorizer(analyzer='word',\n                                                                         binary=False,\n                                                                         decode_error='strict',\n                                                                         dtype=<class 'numpy.float64'>,\n                                                                         encoding='utf-8',\n                                                                         input='content',\n                                                                         lowercase=True,\n                                                                         max_df=1.0,\n                                                                         max_features=5000,\n                                                                         min_df=2,\n                                                                         ngram_range=(1,\n                                                                                      2),\n                                                                         norm='l2',\n                                                                         preprocessor=None,\n                                                                         smooth_...\n                                                               min_weight_fraction_leaf=0.0,\n                                                               n_estimators=100,\n                                                               n_jobs=None,\n                                                               oob_score=False,\n                                                               random_state=None,\n                                                               verbose=0,\n                                                               warm_start=False))],\n                                verbose=False),\n             iid='deprecated', n_jobs=3,\n             param_grid={'clf__max_depth': (5, 10, 15, 20),\n                         'lsi__svd__n_components': [10, 100, 250],\n                         'lsi__vect__max_df': (0.75, 1.0)},\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring=None, verbose=1)"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=3, verbose=1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'clf__max_depth': 10, 'lsi__svd__n_components': 10, 'lsi__vect__max_df': 1.0}"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# finding the best parameters\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7265254225381794"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1782    \\nVery fragrant, with notes of fresh ripe plum...\n3414    \\nThe good news: This is one of the best Highl...\nName: description, dtype: object"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = grid_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     id  ratingCategory\n0  3461               1\n1  2604               1\n2  3341               1\n3  3764               1\n4  2306               1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>ratingCategory</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3461</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2604</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3341</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3764</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2306</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_SUBMISSION = os.path.join(\".\",\"submission\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "subNumber = 1\n",
    "submission.to_csv(os.path.join(\".\",  f\"submission{subNumber}.csv\"), index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Continue to apply Latent Semantic Indexing (LSI) to various datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings with Spacy (Learn)\n",
    "<a id=\"p3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to your Dataset\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {\n",
    "    'max_depth' : randint(3,10),\n",
    "    'min_samples_leaf': randint(2,15)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing the import for spacy here\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all the vectors for the words from spacy\n",
    "def get_vects(descrip_list):\n",
    "    return [nlp(doc).vector for doc in descrip_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the function to get all the vectors for \n",
    "# for all the descriptions\n",
    "vect_list = get_vects(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going to make a fresh new random forest classifier\n",
    "rf_classifier = RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=None, max_features='auto',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=100,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False)"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "# will fit on the classifier\n",
    "rf_classifier.fit(vect_list, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the vectors of the \n",
    "# test part\n",
    "test_vect = get_vects(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the prediction \n",
    "predictions = rf_classifier.predict(test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the accuracy for the score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The accuracy score is 0.7371638141809291\n"
    }
   ],
   "source": [
    "score = accuracy_score(y_test, predictions)\n",
    "print(f\"The accuracy score is {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will try with the random forest classifier with the parameters better\n",
    "rf_classifier = RandomForestClassifier(max_depth=None, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=None, max_features='auto',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=100,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False)"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "rf_classifier.fit(vect_list, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf_classifier.predict(test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The accuracy score is 0.7383863080684596\n"
    }
   ],
   "source": [
    "score = accuracy_score(y_test, predictions)\n",
    "print(f\"The accuracy score is {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will recombine all the data and then will retrain the same model again\n",
    "\n",
    "# Combining all the data\n",
    "all_vect = vect_list + test_vect\n",
    "all_target = y_train.to_list() + y_test.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=None, max_features='auto',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=100,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False)"
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "rf_classifier.fit(all_vect, all_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vect = get_vects(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = rf_classifier.predict(test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     id  ratingCategory\n0  3461               1\n1  2604               1\n2  3341               1\n3  3764               1\n4  2306               1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>ratingCategory</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3461</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2604</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3341</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3764</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2306</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2"
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "subNumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "submission.to_csv(os.path.join(f\"submission{subNumber}.csv\"), index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n",
    "4. Make a submission to Kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Lecture Assignment\n",
    "<a id=\"p4\"></a>\n",
    "\n",
    "Your primary assignment this afternoon is to achieve a minimum of 70% accuracy on the Kaggle competition. Once you have achieved 70% accuracy, please work on the following: \n",
    "\n",
    "1. Research \"Sentiment Analysis\". Provide answers in markdown to the following questions: \n",
    "    - What is \"Sentiment Analysis\"? \n",
    "    - Is Document Classification different than \"Sentiment Analysis\"? Provide evidence for your response\n",
    "    - How do create labeled sentiment data? Are those labels really sentiment?\n",
    "    - What are common applications of sentiment analysis?\n",
    "2. Research our why word embeddings worked better for the lecture notebook than on the whiskey competition.\n",
    "    - This [text classification documentation](https://developers.google.com/machine-learning/guides/text-classification/step-2-5) from Google might be of interest\n",
    "    - Neural Networks are becoming more popular for document classification. Why is that the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers for part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment analysis is a form of a classification of text, but along the lines of the \n",
    "emotions or sentiment of the text.  For example if the text is negative, or if the text is positive (happy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment analysis is a flavour of Document classification.  You are classifying the text into a type of sentiment.  You are trying to decide of the sentance (or the word) is negative, positive or neutral. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way to create labled data for a sentiment analysis, could be to ceate rules yourself and then apply those rules to the data to label it.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common application for sentiment analyisis would be to see the sentiment of a brand on the internet.  To monitor if reviews for a product are positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers for question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may have to do that word embeddings can generally work better when the number of samples/number of words per sample ratio is more than 1500.  The whiskey the number of words per sample is lower and the ratio is less than 1500."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the reasons why neural networks are becoming more popular for classification is because neural networks can learn from what is in the data and also what is not.\n",
    "They may also be more resistant to letting the classification be skewed when it shouldn't if the data that is fed to the neural networks is not quite balanced in the different types of classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lam4-nlp-s1 (Python3)",
   "language": "python",
   "name": "lam4-nlp-s1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}