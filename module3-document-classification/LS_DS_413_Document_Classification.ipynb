{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 4, Sprint 1, Module 3*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification (Prepare)\n",
    "\n",
    "Today's guided module project will be different. You already know how to do classification. You ready know how to extract features from documents. So? That means you're ready to combine and practice those skills in a kaggle competition. We we will open with a five minute sprint explaining the competition, and then give you 25 minutes to work. After those twenty five minutes are up, I will give a 5-minute demo an NLP technique that will help you with document classification (*and **maybe** the competition*).\n",
    "\n",
    "Today's all about having fun and practicing your skills. The competition will begin\n",
    "\n",
    "## Learning Objectives\n",
    "* <a href=\"#p0\">Part 0</a>: Kaggle Competition\n",
    "* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n",
    "* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n",
    "* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Feature Extraction & Classification Pieplines (Learn)\n",
    "<a id=\"p1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Sklearn pipelines allow you to stitch together multiple components of a machine learning process. The idea is that you can pass you raw data and get predictions out of the pipeline. This ability to pass raw input and receive a prediction from a singular class makes pipelines well suited for production, because you can pickle a a pipeline without worry about other data preprocessing steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['alt.atheism',\n",
    "              'talk.religion.misc']\n",
    "\n",
    "data = fetch_20newsgroups(subset='train', categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipeline Components\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Pipeline\n",
    "pipe = Pipeline([\n",
    "                 #Vectorizer\n",
    "                 ('vect', vect), \n",
    "                 # Classifier\n",
    "                 ('clf', rfc)\n",
    "                ])\n",
    "\n",
    "# The pipeline puts together a bunch fit then transform,fit them predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:   24.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'vect__max_df': (0.75, 1.0), 'vect__min_df': (0.02, 0.05), 'vect__max_features': (500, 1000), 'clf__n_estimators': (5, 10), 'clf__max_depth': (15, 20)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': ( 0.75, 1.0),\n",
    "    'vect__min_df': (.02, .05),\n",
    "    'vect__max_features': (500,1000),\n",
    "    'clf__n_estimators':(5, 10,),\n",
    "    'clf__max_depth':(15,20)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(data.data, data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8891481913652275"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.predict(['Send me lots of money now', 'you won the lottery in Nigeria'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along \n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model (try using the pipe method I just demoed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Competition Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('./data/ds8-which-whiskey/train.csv')\n",
    "test = pd.read_csv('./data/ds8-which-whiskey/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A marriage of 13 and 18 year old bourbons. A m...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>There have been some legendary Bowmores from t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>This bottling celebrates master distiller Park...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>What impresses me most is how this whisky evol...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>A caramel-laden fruit bouquet, followed by une...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                        description  category\n",
       "0   1  A marriage of 13 and 18 year old bourbons. A m...         2\n",
       "1   2  There have been some legendary Bowmores from t...         1\n",
       "2   3  This bottling celebrates master distiller Park...         2\n",
       "3   4  What impresses me most is how this whisky evol...         1\n",
       "4   9  A caramel-laden fruit bouquet, followed by une...         2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>955</td>\n",
       "      <td>Think carnival aromas—the good ones, anyway—me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3532</td>\n",
       "      <td>A blend of three bourbons, between 6 and 12 ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1390</td>\n",
       "      <td>The nose is focused on cereal, hints of fresh ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024</td>\n",
       "      <td>Swiss-based Chapter 7 released this 19 year ol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902</td>\n",
       "      <td>Valkyrie replaces the current Dark Origins exp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                        description\n",
       "0   955  Think carnival aromas—the good ones, anyway—me...\n",
       "1  3532  A blend of three bourbons, between 6 and 12 ye...\n",
       "2  1390  The nose is focused on cereal, hints of fresh ...\n",
       "3  1024  Swiss-based Chapter 7 released this 19 year ol...\n",
       "4  1902  Valkyrie replaces the current Dark Origins exp..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['description']\n",
    "y_train = train['category']\n",
    "X_test = test['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "model = RandomForestClassifier(n_estimators=200)\n",
    "\n",
    "pipe = Pipeline([('vect', vect), ('model', model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   36.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "          estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "          fit_params=None, iid='warn', n_iter=10, n_jobs=-1,\n",
       "          param_distributions={'vect__max_df': (0.7, 1.0), 'vect__min_df': (0.01, 0.1), 'model__max_depth': (5, 10, 15, 20, None), 'model__max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000028808EEADA0>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.7, 1.0),\n",
    "    'vect__min_df': (0.01, 0.1),\n",
    "    'model__max_depth': (5,10,15,20,None),\n",
    "    'model__max_features': uniform(0, 1)\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(pipe,parameters, n_iter=10, cv=5, n_jobs=-1, verbose=1, return_train_score=True)\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8859242072699149"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File\n",
    "*Note:* In a typical Kaggle competition, you are only allowed two submissions a day, so you only submit if you feel you cannot achieve higher test accuracy. For this compeition the max daily submissions are capped at **20**. Submit for each demo and for your assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'category':pred})\n",
    "submission['category'] = submission['category'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>955</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3532</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  category\n",
       "0   955         2\n",
       "1  3532         2\n",
       "2  1390         1\n",
       "3  1024         1\n",
       "4  1902         1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "submission.to_csv('./whiskey-submission-1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   14.3s finished\n",
      "C:\\Anaconda3\\envs\\Unit4_Sprint1\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'vect__max_df': (0.75, 1.0), 'vect__min_df': (0.02, 0.05), 'model__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "pipe = Pipeline([('vect', vect), ('model', model)])\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': ( 0.75, 1.0),\n",
    "    'vect__min_df': (.02, .05),\n",
    "    'model__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8901778808971385"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'category':pred})\n",
    "submission['category'] = submission['category'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>955</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3532</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  category\n",
       "0   955         2\n",
       "1  3532         3\n",
       "2  1390         1\n",
       "3  1024         1\n",
       "4  1902         1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./whiskey-submission-2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third try\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "model = RandomForestClassifier(n_estimators=200)\n",
    "\n",
    "pipe = Pipeline([('vect', vect), ('model', model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max_df corresponds to < documents than min_df",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Anaconda3\\envs\\Unit4_Sprint1\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"C:\\Anaconda3\\envs\\Unit4_Sprint1\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Anaconda3\\envs\\Unit4_Sprint1\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Anaconda3\\envs\\Unit4_Sprint1\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Anaconda3\\envs\\Unit4_Sprint1\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"C:\\Anaconda3\\envs\\Unit4_Sprint1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 528, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Anaconda3\\envs\\Unit4_Sprint1\\lib\\site-packages\\sklearn\\pipeline.py\", line 265, in fit\n    Xt, fit_params = self._fit(X, y, **fit_params)\n  File \"C:\\Anaconda3\\envs\\Unit4_Sprint1\\lib\\site-packages\\sklearn\\pipeline.py\", line 230, in _fit\n    **fit_params_steps[name])\n  File \"C:\\Anaconda3\\envs\\Unit4_Sprint1\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py\", line 342, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Anaconda3\\envs\\Unit4_Sprint1\\lib\\site-packages\\sklearn\\pipeline.py\", line 614, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Anaconda3\\envs\\Unit4_Sprint1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1603, in fit_transform\n    X = super(TfidfVectorizer, self).fit_transform(raw_documents)\n  File \"C:\\Anaconda3\\envs\\Unit4_Sprint1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1049, in fit_transform\n    \"max_df corresponds to < documents than min_df\")\nValueError: max_df corresponds to < documents than min_df\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-d3a9e212d986>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0msearch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0msearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\envs\\Unit4_Sprint1\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    720\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\Unit4_Sprint1\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1513\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[0;32m   1514\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1515\u001b[1;33m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\envs\\Unit4_Sprint1\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    709\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 711\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\Unit4_Sprint1\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    931\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\Unit4_Sprint1\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\Unit4_Sprint1\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\Unit4_Sprint1\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\Unit4_Sprint1\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: max_df corresponds to < documents than min_df"
     ]
    }
   ],
   "source": [
    "# can't figure out why i'm getting this error message...leaving it for posterity\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.6, 1),\n",
    "    'vect__min_df': (0.001, 0.3),\n",
    "    'model__max_depth': (5,10,15,20,None),\n",
    "    'model__max_features': uniform(0, 1)\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(pipe,parameters, n_iter=10, cv=5, n_jobs=-1, verbose=1, return_train_score=True)\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8128383604021655"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You're trying to achienve 90% Accuracy on your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Indexing (Learn)\n",
    "<a id=\"p2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=100, # Just here for demo.\n",
    "                   algorithm='randomized',\n",
    "                   n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { \n",
    "    'lsi__svd__n_components': [10,100,250],\n",
    "    'lsi__vect__max_df':[.9, .95, 1.0],\n",
    "    'clf__n_estimators':[5,10,20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSI\n",
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "\n",
    "\n",
    "# Pipe\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', rfc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  45 out of  45 | elapsed:   23.7s finished\n",
      "/Users/jonathansokoll/anaconda3/envs/U4-S1-NLP-DS6/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('lsi', Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm=...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=4,\n",
       "       param_grid={'lsi__svd__n_components': [10, 100, 250], 'lsi__vect__max_df': [0.9, 0.95, 1.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit\n",
    "grid_search = GridSearchCV(pipe,params, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(data.data, data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8786464410735122"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "4. Make a submission to Kaggle \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "clf = RandomForestClassifier()\n",
    "svd = TruncatedSVD(algorithm='randomized', n_iter=10)\n",
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.4min finished\n",
      "C:\\Anaconda3\\envs\\Unit4_Sprint1\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "          estimator=Pipeline(memory=None,\n",
       "     steps=[('lsi', Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), norm=...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "          fit_params=None, iid='warn', n_iter=10, n_jobs=-1,\n",
       "          param_distributions={'lsi__svd__n_components': [10, 50, 75], 'lsi__vect__max_df': (0.75, 1.0), 'lsi__vect__min_df': (0.01, 0.05), 'clf__max_depth': (5, 10, 15, 20)},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'lsi__svd__n_components': [10,50,75],\n",
    "    'lsi__vect__max_df': (0.75, 1.0),\n",
    "    'lsi__vect__min_df': (0.01, 0.05),\n",
    "    'clf__max_depth':(5,10,15,20)\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(pipe,parameters, n_iter=10, cv=5, n_jobs=-1, verbose=1, return_train_score=True)\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8766434648105181"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File\n",
    "*Note:* You are only allowed two submissions a day. Only submit if you feel you cannot achieve higher test accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'category':pred})\n",
    "submission['category'] = submission['category'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>955</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3532</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  category\n",
       "0   955         2\n",
       "1  3532         3\n",
       "2  1390         1\n",
       "3  1024         1\n",
       "4  1902         1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I forgot to pull the most recent changes so I didn't have the below two cells in my notebook. Copying them here for posterity..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subNumber = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "submission.to_csv('./whiskey-submission-3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Continue to apply Latent Semantic Indexing (LSI) to various datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings with Spacy (Learn)\n",
    "<a id=\"p3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Two bananas in pyjamas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "bananas_vector = doc.vector\n",
    "print(len(bananas_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X) == len(data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vectors(docs):\n",
    "    return [nlp(doc).vector for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathansokoll/anaconda3/envs/U4-S1-NLP-DS6/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = get_word_vectors(data.data)\n",
    "\n",
    "rfc.fit(X, data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9918319719953326"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(X, data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect = get_word_vectors(X_train)\n",
    "\n",
    "assert len(X_train_vect) == len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9930394431554525"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'category':pred})\n",
    "submission['category'] = submission['category'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>955</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3532</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  category\n",
       "0   955         2\n",
       "1  3532         3\n",
       "2  1390         1\n",
       "3  1024         1\n",
       "4  1902         1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./whiskey-submission-4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# majority vote\n",
    "\n",
    "files = ['whiskey-submission-1.csv', 'whiskey-submission-3.csv', 'whiskey-submission-4.csv']\n",
    "\n",
    "target = 'category'\n",
    "submissions = (pd.read_csv(file)[[target]] for file in files)\n",
    "ensemble = pd.concat(submissions, axis='columns')\n",
    "majority_vote = ensemble.mode(axis='columns')[0]\n",
    "\n",
    "submission[target] = majority_vote\n",
    "submission.to_csv('./whiskey-submission-5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n",
    "4. Make a submission to Kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review\n",
    "\n",
    "To review this module: \n",
    "* Continue working on the Kaggle comeptition\n",
    "* Find another text classification task to work on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(docs):\n",
    "    tokenized = []\n",
    "    for doc in docs:\n",
    "        nlp_doc = nlp(doc)\n",
    "        tokens = ''\n",
    "        for token in nlp_doc:\n",
    "            if (token.is_stop is not True) and (token.is_punct is not True):\n",
    "                tokens = tokens + ' ' + token.text.lower()\n",
    "        tokenized.append(tokens)\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mature"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(X_train[0])[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_token = get_tokens(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done 121 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done 157 tasks      | elapsed:   19.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=-1)]: Done 197 tasks      | elapsed:   23.8s\n",
      "[Parallel(n_jobs=-1)]: Done 218 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=-1)]: Done 241 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed:   30.9s\n",
      "[Parallel(n_jobs=-1)]: Done 289 tasks      | elapsed:   33.2s\n",
      "[Parallel(n_jobs=-1)]: Done 314 tasks      | elapsed:   35.6s\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:   38.7s\n",
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed:   41.5s\n",
      "[Parallel(n_jobs=-1)]: Done 397 tasks      | elapsed:   44.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   47.6s\n",
      "[Parallel(n_jobs=-1)]: Done 457 tasks      | elapsed:   50.6s\n",
      "[Parallel(n_jobs=-1)]: Done 488 tasks      | elapsed:   54.5s\n",
      "[Parallel(n_jobs=-1)]: Done 521 tasks      | elapsed:   58.4s\n",
      "[Parallel(n_jobs=-1)]: Done 554 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 589 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 661 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 698 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 737 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 817 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 858 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 901 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 944 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 989 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1034 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1081 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1128 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1177 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1277 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1328 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1381 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1434 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1489 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1544 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1601 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1658 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1717 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1837 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1898 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1961 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:  3.6min finished\n",
      "C:\\Anaconda3\\envs\\Unit4_Sprint1\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Anaconda3\\envs\\Unit4_Sprint1\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise-deprecating',\n",
       "          estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))]),\n",
       "          fit_params=None, iid='warn', n_iter=200, n_jobs=-1,\n",
       "          param_distributions={'vect__max_df': [0.7, 0.8, 0.9, 1.0], 'vect__min_df': [0.01, 0.1, 0.15, 0.2], 'vect__max_features': [100, 250, 500, 1000], 'logreg__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logistic regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('vect', vect),\n",
    "    ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'vect__max_df': [0.7, 0.8, 0.9, 1.0],\n",
    "    'vect__min_df': [0.01, 0.1, 0.15, 0.2],\n",
    "    'vect__max_features': [100, 250, 500, 1000],\n",
    "    'logreg__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(pipe, params, n_iter=200, cv=10, scoring='accuracy', verbose=10, n_jobs=-1)\n",
    "\n",
    "search.fit(X_train_token, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8982985305491106"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vect__min_df': 0.01,\n",
       " 'vect__max_features': 500,\n",
       " 'vect__max_df': 0.7,\n",
       " 'logreg__solver': 'saga'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(search, number):\n",
    "    pred = search.predict(X_test)\n",
    "    submission = pd.DataFrame({'id': test['id'], 'category':pred})\n",
    "    submission['category'] = submission['category'].astype('int64')\n",
    "    submission.to_csv(f'./whiskey-submission-{number}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(search, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   23.0s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   28.9s\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:   33.5s\n",
      "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed:   45.1s\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:   53.9s\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 121 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 157 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 197 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 218 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 241 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 289 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 314 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 397 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 457 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done 488 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 521 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 554 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 589 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 661 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 698 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done 737 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=-1)]: Done 817 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=-1)]: Done 858 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=-1)]: Done 901 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=-1)]: Done 944 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done 989 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1034 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1081 tasks      | elapsed: 14.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1128 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1177 tasks      | elapsed: 16.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed: 16.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1277 tasks      | elapsed: 16.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1328 tasks      | elapsed: 17.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1381 tasks      | elapsed: 17.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1434 tasks      | elapsed: 18.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1489 tasks      | elapsed: 19.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1544 tasks      | elapsed: 19.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1601 tasks      | elapsed: 20.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1658 tasks      | elapsed: 20.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1717 tasks      | elapsed: 21.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed: 22.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1837 tasks      | elapsed: 22.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1898 tasks      | elapsed: 23.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1961 tasks      | elapsed: 24.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed: 24.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise-deprecating',\n",
       "          estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "          fit_params=None, iid='warn', n_iter=200, n_jobs=-1,\n",
       "          param_distributions={'vect__max_df': [0.7, 0.8, 0.9, 1.0], 'vect__min_df': [0.01, 0.1, 0.15, 0.2], 'model__n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001E85E209390>, 'model__max_depth': [5, 10, 15, 20, None], 'model__max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001E85E2092B0>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('vect', vect),\n",
    "    ('model', rfc)\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'vect__max_df': [0.7, 0.8, 0.9, 1.0],\n",
    "    'vect__min_df': [0.01, 0.1, 0.15, 0.2],\n",
    "    'model__n_estimators': randint(50, 500),\n",
    "    'model__max_depth': [5, 10, 15, 20, None],\n",
    "    'model__max_features': uniform(0,1)\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(pipe, params, n_iter=200, cv=10, scoring='accuracy', verbose=10, n_jobs=-1)\n",
    "\n",
    "search.fit(X_train_token, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9017788089713844"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(search, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2), min_df=0.01, max_df=0.7, max_features=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect = vect.fit_transform(X_train_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_vect, X_val_vect = train_test_split(X_train_vect, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_val = train_test_split(y_train, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-merror:0.103146\tvalidation_1-merror:0.25966\n",
      "Multiple eval metrics have been passed: 'validation_1-merror' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-merror hasn't improved in 50 rounds.\n",
      "[1]\tvalidation_0-merror:0.098504\tvalidation_1-merror:0.244204\n",
      "[2]\tvalidation_0-merror:0.098504\tvalidation_1-merror:0.244204\n",
      "[3]\tvalidation_0-merror:0.096957\tvalidation_1-merror:0.236476\n",
      "[4]\tvalidation_0-merror:0.092316\tvalidation_1-merror:0.242658\n",
      "[5]\tvalidation_0-merror:0.0918\tvalidation_1-merror:0.241113\n",
      "[6]\tvalidation_0-merror:0.089737\tvalidation_1-merror:0.242658\n",
      "[7]\tvalidation_0-merror:0.087158\tvalidation_1-merror:0.244204\n",
      "[8]\tvalidation_0-merror:0.08097\tvalidation_1-merror:0.231839\n",
      "[9]\tvalidation_0-merror:0.082001\tvalidation_1-merror:0.230294\n",
      "[10]\tvalidation_0-merror:0.078391\tvalidation_1-merror:0.228748\n",
      "[11]\tvalidation_0-merror:0.079938\tvalidation_1-merror:0.224111\n",
      "[12]\tvalidation_0-merror:0.073749\tvalidation_1-merror:0.224111\n",
      "[13]\tvalidation_0-merror:0.074781\tvalidation_1-merror:0.225657\n",
      "[14]\tvalidation_0-merror:0.073749\tvalidation_1-merror:0.22102\n",
      "[15]\tvalidation_0-merror:0.068076\tvalidation_1-merror:0.214838\n",
      "[16]\tvalidation_0-merror:0.064982\tvalidation_1-merror:0.208655\n",
      "[17]\tvalidation_0-merror:0.064466\tvalidation_1-merror:0.213292\n",
      "[18]\tvalidation_0-merror:0.060856\tvalidation_1-merror:0.213292\n",
      "[19]\tvalidation_0-merror:0.06034\tvalidation_1-merror:0.211747\n",
      "[20]\tvalidation_0-merror:0.058793\tvalidation_1-merror:0.213292\n",
      "[21]\tvalidation_0-merror:0.055183\tvalidation_1-merror:0.208655\n",
      "[22]\tvalidation_0-merror:0.052089\tvalidation_1-merror:0.208655\n",
      "[23]\tvalidation_0-merror:0.051573\tvalidation_1-merror:0.208655\n",
      "[24]\tvalidation_0-merror:0.048994\tvalidation_1-merror:0.20711\n",
      "[25]\tvalidation_0-merror:0.047447\tvalidation_1-merror:0.204019\n",
      "[26]\tvalidation_0-merror:0.046416\tvalidation_1-merror:0.204019\n",
      "[27]\tvalidation_0-merror:0.043321\tvalidation_1-merror:0.204019\n",
      "[28]\tvalidation_0-merror:0.043837\tvalidation_1-merror:0.20711\n",
      "[29]\tvalidation_0-merror:0.041774\tvalidation_1-merror:0.208655\n",
      "[30]\tvalidation_0-merror:0.040743\tvalidation_1-merror:0.20711\n",
      "[31]\tvalidation_0-merror:0.039711\tvalidation_1-merror:0.205564\n",
      "[32]\tvalidation_0-merror:0.038164\tvalidation_1-merror:0.202473\n",
      "[33]\tvalidation_0-merror:0.036617\tvalidation_1-merror:0.202473\n",
      "[34]\tvalidation_0-merror:0.036617\tvalidation_1-merror:0.200927\n",
      "[35]\tvalidation_0-merror:0.035585\tvalidation_1-merror:0.202473\n",
      "[36]\tvalidation_0-merror:0.03507\tvalidation_1-merror:0.200927\n",
      "[37]\tvalidation_0-merror:0.034038\tvalidation_1-merror:0.200927\n",
      "[38]\tvalidation_0-merror:0.033522\tvalidation_1-merror:0.199382\n",
      "[39]\tvalidation_0-merror:0.032491\tvalidation_1-merror:0.197836\n",
      "[40]\tvalidation_0-merror:0.03146\tvalidation_1-merror:0.196291\n",
      "[41]\tvalidation_0-merror:0.029397\tvalidation_1-merror:0.197836\n",
      "[42]\tvalidation_0-merror:0.028881\tvalidation_1-merror:0.196291\n",
      "[43]\tvalidation_0-merror:0.028365\tvalidation_1-merror:0.196291\n",
      "[44]\tvalidation_0-merror:0.028365\tvalidation_1-merror:0.197836\n",
      "[45]\tvalidation_0-merror:0.026302\tvalidation_1-merror:0.197836\n",
      "[46]\tvalidation_0-merror:0.025271\tvalidation_1-merror:0.199382\n",
      "[47]\tvalidation_0-merror:0.023724\tvalidation_1-merror:0.199382\n",
      "[48]\tvalidation_0-merror:0.023208\tvalidation_1-merror:0.199382\n",
      "[49]\tvalidation_0-merror:0.021145\tvalidation_1-merror:0.197836\n",
      "[50]\tvalidation_0-merror:0.020629\tvalidation_1-merror:0.199382\n",
      "[51]\tvalidation_0-merror:0.019598\tvalidation_1-merror:0.199382\n",
      "[52]\tvalidation_0-merror:0.019082\tvalidation_1-merror:0.196291\n",
      "[53]\tvalidation_0-merror:0.018566\tvalidation_1-merror:0.193199\n",
      "[54]\tvalidation_0-merror:0.017535\tvalidation_1-merror:0.193199\n",
      "[55]\tvalidation_0-merror:0.017535\tvalidation_1-merror:0.187017\n",
      "[56]\tvalidation_0-merror:0.017019\tvalidation_1-merror:0.191654\n",
      "[57]\tvalidation_0-merror:0.016503\tvalidation_1-merror:0.188563\n",
      "[58]\tvalidation_0-merror:0.016503\tvalidation_1-merror:0.185471\n",
      "[59]\tvalidation_0-merror:0.015472\tvalidation_1-merror:0.187017\n",
      "[60]\tvalidation_0-merror:0.014956\tvalidation_1-merror:0.187017\n",
      "[61]\tvalidation_0-merror:0.01444\tvalidation_1-merror:0.188563\n",
      "[62]\tvalidation_0-merror:0.012893\tvalidation_1-merror:0.188563\n",
      "[63]\tvalidation_0-merror:0.012893\tvalidation_1-merror:0.191654\n",
      "[64]\tvalidation_0-merror:0.011862\tvalidation_1-merror:0.190108\n",
      "[65]\tvalidation_0-merror:0.01083\tvalidation_1-merror:0.187017\n",
      "[66]\tvalidation_0-merror:0.01083\tvalidation_1-merror:0.185471\n",
      "[67]\tvalidation_0-merror:0.010315\tvalidation_1-merror:0.185471\n",
      "[68]\tvalidation_0-merror:0.010315\tvalidation_1-merror:0.185471\n",
      "[69]\tvalidation_0-merror:0.010315\tvalidation_1-merror:0.183926\n",
      "[70]\tvalidation_0-merror:0.010315\tvalidation_1-merror:0.183926\n",
      "[71]\tvalidation_0-merror:0.009799\tvalidation_1-merror:0.18238\n",
      "[72]\tvalidation_0-merror:0.009283\tvalidation_1-merror:0.185471\n",
      "[73]\tvalidation_0-merror:0.009283\tvalidation_1-merror:0.185471\n",
      "[74]\tvalidation_0-merror:0.009283\tvalidation_1-merror:0.183926\n",
      "[75]\tvalidation_0-merror:0.008767\tvalidation_1-merror:0.185471\n",
      "[76]\tvalidation_0-merror:0.008252\tvalidation_1-merror:0.185471\n",
      "[77]\tvalidation_0-merror:0.007736\tvalidation_1-merror:0.185471\n",
      "[78]\tvalidation_0-merror:0.007736\tvalidation_1-merror:0.183926\n",
      "[79]\tvalidation_0-merror:0.006704\tvalidation_1-merror:0.185471\n",
      "[80]\tvalidation_0-merror:0.006704\tvalidation_1-merror:0.185471\n",
      "[81]\tvalidation_0-merror:0.006704\tvalidation_1-merror:0.185471\n",
      "[82]\tvalidation_0-merror:0.006704\tvalidation_1-merror:0.185471\n",
      "[83]\tvalidation_0-merror:0.006704\tvalidation_1-merror:0.185471\n",
      "[84]\tvalidation_0-merror:0.006704\tvalidation_1-merror:0.183926\n",
      "[85]\tvalidation_0-merror:0.006704\tvalidation_1-merror:0.185471\n",
      "[86]\tvalidation_0-merror:0.006189\tvalidation_1-merror:0.185471\n",
      "[87]\tvalidation_0-merror:0.006189\tvalidation_1-merror:0.185471\n",
      "[88]\tvalidation_0-merror:0.005673\tvalidation_1-merror:0.185471\n",
      "[89]\tvalidation_0-merror:0.004642\tvalidation_1-merror:0.187017\n",
      "[90]\tvalidation_0-merror:0.004642\tvalidation_1-merror:0.185471\n",
      "[91]\tvalidation_0-merror:0.004642\tvalidation_1-merror:0.183926\n",
      "[92]\tvalidation_0-merror:0.004126\tvalidation_1-merror:0.18238\n",
      "[93]\tvalidation_0-merror:0.004126\tvalidation_1-merror:0.179289\n",
      "[94]\tvalidation_0-merror:0.004126\tvalidation_1-merror:0.180835\n",
      "[95]\tvalidation_0-merror:0.004126\tvalidation_1-merror:0.179289\n",
      "[96]\tvalidation_0-merror:0.00361\tvalidation_1-merror:0.180835\n",
      "[97]\tvalidation_0-merror:0.00361\tvalidation_1-merror:0.180835\n",
      "[98]\tvalidation_0-merror:0.00361\tvalidation_1-merror:0.179289\n",
      "[99]\tvalidation_0-merror:0.003094\tvalidation_1-merror:0.179289\n",
      "[100]\tvalidation_0-merror:0.003094\tvalidation_1-merror:0.177743\n",
      "[101]\tvalidation_0-merror:0.003094\tvalidation_1-merror:0.179289\n",
      "[102]\tvalidation_0-merror:0.003094\tvalidation_1-merror:0.179289\n",
      "[103]\tvalidation_0-merror:0.002579\tvalidation_1-merror:0.179289\n",
      "[104]\tvalidation_0-merror:0.002579\tvalidation_1-merror:0.179289\n",
      "[105]\tvalidation_0-merror:0.002579\tvalidation_1-merror:0.179289\n",
      "[106]\tvalidation_0-merror:0.002579\tvalidation_1-merror:0.177743\n",
      "[107]\tvalidation_0-merror:0.002063\tvalidation_1-merror:0.179289\n",
      "[108]\tvalidation_0-merror:0.002063\tvalidation_1-merror:0.179289\n",
      "[109]\tvalidation_0-merror:0.002063\tvalidation_1-merror:0.177743\n",
      "[110]\tvalidation_0-merror:0.002063\tvalidation_1-merror:0.179289\n",
      "[111]\tvalidation_0-merror:0.002063\tvalidation_1-merror:0.180835\n",
      "[112]\tvalidation_0-merror:0.002063\tvalidation_1-merror:0.179289\n",
      "[113]\tvalidation_0-merror:0.002063\tvalidation_1-merror:0.180835\n",
      "[114]\tvalidation_0-merror:0.002063\tvalidation_1-merror:0.180835\n",
      "[115]\tvalidation_0-merror:0.002063\tvalidation_1-merror:0.18238\n",
      "[116]\tvalidation_0-merror:0.002063\tvalidation_1-merror:0.18238\n",
      "[117]\tvalidation_0-merror:0.002063\tvalidation_1-merror:0.183926\n",
      "[118]\tvalidation_0-merror:0.002063\tvalidation_1-merror:0.183926\n",
      "[119]\tvalidation_0-merror:0.002063\tvalidation_1-merror:0.183926\n",
      "[120]\tvalidation_0-merror:0.001547\tvalidation_1-merror:0.183926\n",
      "[121]\tvalidation_0-merror:0.001547\tvalidation_1-merror:0.183926\n",
      "[122]\tvalidation_0-merror:0.002063\tvalidation_1-merror:0.183926\n",
      "[123]\tvalidation_0-merror:0.002063\tvalidation_1-merror:0.183926\n",
      "[124]\tvalidation_0-merror:0.002063\tvalidation_1-merror:0.183926\n",
      "[125]\tvalidation_0-merror:0.001547\tvalidation_1-merror:0.183926\n",
      "[126]\tvalidation_0-merror:0.001547\tvalidation_1-merror:0.183926\n",
      "[127]\tvalidation_0-merror:0.002063\tvalidation_1-merror:0.183926\n",
      "[128]\tvalidation_0-merror:0.002063\tvalidation_1-merror:0.187017\n",
      "[129]\tvalidation_0-merror:0.001547\tvalidation_1-merror:0.187017\n",
      "[130]\tvalidation_0-merror:0.001547\tvalidation_1-merror:0.185471\n",
      "[131]\tvalidation_0-merror:0.001547\tvalidation_1-merror:0.188563\n",
      "[132]\tvalidation_0-merror:0.001547\tvalidation_1-merror:0.190108\n",
      "[133]\tvalidation_0-merror:0.001547\tvalidation_1-merror:0.188563\n",
      "[134]\tvalidation_0-merror:0.001547\tvalidation_1-merror:0.188563\n",
      "[135]\tvalidation_0-merror:0.001547\tvalidation_1-merror:0.188563\n",
      "[136]\tvalidation_0-merror:0.001547\tvalidation_1-merror:0.188563\n",
      "[137]\tvalidation_0-merror:0.001547\tvalidation_1-merror:0.190108\n",
      "[138]\tvalidation_0-merror:0.001031\tvalidation_1-merror:0.190108\n",
      "[139]\tvalidation_0-merror:0.001031\tvalidation_1-merror:0.190108\n",
      "[140]\tvalidation_0-merror:0.001031\tvalidation_1-merror:0.190108\n",
      "[141]\tvalidation_0-merror:0.001031\tvalidation_1-merror:0.190108\n",
      "[142]\tvalidation_0-merror:0.001031\tvalidation_1-merror:0.191654\n",
      "[143]\tvalidation_0-merror:0.001031\tvalidation_1-merror:0.191654\n",
      "[144]\tvalidation_0-merror:0.001031\tvalidation_1-merror:0.191654\n",
      "[145]\tvalidation_0-merror:0.001031\tvalidation_1-merror:0.188563\n",
      "[146]\tvalidation_0-merror:0.001031\tvalidation_1-merror:0.188563\n",
      "[147]\tvalidation_0-merror:0.001031\tvalidation_1-merror:0.188563\n",
      "[148]\tvalidation_0-merror:0.001031\tvalidation_1-merror:0.190108\n",
      "[149]\tvalidation_0-merror:0.000516\tvalidation_1-merror:0.188563\n",
      "[150]\tvalidation_0-merror:0.000516\tvalidation_1-merror:0.188563\n",
      "Stopping. Best iteration:\n",
      "[100]\tvalidation_0-merror:0.003094\tvalidation_1-merror:0.177743\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=1000, n_jobs=-1, nthread=None,\n",
       "       objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "eval_set = [(X_train_vect, y_train),\n",
    "            (X_val_vect, y_val)]\n",
    "\n",
    "model = XGBClassifier(\n",
    "    n_estimators=1000,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train_vect, y_train, eval_set=eval_set, eval_metric='merror', early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect = vect.fit_transform(X_train_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=1000, n_jobs=-1, nthread=None,\n",
       "       objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(\n",
    "    n_estimators=1000,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_token = get_tokens(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vect = vect.transform(X_test_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'category':pred})\n",
    "submission['category'] = submission['category'].astype('int64')\n",
    "submission.to_csv('./whiskey-submission-7.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above got me over 94% accuracy--and even more importantly, let me beat Jeremy!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Unit4_Sprint1 (Python3)",
   "language": "python",
   "name": "unit4_sprint1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
