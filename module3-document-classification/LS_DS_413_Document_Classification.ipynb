{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 4, Sprint 1, Module 3*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification (Prepare)\n",
    "\n",
    "Today's guided module project will be different. You already know how to do classification. You ready know how to extract features from documents. So? That means you're ready to combine and practice those skills in a kaggle competition. We we will open with a five minute sprint explaining the competition, and then give you 25 minutes to work. After those twenty five minutes are up, I will give a 5-minute demo an NLP technique that will help you with document classification (*and **maybe** the competition*). a\n",
    "\n",
    "Today's all about having fun and practicing your skills. The competition will begin\n",
    "\n",
    "## Learning Objectives\n",
    "* <a href=\"#p0\">Part 0</a>: Kaggle Competition\n",
    "* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n",
    "* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n",
    "* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Feature Extraction & Classification Pieplines (Learn)\n",
    "<a id=\"p1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Sklearn pipelines allow you to stitch together multiple components of a machine learning process. The idea is that you can pass you raw data and get predictions out of the pipeline. This ability to pass raw input and receive a prediction from a singular class makes pipelines well suited for production, because you can pickle a a pipeline without worry about other data preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T16:26:29.391784Z",
     "start_time": "2019-10-02T16:26:26.448048Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T16:26:29.889907Z",
     "start_time": "2019-10-02T16:26:29.395310Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['alt.atheism',\n",
    "              'talk.religion.misc']\n",
    "\n",
    "data = fetch_20newsgroups(subset='train', categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T16:26:33.152933Z",
     "start_time": "2019-10-02T16:26:33.139144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: mangoe@cs.umd.edu (Charley Wingate)\\nSubject: Benediktine Metaphysics\\nLines: 24\\n\\nBenedikt Rosenau writes, with great authority:\\n\\n>     IF IT IS CONTRADICTORY IT CANNOT EXIST.\\n\\n\"Contradictory\" is a property of language.  If I correct this to\\n\\n\\n      THINGS DEFINED BY CONTRADICTORY LANGUAGE DO NOT EXIST\\n\\nI will object to definitions as reality.  If you then amend it to\\n\\n      THINGS DESCRIBED BY CONTRADICTORY LANGUAGE DO NOT EXIST\\n\\nthen we\\'ve come to something which is plainly false.  Failures in\\ndescription are merely failures in description.\\n\\n(I\\'m not an objectivist, remember.)\\n\\n\\n-- \\nC. Wingate        + \"The peace of God, it is no peace,\\n                  +    but strife closed in the sod.\\nmangoe@cs.umd.edu +  Yet, brothers, pray for but one thing:\\ntove!mangoe       +    the marv\\'lous peace of God.\"\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn Pipeline Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T16:27:54.572681Z",
     "start_time": "2019-10-02T16:27:54.569706Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Pipeline\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# Define the Pipeline\n",
    "pipe = Pipeline([\n",
    "    # Vectorizer\n",
    "    ('vect', vect), \n",
    "    # Classifier\n",
    "    ('clf', rfc)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T16:30:44.367149Z",
     "start_time": "2019-10-02T16:27:55.513616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   51.2s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'vect__max_df': (0.5, 0.75, 1.0), 'vect__min_df': (0.02, 0.05), 'vect__max_features': (100, 500, 1000), 'clf__n_estimators': (5, 10, 50, 100), 'clf__max_depth': (5, 10, 15, 20)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__min_df': (.02, .05),\n",
    "    'vect__max_features': (100, 500,1000),\n",
    "    'clf__n_estimators':(5, 10, 50, 100),\n",
    "    'clf__max_depth':(5,10,15,20)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(data.data, data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T16:30:44.392945Z",
     "start_time": "2019-10-02T16:30:44.372145Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.predict(['Send me lots of money now', 'you won the lottery in Nigeria'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along \n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model (try using the pipe method I just demoed)\n",
    "4. Make a submission to Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Competition Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T16:31:21.023007Z",
     "start_time": "2019-10-02T16:31:19.055670Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T16:56:14.060169Z",
     "start_time": "2019-10-02T16:56:14.048126Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A marriage of 13 and 18 year old bourbons. A m...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>There have been some legendary Bowmores from t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>This bottling celebrates master distiller Park...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>What impresses me most is how this whisky evol...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>A caramel-laden fruit bouquet, followed by une...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                        description  category\n",
       "0   1  A marriage of 13 and 18 year old bourbons. A m...         2\n",
       "1   2  There have been some legendary Bowmores from t...         1\n",
       "2   3  This bottling celebrates master distiller Park...         2\n",
       "3   4  What impresses me most is how this whisky evol...         1\n",
       "4   9  A caramel-laden fruit bouquet, followed by une...         2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T16:56:25.275574Z",
     "start_time": "2019-10-02T16:56:25.264511Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2586 entries, 0 to 2585\n",
      "Data columns (total 3 columns):\n",
      "id             2586 non-null int64\n",
      "description    2586 non-null object\n",
      "category       2586 non-null int64\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 60.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T16:56:39.279390Z",
     "start_time": "2019-10-02T16:56:39.272435Z"
    }
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words='english')\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "pipe = Pipeline([('vect', vect), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T16:59:25.505872Z",
     "start_time": "2019-10-02T16:56:41.332897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   41.3s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=4)]: Done 1440 out of 1440 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=4,\n",
       "       param_grid={'vect__max_df': (0.5, 0.75, 1.0), 'vect__min_df': (0.02, 0.05), 'vect__max_features': (100, 500, 1000), 'clf__n_estimators': (5, 10, 50, 100), 'clf__max_depth': (5, 10, 15, 20)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__min_df': (.02, .05),\n",
    "    'vect__max_features': (100, 500,1000),\n",
    "    'clf__n_estimators':(5, 10, 50, 100),\n",
    "    'clf__max_depth':(5,10,15,20)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=5, n_jobs=4, verbose=1)\n",
    "grid_search.fit(train['description'], train['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T16:59:25.526067Z",
     "start_time": "2019-10-02T16:59:25.510066Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__max_depth': 20,\n",
       " 'clf__n_estimators': 100,\n",
       " 'vect__max_df': 0.75,\n",
       " 'vect__max_features': 500,\n",
       " 'vect__min_df': 0.02}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T16:59:25.559369Z",
     "start_time": "2019-10-02T16:59:25.529055Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8812838360402165"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File\n",
    "\n",
    "*Note: You are only allowed two submissions a day. Only submit if you feel you cannot achieve higher test accuracy.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T16:59:25.626397Z",
     "start_time": "2019-10-02T16:59:25.561742Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = grid_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T16:59:25.654678Z",
     "start_time": "2019-10-02T16:59:25.628209Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'category':pred})\n",
    "submission['category'] = submission['category'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T16:59:25.698028Z",
     "start_time": "2019-10-02T16:59:25.658821Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>955</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3532</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  category\n",
       "0   955         2\n",
       "1  3532         3\n",
       "2  1390         1\n",
       "3  1024         1\n",
       "4  1902         1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T16:59:25.739037Z",
     "start_time": "2019-10-02T16:59:25.702474Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "submission.to_csv('./data/submission1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "4. Make a submission to Kaggle\n",
    "\n",
    "You're trying to achieve 90% Accuracy on your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Indexing (Learn)\n",
    "<a id=\"p2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T16:59:25.773462Z",
     "start_time": "2019-10-02T16:59:25.742521Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=100, \n",
    "                   algorithm='randomized',\n",
    "                   n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T16:59:25.812838Z",
     "start_time": "2019-10-02T16:59:25.775691Z"
    }
   },
   "outputs": [],
   "source": [
    "params = { \n",
    "    'lsi__svd__n_components': [10,100,250],\n",
    "    'lsi__vect__max_df':[.9, .95, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T16:59:25.852681Z",
     "start_time": "2019-10-02T16:59:25.814739Z"
    }
   },
   "outputs": [],
   "source": [
    "# LSI\n",
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "\n",
    "\n",
    "# Pipe\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', rfc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T16:59:58.588473Z",
     "start_time": "2019-10-02T16:59:25.854600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  45 out of  45 | elapsed:   31.5s finished\n",
      "/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('lsi', Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm=...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=4,\n",
       "       param_grid={'lsi__svd__n_components': [10, 100, 250], 'lsi__vect__max_df': [0.9, 0.95, 1.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit\n",
    "grid_search = GridSearchCV(pipe,params, cv=5, n_jobs=4, verbose=1)\n",
    "grid_search.fit(data.data, data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:00:07.910578Z",
     "start_time": "2019-10-02T17:00:07.906819Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lsi__svd__n_components': 100, 'lsi__vect__max_df': 0.95}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T16:59:58.613469Z",
     "start_time": "2019-10-02T16:59:58.593002Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8774795799299884"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "4. Make a submission to Kaggle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:41:02.987441Z",
     "start_time": "2019-10-02T17:38:51.306868Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=4)]: Done 900 out of 900 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=4,\n",
       "       param_grid={'vect__max_df': (0.95, 0.99, 1.0), 'vect__min_df': (0.02, 0.05, 0.075), 'clf__n_estimators': (5, 10, 50, 100, 200), 'clf__max_depth': (5, 10, 15, 20)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = TruncatedSVD(algorithm='randomized',\n",
    "                   n_iter=10)\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "pipe = Pipeline([('vect', vect), ('svd', svd), ('clf', clf)])\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.95, 0.99, 1.0),\n",
    "    'vect__min_df': (.02, .05, .075),\n",
    "    'clf__n_estimators':(5, 10, 50, 100, 200),\n",
    "    'clf__max_depth':(5, 10, 15, 20),\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=5, n_jobs=4, verbose=1)\n",
    "grid_search.fit(data.data, data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:41:03.000642Z",
     "start_time": "2019-10-02T17:41:02.991056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__max_depth': 5,\n",
       " 'clf__n_estimators': 50,\n",
       " 'vect__max_df': 0.95,\n",
       " 'vect__min_df': 0.02}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:41:03.055956Z",
     "start_time": "2019-10-02T17:41:03.010201Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6954492415402567"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Continue to apply Latent Semantic Indexing (LSI) to various datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings with Spacy (Learn)\n",
    "<a id=\"p3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:41:20.286776Z",
     "start_time": "2019-10-02T17:41:03.058098Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:41:20.330912Z",
     "start_time": "2019-10-02T17:41:20.289511Z"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"Two bananas in pyjamas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:41:20.346571Z",
     "start_time": "2019-10-02T17:41:20.332957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "bananas_vector = doc.vector\n",
    "print(len(bananas_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:41:20.387431Z",
     "start_time": "2019-10-02T17:41:20.348316Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_word_vectors(docs):\n",
    "    return [nlp(doc).vector for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T18:01:52.767221Z",
     "start_time": "2019-10-02T18:01:10.405606Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-2.24261973e-02,  1.16948791e-01, -1.40623569e-01, -8.97146240e-02,\n",
       "         5.67572452e-02,  2.33658105e-02, -1.04296878e-02, -3.83221991e-02,\n",
       "        -3.14497203e-02,  1.60095787e+00, -1.52854711e-01,  7.60015845e-02,\n",
       "         3.35256122e-02, -3.82818922e-04, -8.83924514e-02, -2.05108356e-02,\n",
       "        -6.14920035e-02,  8.94030511e-01, -1.21286541e-01, -1.76449474e-02,\n",
       "         3.00883572e-03, -2.65389066e-02,  5.69479540e-03,  3.20637971e-02,\n",
       "         1.32068964e-02,  3.05791143e-02, -4.84521687e-02, -4.10817144e-03,\n",
       "         3.47910374e-02, -2.70029213e-02, -4.06233370e-02,  9.24473107e-02,\n",
       "        -4.75446433e-02,  1.73872765e-02,  7.95437545e-02, -3.22926454e-02,\n",
       "         2.25547757e-02,  3.64724770e-02, -8.19447264e-02, -1.99605860e-02,\n",
       "        -1.32072708e-02,  3.00613586e-02,  1.62900332e-02, -1.20532522e-02,\n",
       "        -8.38013925e-03, -7.63823558e-03, -6.95322007e-02,  3.03549431e-02,\n",
       "        -2.01541363e-04,  1.80957410e-02, -4.44174521e-02,  8.56731161e-02,\n",
       "        -6.44384250e-02, -1.01379957e-02,  3.68251912e-02,  1.61645990e-02,\n",
       "        -8.66862293e-03, -4.81753200e-02,  1.90909673e-02, -4.76901345e-02,\n",
       "        -5.07223085e-02, -2.60085408e-02, -1.90023445e-02,  6.04435168e-02,\n",
       "        -7.29399547e-03, -4.32707965e-02, -2.54089432e-03,  1.44851059e-02,\n",
       "        -1.72077212e-02,  1.00335248e-01,  1.66902028e-03,  5.13673201e-02,\n",
       "         1.01042941e-01, -3.83405089e-02,  1.16151392e-01,  4.48766649e-02,\n",
       "        -2.92251091e-02, -5.20351082e-02, -5.48995920e-02,  1.75982296e-01,\n",
       "        -3.50107662e-02,  5.00081144e-02, -9.77369025e-02, -4.45048884e-02,\n",
       "         3.29432823e-02, -2.18612060e-01,  9.47913155e-02, -2.76871473e-01,\n",
       "         1.84978187e-01,  1.12034185e-02, -1.17016964e-01,  7.41585682e-04,\n",
       "        -7.65368566e-02,  1.16831893e-02,  1.07339531e-01,  1.20514473e-02,\n",
       "        -6.36487007e-02, -4.93548214e-02,  1.16742151e-02, -5.68343773e-02,\n",
       "        -5.47548151e-03,  1.46009307e-02, -4.84171361e-02,  3.87900206e-03,\n",
       "         1.03004590e-01, -4.51588541e-01,  1.06050875e-02,  1.88465379e-02,\n",
       "        -4.00046371e-02,  8.29541311e-02, -1.50775285e-02, -7.88107589e-02,\n",
       "         5.66262715e-02, -1.28116801e-01, -4.36016284e-02, -2.58045215e-02,\n",
       "         1.84562821e-02, -3.28731574e-02, -4.23721559e-02, -8.58055800e-02,\n",
       "        -1.34064173e-02, -6.57399446e-02,  2.28124205e-02,  3.35416906e-02,\n",
       "         3.31814401e-02,  4.62324321e-02,  1.40879098e-02, -8.38614628e-02,\n",
       "         4.22727168e-02, -4.57413048e-02,  4.46854159e-02, -3.99017660e-03,\n",
       "        -6.53222352e-02,  2.04042066e-03,  7.08221085e-03,  9.88571495e-02,\n",
       "         1.34236468e-02, -2.78376359e-02,  1.16308173e-02,  8.26605409e-03,\n",
       "        -7.89071023e-01,  9.22556743e-02,  9.05948281e-02,  2.34123059e-02,\n",
       "        -2.58604297e-03, -2.31077685e-03,  2.24269857e-03,  1.26571385e-02,\n",
       "        -2.76336856e-02, -8.14458057e-02,  2.82807127e-02,  2.72207540e-02,\n",
       "         3.06711961e-02,  4.45985831e-02,  1.63870899e-03, -2.84041129e-02,\n",
       "        -1.04572043e-01, -1.19941272e-01, -1.31949652e-02, -6.71681203e-03,\n",
       "         1.01320213e-02,  1.56351773e-03, -1.24058640e-02, -2.09471285e-02,\n",
       "        -1.43706679e-01, -8.14125761e-02,  3.01197022e-02, -3.35221440e-02,\n",
       "         6.46543577e-02,  1.81645099e-02, -1.49824405e-02,  3.29184979e-02,\n",
       "         7.21177086e-02, -1.03158481e-01,  1.65972561e-02,  6.25339150e-02,\n",
       "         5.22560291e-02, -2.61695534e-02, -2.15428765e-03, -1.23825453e-01,\n",
       "         2.25111954e-02, -2.44774707e-02, -6.87108040e-02, -7.82508329e-02,\n",
       "        -1.01412214e-01, -9.40319803e-03, -8.00314248e-02, -3.63482232e-03,\n",
       "         7.33532086e-02,  1.85952038e-02, -6.29070923e-02,  1.58203989e-02,\n",
       "        -8.14530924e-02,  4.11531068e-02,  1.72483642e-02,  5.91628253e-02,\n",
       "        -9.58606526e-02, -1.62056923e-01,  1.36137567e-02,  2.06642658e-01,\n",
       "        -5.25170527e-02, -2.81243678e-02, -8.63770023e-02,  1.17431507e-02,\n",
       "         8.88439268e-02, -1.68050062e-02,  1.16265416e-02,  5.43329772e-03,\n",
       "         3.06705832e-02,  7.15277623e-03, -2.47791801e-02, -7.13435486e-02,\n",
       "         5.08098230e-02, -1.30577520e-01,  4.75263149e-02, -6.42042421e-03,\n",
       "        -2.08248328e-02,  7.28075802e-02, -2.24588990e-01,  1.78690329e-02,\n",
       "         4.00597155e-02,  2.88579948e-02, -1.22829098e-02,  3.58755067e-02,\n",
       "         5.09725623e-02,  1.37627274e-02,  2.70046294e-02,  4.72648442e-02,\n",
       "        -1.36863394e-02, -2.96436492e-02, -8.52983668e-02,  3.44847590e-02,\n",
       "         1.01481952e-01,  4.78846468e-02, -5.01865000e-02, -3.25704776e-02,\n",
       "        -3.09856422e-02, -7.72578940e-02, -9.80750248e-02,  6.57135993e-02,\n",
       "         5.15750460e-02,  2.51168199e-02,  4.41309810e-02,  3.13052386e-02,\n",
       "         8.82827714e-02, -1.01821758e-01, -4.50850204e-02, -9.64435339e-02,\n",
       "        -1.10256881e-01,  2.60082874e-02,  6.39615878e-02,  2.94563151e-03,\n",
       "        -5.54638840e-02, -6.27679899e-02, -2.14260146e-02,  1.81864828e-01,\n",
       "         1.06344678e-01, -8.90759751e-02,  1.65668260e-02,  3.51159796e-02,\n",
       "         5.27693778e-02,  1.30297214e-01,  1.33668073e-02,  1.03425533e-01,\n",
       "         2.14397162e-02, -7.30981007e-02,  1.53310355e-02,  4.59636897e-02,\n",
       "         3.61959636e-01, -2.10708547e-02,  2.27870960e-02, -3.18665951e-02,\n",
       "        -9.46877077e-02, -8.67584869e-02, -1.71733480e-02,  1.31538529e-02,\n",
       "         5.39100766e-02,  2.55729947e-02, -2.36161835e-02,  1.36125967e-01,\n",
       "         1.92951471e-01, -4.59868610e-02,  1.08493403e-01, -1.26087055e-01,\n",
       "        -4.32118215e-02, -7.97328427e-02,  3.02468166e-02, -3.52702825e-03,\n",
       "         1.70603245e-01, -6.90357313e-02, -1.01174608e-01,  5.03605530e-02,\n",
       "        -8.23118985e-02, -8.99672043e-03, -3.47634824e-03,  4.15571742e-02,\n",
       "        -5.58306649e-02, -5.20813651e-02,  1.70197859e-02,  1.06796706e-02],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = get_word_vectors(data.data)\n",
    "\n",
    "X[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T17:42:07.961508Z",
     "start_time": "2019-10-02T17:39:27.592Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply to your Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n",
    "4. Make a submission to Kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review\n",
    "\n",
    "To review this module: \n",
    "* Continue working on the Kaggle comeptition\n",
    "* Find another text classification task to work on"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S1-NLP-DS6 (Python 3.7)",
   "language": "python",
   "name": "u4-s1-nlp-ds6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
