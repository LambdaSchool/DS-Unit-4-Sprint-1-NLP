{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add author to description\n",
    "train['new_description'] = train.author + ' ' + train.description\n",
    "test['new_description'] = test.author + ' ' + test.description\n",
    "\n",
    "#convert author col to categorical\n",
    "train.author = train.author.astype('category')\n",
    "test.author = test.author.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean/replace numeric feature NaNs w/ median vals:\n",
    "median_price = 80\n",
    "median_pert_alcohol = 46\n",
    "train.price = train.price.fillna(median_price)\n",
    "test.price = test.price.fillna(median_price)\n",
    "train.pert_alcohol = train.pert_alcohol.fillna(median_pert_alcohol)\n",
    "test.pert_alcohol = test.pert_alcohol.fillna(median_pert_alcohol) \n",
    "\n",
    "#drop rows w/ NaNs in target feature\n",
    "train = train.dropna().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGDClassifier Pipeline w/ TD-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words='english')\n",
    "sgdc = SGDClassifier()\n",
    "pipe = Pipeline([('vect', vect), ('classifier', sgdc)])\n",
    "\n",
    "target = 'category'\n",
    "X_train = train['description']\n",
    "y_train = train[target]\n",
    "X_test = test['description']\n",
    "\n",
    "#Fit pipeline:\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 4., 1., 1., 1., 1., 1., 2., 1., 4., 4., 1., 1., 1., 1., 1.,\n",
       "       1., 2., 1., 1., 1., 1., 1., 4., 1., 1., 1., 3., 1., 4., 2., 1., 1.,\n",
       "       1., 1., 1., 3., 4., 3., 2., 1., 1., 3., 1., 1., 1., 2., 1., 1., 3.,\n",
       "       1., 3., 1., 1., 1., 1., 1., 1., 1., 3., 1., 1., 1., 1., 4., 2., 3.,\n",
       "       1., 1., 1., 3., 1., 1., 4., 1., 3., 2., 1., 1., 4., 2., 2., 1., 1.,\n",
       "       3., 2., 4., 1., 3., 1., 1., 1., 1., 1., 4., 1., 1., 4., 3., 1., 1.,\n",
       "       1., 2., 1., 1., 1., 2., 1., 2., 3., 1., 1., 1., 1., 3., 1., 1., 1.,\n",
       "       1., 3., 1., 2., 1., 1., 1., 1., 2., 2., 4., 1., 1., 1., 1., 3., 2.,\n",
       "       1., 1., 1., 1., 1., 3., 2., 1., 1., 3., 4., 1., 1., 1., 3., 1., 1.,\n",
       "       1., 1., 1., 2., 1., 1., 1., 1., 1., 4., 1., 1., 1., 3., 1., 2., 2.,\n",
       "       1., 3., 3., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 1., 2., 1.,\n",
       "       4., 1., 3., 1., 4., 1., 1., 2., 2., 1., 1., 2., 1., 1., 1., 1., 2.,\n",
       "       2., 1., 1., 1., 1., 4., 1., 1., 3., 1., 2., 1., 1., 1., 1., 1., 1.,\n",
       "       4., 2., 2., 2., 2., 1., 2., 2., 2., 1., 1., 1., 2., 1., 1., 2., 1.,\n",
       "       1., 1., 1., 3., 2., 2., 1., 3., 1., 3., 3., 3., 1., 1., 2., 1., 2.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1., 3., 2., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 2., 1., 2., 4., 1., 1., 1., 3., 2., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  45 | elapsed:   11.5s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   11.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words...\n",
       "                                                      max_iter=1000,\n",
       "                                                      n_iter_no_change=5,\n",
       "                                                      n_jobs=None, penalty='l2',\n",
       "                                                      power_t=0.5,\n",
       "                                                      random_state=None,\n",
       "                                                      shuffle=True, tol=0.001,\n",
       "                                                      validation_fraction=0.1,\n",
       "                                                      verbose=0,\n",
       "                                                      warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'classifier__max_iter': (20, 10, 100),\n",
       "                         'vect__max_df': (0.5, 0.75, 1.0)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'classifier__max_iter': (20, 10, 100)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=5, n_jobs=-1, verbose=10)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = grid_search.best_estimator_\n",
    "grid_y_pred = best.predict(X_test)\n",
    "\n",
    "best_df = pd.DataFrame(test.id)\n",
    "best_df['category'] = grid_y_pred.astype('int')\n",
    "best_df.to_csv('first_grid.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = pd.DataFrame(test.id)\n",
    "baseline['category'] = y_pred.astype('int')\n",
    "baseline.to_csv('baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>955</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3532</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1390</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  category\n",
       "0   955         2\n",
       "1  3532         2\n",
       "2  1390         4\n",
       "3  1024         1\n",
       "4  1902         1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  45 | elapsed:    7.8s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    7.9s finished\n",
      "/home/jm/.local/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer(stop_words='english')\n",
    "sgdc = SGDClassifier()\n",
    "pipe = Pipeline([('vect', vect), ('classifier', sgdc)])\n",
    "\n",
    "target = 'category'\n",
    "X_train = train['new_description']\n",
    "y_train = train[target]\n",
    "X_test = test['new_description']\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'classifier__max_iter': (20, 10, 100)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=5, n_jobs=-1, verbose=10)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best = grid_search.best_estimator_\n",
    "grid_y_pred = best.predict(X_test)\n",
    "\n",
    "best_df = pd.DataFrame(test.id)\n",
    "best_df['category'] = grid_y_pred.astype('int')\n",
    "best_df.to_csv('new_desc_grid.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>955</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3532</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1390</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  category\n",
       "0   955         2\n",
       "1  3532         2\n",
       "2  1390         4\n",
       "3  1024         1\n",
       "4  1902         1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=100, algorithm='randomized', n_iter=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "pipe = Pipeline([('lsi', lsi), ('classifier', sgdc)])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "lsi_y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_df = pd.DataFrame(test.id)\n",
    "lsi_df['category'] = lsi_y_pred.astype('int')\n",
    "lsi_df.to_csv('baseline_lsi.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "doc = nlp('Two bananas in pajamas')\n",
    "\n",
    "bananas_vector = doc.vector\n",
    "print(len(bananas_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vectors(docs):\n",
    "    return [nlp(doc).vector for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train.new_description\n",
    "X_train = get_word_vectors(data)\n",
    "y_train = train[target]\n",
    "X_test = get_word_vectors(test.new_description)\n",
    "sgdc.fit(X_train, y_train)\n",
    "spacy_y_pred = sgdc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_df = pd.DataFrame(test.id)\n",
    "spacy_df['category'] = spacy_y_pred.astype('int')\n",
    "spacy_df.to_csv('spacy1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>955</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3532</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1390</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  category\n",
       "0   955         2\n",
       "1  3532         2\n",
       "2  1390         4\n",
       "3  1024         1\n",
       "4  1902         1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest using the numeric features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode author feature:\n",
    "\n",
    "import category_encoders as ce\n",
    "one_hot_ce = ce.OneHotEncoder(cols=['author'], verbose=10, use_cat_names=True)\n",
    "train = one_hot_ce.fit_transform(train)\n",
    "test['category'] = 1\n",
    "test = one_hot_ce.transform(test)\n",
    "test = test.drop(\"category\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2586, 16), (2586,), (288, 16))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train = train.drop(['description', 'new_description', target], axis=1)\n",
    "y_train = train[target]\n",
    "X_test = test.drop(['description', 'new_description'], axis=1)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 170 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed:   35.7s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:   40.0s finished\n",
      "/home/jm/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=1,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'max_depth': [3, 5, 10], 'min_samples_leaf': [1, 2],\n",
       "                         'min_samples_split': [2, 3, 4],\n",
       "                         'n_estimators': [5, 10, 25, 100, 250]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_jobs=1)\n",
    "\n",
    "params = {\n",
    "    'max_depth': [3,5,10],\n",
    "    'min_samples_split': [2,3,4],\n",
    "    'min_samples_leaf': [1,2],\n",
    "    'n_estimators': [5,10,25,100,250]    \n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(rf, param_grid=params, cv=4, verbose=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.025583</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 1, 'min_s...</td>\n",
       "      <td>0.783951</td>\n",
       "      <td>0.843653</td>\n",
       "      <td>0.843653</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.808971</td>\n",
       "      <td>0.035317</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.060644</td>\n",
       "      <td>0.008718</td>\n",
       "      <td>0.012380</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 2, 'min_s...</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.857585</td>\n",
       "      <td>0.843653</td>\n",
       "      <td>0.727554</td>\n",
       "      <td>0.798144</td>\n",
       "      <td>0.054211</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.024536</td>\n",
       "      <td>0.003744</td>\n",
       "      <td>0.005118</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 2, 'min_s...</td>\n",
       "      <td>0.768519</td>\n",
       "      <td>0.780186</td>\n",
       "      <td>0.806502</td>\n",
       "      <td>0.747678</td>\n",
       "      <td>0.775715</td>\n",
       "      <td>0.021239</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.171958</td>\n",
       "      <td>0.045948</td>\n",
       "      <td>0.013037</td>\n",
       "      <td>0.003268</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 1, 'min_s...</td>\n",
       "      <td>0.459877</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.905573</td>\n",
       "      <td>0.777090</td>\n",
       "      <td>0.765661</td>\n",
       "      <td>0.185432</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.028492</td>\n",
       "      <td>0.004067</td>\n",
       "      <td>0.005828</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 1, 'min_s...</td>\n",
       "      <td>0.797840</td>\n",
       "      <td>0.812693</td>\n",
       "      <td>0.876161</td>\n",
       "      <td>0.527864</td>\n",
       "      <td>0.753674</td>\n",
       "      <td>0.133583</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "10       0.025583      0.000539         0.005611        0.000072   \n",
       "21       0.060644      0.008718         0.012380        0.004217   \n",
       "25       0.024536      0.003744         0.005118        0.000491   \n",
       "32       0.171958      0.045948         0.013037        0.003268   \n",
       "5        0.028492      0.004067         0.005828        0.000875   \n",
       "\n",
       "   param_max_depth param_min_samples_leaf param_min_samples_split  \\\n",
       "10               3                      1                       4   \n",
       "21               3                      2                       3   \n",
       "25               3                      2                       4   \n",
       "32               5                      1                       2   \n",
       "5                3                      1                       3   \n",
       "\n",
       "   param_n_estimators                                             params  \\\n",
       "10                  5  {'max_depth': 3, 'min_samples_leaf': 1, 'min_s...   \n",
       "21                 10  {'max_depth': 3, 'min_samples_leaf': 2, 'min_s...   \n",
       "25                  5  {'max_depth': 3, 'min_samples_leaf': 2, 'min_s...   \n",
       "32                 25  {'max_depth': 5, 'min_samples_leaf': 1, 'min_s...   \n",
       "5                   5  {'max_depth': 3, 'min_samples_leaf': 1, 'min_s...   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "10           0.783951           0.843653           0.843653   \n",
       "21           0.763889           0.857585           0.843653   \n",
       "25           0.768519           0.780186           0.806502   \n",
       "32           0.459877           0.921053           0.905573   \n",
       "5            0.797840           0.812693           0.876161   \n",
       "\n",
       "    split3_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "10           0.764706         0.808971        0.035317                1  \n",
       "21           0.727554         0.798144        0.054211                2  \n",
       "25           0.747678         0.775715        0.021239                3  \n",
       "32           0.777090         0.765661        0.185432                4  \n",
       "5            0.527864         0.753674        0.133583                5  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(grid_search_rf.cv_results_).sort_values('rank_test_score')\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = grid_search_rf.best_estimator_\n",
    "best_rf.fit(X_train, y_train)\n",
    "rf_y_pred = best_rf.predict(X_test)\n",
    "\n",
    "best_rf_df = pd.DataFrame(test.id)\n",
    "best_rf_df['category'] = rf_y_pred.astype('int')\n",
    "best_rf_df.to_csv('rf_grid.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
