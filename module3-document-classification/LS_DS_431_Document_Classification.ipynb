{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Document Classification\n",
    "## *Data Science Unit 4 Sprint 1 Lesson 3*\n",
    "\n",
    "Today's lesson will be different. You already know how to do classification. You ready know how to extract features from documents. So? That means you're ready to combine and practice those skills in a kaggle competition. We we will open with a five minute sprint explaining the competition, and then give you 25 minutes to work. After those twenty five minutes are up, I will give a 5-minute demo an NLP technique that will help you with document classification (*and **maybe** the competition*). \n",
    "\n",
    "Today's all about having fun and practicing your skills.\n",
    "\n",
    "## Learning Objectives\n",
    "* <a href=\"#p0\">Part 0</a>: Kaggle Competition\n",
    "* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n",
    "* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n",
    "* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./ds4-which-whisk/train.csv')\n",
    "test = pd.read_csv('./ds4-which-whisk/test.csv')\n",
    "sample_submission = pd.read_csv('./ds4-which-whisk/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>pert_alcohol</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John Hansell</td>\n",
       "      <td>A marriage of 13 and 18 year old bourbons. A m...</td>\n",
       "      <td>85.0</td>\n",
       "      <td>97</td>\n",
       "      <td>51.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Dave Broom</td>\n",
       "      <td>There have been some legendary Bowmores from t...</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>97</td>\n",
       "      <td>42.9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>John Hansell</td>\n",
       "      <td>This bottling celebrates master distiller Park...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>97</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>John Hansell</td>\n",
       "      <td>What impresses me most is how this whisky evol...</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>97</td>\n",
       "      <td>40.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Davin de Kergommeaux</td>\n",
       "      <td>After 40 years in barrels, the trademark Canad...</td>\n",
       "      <td>199.0</td>\n",
       "      <td>96</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                author  \\\n",
       "0   1          John Hansell   \n",
       "1   2            Dave Broom   \n",
       "2   3          John Hansell   \n",
       "3   4          John Hansell   \n",
       "4   6  Davin de Kergommeaux   \n",
       "\n",
       "                                         description    price  ratingValue  \\\n",
       "0  A marriage of 13 and 18 year old bourbons. A m...     85.0           97   \n",
       "1  There have been some legendary Bowmores from t...  13500.0           97   \n",
       "2  This bottling celebrates master distiller Park...    150.0           97   \n",
       "3  What impresses me most is how this whisky evol...   4500.0           97   \n",
       "4  After 40 years in barrels, the trademark Canad...    199.0           96   \n",
       "\n",
       "   pert_alcohol  category  \n",
       "0          51.5       2.0  \n",
       "1          42.9       1.0  \n",
       "2          50.0       2.0  \n",
       "3          40.5       1.0  \n",
       "4          45.0       NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2874, 7)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>pert_alcohol</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2874.000000</td>\n",
       "      <td>2811.000000</td>\n",
       "      <td>2874.000000</td>\n",
       "      <td>2814.000000</td>\n",
       "      <td>2586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2075.814544</td>\n",
       "      <td>225.297937</td>\n",
       "      <td>86.361517</td>\n",
       "      <td>48.043019</td>\n",
       "      <td>1.637664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1177.805945</td>\n",
       "      <td>990.619608</td>\n",
       "      <td>4.511554</td>\n",
       "      <td>6.298527</td>\n",
       "      <td>0.963049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1087.250000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>43.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2109.500000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3102.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>51.375000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4157.000000</td>\n",
       "      <td>26650.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>98.600000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id         price  ratingValue  pert_alcohol     category\n",
       "count  2874.000000   2811.000000  2874.000000   2814.000000  2586.000000\n",
       "mean   2075.814544    225.297937    86.361517     48.043019     1.637664\n",
       "std    1177.805945    990.619608     4.511554      6.298527     0.963049\n",
       "min       1.000000      7.500000    60.000000     33.000000     1.000000\n",
       "25%    1087.250000     50.000000    84.000000     43.300000     1.000000\n",
       "50%    2109.500000     80.000000    87.000000     46.000000     1.000000\n",
       "75%    3102.000000    140.000000    90.000000     51.375000     2.000000\n",
       "max    4157.000000  26650.000000    97.000000     98.600000     4.000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2874</td>\n",
       "      <td>2874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>12</td>\n",
       "      <td>2871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>John Hansell</td>\n",
       "      <td>Swiss-based Chapter 7 released this 19 year ol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>992</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              author                                        description\n",
       "count           2874                                               2874\n",
       "unique            12                                               2871\n",
       "top     John Hansell  Swiss-based Chapter 7 released this 19 year ol...\n",
       "freq             992                                                  2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looks like we have a duplicate description\n",
    "train.describe(exclude='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                0\n",
       "author            0\n",
       "description       0\n",
       "price            63\n",
       "ratingValue       0\n",
       "pert_alcohol     60\n",
       "category        288\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some null values (~60) for price and pert_alcohol\n",
    "# 288 null values in category\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A marriage of 13 and 18 year old bourbons. A mature yet very elegant whiskey, with a silky texture and so easy to embrace with a splash of water. Balanced notes of honeyed vanilla, soft caramel, a basket of complex orchard fruit, blackberry, papaya, and a dusting of cocoa and nutmeg; smooth finish. Sophisticated, stylish, with well-defined flavors. A classic!'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example description\n",
    "train['description'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# something odd about the labels\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words='english')\n",
    "cvect = CountVectorizer()\n",
    "lsvm = svm.LinearSVC()\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "pipe = Pipeline([('vect', vect), ('clf', mnb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2586, 7)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clean = train[train['category'].isnull()==False]\n",
    "train_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.7, max_features=1825, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...max_iter=500,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(train_clean['description'], train_clean['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pipe.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 4., 1., 1., 1., 1., 1., 2., 1., 4., 4., 1., 1., 1., 1., 1.,\n",
       "       1., 2., 1., 1., 1., 1., 1., 4., 1., 1., 1., 3., 1., 4., 2., 1., 1.,\n",
       "       1., 1., 1., 3., 4., 3., 2., 1., 1., 3., 1., 1., 1., 2., 1., 1., 3.,\n",
       "       1., 2., 1., 1., 1., 1., 1., 1., 1., 3., 1., 1., 1., 1., 4., 2., 3.,\n",
       "       1., 1., 1., 3., 1., 1., 4., 1., 3., 2., 1., 1., 4., 2., 2., 1., 1.,\n",
       "       3., 2., 4., 1., 3., 1., 1., 1., 1., 1., 4., 1., 1., 4., 3., 1., 1.,\n",
       "       1., 2., 1., 1., 1., 2., 1., 2., 3., 1., 1., 1., 1., 3., 1., 1., 1.,\n",
       "       1., 3., 1., 2., 1., 1., 1., 1., 2., 2., 4., 1., 1., 1., 1., 3., 2.,\n",
       "       1., 1., 1., 1., 1., 3., 2., 1., 1., 3., 4., 1., 1., 1., 3., 1., 1.,\n",
       "       1., 1., 1., 2., 1., 1., 1., 1., 1., 4., 1., 1., 1., 3., 1., 2., 2.,\n",
       "       1., 3., 3., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 1., 2., 1.,\n",
       "       4., 1., 3., 1., 4., 1., 1., 2., 2., 1., 1., 2., 1., 1., 1., 1., 2.,\n",
       "       1., 1., 1., 1., 1., 4., 1., 1., 3., 1., 2., 1., 1., 1., 1., 1., 1.,\n",
       "       4., 2., 2., 2., 2., 1., 2., 2., 2., 1., 1., 1., 2., 1., 1., 2., 1.,\n",
       "       1., 1., 1., 3., 2., 2., 1., 3., 1., 3., 3., 3., 1., 1., 2., 1., 2.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1., 3., 2., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 2., 1., 3., 4., 1., 1., 1., 3., 2., 1.])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>955</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3532</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1390</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  category\n",
       "0   955       1.0\n",
       "1  3532       1.0\n",
       "2  1390       1.0\n",
       "3  1024       1.0\n",
       "4  1902       1.0"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>955</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3532</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1390</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  category\n",
       "0   955       2.0\n",
       "1  3532       2.0\n",
       "2  1390       4.0\n",
       "3  1024       1.0\n",
       "4  1902       1.0"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission['category'] = preds\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>955</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3532</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1390</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  category\n",
       "0   955         2\n",
       "1  3532         2\n",
       "2  1390         4\n",
       "3  1024         1\n",
       "4  1902         1"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission['category'] = sample_submission['category'].apply(lambda x: int(x))\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinclair_sub_1 = sample_submission\n",
    "sinclair_sub_1.to_csv('sinclair_sub_2', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': (.275, .28, .29),\n",
    "    'vect__min_df': (21, 22, 23),\n",
    "    'vect__max_features': (725, 750, 775),\n",
    "#     'clf__C': (1, 1.45, 1.5),\n",
    "#     'clf__max_iter': (500, 1000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 135 out of 135 | elapsed:   25.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...rue,\n",
       "        vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'vect__max_df': (0.275, 0.28, 0.29), 'vect__min_df': (21, 22, 23), 'vect__max_features': (725, 750, 775)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(train_clean['description'], train_clean['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vect__max_df': 0.275, 'vect__max_features': 725, 'vect__min_df': 22}"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8894044856921887"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 4., 1., 1., 1., 1., 1., 2., 1., 4., 4., 1., 1., 1., 1., 1.,\n",
       "       1., 2., 1., 1., 1., 1., 1., 4., 1., 1., 1., 3., 1., 4., 2., 1., 1.,\n",
       "       1., 1., 1., 3., 4., 3., 2., 1., 1., 3., 1., 1., 1., 2., 1., 1., 3.,\n",
       "       1., 2., 1., 1., 1., 1., 1., 1., 1., 3., 1., 1., 1., 1., 4., 2., 3.,\n",
       "       1., 1., 1., 3., 1., 1., 4., 1., 3., 2., 1., 1., 4., 2., 2., 1., 1.,\n",
       "       3., 2., 4., 1., 3., 1., 1., 1., 1., 1., 4., 1., 1., 4., 3., 1., 1.,\n",
       "       1., 2., 1., 1., 1., 2., 1., 2., 3., 1., 1., 1., 1., 3., 1., 1., 1.,\n",
       "       1., 3., 1., 2., 1., 1., 1., 1., 2., 2., 4., 1., 1., 1., 1., 3., 2.,\n",
       "       1., 1., 1., 1., 1., 3., 2., 1., 1., 3., 4., 1., 1., 1., 3., 1., 1.,\n",
       "       1., 1., 1., 2., 1., 1., 1., 1., 1., 4., 1., 1., 1., 3., 1., 2., 2.,\n",
       "       1., 3., 3., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 1., 2., 1.,\n",
       "       4., 1., 3., 1., 4., 1., 1., 2., 2., 1., 1., 2., 1., 1., 1., 1., 2.,\n",
       "       1., 1., 1., 1., 1., 4., 1., 1., 3., 1., 2., 1., 1., 1., 1., 1., 1.,\n",
       "       4., 2., 2., 2., 2., 1., 2., 2., 2., 1., 1., 1., 2., 1., 1., 2., 1.,\n",
       "       1., 1., 1., 3., 2., 2., 1., 3., 1., 3., 3., 3., 1., 1., 2., 1., 2.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1., 3., 2., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 2., 1., 3., 4., 1., 1., 1., 3., 2., 1.])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_preds = grid_search.predict(test['description'])\n",
    "grid_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_sub(grid_preds, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Indexing\n",
    "<a id=\"p2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=100, \n",
    "                   algorithm='randomized',\n",
    "                   n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSI\n",
    "\n",
    "lsi = Pipeline([('vect', vect), ('svd', svd)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipe\n",
    "\n",
    "lsi_pipe = Pipeline([('lsi', lsi), ('clf', lsvm)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a syntax error here, also not sure what the parameter is\n",
    "params = {\n",
    "    'lsi__vect__max_df':\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('lsi', Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.7, max_features=1825, min_df=1,\n",
       "        ngram_range=(1, 1), norm=...max_iter=500,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit\n",
    "lsi_pipe.fit(train_clean['description'], train_clean['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lsi_pipe.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 1., 1., 1., 1., 1., 1., 2., 1., 4., 4., 1., 1., 1., 1., 1.,\n",
       "       1., 3., 1., 1., 1., 1., 1., 1., 1., 1., 1., 3., 1., 4., 2., 1., 1.,\n",
       "       1., 1., 1., 3., 4., 3., 2., 1., 1., 1., 1., 1., 1., 2., 1., 1., 3.,\n",
       "       1., 2., 1., 1., 1., 1., 1., 1., 1., 3., 1., 1., 1., 1., 4., 2., 1.,\n",
       "       1., 1., 1., 3., 1., 1., 4., 1., 3., 2., 1., 1., 4., 2., 2., 1., 1.,\n",
       "       3., 2., 4., 1., 3., 1., 1., 1., 1., 1., 4., 1., 1., 4., 3., 1., 1.,\n",
       "       1., 2., 1., 1., 1., 2., 1., 2., 3., 1., 1., 1., 1., 3., 1., 1., 1.,\n",
       "       1., 3., 1., 2., 1., 1., 1., 1., 2., 2., 4., 1., 1., 1., 1., 3., 2.,\n",
       "       1., 1., 1., 1., 1., 3., 2., 1., 1., 3., 4., 1., 1., 1., 3., 1., 1.,\n",
       "       1., 1., 1., 3., 1., 1., 1., 1., 1., 4., 1., 1., 1., 3., 1., 2., 2.,\n",
       "       1., 3., 3., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 1., 2., 1.,\n",
       "       4., 1., 3., 1., 4., 1., 1., 2., 3., 1., 1., 2., 1., 1., 1., 1., 3.,\n",
       "       1., 1., 1., 1., 1., 4., 1., 1., 3., 1., 2., 1., 1., 1., 1., 1., 1.,\n",
       "       4., 2., 2., 2., 2., 1., 2., 2., 2., 1., 1., 1., 3., 1., 1., 2., 1.,\n",
       "       1., 1., 1., 3., 2., 2., 1., 3., 1., 3., 3., 3., 1., 1., 2., 1., 2.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 3., 1., 3., 2., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 2., 1., 3., 4., 1., 1., 1., 3., 2., 1.])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['category'] = preds\n",
    "sample_submission['category'] = sample_submission['category'].apply(lambda x: int(x))\n",
    "sample_submission.to_csv('sinclair_sub_3', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sub(preds, num):\n",
    "    # write predictions over category feature in sample_submission\n",
    "    sample_submission['category'] = preds\n",
    "    sample_submission['category'] = sample_submission['category'].apply(lambda x: int(x))\n",
    "    \n",
    "    # create file name\n",
    "    file_name = 'sinclair_submission_' + str(num)\n",
    "    \n",
    "    # write to csv\n",
    "    sample_submission.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings with Spacy\n",
    "<a id=\"p3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Two bananas in pyjamas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "bananas_vector = doc.vector\n",
    "print(len(bananas_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdc = SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vectors(docs):\n",
    "    return [nlp(doc).vector for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = get_word_vectors(train_clean['description'])\n",
    "X_test = get_word_vectors(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2586"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stephensinclair/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgdc.fit(X_train, train_clean['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = sgdc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 1., 1., 1., 1., 1., 1., 2., 1., 2., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 3., 1., 1., 1., 1., 1., 1., 1., 1., 1., 3., 1., 4., 2., 1., 1.,\n",
       "       1., 1., 2., 3., 4., 3., 2., 1., 1., 3., 1., 1., 1., 2., 1., 1., 3.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 3., 1., 2., 1., 1., 4., 2., 2.,\n",
       "       1., 1., 1., 3., 1., 1., 4., 1., 2., 2., 1., 1., 1., 2., 2., 1., 1.,\n",
       "       3., 2., 4., 1., 1., 1., 1., 1., 1., 1., 4., 1., 1., 3., 3., 1., 1.,\n",
       "       1., 2., 1., 1., 1., 2., 1., 2., 3., 1., 1., 1., 1., 3., 1., 1., 1.,\n",
       "       1., 3., 3., 2., 1., 1., 1., 1., 2., 2., 3., 1., 1., 1., 1., 3., 2.,\n",
       "       1., 1., 1., 1., 1., 3., 2., 1., 1., 3., 3., 1., 1., 1., 3., 1., 1.,\n",
       "       1., 1., 1., 3., 1., 1., 1., 4., 1., 4., 1., 1., 1., 3., 1., 2., 3.,\n",
       "       1., 3., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 1., 3., 2.,\n",
       "       4., 1., 3., 1., 1., 2., 1., 2., 3., 1., 1., 2., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 4., 1., 1., 3., 1., 2., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 2., 2., 2., 2., 1., 2., 3., 2., 1., 1., 2., 2., 1., 1., 2., 1.,\n",
       "       1., 1., 1., 3., 1., 2., 1., 3., 1., 3., 3., 3., 1., 1., 2., 1., 2.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 3., 1., 3., 2., 1., 1.,\n",
       "       1., 1., 1., 1., 2., 1., 2., 2., 3., 3., 1., 1., 1., 3., 2., 1.])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['category'] = preds\n",
    "sample_submission['category'] = sample_submission['category'].apply(lambda x: int(x))\n",
    "sample_submission.to_csv('sinclair_sub_4', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(stop_words='english', max_features=1825, max_df=0.9)\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "nb_pipe = Pipeline([('vect', tfidf_vect), ('clf', mnb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.9, max_features=1825, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...rue,\n",
       "        vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_pipe.fit(train_clean['description'], train_clean['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_preds = nb_pipe.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 3., 1., 1., 1., 1., 1., 1., 2., 1., 4., 4., 1., 1., 1., 1., 1.,\n",
       "       1., 2., 1., 1., 1., 1., 1., 4., 1., 1., 1., 3., 1., 4., 1., 1., 1.,\n",
       "       1., 1., 1., 3., 4., 1., 2., 1., 1., 1., 1., 1., 1., 2., 1., 1., 3.,\n",
       "       1., 2., 1., 1., 1., 1., 1., 1., 1., 3., 1., 1., 1., 1., 4., 2., 1.,\n",
       "       1., 1., 1., 3., 1., 1., 4., 1., 3., 2., 1., 1., 1., 2., 2., 1., 1.,\n",
       "       3., 2., 4., 1., 3., 1., 1., 1., 1., 1., 4., 1., 1., 4., 3., 1., 1.,\n",
       "       1., 2., 1., 1., 1., 2., 1., 2., 3., 1., 1., 1., 1., 3., 1., 1., 1.,\n",
       "       1., 3., 1., 2., 1., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 3., 2.,\n",
       "       1., 1., 1., 1., 1., 3., 1., 1., 1., 3., 4., 1., 1., 1., 3., 1., 1.,\n",
       "       1., 1., 1., 2., 1., 1., 1., 1., 1., 4., 1., 1., 1., 3., 1., 2., 2.,\n",
       "       1., 3., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1.,\n",
       "       4., 1., 1., 1., 4., 1., 1., 2., 1., 1., 1., 2., 1., 1., 1., 1., 2.,\n",
       "       1., 1., 1., 1., 1., 4., 1., 1., 3., 1., 2., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 2., 2., 2., 2., 1., 2., 2., 2., 1., 1., 1., 2., 1., 1., 2., 1.,\n",
       "       1., 1., 1., 3., 1., 1., 1., 3., 1., 3., 3., 3., 1., 1., 2., 1., 2.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 3., 1., 3., 2., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 2., 1., 3., 1., 1., 1., 1., 3., 2., 1.])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_sub(nb_preds, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into train and test sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_clean['description'],\n",
    "                                                    train_clean['category'],\n",
    "                                                    random_state=42, test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and evaluate the model\n",
    "vect = CountVectorizer().fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "clfrNB = MultinomialNB(alpha = 0.1)\n",
    "clfrNB.fit(X_train_vectorized, y_train)\n",
    "val_preds = clfrNB.predict(vect.transform(X_val))\n",
    "# score = roc_auc_score(y_test, preds)\n",
    "# print(score)\n",
    "# #0.9720812182741116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_sub(preds, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.97      0.98      0.98       151\n",
      "         2.0       0.90      0.90      0.90        50\n",
      "         3.0       0.94      0.85      0.89        40\n",
      "         4.0       0.86      1.00      0.92        18\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       259\n",
      "   macro avg       0.92      0.93      0.92       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(val_preds, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   15.8s finished\n",
      "/Users/stephensinclair/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer(stop_words='english')\n",
    "sgdc = MultinomialNB()\n",
    "\n",
    "pipe = Pipeline([('vect', vect), ('clf', sgdc)])\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'clf__max_iter':(20, 10, 100)\n",
    "}\n",
    "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "grid_search.fit(train_clean['description'], train_clean['category'])\n",
    "predictions = grid_search.predict(test['description']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 4, 1, 1, 1, 1, 1, 2, 1, 4, 4, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1,\n",
       "       1, 1, 4, 1, 1, 1, 3, 1, 4, 2, 1, 1, 1, 1, 1, 3, 4, 3, 2, 1, 1, 3,\n",
       "       1, 1, 1, 2, 1, 1, 3, 1, 3, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 4,\n",
       "       2, 3, 1, 1, 1, 3, 1, 1, 4, 1, 3, 2, 1, 1, 4, 2, 2, 1, 1, 3, 2, 4,\n",
       "       1, 3, 1, 1, 1, 1, 1, 4, 1, 1, 4, 3, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2,\n",
       "       3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 2, 2, 4, 1, 1,\n",
       "       1, 1, 3, 2, 1, 1, 1, 1, 1, 3, 2, 1, 1, 3, 4, 1, 1, 1, 3, 1, 1, 1,\n",
       "       1, 1, 2, 1, 1, 1, 1, 1, 4, 1, 1, 1, 3, 1, 2, 2, 1, 3, 3, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 4, 1, 3, 1, 4, 1, 1, 2, 2, 1, 1,\n",
       "       2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 4, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1,\n",
       "       1, 4, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 3,\n",
       "       2, 2, 1, 3, 1, 3, 3, 3, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 2, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 3, 4, 1, 1, 1, 3,\n",
       "       2, 1])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_sub(predictions, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python 3.6)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
