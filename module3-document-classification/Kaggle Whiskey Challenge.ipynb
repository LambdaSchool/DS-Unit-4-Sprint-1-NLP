{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guide to whoop Josh's ass in Kaggle Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T00:53:34.776717Z",
     "start_time": "2019-10-03T00:53:13.431902Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# ---------------- Pandas settings --------------- #\n",
    "# Removes rows and columns truncation of '...'\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import xgboost as xgb\n",
    "import spacy\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T00:05:43.344545Z",
     "start_time": "2019-10-03T00:05:43.307385Z"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('./data/test.csv')\n",
    "train = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T00:05:43.371964Z",
     "start_time": "2019-10-03T00:05:43.347041Z"
    }
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T00:05:43.439030Z",
     "start_time": "2019-10-03T00:05:43.374702Z"
    }
   },
   "outputs": [],
   "source": [
    "train[train.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T00:05:43.467452Z",
     "start_time": "2019-10-03T00:05:43.447268Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "description    0\n",
       "category       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T00:05:43.518998Z",
     "start_time": "2019-10-03T00:05:43.470986Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A marriage of 13 and 18 year old bourbons. A m...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>There have been some legendary Bowmores from t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>This bottling celebrates master distiller Park...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>What impresses me most is how this whisky evol...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>A caramel-laden fruit bouquet, followed by une...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                        description  category\n",
       "0   1  A marriage of 13 and 18 year old bourbons. A m...         2\n",
       "1   2  There have been some legendary Bowmores from t...         1\n",
       "2   3  This bottling celebrates master distiller Park...         2\n",
       "3   4  What impresses me most is how this whisky evol...         1\n",
       "4   9  A caramel-laden fruit bouquet, followed by une...         2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T00:05:43.564566Z",
     "start_time": "2019-10-03T00:05:43.523300Z"
    }
   },
   "outputs": [],
   "source": [
    "def wrangle(df):\n",
    "    df = df.copy()\n",
    "    df['description'] = df['description'].str.lower().str.strip().str.replace(r\"â€™\", \"'\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T00:05:43.632519Z",
     "start_time": "2019-10-03T00:05:43.569218Z"
    }
   },
   "outputs": [],
   "source": [
    "train = wrangle(train)\n",
    "test = wrangle(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T00:05:43.674533Z",
     "start_time": "2019-10-03T00:05:43.635624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a marriage of 13 and 18 year old bourbons. a mature yet very elegant whiskey, with a silky texture and so easy to embrace with a splash of water. balanced notes of honeyed vanilla, soft caramel, a basket of complex orchard fruit, blackberry, papaya, and a dusting of cocoa and nutmeg; smooth finish. sophisticated, stylish, with well-defined flavors. a classic!'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[0, 'description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T00:05:43.715612Z",
     "start_time": "2019-10-03T00:05:43.676993Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"another excellent stagg, and considering its alcohol level, it's also a good value if you can get it at this price. notes of toffee, pot still rum, nougat, dates, tobacco, roasted nuts, polished oak, and leather. great depth and nicely balanced. a masculine bourbon of character and structure.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[10, 'description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T00:05:43.762654Z",
     "start_time": "2019-10-03T00:05:43.717750Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = []\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        if (token.is_stop == False) and (token.is_punct == False or token.text not in string.punctuation):\n",
    "            tokens.append(token.text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T00:05:43.823536Z",
     "start_time": "2019-10-03T00:05:43.764526Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['excellent',\n",
       " 'stagg',\n",
       " 'considering',\n",
       " 'alcohol',\n",
       " 'level',\n",
       " 'good',\n",
       " 'value',\n",
       " 'price',\n",
       " 'notes',\n",
       " 'toffee',\n",
       " 'pot',\n",
       " 'rum',\n",
       " 'nougat',\n",
       " 'dates',\n",
       " 'tobacco',\n",
       " 'roasted',\n",
       " 'nuts',\n",
       " 'polished',\n",
       " 'oak',\n",
       " 'leather',\n",
       " 'great',\n",
       " 'depth',\n",
       " 'nicely',\n",
       " 'balanced',\n",
       " 'masculine',\n",
       " 'bourbon',\n",
       " 'character',\n",
       " 'structure']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = train.loc[10, 'description']\n",
    "tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T00:05:43.851576Z",
     "start_time": "2019-10-03T00:05:43.825504Z"
    }
   },
   "outputs": [],
   "source": [
    "def submission(model, file_name_suffix):\n",
    "    # Predictions on test sample\n",
    "    preds = model.predict(test['description'])\n",
    "    \n",
    "    # Convert predictions to dataframe\n",
    "    submission = pd.DataFrame({'id': test['id'], 'category':preds})\n",
    "    submission['category'] = submission['category'].astype(int)\n",
    "    \n",
    "    # Save your Submission File\n",
    "    file_path = f'./data/submission_{file_name_suffix}.csv'\n",
    "    submission.to_csv(file_path, index=False)\n",
    "    print(f'File saved at: {file_path}')\n",
    "    print(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T00:05:43.892125Z",
     "start_time": "2019-10-03T00:05:43.854587Z"
    }
   },
   "outputs": [],
   "source": [
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFID + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T00:21:36.810789Z",
     "start_time": "2019-10-03T00:05:43.894088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:   33.4s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:   44.0s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   50.1s\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:   56.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 537 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 570 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 605 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 677 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 714 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 753 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 833 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 917 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 960 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1050 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1097 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1193 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1293 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1344 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1397 tasks      | elapsed: 14.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed: 15.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1500 out of 1500 | elapsed: 15.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Time taken: 0 hours 15 minutes and 52.87 seconds.\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "pipe1 = Pipeline([('vect', vect), ('rfc', rfc)])\n",
    "\n",
    "parameters1 = {\n",
    "    'vect__max_df': (0.5, 0.75, 0.9, 0.95, 0.99),\n",
    "    'vect__min_df': (0.02, 0.05, 0.1, 0.15),\n",
    "    'vect__max_features': (100, 500, 1000),\n",
    "    'rfc__n_estimators': (100, 200, 300, 400, 500),\n",
    "}\n",
    "\n",
    "start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "grid_search1 = GridSearchCV(pipe1, parameters1, cv=5, n_jobs=-1, verbose=10)\n",
    "grid_search1.fit(train['description'], train['category'])\n",
    "timer(start_time) # timing ends here for \"start_time\" variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T00:21:36.819045Z",
     "start_time": "2019-10-03T00:21:36.813767Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.5, max_features=1000, min_df=0.02,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=Tru...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T00:21:36.880643Z",
     "start_time": "2019-10-03T00:21:36.821157Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rfc__n_estimators': 400,\n",
       " 'vect__max_df': 0.5,\n",
       " 'vect__max_features': 1000,\n",
       " 'vect__min_df': 0.02}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T00:21:36.925587Z",
     "start_time": "2019-10-03T00:21:36.883168Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8994586233565351"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T00:21:37.057541Z",
     "start_time": "2019-10-03T00:21:36.928037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved at: ./data/submission_TFIDF_RF.csv\n",
      "     id  category\n",
      "0   955         2\n",
      "1  3532         3\n",
      "2  1390         1\n",
      "3  1024         1\n",
      "4  1902         1\n"
     ]
    }
   ],
   "source": [
    "submission(grid_search1, 'TFIDF_RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF + SGDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T00:25:22.473668Z",
     "start_time": "2019-10-03T00:21:37.060281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:   24.4s\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:   26.7s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed:   32.6s\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed:   37.6s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:   42.9s\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:   47.8s\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed:   54.3s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   59.7s\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 537 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 570 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 605 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 677 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 714 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 753 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 833 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 900 out of 900 | elapsed:  3.7min finished\n",
      "/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Time taken: 0 hours 3 minutes and 45.4 seconds.\n"
     ]
    }
   ],
   "source": [
    "sgdc = SGDClassifier()\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "pipe2 = Pipeline([('vect', vect), \n",
    "                  ('sgdc', sgdc)])\n",
    "\n",
    "parameters2 = {\n",
    "    'vect__max_df': (0.5, 0.75, 0.9, 0.95, 0.99),\n",
    "    'vect__min_df': (0.02, 0.05, 0.1, 0.15),\n",
    "    'vect__max_features': (100, 500, 1000),\n",
    "    'sgdc__max_iter': (300, 1000, 3000),\n",
    "}\n",
    "start_time = timer(None)\n",
    "grid_search2 = GridSearchCV(pipe2, parameters2, cv=5, n_jobs=-1, verbose=10)\n",
    "grid_search2.fit(train['description'], train['category'])\n",
    "timer(start_time) # timing ends here for \"start_time\" variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T00:25:22.482194Z",
     "start_time": "2019-10-03T00:25:22.476448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.5, max_features=500, min_df=0.02,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True...m_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T00:25:22.528729Z",
     "start_time": "2019-10-03T00:25:22.485081Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sgdc__max_iter': 1000,\n",
       " 'vect__max_df': 0.5,\n",
       " 'vect__max_features': 500,\n",
       " 'vect__min_df': 0.02}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T00:25:22.574214Z",
     "start_time": "2019-10-03T00:25:22.530858Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9025522041763341"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T00:25:22.643303Z",
     "start_time": "2019-10-03T00:25:22.576240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved at: ./data/submission_TFIDF_SGDC.csv\n",
      "     id  category\n",
      "0   955         2\n",
      "1  3532         2\n",
      "2  1390         1\n",
      "3  1024         1\n",
      "4  1902         1\n"
     ]
    }
   ],
   "source": [
    "submission(grid_search2, 'TFIDF_SGDC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFID + XGBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T00:32:26.909633Z",
     "start_time": "2019-10-03T00:28:55.578123Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.3min remaining:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  1.3min remaining:   51.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Time taken: 0 hours 3 minutes and 31.32 seconds.\n"
     ]
    }
   ],
   "source": [
    "xgbc = xgb.XGBClassifier()\n",
    "vect = TfidfVectorizer(stop_words='english', max_features=500, min_df=0.02)\n",
    "pipe3 = Pipeline([('vect', vect), \n",
    "                  ('xgbc', xgbc)])\n",
    "\n",
    "# parameters3 = {\n",
    "#         'vect__max_df': (0.5, 0.75, 0.95, 0.99, 1),\n",
    "#         'vect__min_df': (.02,),\n",
    "#         'xgbc__learning_rate': (0.01, 0.05, 0.1),\n",
    "#         'xgbc__n_estimators': (100, 500, 800, 1000),\n",
    "#         'xgbc__min_child_weight': [1, 5, 10],\n",
    "#         'xgbc__gamma': [0.5, 1, 1.5, 2, 5],\n",
    "#         'xgbc__subsample': [0.6, 0.8, 1.0],\n",
    "#         'xgbc__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "#         'xgbc__max_depth': [3, 5, 10, 15, 20],\n",
    "#         'xgbc__booster':['booster', 'gblinear', 'gbtree']\n",
    "# }\n",
    "\n",
    "# parameters3 = {\n",
    "#         'vect__max_df': (0.5, 0.75, 0.95, 0.99, 1), \n",
    "#         'vect__min_df': (.02,), \n",
    "#         'xgbc__learning_rate': (0.01, 0.05, 0.1),\n",
    "#         'xgbc__n_estimators': (100, 500, 800, 1000),\n",
    "#         'xgbc__max_depth': [3, 5, 10, 15, 20]\n",
    "# }\n",
    "\n",
    "parameters3 = {\n",
    "        'vect__max_df': (0.99,), \n",
    "        'vect__min_df': (.02,), \n",
    "        'xgbc__learning_rate': (0.01,),\n",
    "        'xgbc__n_estimators': (1000,),\n",
    "        'xgbc__max_depth': (15,),\n",
    "}\n",
    "start_time = timer(None)\n",
    "grid_search3 = GridSearchCV(pipe3, parameters3, cv=5, n_jobs=-1, verbose=10)\n",
    "grid_search3.fit(train['description'], train['category'])\n",
    "timer(start_time) # timing ends here for \"start_time\" variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T00:32:26.923410Z",
     "start_time": "2019-10-03T00:32:26.914563Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.99, max_features=500, min_df=0.02,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=Tru...\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T00:32:26.960437Z",
     "start_time": "2019-10-03T00:32:26.926460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vect__max_df': 0.99,\n",
       " 'vect__min_df': 0.02,\n",
       " 'xgbc__learning_rate': 0.01,\n",
       " 'xgbc__max_depth': 15,\n",
       " 'xgbc__n_estimators': 1000}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T00:32:27.001300Z",
     "start_time": "2019-10-03T00:32:26.966849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88553750966744"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T00:32:27.365898Z",
     "start_time": "2019-10-03T00:32:27.003554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved at: ./data/submission_TFIDF_XGBC.csv\n",
      "     id  category\n",
      "0   955         2\n",
      "1  3532         2\n",
      "2  1390         1\n",
      "3  1024         1\n",
      "4  1902         1\n"
     ]
    }
   ],
   "source": [
    "submission(grid_search3, 'TFIDF_XGBC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFID + SVD + SGDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T00:55:42.093247Z",
     "start_time": "2019-10-03T00:55:41.146335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2586, 885)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>000 bottles</th>\n",
       "      <th>10</th>\n",
       "      <th>10 year</th>\n",
       "      <th>10 year old</th>\n",
       "      <th>100</th>\n",
       "      <th>12</th>\n",
       "      <th>12 year</th>\n",
       "      <th>12 year old</th>\n",
       "      <th>15</th>\n",
       "      <th>15 year</th>\n",
       "      <th>15 year old</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>18 year</th>\n",
       "      <th>18 year old</th>\n",
       "      <th>20</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>21</th>\n",
       "      <th>25</th>\n",
       "      <th>30</th>\n",
       "      <th>30 year</th>\n",
       "      <th>30 year old</th>\n",
       "      <th>375</th>\n",
       "      <th>375 ml</th>\n",
       "      <th>40</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>50</th>\n",
       "      <th>500</th>\n",
       "      <th>60</th>\n",
       "      <th>70</th>\n",
       "      <th>80</th>\n",
       "      <th>add</th>\n",
       "      <th>added</th>\n",
       "      <th>adding</th>\n",
       "      <th>addition</th>\n",
       "      <th>additional</th>\n",
       "      <th>adds</th>\n",
       "      <th>age</th>\n",
       "      <th>age statement</th>\n",
       "      <th>aged</th>\n",
       "      <th>aged bourbon</th>\n",
       "      <th>aged years</th>\n",
       "      <th>aggressive</th>\n",
       "      <th>aging</th>\n",
       "      <th>ago</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>allowing</th>\n",
       "      <th>allspice</th>\n",
       "      <th>almond</th>\n",
       "      <th>almonds</th>\n",
       "      <th>alongside</th>\n",
       "      <th>amber</th>\n",
       "      <th>amber color</th>\n",
       "      <th>american</th>\n",
       "      <th>american oak</th>\n",
       "      <th>anise</th>\n",
       "      <th>aniseed</th>\n",
       "      <th>antique</th>\n",
       "      <th>appears</th>\n",
       "      <th>appetizing</th>\n",
       "      <th>apple</th>\n",
       "      <th>apples</th>\n",
       "      <th>apricot</th>\n",
       "      <th>apricots</th>\n",
       "      <th>aroma</th>\n",
       "      <th>aromas</th>\n",
       "      <th>aromatic</th>\n",
       "      <th>arran</th>\n",
       "      <th>available</th>\n",
       "      <th>background</th>\n",
       "      <th>baked</th>\n",
       "      <th>baking</th>\n",
       "      <th>baking spices</th>\n",
       "      <th>balance</th>\n",
       "      <th>balanced</th>\n",
       "      <th>banana</th>\n",
       "      <th>barley</th>\n",
       "      <th>barrel</th>\n",
       "      <th>barrels</th>\n",
       "      <th>base</th>\n",
       "      <th>batch</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>beautifully</th>\n",
       "      <th>bed</th>\n",
       "      <th>begins</th>\n",
       "      <th>berries</th>\n",
       "      <th>berry</th>\n",
       "      <th>best</th>\n",
       "      <th>better</th>\n",
       "      <th>big</th>\n",
       "      <th>bit</th>\n",
       "      <th>bitter</th>\n",
       "      <th>bitterness</th>\n",
       "      <th>black</th>\n",
       "      <th>black pepper</th>\n",
       "      <th>blackberry</th>\n",
       "      <th>...</th>\n",
       "      <th>sweeter</th>\n",
       "      <th>sweetness</th>\n",
       "      <th>syrup</th>\n",
       "      <th>taffy</th>\n",
       "      <th>takes</th>\n",
       "      <th>tangerine</th>\n",
       "      <th>tannic</th>\n",
       "      <th>tannins</th>\n",
       "      <th>tar</th>\n",
       "      <th>tarry</th>\n",
       "      <th>tart</th>\n",
       "      <th>taste</th>\n",
       "      <th>tasted</th>\n",
       "      <th>tastes</th>\n",
       "      <th>tea</th>\n",
       "      <th>teasing</th>\n",
       "      <th>texture</th>\n",
       "      <th>textured</th>\n",
       "      <th>thing</th>\n",
       "      <th>things</th>\n",
       "      <th>think</th>\n",
       "      <th>time</th>\n",
       "      <th>tinged</th>\n",
       "      <th>tinned</th>\n",
       "      <th>toasted</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>toffee</th>\n",
       "      <th>tongue</th>\n",
       "      <th>touch</th>\n",
       "      <th>trace</th>\n",
       "      <th>traditional</th>\n",
       "      <th>travel</th>\n",
       "      <th>travel retail</th>\n",
       "      <th>travel retail exclusive</th>\n",
       "      <th>treacle</th>\n",
       "      <th>tropical</th>\n",
       "      <th>tropical fruit</th>\n",
       "      <th>tropical fruits</th>\n",
       "      <th>true</th>\n",
       "      <th>turn</th>\n",
       "      <th>turns</th>\n",
       "      <th>typical</th>\n",
       "      <th>ultimately</th>\n",
       "      <th>underlying</th>\n",
       "      <th>used</th>\n",
       "      <th>using</th>\n",
       "      <th>value</th>\n",
       "      <th>vanilla</th>\n",
       "      <th>vanilla caramel</th>\n",
       "      <th>vanilla cream</th>\n",
       "      <th>vanilla fudge</th>\n",
       "      <th>vanilla honey</th>\n",
       "      <th>variant</th>\n",
       "      <th>ve</th>\n",
       "      <th>version</th>\n",
       "      <th>vibrant</th>\n",
       "      <th>vintage</th>\n",
       "      <th>viscous</th>\n",
       "      <th>walnuts</th>\n",
       "      <th>want</th>\n",
       "      <th>warehouse</th>\n",
       "      <th>warm</th>\n",
       "      <th>warming</th>\n",
       "      <th>water</th>\n",
       "      <th>water brings</th>\n",
       "      <th>waxy</th>\n",
       "      <th>way</th>\n",
       "      <th>weight</th>\n",
       "      <th>wet</th>\n",
       "      <th>wheat</th>\n",
       "      <th>whiff</th>\n",
       "      <th>whiskey</th>\n",
       "      <th>whiskeys</th>\n",
       "      <th>whiskies</th>\n",
       "      <th>whisky</th>\n",
       "      <th>white</th>\n",
       "      <th>white chocolate</th>\n",
       "      <th>white pepper</th>\n",
       "      <th>wine</th>\n",
       "      <th>wine casks</th>\n",
       "      <th>wisp</th>\n",
       "      <th>wood</th>\n",
       "      <th>wood smoke</th>\n",
       "      <th>woody</th>\n",
       "      <th>work</th>\n",
       "      <th>world</th>\n",
       "      <th>worth</th>\n",
       "      <th>year</th>\n",
       "      <th>year old</th>\n",
       "      <th>year old expression</th>\n",
       "      <th>years</th>\n",
       "      <th>years old</th>\n",
       "      <th>yes</th>\n",
       "      <th>yields</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youth</th>\n",
       "      <th>youthful</th>\n",
       "      <th>zest</th>\n",
       "      <th>zesty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.212281</td>\n",
       "      <td>0.233001</td>\n",
       "      <td>0.234217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.147286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.243818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.119665</td>\n",
       "      <td>0.128763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.186185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.170648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.199707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20473</td>\n",
       "      <td>0.226971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.145004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.158906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114213</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.186599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.164057</td>\n",
       "      <td>0.088265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154506</td>\n",
       "      <td>0.10927</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.201269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.161313</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 885 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  000 bottles   10  10 year  10 year old  100   12  12 year  \\\n",
       "0  0.0          0.0  0.0      0.0          0.0  0.0  0.0      0.0   \n",
       "1  0.0          0.0  0.0      0.0          0.0  0.0  0.0      0.0   \n",
       "2  0.0          0.0  0.0      0.0          0.0  0.0  0.0      0.0   \n",
       "3  0.0          0.0  0.0      0.0          0.0  0.0  0.0      0.0   \n",
       "4  0.0          0.0  0.0      0.0          0.0  0.0  0.0      0.0   \n",
       "\n",
       "   12 year old   15  15 year  15 year old   16   17        18   18 year  \\\n",
       "0          0.0  0.0      0.0          0.0  0.0  0.0  0.212281  0.233001   \n",
       "1          0.0  0.0      0.0          0.0  0.0  0.0  0.000000  0.000000   \n",
       "2          0.0  0.0      0.0          0.0  0.0  0.0  0.000000  0.000000   \n",
       "3          0.0  0.0      0.0          0.0  0.0  0.0  0.000000  0.000000   \n",
       "4          0.0  0.0      0.0          0.0  0.0  0.0  0.000000  0.000000   \n",
       "\n",
       "   18 year old   20  2015  2016   21   25   30  30 year  30 year old  375  \\\n",
       "0     0.234217  0.0   0.0   0.0  0.0  0.0  0.0      0.0          0.0  0.0   \n",
       "1     0.000000  0.0   0.0   0.0  0.0  0.0  0.0      0.0          0.0  0.0   \n",
       "2     0.000000  0.0   0.0   0.0  0.0  0.0  0.0      0.0          0.0  0.0   \n",
       "3     0.000000  0.0   0.0   0.0  0.0  0.0  0.0      0.0          0.0  0.0   \n",
       "4     0.000000  0.0   0.0   0.0  0.0  0.0  0.0      0.0          0.0  0.0   \n",
       "\n",
       "   375 ml   40   45   46        50  500   60   70   80  add  added  adding  \\\n",
       "0     0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0    0.0     0.0   \n",
       "1     0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0    0.0     0.0   \n",
       "2     0.0  0.0  0.0  0.0  0.145004  0.0  0.0  0.0  0.0  0.0    0.0     0.0   \n",
       "3     0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0    0.0     0.0   \n",
       "4     0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0    0.0     0.0   \n",
       "\n",
       "   addition  additional  adds  age  age statement  aged  aged bourbon  \\\n",
       "0       0.0         0.0   0.0  0.0            0.0   0.0           0.0   \n",
       "1       0.0         0.0   0.0  0.0            0.0   0.0           0.0   \n",
       "2       0.0         0.0   0.0  0.0            0.0   0.0           0.0   \n",
       "3       0.0         0.0   0.0  0.0            0.0   0.0           0.0   \n",
       "4       0.0         0.0   0.0  0.0            0.0   0.0           0.0   \n",
       "\n",
       "   aged years  aggressive  aging  ago  alcohol  allowing  allspice  almond  \\\n",
       "0         0.0         0.0    0.0  0.0      0.0       0.0       0.0     0.0   \n",
       "1         0.0         0.0    0.0  0.0      0.0       0.0       0.0     0.0   \n",
       "2         0.0         0.0    0.0  0.0      0.0       0.0       0.0     0.0   \n",
       "3         0.0         0.0    0.0  0.0      0.0       0.0       0.0     0.0   \n",
       "4         0.0         0.0    0.0  0.0      0.0       0.0       0.0     0.0   \n",
       "\n",
       "   almonds  alongside  amber  amber color  american  american oak  anise  \\\n",
       "0      0.0        0.0    0.0          0.0       0.0           0.0    0.0   \n",
       "1      0.0        0.0    0.0          0.0       0.0           0.0    0.0   \n",
       "2      0.0        0.0    0.0          0.0       0.0           0.0    0.0   \n",
       "3      0.0        0.0    0.0          0.0       0.0           0.0    0.0   \n",
       "4      0.0        0.0    0.0          0.0       0.0           0.0    0.0   \n",
       "\n",
       "   aniseed  antique  appears  appetizing     apple  apples  apricot  apricots  \\\n",
       "0      0.0      0.0      0.0         0.0  0.000000     0.0      0.0       0.0   \n",
       "1      0.0      0.0      0.0         0.0  0.000000     0.0      0.0       0.0   \n",
       "2      0.0      0.0      0.0         0.0  0.000000     0.0      0.0       0.0   \n",
       "3      0.0      0.0      0.0         0.0  0.000000     0.0      0.0       0.0   \n",
       "4      0.0      0.0      0.0         0.0  0.156394     0.0      0.0       0.0   \n",
       "\n",
       "      aroma  aromas  aromatic  arran  available  background  baked  baking  \\\n",
       "0  0.000000     0.0       0.0    0.0        0.0         0.0    0.0     0.0   \n",
       "1  0.186185     0.0       0.0    0.0        0.0         0.0    0.0     0.0   \n",
       "2  0.000000     0.0       0.0    0.0        0.0         0.0    0.0     0.0   \n",
       "3  0.000000     0.0       0.0    0.0        0.0         0.0    0.0     0.0   \n",
       "4  0.000000     0.0       0.0    0.0        0.0         0.0    0.0     0.0   \n",
       "\n",
       "   baking spices  balance  balanced  banana  barley    barrel  barrels  base  \\\n",
       "0            0.0      0.0  0.147286     0.0     0.0  0.000000      0.0   0.0   \n",
       "1            0.0      0.0  0.000000     0.0     0.0  0.000000      0.0   0.0   \n",
       "2            0.0      0.0  0.000000     0.0     0.0  0.106727      0.0   0.0   \n",
       "3            0.0      0.0  0.000000     0.0     0.0  0.000000      0.0   0.0   \n",
       "4            0.0      0.0  0.000000     0.0     0.0  0.000000      0.0   0.0   \n",
       "\n",
       "   batch  beautiful  beautifully  bed  begins  berries  berry  best  better  \\\n",
       "0    0.0        0.0          0.0  0.0     0.0      0.0    0.0   0.0     0.0   \n",
       "1    0.0        0.0          0.0  0.0     0.0      0.0    0.0   0.0     0.0   \n",
       "2    0.0        0.0          0.0  0.0     0.0      0.0    0.0   0.0     0.0   \n",
       "3    0.0        0.0          0.0  0.0     0.0      0.0    0.0   0.0     0.0   \n",
       "4    0.0        0.0          0.0  0.0     0.0      0.0    0.0   0.0     0.0   \n",
       "\n",
       "   big       bit  bitter  bitterness     black  black pepper  blackberry  ...  \\\n",
       "0  0.0  0.000000     0.0         0.0  0.000000           0.0    0.243818  ...   \n",
       "1  0.0  0.170648     0.0         0.0  0.000000           0.0    0.000000  ...   \n",
       "2  0.0  0.000000     0.0         0.0  0.000000           0.0    0.000000  ...   \n",
       "3  0.0  0.000000     0.0         0.0  0.137397           0.0    0.000000  ...   \n",
       "4  0.0  0.000000     0.0         0.0  0.000000           0.0    0.000000  ...   \n",
       "\n",
       "   sweeter  sweetness     syrup  taffy  takes  tangerine  tannic  tannins  \\\n",
       "0      0.0        0.0  0.000000    0.0    0.0        0.0     0.0      0.0   \n",
       "1      0.0        0.0  0.000000    0.0    0.0        0.0     0.0      0.0   \n",
       "2      0.0        0.0  0.000000    0.0    0.0        0.0     0.0      0.0   \n",
       "3      0.0        0.0  0.000000    0.0    0.0        0.0     0.0      0.0   \n",
       "4      0.0        0.0  0.159277    0.0    0.0        0.0     0.0      0.0   \n",
       "\n",
       "   tar  tarry  tart  taste  tasted  tastes  tea   teasing   texture  textured  \\\n",
       "0  0.0    0.0   0.0    0.0     0.0     0.0  0.0  0.000000  0.173912       0.0   \n",
       "1  0.0    0.0   0.0    0.0     0.0     0.0  0.0  0.000000  0.000000       0.0   \n",
       "2  0.0    0.0   0.0    0.0     0.0     0.0  0.0  0.158906  0.000000       0.0   \n",
       "3  0.0    0.0   0.0    0.0     0.0     0.0  0.0  0.000000  0.000000       0.0   \n",
       "4  0.0    0.0   0.0    0.0     0.0     0.0  0.0  0.000000  0.000000       0.0   \n",
       "\n",
       "   thing  things  think  time  tinged  tinned  toasted   tobacco   toffee  \\\n",
       "0    0.0     0.0    0.0   0.0     0.0     0.0      0.0  0.000000  0.00000   \n",
       "1    0.0     0.0    0.0   0.0     0.0     0.0      0.0  0.000000  0.00000   \n",
       "2    0.0     0.0    0.0   0.0     0.0     0.0      0.0  0.114213  0.00000   \n",
       "3    0.0     0.0    0.0   0.0     0.0     0.0      0.0  0.154506  0.10927   \n",
       "4    0.0     0.0    0.0   0.0     0.0     0.0      0.0  0.161313  0.00000   \n",
       "\n",
       "   tongue     touch  trace  traditional  travel  travel retail  \\\n",
       "0     0.0  0.000000    0.0          0.0     0.0            0.0   \n",
       "1     0.0  0.199707    0.0          0.0     0.0            0.0   \n",
       "2     0.0  0.000000    0.0          0.0     0.0            0.0   \n",
       "3     0.0  0.000000    0.0          0.0     0.0            0.0   \n",
       "4     0.0  0.000000    0.0          0.0     0.0            0.0   \n",
       "\n",
       "   travel retail exclusive  treacle  tropical  tropical fruit  \\\n",
       "0                      0.0      0.0   0.00000        0.000000   \n",
       "1                      0.0      0.0   0.20473        0.226971   \n",
       "2                      0.0      0.0   0.00000        0.000000   \n",
       "3                      0.0      0.0   0.00000        0.000000   \n",
       "4                      0.0      0.0   0.00000        0.000000   \n",
       "\n",
       "   tropical fruits  true  turn  turns  typical  ultimately  underlying  used  \\\n",
       "0              0.0   0.0   0.0    0.0      0.0         0.0         0.0   0.0   \n",
       "1              0.0   0.0   0.0    0.0      0.0         0.0         0.0   0.0   \n",
       "2              0.0   0.0   0.0    0.0      0.0         0.0         0.0   0.0   \n",
       "3              0.0   0.0   0.0    0.0      0.0         0.0         0.0   0.0   \n",
       "4              0.0   0.0   0.0    0.0      0.0         0.0         0.0   0.0   \n",
       "\n",
       "   using  value   vanilla  vanilla caramel  vanilla cream  vanilla fudge  \\\n",
       "0    0.0    0.0  0.085817              0.0            0.0            0.0   \n",
       "1    0.0    0.0  0.000000              0.0            0.0            0.0   \n",
       "2    0.0    0.0  0.058826              0.0            0.0            0.0   \n",
       "3    0.0    0.0  0.000000              0.0            0.0            0.0   \n",
       "4    0.0    0.0  0.083086              0.0            0.0            0.0   \n",
       "\n",
       "   vanilla honey  variant   ve  version  vibrant  vintage   viscous  walnuts  \\\n",
       "0            0.0      0.0  0.0      0.0      0.0      0.0  0.000000      0.0   \n",
       "1            0.0      0.0  0.0      0.0      0.0      0.0  0.000000      0.0   \n",
       "2            0.0      0.0  0.0      0.0      0.0      0.0  0.000000      0.0   \n",
       "3            0.0      0.0  0.0      0.0      0.0      0.0  0.201269      0.0   \n",
       "4            0.0      0.0  0.0      0.0      0.0      0.0  0.000000      0.0   \n",
       "\n",
       "   want  warehouse  warm   warming     water  water brings  waxy  way  weight  \\\n",
       "0   0.0        0.0   0.0  0.000000  0.140816           0.0   0.0  0.0     0.0   \n",
       "1   0.0        0.0   0.0  0.000000  0.000000           0.0   0.0  0.0     0.0   \n",
       "2   0.0        0.0   0.0  0.133002  0.000000           0.0   0.0  0.0     0.0   \n",
       "3   0.0        0.0   0.0  0.000000  0.000000           0.0   0.0  0.0     0.0   \n",
       "4   0.0        0.0   0.0  0.000000  0.000000           0.0   0.0  0.0     0.0   \n",
       "\n",
       "   wet  wheat  whiff   whiskey  whiskeys  whiskies   whisky  white  \\\n",
       "0  0.0    0.0    0.0  0.136108       0.0       0.0  0.00000    0.0   \n",
       "1  0.0    0.0    0.0  0.000000       0.0       0.0  0.00000    0.0   \n",
       "2  0.0    0.0    0.0  0.186599       0.0       0.0  0.00000    0.0   \n",
       "3  0.0    0.0    0.0  0.000000       0.0       0.0  0.29023    0.0   \n",
       "4  0.0    0.0    0.0  0.000000       0.0       0.0  0.00000    0.0   \n",
       "\n",
       "   white chocolate  white pepper  wine  wine casks  wisp  wood  wood smoke  \\\n",
       "0              0.0           0.0   0.0         0.0   0.0   0.0         0.0   \n",
       "1              0.0           0.0   0.0         0.0   0.0   0.0         0.0   \n",
       "2              0.0           0.0   0.0         0.0   0.0   0.0         0.0   \n",
       "3              0.0           0.0   0.0         0.0   0.0   0.0         0.0   \n",
       "4              0.0           0.0   0.0         0.0   0.0   0.0         0.0   \n",
       "\n",
       "   woody  work  world  worth      year  year old  year old expression  \\\n",
       "0    0.0   0.0    0.0    0.0  0.119665  0.128763                  0.0   \n",
       "1    0.0   0.0    0.0    0.0  0.000000  0.000000                  0.0   \n",
       "2    0.0   0.0    0.0    0.0  0.164057  0.088265                  0.0   \n",
       "3    0.0   0.0    0.0    0.0  0.000000  0.000000                  0.0   \n",
       "4    0.0   0.0    0.0    0.0  0.000000  0.000000                  0.0   \n",
       "\n",
       "     years  years old  yes  yields  young  younger     youth  youthful  zest  \\\n",
       "0  0.00000        0.0  0.0     0.0    0.0      0.0  0.000000       0.0   0.0   \n",
       "1  0.00000        0.0  0.0     0.0    0.0      0.0  0.000000       0.0   0.0   \n",
       "2  0.09185        0.0  0.0     0.0    0.0      0.0  0.157345       0.0   0.0   \n",
       "3  0.00000        0.0  0.0     0.0    0.0      0.0  0.000000       0.0   0.0   \n",
       "4  0.00000        0.0  0.0     0.0    0.0      0.0  0.000000       0.0   0.0   \n",
       "\n",
       "   zesty  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "3    0.0  \n",
       "4    0.0  \n",
       "\n",
       "[5 rows x 885 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vect = TfidfVectorizer(stop_words='english', ngram_range=(1, 3), min_df=0.01)\n",
    "\n",
    "# sparse = vect.fit_transform(train['description'])\n",
    "\n",
    "# dtm = pd.DataFrame(sparse.todense(), columns=vect.get_feature_names())\n",
    "# print(dtm.shape)\n",
    "# dtm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T01:18:15.932314Z",
     "start_time": "2019-10-03T01:06:23.885181Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   24.4s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   32.9s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   39.7s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   49.0s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   56.9s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed: 11.6min finished\n",
      "/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Time taken: 0 hours 11 minutes and 52.04 seconds.\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1, 3))\n",
    "\n",
    "svd = TruncatedSVD(algorithm='randomized', n_components=100)\n",
    "\n",
    "sgdc = SGDClassifier(early_stopping=True)\n",
    "\n",
    "pipe4 = Pipeline([('vect', vect), ('svd', svd), ('sgdc', sgdc)])\n",
    "\n",
    "parameters4 = { \n",
    "    'svd__n_iter': (5, 10, 15),\n",
    "    'svd__n_components': (100, 300, 500, 1000),\n",
    "    'sgdc__max_iter': (300, 1000, 3000)\n",
    "}\n",
    "\n",
    "start_time = timer(None)\n",
    "grid_search4 = GridSearchCV(pipe4, parameters4, cv=5, n_jobs=-1, verbose=10)\n",
    "grid_search4.fit(train['description'], train['category'])\n",
    "timer(start_time) # timing ends here for \"start_time\" variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T01:18:15.949584Z",
     "start_time": "2019-10-03T01:18:15.935339Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.95, max_features=None, min_df=0.01,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=Tr...m_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search4.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T01:18:15.992427Z",
     "start_time": "2019-10-03T01:18:15.952101Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sgdc__max_iter': 3000,\n",
       " 'svd__n_iter': 15,\n",
       " 'vect__max_df': 0.95,\n",
       " 'vect__min_df': 0.01}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T01:18:16.032549Z",
     "start_time": "2019-10-03T01:18:15.995213Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9191802010827533"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T01:18:16.137584Z",
     "start_time": "2019-10-03T01:18:16.034721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved at: ./data/submission_TFIDF_SVD_SGDC.csv\n",
      "     id  category\n",
      "0   955         2\n",
      "1  3532         2\n",
      "2  1390         1\n",
      "3  1024         1\n",
      "4  1902         1\n"
     ]
    }
   ],
   "source": [
    "submission(grid_search4, 'TFIDF_SVD_SGDC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Tokenizer + TFIDF + SVD + SGDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T02:32:17.797368Z",
     "start_time": "2019-10-03T02:32:14.278141Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1654s.) Setting batch_size=2.\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Could not pickle the task to send it to the workers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/backend/queues.py\", line 150, in _feed\n    obj_ = dumps(obj, reducers=reducers)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/backend/reduction.py\", line 243, in dumps\n    dump(obj, buf, reducers=reducers, protocol=protocol)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/backend/reduction.py\", line 236, in dump\n    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py\", line 284, in dump\n    return Pickler.dump(self, obj)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 437, in dump\n    self.save(obj)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 856, in save_dict\n    self._batch_setitems(obj.items())\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n    save(v)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 856, in save_dict\n    self._batch_setitems(obj.items())\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 887, in _batch_setitems\n    save(v)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 856, in save_dict\n    self._batch_setitems(obj.items())\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n    save(v)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 816, in save_list\n    self._batch_appends(obj)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 843, in _batch_appends\n    save(tmp[0])\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 771, in save_tuple\n    save(element)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 771, in save_tuple\n    save(element)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 856, in save_dict\n    self._batch_setitems(obj.items())\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n    save(v)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 816, in save_list\n    self._batch_appends(obj)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 840, in _batch_appends\n    save(x)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 771, in save_tuple\n    save(element)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 856, in save_dict\n    self._batch_setitems(obj.items())\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n    save(v)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py\", line 414, in save_function\n    self.save_function_tuple(obj)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py\", line 579, in save_function_tuple\n    save(state)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 856, in save_dict\n    self._batch_setitems(obj.items())\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n    save(v)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 856, in save_dict\n    self._batch_setitems(obj.items())\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n    save(v)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 856, in save_dict\n    self._batch_setitems(obj.items())\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n    save(v)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 786, in save_tuple\n    save(element)\n  File \"/home/asura/miniconda3/envs/U4-S1-NLP/lib/python3.7/pickle.py\", line 524, in save\n    rv = reduce(self.proto)\n  File \"stringsource\", line 2, in preshed.maps.PreshMap.__reduce_cython__\nTypeError: self.c_map cannot be converted to a Python object for pickling\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-f682b440cff7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mgrid_search5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mgrid_search5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# timing ends here for \"start_time\" variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/U4-S1-NLP/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/U4-S1-NLP/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Could not pickle the task to send it to the workers."
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer(tokenizer=tokenize, ngram_range=(1, 3))\n",
    "\n",
    "svd = TruncatedSVD(algorithm='randomized')\n",
    "\n",
    "sgdc = SGDClassifier(early_stopping=True)\n",
    "\n",
    "pipe5 = Pipeline([('vect', vect), ('svd', svd), ('sgdc', sgdc)])\n",
    "\n",
    "parameters5 = { \n",
    "    'svd__n_iter': (5, 10, 15),\n",
    "    'sgdc__max_iter': (300, 1000, 3000, 4000, 5000),\n",
    "    'svd__n_components': (300, 1000, 3000),\n",
    "}\n",
    "\n",
    "start_time = timer(None)\n",
    "grid_search5 = GridSearchCV(pipe5, parameters5, cv=5, n_jobs=-1, verbose=10)\n",
    "grid_search5.fit(train['description'], train['category'])\n",
    "timer(start_time) # timing ends here for \"start_time\" variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T02:30:05.378029Z",
     "start_time": "2019-10-03T02:28:56.356Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_search5.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T02:30:05.379827Z",
     "start_time": "2019-10-03T02:28:56.780Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_search5.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T02:30:05.381189Z",
     "start_time": "2019-10-03T02:28:57.771Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_search5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T02:30:05.382266Z",
     "start_time": "2019-10-03T02:28:58.212Z"
    }
   },
   "outputs": [],
   "source": [
    "submission(grid_search5, 'CUSTOM_TOKENIZER_TFIDF_SVD_SGDC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy Embeddings + SGDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vectors(docs):\n",
    "    return [nlp(doc).vector for doc in docs]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T03:15:18.336713Z",
     "start_time": "2019-10-02T03:15:18.333686Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Filenames of your submissions you want to ensemble\n",
    "# files = ['submission-01.csv', 'submission-02.csv', 'submission-03.csv']\n",
    "\n",
    "# target = 'status_group'\n",
    "# submissions = (pd.read_csv(file)[[target]] for file in files)\n",
    "# ensemble = pd.concat(submissions, axis='columns')\n",
    "# majority_vote = ensemble.mode(axis='columns')[0]\n",
    "\n",
    "# sample_submission = pd.read_csv('sample_submission.csv')\n",
    "# submission = sample_submission.copy()\n",
    "# submission[target] = majority_vote\n",
    "# submission.to_csv('my-ultimate-ensemble-submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S1-NLP-DS6 (Python 3.7)",
   "language": "python",
   "name": "u4-s1-nlp-ds6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
