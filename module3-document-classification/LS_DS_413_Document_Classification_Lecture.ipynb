{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 4, Sprint 1, Module 3*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification (Prepare)\n",
    "\n",
    "Today's guided module project will be different. You already know how to do classification. You ready know how to extract features from documents. So? That means you're ready to combine and practice those skills in a kaggle competition. We we will open with a five minute sprint explaining the competition, and then give you 25 minutes to work. After those twenty five minutes are up, I will give a 5-minute demo an NLP technique that will help you with document classification (*and **maybe** the competition*).\n",
    "\n",
    "Today's all about having fun and practicing your skills. The competition will begin\n",
    "\n",
    "## Learning Objectives\n",
    "* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n",
    "* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n",
    "* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Feature Extraction & Classification Pipelines (Learn)\n",
    "<a id=\"p1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Sklearn pipelines allow you to stitch together multiple components of a machine learning process. The idea is that you can pass you raw data and get predictions out of the pipeline. This ability to pass raw input and receive a prediction from a singular class makes pipelines well suited for production, because you can pickle a a pipeline without worry about other data preprocessing steps. \n",
    "\n",
    "*Note:* Each time we call the pipeline during grid search, each component is fit again. The vectorizer (tf-idf) is transforming our entire vocabulary during each cross-validation fold. That transformation adds significant run time to our grid search. There *might* be interactions between the vectorizer and our classifier, so we estimate their performance together in the code below. However, if your goal is to reduce run time. Train your vectorizer separately (ie out of the grid-searched pipeline). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "categories = ['alt.atheism',\n",
    "              'talk.religion.misc']\n",
    "\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "sample = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1321</td>\n",
       "      <td>Sometimes, when whisky is batched, a few lefto...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3861</td>\n",
       "      <td>An uncommon exclusive bottling of a 6 year old...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655</td>\n",
       "      <td>This release is a port version of Amrut’s Inte...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>555</td>\n",
       "      <td>This 41 year old single cask was aged in a she...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1965</td>\n",
       "      <td>Quite herbal on the nose, with aromas of dried...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4082</th>\n",
       "      <td>3342</td>\n",
       "      <td>What lies beneath the surface of Dewar’s? Here...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4083</th>\n",
       "      <td>3130</td>\n",
       "      <td>After 6 to 7 years of maturation in bourbon ca...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084</th>\n",
       "      <td>2811</td>\n",
       "      <td>Bright, delicate, and approachable. While not ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4085</th>\n",
       "      <td>478</td>\n",
       "      <td>I’m calling this the pitmaster’s dram: the nos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4086</th>\n",
       "      <td>1209</td>\n",
       "      <td>Spicy sultanas, greengage plums, toffee, and n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4087 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                        description  ratingCategory\n",
       "0     1321  Sometimes, when whisky is batched, a few lefto...               1\n",
       "1     3861  An uncommon exclusive bottling of a 6 year old...               0\n",
       "2      655  This release is a port version of Amrut’s Inte...               1\n",
       "3      555  This 41 year old single cask was aged in a she...               1\n",
       "4     1965  Quite herbal on the nose, with aromas of dried...               1\n",
       "...    ...                                                ...             ...\n",
       "4082  3342  What lies beneath the surface of Dewar’s? Here...               1\n",
       "4083  3130  After 6 to 7 years of maturation in bourbon ca...               1\n",
       "4084  2811  Bright, delicate, and approachable. While not ...               1\n",
       "4085   478  I’m calling this the pitmaster’s dram: the nos...               1\n",
       "4086  1209  Spicy sultanas, greengage plums, toffee, and n...               1\n",
       "\n",
       "[4087 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.description = train.description.str.strip()\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2881\n",
       "0    1141\n",
       "2      65\n",
       "Name: ratingCategory, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.ratingCategory.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>Style: Speyside single malt scotch Color: Waln...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>Very bright and lively, with a nice balance of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>A new oloroso-forward Chivas positioned to spl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>Aged in bourbon casks and then enhanced in Rio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>There is a freshness to the wood on the nose, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>2853</td>\n",
       "      <td>Care for a small batch, bourbon-matured blend ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>219</td>\n",
       "      <td>This is the pick of the bunch, the whisky equi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>1286</td>\n",
       "      <td>Port Ellen, for sure! Very old-fashioned in na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>2201</td>\n",
       "      <td>Youthful and very lively. Bold, crisp, spices ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>4019</td>\n",
       "      <td>A mashbill of 60/20/10/10 corn/wheat/rye/malt,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1022 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                        description\n",
       "0     3461  Style: Speyside single malt scotch Color: Waln...\n",
       "1     2604  Very bright and lively, with a nice balance of...\n",
       "2     3341  A new oloroso-forward Chivas positioned to spl...\n",
       "3     3764  Aged in bourbon casks and then enhanced in Rio...\n",
       "4     2306  There is a freshness to the wood on the nose, ...\n",
       "...    ...                                                ...\n",
       "1017  2853  Care for a small batch, bourbon-matured blend ...\n",
       "1018   219  This is the pick of the bunch, the whisky equi...\n",
       "1019  1286  Port Ellen, for sure! Very old-fashioned in na...\n",
       "1020  2201  Youthful and very lively. Bold, crisp, spices ...\n",
       "1021  4019  A mashbill of 60/20/10/10 corn/wheat/rye/malt,...\n",
       "\n",
       "[1022 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.description = test.description.str.strip()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>2853</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>219</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>1286</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>2201</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>4019</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1022 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  ratingCategory\n",
       "0     3461               2\n",
       "1     2604               2\n",
       "2     3341               2\n",
       "3     3764               2\n",
       "4     2306               2\n",
       "...    ...             ...\n",
       "1017  2853               2\n",
       "1018   219               2\n",
       "1019  1286               2\n",
       "1020  2201               2\n",
       "1021  4019               2\n",
       "\n",
       "[1022 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipeline Components\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Pipeline\n",
    "pipe = Pipeline([\n",
    "                 #Vectorizer\n",
    "                 ('vect', vect),\n",
    "                 # Classifier\n",
    "                 ('clf', rfc)\n",
    "                ])\n",
    "\n",
    "# The pipeline puts together a bunch fit then transform,fit then predict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:   54.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words='english',\n",
       "                                                        strip...\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'clf__max_depth': (15, 20),\n",
       "                         'clf__n_estimators': (5, 10),\n",
       "                         'vect__max_df': (0.75, 1.0),\n",
       "                         'vect__max_features': (500, 1000),\n",
       "                         'vect__min_df': (0.02, 0.05)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': ( 0.75, 1.0),\n",
    "    'vect__min_df': (.02, .05),\n",
    "    'vect__max_features': (500,1000),\n",
    "    'clf__n_estimators':(5, 10,),\n",
    "    'clf__max_depth':(15,20)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(train.description, train.ratingCategory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7230220886839263"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>2853</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>219</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>1286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>2201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>4019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1022 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  ratingCategory\n",
       "0     3461               1\n",
       "1     2604               1\n",
       "2     3341               1\n",
       "3     3764               1\n",
       "4     2306               1\n",
       "...    ...             ...\n",
       "1017  2853               1\n",
       "1018   219               1\n",
       "1019  1286               1\n",
       "1020  2201               1\n",
       "1021  4019               1\n",
       "\n",
       "[1022 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = test.copy()\n",
    "submission[\"ratingCategory\"] = pd.Series(grid_search.predict(test.description))\n",
    "submission = submission[[\"id\", \"ratingCategory\"]]\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('data/submission_01_08_04_2020.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = {'-pron-', '.', ',', '(', ')', '-', \"’\", 'whisky', 'whiskey'}\n",
    "\n",
    "lemmas = pd.Series([[token.lemma_.lower() for token in doc if token.lemma_.lower() not in STOP_WORDS] for doc in nlp.pipe(train['description'], batch_size=500)])\n",
    "train['lemmas'] = lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.lemmatizedDescription = train.lemmas.apply(lambda x : \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object from Base Python\n",
    "from collections import Counter\n",
    "\n",
    "def count(docs):\n",
    "\n",
    "        word_counts = Counter()\n",
    "        appears_in = Counter()\n",
    "        \n",
    "        total_docs = len(docs)\n",
    "\n",
    "        for doc in docs:\n",
    "            word_counts.update(doc)\n",
    "            appears_in.update(set(doc))\n",
    "\n",
    "        temp = zip(word_counts.keys(), word_counts.values())\n",
    "        \n",
    "        wc = pd.DataFrame(temp, columns = ['word', 'count'])\n",
    "\n",
    "        wc['rank'] = wc['count'].rank(method='first', ascending=False)\n",
    "        total = wc['count'].sum()\n",
    "\n",
    "        wc['pct_total'] = wc['count'].apply(lambda x: x / total)\n",
    "        \n",
    "        wc = wc.sort_values(by='rank')\n",
    "        wc['cul_pct_total'] = wc['pct_total'].cumsum()\n",
    "\n",
    "        t2 = zip(appears_in.keys(), appears_in.values())\n",
    "        ac = pd.DataFrame(t2, columns=['word', 'appears_in'])\n",
    "        wc = ac.merge(wc, on='word')\n",
    "\n",
    "        wc['appears_in_pct'] = wc['appears_in'].apply(lambda x: x / total_docs)\n",
    "        \n",
    "        return wc.sort_values(by='rank')\n",
    "    \n",
    "wc = count(train['lemmas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import squarify\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "wc_top20 = wc[wc['rank'] <= 20]\n",
    "\n",
    "squarify.plot(sizes=wc_top20['pct_total'], label=wc_top20['word'], alpha=.8)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:   47.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7227745972653246"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(train.lemmatizedDescription, train.ratingCategory)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along \n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model (try using the pipe method I just demoed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You're trying to achieve 75% Accuracy on your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Indexing (Learn)\n",
    "<a id=\"p2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "svd = TruncatedSVD(n_components=100, # Just here for demo. \n",
    "                   algorithm='randomized',\n",
    "                   n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { \n",
    "    'lsi__svd__n_components': [10,100,250],\n",
    "    'lsi__vect__max_df':[.9, .95, 1.0],\n",
    "    'lsi__vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'clf__n_estimators':[5,10,20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSI\n",
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "\n",
    "\n",
    "# Pipe\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', rfc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('lsi',\n",
      "                 Pipeline(memory=None,\n",
      "                          steps=[('vect',\n",
      "                                  TfidfVectorizer(analyzer='word', binary=False,\n",
      "                                                  decode_error='strict',\n",
      "                                                  dtype=<class 'numpy.float64'>,\n",
      "                                                  encoding='utf-8',\n",
      "                                                  input='content',\n",
      "                                                  lowercase=True, max_df=1.0,\n",
      "                                                  max_features=None, min_df=1,\n",
      "                                                  ngram_range=(1, 1), norm='l2',\n",
      "                                                  preprocessor=None,\n",
      "                                                  smooth_idf=True,\n",
      "                                                  stop_words='english',\n",
      "                                                  strip_accents=...\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=None, max_features='auto',\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=1, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  36 tasks      | elapsed:  1.3min\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 71.7 MiB for an array with shape (9394000,) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\crlga\\AppData\\Roaming\\Python\\Python37\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\crlga\\AppData\\Roaming\\Python\\Python37\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\crlga\\AppData\\Roaming\\Python\\Python37\\site-packages\\joblib\\_parallel_backends.py\", line 608, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\crlga\\AppData\\Roaming\\Python\\Python37\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\crlga\\AppData\\Roaming\\Python\\Python37\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\crlga\\.conda\\envs\\U4-S1-NLP\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 544, in _fit_and_score\n    test_scores = _score(estimator, X_test, y_test, scorer)\n  File \"C:\\Users\\crlga\\.conda\\envs\\U4-S1-NLP\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 591, in _score\n    scores = scorer(estimator, X_test, y_test)\n  File \"C:\\Users\\crlga\\.conda\\envs\\U4-S1-NLP\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 89, in __call__\n    score = scorer(estimator, *args, **kwargs)\n  File \"C:\\Users\\crlga\\.conda\\envs\\U4-S1-NLP\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 371, in _passthrough_scorer\n    return estimator.score(*args, **kwargs)\n  File \"C:\\Users\\crlga\\.conda\\envs\\U4-S1-NLP\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 116, in <lambda>\n    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)\n  File \"C:\\Users\\crlga\\.conda\\envs\\U4-S1-NLP\\lib\\site-packages\\sklearn\\pipeline.py\", line 615, in score\n    Xt = transform.transform(Xt)\n  File \"C:\\Users\\crlga\\.conda\\envs\\U4-S1-NLP\\lib\\site-packages\\sklearn\\pipeline.py\", line 557, in _transform\n    Xt = transform.transform(Xt)\n  File \"C:\\Users\\crlga\\.conda\\envs\\U4-S1-NLP\\lib\\site-packages\\sklearn\\decomposition\\_truncated_svd.py\", line 213, in transform\n    return safe_sparse_dot(X, self.components_.T)\n  File \"C:\\Users\\crlga\\.conda\\envs\\U4-S1-NLP\\lib\\site-packages\\sklearn\\utils\\extmath.py\", line 151, in safe_sparse_dot\n    ret = a @ b\n  File \"C:\\Users\\crlga\\.conda\\envs\\U4-S1-NLP\\lib\\site-packages\\scipy\\sparse\\base.py\", line 564, in __matmul__\n    return self.__mul__(other)\n  File \"C:\\Users\\crlga\\.conda\\envs\\U4-S1-NLP\\lib\\site-packages\\scipy\\sparse\\base.py\", line 475, in __mul__\n    return self._mul_multivector(other)\n  File \"C:\\Users\\crlga\\.conda\\envs\\U4-S1-NLP\\lib\\site-packages\\scipy\\sparse\\compressed.py\", line 487, in _mul_multivector\n    other.ravel(), result.ravel())\nMemoryError: Unable to allocate 71.7 MiB for an array with shape (9394000,) and data type float64\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-54d36e7d2b35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatizedDescription\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mratingCategory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\U4-S1-NLP\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    708\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\U4-S1-NLP\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1151\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\U4-S1-NLP\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    687\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 689\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1018\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    907\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    561\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\U4-S1-NLP\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\U4-S1-NLP\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 71.7 MiB for an array with shape (9394000,) and data type float64"
     ]
    }
   ],
   "source": [
    "# Fit\n",
    "grid_search = GridSearchCV(pipe,params, cv=5, n_jobs=-2, verbose=1)\n",
    "grid_search.fit(train.lemmatizedDescription, train.ratingCategory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7291435360448657"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "4. Make a submission to Kaggle \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Continue to apply Latent Semantic Indexing (LSI) to various datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings with Spacy (Learn)\n",
    "<a id=\"p3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Two bananas in pyjamas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bananas_vector = doc.vector\n",
    "print(len(bananas_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vectors(docs):\n",
    "    return [nlp(doc).vector for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_word_vectors(train['description'])\n",
    "\n",
    "len(X) == len(data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = get_word_vectors(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit(X, train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.score(X, train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['ratingCategory'] = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['id', 'ratingCategory']].to_csv('testSolutionSubmission.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n",
    "4. Make a submission to Kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review\n",
    "\n",
    "To review this module: \n",
    "* Continue working on the Kaggle competition\n",
    "* Find another text classification task to work on"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
