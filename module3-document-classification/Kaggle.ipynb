{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: nltk in c:\\users\\mhdal\\anaconda3\\envs\\lambda-nlp\\lib\\site-packages (3.4.4)\n",
      "Requirement already satisfied, skipping upgrade: six in c:\\users\\mhdal\\anaconda3\\envs\\lambda-nlp\\lib\\site-packages (from nltk) (1.12.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mhdal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mhdal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "!pip install -U nltk\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import sent_tokenize # Sentence Tokenizer\n",
    "from nltk.tokenize import word_tokenize # Word Tokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                0\n",
       "author            0\n",
       "description       0\n",
       "price            63\n",
       "ratingValue       0\n",
       "pert_alcohol     60\n",
       "category        288\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2874, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>pert_alcohol</th>\n",
       "      <th>category</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokenized_sentences</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>lammatized_sentence</th>\n",
       "      <th>string_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John Hansell</td>\n",
       "      <td>A marriage of 13 and 18 year old bourbons. A m...</td>\n",
       "      <td>85.0</td>\n",
       "      <td>97</td>\n",
       "      <td>51.50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[marriage, 13, 18, year, old, bourbons., a, ma...</td>\n",
       "      <td>marriage 13 18 year old bourbons. a mature el...</td>\n",
       "      <td>[ , marriage, 13, 18, year, old, bourbon, a, m...</td>\n",
       "      <td>marriage 13 18 year old bourbon a mature el...</td>\n",
       "      <td>Bourbon/Tennessee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Dave Broom</td>\n",
       "      <td>There have been some legendary Bowmores from t...</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>97</td>\n",
       "      <td>42.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[legendary, bowmores, mid-60s, bit, equal., al...</td>\n",
       "      <td>legendary bowmores mid-60s bit equal. all sha...</td>\n",
       "      <td>[ , legendary, bowmore, mid-60, bit, equal, al...</td>\n",
       "      <td>legendary bowmore mid-60 bit equal all shar...</td>\n",
       "      <td>Scotch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>John Hansell</td>\n",
       "      <td>This bottling celebrates master distiller Park...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>97</td>\n",
       "      <td>50.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[bottling, celebrates, master, distiller, park...</td>\n",
       "      <td>bottling celebrates master distiller parker b...</td>\n",
       "      <td>[ , bottling, celebrate, master, distiller, pa...</td>\n",
       "      <td>bottling celebrate master distiller parker ...</td>\n",
       "      <td>Bourbon/Tennessee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>John Hansell</td>\n",
       "      <td>What impresses me most is how this whisky evol...</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>97</td>\n",
       "      <td>40.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[impresses, whisky, evolves;, incredibly, comp...</td>\n",
       "      <td>impresses whisky evolves; incredibly complex....</td>\n",
       "      <td>[ , impress, whisky, evolve, incredibly, compl...</td>\n",
       "      <td>impress whisky evolve incredibly complex on...</td>\n",
       "      <td>Scotch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>Fred Minnick</td>\n",
       "      <td>A caramel-laden fruit bouquet, followed by une...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>96</td>\n",
       "      <td>54.49</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[caramel-laden, fruit, bouquet,, followed, une...</td>\n",
       "      <td>caramel-laden fruit bouquet, followed unendin...</td>\n",
       "      <td>[ , caramel, laden, fruit, bouquet, follow, un...</td>\n",
       "      <td>caramel laden fruit bouquet follow unending...</td>\n",
       "      <td>Bourbon/Tennessee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        author                                        description  \\\n",
       "0   1  John Hansell  A marriage of 13 and 18 year old bourbons. A m...   \n",
       "1   2    Dave Broom  There have been some legendary Bowmores from t...   \n",
       "2   3  John Hansell  This bottling celebrates master distiller Park...   \n",
       "3   4  John Hansell  What impresses me most is how this whisky evol...   \n",
       "5   9  Fred Minnick  A caramel-laden fruit bouquet, followed by une...   \n",
       "\n",
       "     price  ratingValue  pert_alcohol  category  \\\n",
       "0     85.0           97         51.50       2.0   \n",
       "1  13500.0           97         42.90       1.0   \n",
       "2    150.0           97         50.00       2.0   \n",
       "3   4500.0           97         40.50       1.0   \n",
       "5    150.0           96         54.49       2.0   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [marriage, 13, 18, year, old, bourbons., a, ma...   \n",
       "1  [legendary, bowmores, mid-60s, bit, equal., al...   \n",
       "2  [bottling, celebrates, master, distiller, park...   \n",
       "3  [impresses, whisky, evolves;, incredibly, comp...   \n",
       "5  [caramel-laden, fruit, bouquet,, followed, une...   \n",
       "\n",
       "                                 tokenized_sentences  \\\n",
       "0   marriage 13 18 year old bourbons. a mature el...   \n",
       "1   legendary bowmores mid-60s bit equal. all sha...   \n",
       "2   bottling celebrates master distiller parker b...   \n",
       "3   impresses whisky evolves; incredibly complex....   \n",
       "5   caramel-laden fruit bouquet, followed unendin...   \n",
       "\n",
       "                                              lemmas  \\\n",
       "0  [ , marriage, 13, 18, year, old, bourbon, a, m...   \n",
       "1  [ , legendary, bowmore, mid-60, bit, equal, al...   \n",
       "2  [ , bottling, celebrate, master, distiller, pa...   \n",
       "3  [ , impress, whisky, evolve, incredibly, compl...   \n",
       "5  [ , caramel, laden, fruit, bouquet, follow, un...   \n",
       "\n",
       "                                 lammatized_sentence    string_category  \n",
       "0     marriage 13 18 year old bourbon a mature el...  Bourbon/Tennessee  \n",
       "1     legendary bowmore mid-60 bit equal all shar...             Scotch  \n",
       "2     bottling celebrate master distiller parker ...  Bourbon/Tennessee  \n",
       "3     impress whisky evolve incredibly complex on...             Scotch  \n",
       "5     caramel laden fruit bouquet follow unending...  Bourbon/Tennessee  "
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "author           0\n",
       "description      0\n",
       "price           54\n",
       "ratingValue      0\n",
       "pert_alcohol    56\n",
       "category         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.dropna(subset=['category'])\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>pert_alcohol</th>\n",
       "      <th>category</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokenized_sentences</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>lammatized_sentence</th>\n",
       "      <th>string_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John Hansell</td>\n",
       "      <td>A marriage of 13 and 18 year old bourbons. A m...</td>\n",
       "      <td>85.0</td>\n",
       "      <td>97</td>\n",
       "      <td>51.50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[marriage, 13, 18, year, old, bourbons., a, ma...</td>\n",
       "      <td>marriage 13 18 year old bourbons. a mature el...</td>\n",
       "      <td>[ , marriage, 13, 18, year, old, bourbon, a, m...</td>\n",
       "      <td>marriage 13 18 year old bourbon a mature el...</td>\n",
       "      <td>Bourbon/Tennessee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Dave Broom</td>\n",
       "      <td>There have been some legendary Bowmores from t...</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>97</td>\n",
       "      <td>42.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[legendary, bowmores, mid-60s, bit, equal., al...</td>\n",
       "      <td>legendary bowmores mid-60s bit equal. all sha...</td>\n",
       "      <td>[ , legendary, bowmore, mid-60, bit, equal, al...</td>\n",
       "      <td>legendary bowmore mid-60 bit equal all shar...</td>\n",
       "      <td>Scotch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>John Hansell</td>\n",
       "      <td>This bottling celebrates master distiller Park...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>97</td>\n",
       "      <td>50.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[bottling, celebrates, master, distiller, park...</td>\n",
       "      <td>bottling celebrates master distiller parker b...</td>\n",
       "      <td>[ , bottling, celebrate, master, distiller, pa...</td>\n",
       "      <td>bottling celebrate master distiller parker ...</td>\n",
       "      <td>Bourbon/Tennessee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>John Hansell</td>\n",
       "      <td>What impresses me most is how this whisky evol...</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>97</td>\n",
       "      <td>40.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[impresses, whisky, evolves;, incredibly, comp...</td>\n",
       "      <td>impresses whisky evolves; incredibly complex....</td>\n",
       "      <td>[ , impress, whisky, evolve, incredibly, compl...</td>\n",
       "      <td>impress whisky evolve incredibly complex on...</td>\n",
       "      <td>Scotch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>Fred Minnick</td>\n",
       "      <td>A caramel-laden fruit bouquet, followed by une...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>96</td>\n",
       "      <td>54.49</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[caramel-laden, fruit, bouquet,, followed, une...</td>\n",
       "      <td>caramel-laden fruit bouquet, followed unendin...</td>\n",
       "      <td>[ , caramel, laden, fruit, bouquet, follow, un...</td>\n",
       "      <td>caramel laden fruit bouquet follow unending...</td>\n",
       "      <td>Bourbon/Tennessee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        author                                        description  \\\n",
       "0   1  John Hansell  A marriage of 13 and 18 year old bourbons. A m...   \n",
       "1   2    Dave Broom  There have been some legendary Bowmores from t...   \n",
       "2   3  John Hansell  This bottling celebrates master distiller Park...   \n",
       "3   4  John Hansell  What impresses me most is how this whisky evol...   \n",
       "4   9  Fred Minnick  A caramel-laden fruit bouquet, followed by une...   \n",
       "\n",
       "     price  ratingValue  pert_alcohol  category  \\\n",
       "0     85.0           97         51.50       2.0   \n",
       "1  13500.0           97         42.90       1.0   \n",
       "2    150.0           97         50.00       2.0   \n",
       "3   4500.0           97         40.50       1.0   \n",
       "4    150.0           96         54.49       2.0   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [marriage, 13, 18, year, old, bourbons., a, ma...   \n",
       "1  [legendary, bowmores, mid-60s, bit, equal., al...   \n",
       "2  [bottling, celebrates, master, distiller, park...   \n",
       "3  [impresses, whisky, evolves;, incredibly, comp...   \n",
       "4  [caramel-laden, fruit, bouquet,, followed, une...   \n",
       "\n",
       "                                 tokenized_sentences  \\\n",
       "0   marriage 13 18 year old bourbons. a mature el...   \n",
       "1   legendary bowmores mid-60s bit equal. all sha...   \n",
       "2   bottling celebrates master distiller parker b...   \n",
       "3   impresses whisky evolves; incredibly complex....   \n",
       "4   caramel-laden fruit bouquet, followed unendin...   \n",
       "\n",
       "                                              lemmas  \\\n",
       "0  [ , marriage, 13, 18, year, old, bourbon, a, m...   \n",
       "1  [ , legendary, bowmore, mid-60, bit, equal, al...   \n",
       "2  [ , bottling, celebrate, master, distiller, pa...   \n",
       "3  [ , impress, whisky, evolve, incredibly, compl...   \n",
       "4  [ , caramel, laden, fruit, bouquet, follow, un...   \n",
       "\n",
       "                                 lammatized_sentence    string_category  \n",
       "0     marriage 13 18 year old bourbon a mature el...  Bourbon/Tennessee  \n",
       "1     legendary bowmore mid-60 bit equal all shar...             Scotch  \n",
       "2     bottling celebrate master distiller parker ...  Bourbon/Tennessee  \n",
       "3     impress whisky evolve incredibly complex on...             Scotch  \n",
       "4     caramel laden fruit bouquet follow unending...  Bourbon/Tennessee  "
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "cagtegory_mapper = {1:    'Scotch',\n",
    "2:    'Bourbon/Tennessee',\n",
    "3:    'Craft Whiskey',\n",
    "4:    'Canadian',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['string_category'] = train.replace({\"category\": cagtegory_mapper})['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmas_sentence(data, series):\n",
    "    tokenizer = Tokenizer(nlp.vocab)\n",
    "    STOP_WORDS = nlp.Defaults.stop_words.union([' ','I', 'i', 'and', 'it', \"it's\", 'it.', 'the', 'this','of', 'is', 'my', 'but'])\n",
    "    tokens = []\n",
    "\n",
    "    \"\"\" Make them tokens \"\"\"\n",
    "    for doc in tokenizer.pipe(data[series], batch_size=500):\n",
    "        doc_tokens = []\n",
    "        for token in doc[1:]:\n",
    "            if token.text not in STOP_WORDS:\n",
    "                doc_tokens.append(token.text.lower())\n",
    "        tokens.append(doc_tokens)\n",
    "        \n",
    "            \n",
    "    data['tokens'] = tokens\n",
    "    list_string = []\n",
    "    for i in data['tokens']:\n",
    "        stringe = \"\"\n",
    "        for string in i:\n",
    "            stringe = stringe + ' ' + string\n",
    "        list_string.append(stringe)\n",
    "    data['tokenized_sentences'] = list_string\n",
    "    \n",
    "    def get_lemmas(text):\n",
    "\n",
    "        lemmas = []\n",
    "\n",
    "        doc = nlp(text)\n",
    "\n",
    "        # Something goes here :P\n",
    "        for token in doc: \n",
    "            if ((token.is_stop == False) and (token.is_punct == False)) and (token.pos_!= 'PRON'):\n",
    "                lemmas.append(token.lemma_)\n",
    "\n",
    "        return lemmas\n",
    "\n",
    "    data['lemmas'] = data['tokenized_sentences'].apply(get_lemmas)\n",
    "    \n",
    "    list_string = []\n",
    "    for i in data['lemmas']:\n",
    "        stringe = \"\"\n",
    "        for string in i:\n",
    "            stringe = stringe + ' ' + string\n",
    "        list_string.append(stringe)\n",
    "        \n",
    "    data['lammatized_sentence'] = list_string\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = lemmas_sentence(test, 'description')\n",
    "train = lemmas_sentence(train, 'description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmas_sentence(data, series):\n",
    "    \n",
    "    def get_lemmas(text):\n",
    "\n",
    "        lemmas = []\n",
    "\n",
    "        doc = nlp(text)\n",
    "\n",
    "        # Something goes here :P\n",
    "        for token in doc: \n",
    "            if ((token.is_stop == False) and (token.is_punct == False)) and (token.pos_!= 'PRON'):\n",
    "                lemmas.append(token.lemma_)\n",
    "\n",
    "        return lemmas\n",
    "\n",
    "    data['lemmas'] = data[series].apply(get_lemmas)\n",
    "    \n",
    "    list_string = []\n",
    "    for i in data['lemmas']:\n",
    "        stringe = \"\"\n",
    "        for string in i:\n",
    "            stringe = stringe + ' ' + string\n",
    "        list_string.append(stringe)\n",
    "        \n",
    "    data['lammatized_author'] = list_string\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = lemmas_sentence(testing, 'author')\n",
    "train = lemmas_sentence(train, 'author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     id                author  \\\n",
       " 0   955          Fred Minnick   \n",
       " 1  3532            Lew Bryson   \n",
       " 2  1390  Davin de Kergommeaux   \n",
       " 3  1024           Gavin Smith   \n",
       " 4  1902           Gavin Smith   \n",
       " \n",
       "                                          description  price  ratingValue  \\\n",
       " 0  Think carnival aromas—the good ones, anyway—me...   36.0           90   \n",
       " 1  A blend of three bourbons, between 6 and 12 ye...   90.0           82   \n",
       " 2  The nose is focused on cereal, hints of fresh ...   48.0           89   \n",
       " 3  Swiss-based Chapter 7 released this 19 year ol...  180.0           90   \n",
       " 4  Valkyrie replaces the current Dark Origins exp...   71.0           87   \n",
       " \n",
       "    pert_alcohol             tokens tokenized_sentences  \\\n",
       " 0          50.0          [minnick]             minnick   \n",
       " 1          49.3           [bryson]              bryson   \n",
       " 2          45.0  [de, kergommeaux]      de kergommeaux   \n",
       " 3          55.8            [smith]               smith   \n",
       " 4          45.9            [smith]               smith   \n",
       " \n",
       "                      lemmas  \\\n",
       " 0           [fred, minnick]   \n",
       " 1             [lew, bryson]   \n",
       " 2  [davin, de, kergommeaux]   \n",
       " 3            [gavin, smith]   \n",
       " 4            [gavin, smith]   \n",
       " \n",
       "                                  lammatized_sentence      lammatized_author  \n",
       " 0     carnival aroma the good one anyway meeting ...           fred minnick  \n",
       " 1     blend bourbon 6 12 year old rye wheat nothi...             lew bryson  \n",
       " 2     nose focus cereal hint fresh ripe cherry co...   davin de kergommeaux  \n",
       " 3     chapter 7 release 19 year old single malt m...            gavin smith  \n",
       " 4     replace current dark origin expression matu...            gavin smith  ,\n",
       "    id        author                                        description  \\\n",
       " 0   1  John Hansell  A marriage of 13 and 18 year old bourbons. A m...   \n",
       " 1   2    Dave Broom  There have been some legendary Bowmores from t...   \n",
       " 2   3  John Hansell  This bottling celebrates master distiller Park...   \n",
       " 3   4  John Hansell  What impresses me most is how this whisky evol...   \n",
       " 4   9  Fred Minnick  A caramel-laden fruit bouquet, followed by une...   \n",
       " \n",
       "      price  ratingValue  pert_alcohol  category  \\\n",
       " 0     85.0           97         51.50       2.0   \n",
       " 1  13500.0           97         42.90       1.0   \n",
       " 2    150.0           97         50.00       2.0   \n",
       " 3   4500.0           97         40.50       1.0   \n",
       " 4    150.0           96         54.49       2.0   \n",
       " \n",
       "                                               tokens  \\\n",
       " 0  [marriage, 13, 18, year, old, bourbons., a, ma...   \n",
       " 1  [legendary, bowmores, mid-60s, bit, equal., al...   \n",
       " 2  [bottling, celebrates, master, distiller, park...   \n",
       " 3  [impresses, whisky, evolves;, incredibly, comp...   \n",
       " 4  [caramel-laden, fruit, bouquet,, followed, une...   \n",
       " \n",
       "                                  tokenized_sentences           lemmas  \\\n",
       " 0   marriage 13 18 year old bourbons. a mature el...  [john, hansell]   \n",
       " 1   legendary bowmores mid-60s bit equal. all sha...    [dave, broom]   \n",
       " 2   bottling celebrates master distiller parker b...  [john, hansell]   \n",
       " 3   impresses whisky evolves; incredibly complex....  [john, hansell]   \n",
       " 4   caramel-laden fruit bouquet, followed unendin...  [fred, minnick]   \n",
       " \n",
       "                                  lammatized_sentence    string_category  \\\n",
       " 0     marriage 13 18 year old bourbon a mature el...  Bourbon/Tennessee   \n",
       " 1     legendary bowmore mid-60 bit equal all shar...             Scotch   \n",
       " 2     bottling celebrate master distiller parker ...  Bourbon/Tennessee   \n",
       " 3     impress whisky evolve incredibly complex on...             Scotch   \n",
       " 4     caramel laden fruit bouquet follow unending...  Bourbon/Tennessee   \n",
       " \n",
       "   lammatized_author  \n",
       " 0      john hansell  \n",
       " 1        dave broom  \n",
       " 2      john hansell  \n",
       " 3      john hansell  \n",
       " 4      fred minnick  )"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing.head(), train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = nlp.Defaults.stop_words.union([' ','I', 'i', 'and', 'it', \"it's\", 'it.', 'the', 'this','of', 'is', 'my', 'but'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer Pipe\n",
    "\n",
    "tokens = []\n",
    "\n",
    "\"\"\" Make them tokens \"\"\"\n",
    "for doc in tokenizer.pipe(train['description'], batch_size=500):\n",
    "    doc_tokens = []\n",
    "    for token in doc[1:]:\n",
    "        if token.text not in STOP_WORDS:\n",
    "            doc_tokens.append(token.text.lower())\n",
    "    tokens.append(doc_tokens)\n",
    "        \n",
    "            \n",
    "train['tokens'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_string = []\n",
    "for i in train['tokens']:\n",
    "    stringe = \"\"\n",
    "    for string in i:\n",
    "        stringe = stringe + ' ' + string\n",
    "    list_string.append(stringe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tokenized_sentences'] = list_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemmas(text):\n",
    "\n",
    "    lemmas = []\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Something goes here :P\n",
    "    for token in doc: \n",
    "        if ((token.is_stop == False) and (token.is_punct == False)) and (token.pos_!= 'PRON'):\n",
    "            lemmas.append(token.lemma_)\n",
    "    \n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['lemmas'] = train['tokenized_sentences'].apply(get_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_string = []\n",
    "for i in train['lemmas']:\n",
    "    stringe = \"\"\n",
    "    for string in i:\n",
    "        stringe = stringe + ' ' + string\n",
    "    list_string.append(stringe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['lammatized_sentence'] = list_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>pert_alcohol</th>\n",
       "      <th>category</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokenized_sentences</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>lammatized_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John Hansell</td>\n",
       "      <td>A marriage of 13 and 18 year old bourbons. A m...</td>\n",
       "      <td>85.0</td>\n",
       "      <td>97</td>\n",
       "      <td>51.50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[marriage, 13, 18, year, old, bourbons., a, ma...</td>\n",
       "      <td>marriage 13 18 year old bourbons. a mature el...</td>\n",
       "      <td>[ , marriage, 13, 18, year, old, bourbon, a, m...</td>\n",
       "      <td>marriage 13 18 year old bourbon a mature el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Dave Broom</td>\n",
       "      <td>There have been some legendary Bowmores from t...</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>97</td>\n",
       "      <td>42.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[legendary, bowmores, mid-60s, bit, equal., al...</td>\n",
       "      <td>legendary bowmores mid-60s bit equal. all sha...</td>\n",
       "      <td>[ , legendary, bowmore, mid-60, bit, equal, al...</td>\n",
       "      <td>legendary bowmore mid-60 bit equal all shar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>John Hansell</td>\n",
       "      <td>This bottling celebrates master distiller Park...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>97</td>\n",
       "      <td>50.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[bottling, celebrates, master, distiller, park...</td>\n",
       "      <td>bottling celebrates master distiller parker b...</td>\n",
       "      <td>[ , bottling, celebrate, master, distiller, pa...</td>\n",
       "      <td>bottling celebrate master distiller parker ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>John Hansell</td>\n",
       "      <td>What impresses me most is how this whisky evol...</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>97</td>\n",
       "      <td>40.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[impresses, whisky, evolves;, incredibly, comp...</td>\n",
       "      <td>impresses whisky evolves; incredibly complex....</td>\n",
       "      <td>[ , impress, whisky, evolve, incredibly, compl...</td>\n",
       "      <td>impress whisky evolve incredibly complex on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>Fred Minnick</td>\n",
       "      <td>A caramel-laden fruit bouquet, followed by une...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>96</td>\n",
       "      <td>54.49</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[caramel-laden, fruit, bouquet,, followed, une...</td>\n",
       "      <td>caramel-laden fruit bouquet, followed unendin...</td>\n",
       "      <td>[ , caramel, laden, fruit, bouquet, follow, un...</td>\n",
       "      <td>caramel laden fruit bouquet follow unending...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        author                                        description  \\\n",
       "0   1  John Hansell  A marriage of 13 and 18 year old bourbons. A m...   \n",
       "1   2    Dave Broom  There have been some legendary Bowmores from t...   \n",
       "2   3  John Hansell  This bottling celebrates master distiller Park...   \n",
       "3   4  John Hansell  What impresses me most is how this whisky evol...   \n",
       "5   9  Fred Minnick  A caramel-laden fruit bouquet, followed by une...   \n",
       "\n",
       "     price  ratingValue  pert_alcohol  category  \\\n",
       "0     85.0           97         51.50       2.0   \n",
       "1  13500.0           97         42.90       1.0   \n",
       "2    150.0           97         50.00       2.0   \n",
       "3   4500.0           97         40.50       1.0   \n",
       "5    150.0           96         54.49       2.0   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [marriage, 13, 18, year, old, bourbons., a, ma...   \n",
       "1  [legendary, bowmores, mid-60s, bit, equal., al...   \n",
       "2  [bottling, celebrates, master, distiller, park...   \n",
       "3  [impresses, whisky, evolves;, incredibly, comp...   \n",
       "5  [caramel-laden, fruit, bouquet,, followed, une...   \n",
       "\n",
       "                                 tokenized_sentences  \\\n",
       "0   marriage 13 18 year old bourbons. a mature el...   \n",
       "1   legendary bowmores mid-60s bit equal. all sha...   \n",
       "2   bottling celebrates master distiller parker b...   \n",
       "3   impresses whisky evolves; incredibly complex....   \n",
       "5   caramel-laden fruit bouquet, followed unendin...   \n",
       "\n",
       "                                              lemmas  \\\n",
       "0  [ , marriage, 13, 18, year, old, bourbon, a, m...   \n",
       "1  [ , legendary, bowmore, mid-60, bit, equal, al...   \n",
       "2  [ , bottling, celebrate, master, distiller, pa...   \n",
       "3  [ , impress, whisky, evolve, incredibly, compl...   \n",
       "5  [ , caramel, laden, fruit, bouquet, follow, un...   \n",
       "\n",
       "                                 lammatized_sentence  \n",
       "0     marriage 13 18 year old bourbon a mature el...  \n",
       "1     legendary bowmore mid-60 bit equal all shar...  \n",
       "2     bottling celebrate master distiller parker ...  \n",
       "3     impress whisky evolve incredibly complex on...  \n",
       "5     caramel laden fruit bouquet follow unending...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'string_category'\n",
    "features = ['lammatized_sentence', 'price', 'ratingValue', 'pert_alcohol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = pd.DataFrame(train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2586, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     0\n",
       "author                 0\n",
       "description            0\n",
       "price                  0\n",
       "ratingValue            0\n",
       "pert_alcohol           0\n",
       "category               0\n",
       "tokens                 0\n",
       "tokenized_sentences    0\n",
       "lemmas                 0\n",
       "lammatized_sentence    0\n",
       "string_category        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2586,)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[target].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GridSearchCV(GridSearchCV):\n",
    "\n",
    "#   def fit(self, *args, **kwargs):\n",
    "#     return super().fit(*args, eval_set=eval_set, eval_metric='rmse', \n",
    "#           early_stopping_rounds=50, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model = XGBRegressor(n_estimators=5000, n_jobs=-1, max_depth=7)\n",
    "# model.fit(X_train_encoded, y_train['outcome'], \n",
    "#           eval_set=eval_set, eval_metric='auc', early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(train, train_target, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2068, 11), (2068, 1))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_set = [(X_test, y_train), \n",
    "#             (X_test, y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class XGRegressorEval(XGBRegressor):\n",
    "#   def fit(self, *args, **kwargs):\n",
    "#     return super().fit(*args, eval_set=eval_set, eval_metric='rmse', \n",
    "#           early_stopping_rounds=10, **kwargs)\n",
    "    \n",
    "# pipeline = make_pipeline(ce.OrdinalEncoder(), XGRegressorEval(n_estimators=1000, n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create Pipeline\n",
    "\n",
    "vect = TfidfVectorizer(stop_words = 'english')\n",
    "sgdc = SGDClassifier()\n",
    "\n",
    "pipe = Pipeline([('vect', vect), ('clf', sgdc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mhdal\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mhdal\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...m_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(train['lammatized_sentence'], train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 27 candidates, totalling 189 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 189 out of 189 | elapsed:   17.0s finished\n",
      "C:\\Users\\mhdal\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mhdal\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=7, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...m_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'vect__max_df': (0.5, 0.75, 1.0), 'vect__max_features': (100, 500, 1000), 'clf__max_iter': (20, 10, 1000)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__max_features': (100, 500, 1000),\n",
    "    'clf__max_iter':(20, 10, 1000)\n",
    "}\n",
    "grid_search = GridSearchCV(pipe,parameters, cv=7, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(train['lammatized_sentence'], train_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mhdal\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\pipeline.py:267: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n",
      "C:\\Users\\mhdal\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\neighbors\\base.py:217: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 27 candidates, totalling 189 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 189 out of 189 | elapsed:   21.3s finished\n",
      "C:\\Users\\mhdal\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\pipeline.py:267: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n",
      "C:\\Users\\mhdal\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\neighbors\\base.py:217: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=7, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...ki',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform'))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'vect__max_df': (0.5, 0.75, 1.0), 'vect__max_features': (100, 500, 1000), 'clf__leaf_size': (30, 50, 100)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "vect = TfidfVectorizer(stop_words = 'english')\n",
    "# Fit on TF-IDF Vectors\n",
    "nn  = KNeighborsClassifier( n_neighbors=5, algorithm='ball_tree')\n",
    "pipe_nn = Pipeline([('vect', vect), ('clf', nn)])\n",
    "pipe_nn.fit(train['lammatized_sentence'], train_target )\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.2, 0.75, 1.0),\n",
    "    'vect__max_features': (100, 500, 1000),\n",
    "    'clf__leaf_size':(30, 50, 100)\n",
    "}\n",
    "grid_search = GridSearchCV(pipe_nn, parameters, cv=7, n_jobs=-1, verbose=1, scoring='accuracy')\n",
    "grid_search.fit(train['lammatized_sentence'], train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapper = {'Scotch': 1,\n",
    "'Bourbon/Tennessee': 2,\n",
    "'Craft Whiskey': 3,\n",
    "'Canadian': 4}\n",
    "y_pred = [category_mapper[letter] for letter in grid_search.predict(testing['lammatized_sentence'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.score(pgrid_search.predict(testing['lammatized_sentence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Scotch': 1, 'Bourbon/Tennessee': 2, 'Craft Whiskey': 3, 'Canadian': 4}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [category_mapper[letter] for letter in grid_search.predict(testing['lammatized_sentence'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submission3 = pd.DataFrame({'id':testing['id'],'category':y_pred})\n",
    "submission3['category'] = submission3['category'].astype(int)\n",
    "filename = 'kaggle submission 3.csv'\n",
    "\n",
    "submission.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.9, max_features=None, min_df=0.05,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=Tru...m_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(train['lammatized_sentence'], train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 6)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':test['id'],'category':y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['category'] = submission['category'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'kaggle submission 1.csv'\n",
    "\n",
    "submission.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['category'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mhdal\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mhdal\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.9, max_features=None, min_df=0.05,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=Tru...m_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(train['description'], train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(test['description'])\n",
    "submission2 = pd.DataFrame({'id':test['id'],'category':y_pred})\n",
    "submission2['category'] = submission2['category'].astype(int)\n",
    "filename = 'kaggle submission 2.csv'\n",
    "\n",
    "submission.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RangeIndex(start=0, stop=2586, step=1),\n",
       " RangeIndex(start=0, stop=2586, step=1),\n",
       " Int64Index([   0,    1,    2,    3,    5,    6,    7,    8,   10,   11,\n",
       "             ...\n",
       "             2864, 2865, 2866, 2867, 2868, 2869, 2870, 2871, 2872, 2873],\n",
       "            dtype='int64', length=2586),\n",
       " (2586, 25),\n",
       " (2586, 1))"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sparse, columns=sparse_columns).index, pd.DataFrame(sparce_author, columns=author_colums).index, train.index, sparce_author.shape, train_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2586, 7330)"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([pd.DataFrame(sparse, columns=sparse_columns), pd.DataFrame(sparce_author, columns=author_colums)], axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2586, 12)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words = 'english')\n",
    "sparse = vect.fit_transform(train['lammatized_sentence']).todense()\n",
    "sparse_columns= vect.get_feature_names()\n",
    "vect = TfidfVectorizer(stop_words = 'english')\n",
    "sparce_author = vect.fit_transform(train['lammatized_author']).todense()\n",
    "author_colums = vect.get_feature_names()\n",
    "dtm = pd.concat([pd.DataFrame(sparse, columns=sparse_columns), pd.DataFrame(sparce_author, columns=author_colums)], axis=1)\n",
    "dtm2 = pd.concat([dtm, train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['00', '000', '005', '011', '035', '070', '076', '08', '080', '09',\n",
       "       ...\n",
       "       'price', 'ratingValue', 'pert_alcohol', 'category', 'tokens',\n",
       "       'tokenized_sentences', 'lemmas', 'lammatized_sentence',\n",
       "       'string_category', 'lammatized_author'],\n",
       "      dtype='object', length=7343)"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2586, 13), (2586, 7343))"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, dtm2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = author_colums + sparse_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.extend(['price', 'ratingValue', 'pert_alcohol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pert_alcohol'"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words = 'english')\n",
    "sparce_author = vect.fit_transform(testing['lammatized_author']).todense()\n",
    "author_colums = vect.get_feature_names()\n",
    "vect = TfidfVectorizer(stop_words = 'english')\n",
    "sparce = vect.fit_transform(testing['lammatized_sentence']).todense()\n",
    "sparce_colums = vect.get_feature_names()\n",
    "testing2 = pd.concat([pd.DataFrame(sparse, columns=sparse_columns), pd.DataFrame(sparce_author, columns=author_colums)], axis=1)\n",
    "testing3 = pd.concat([testing2, testing], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=2586, step=1)"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=2586, step=1)"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing3.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdc = SGDClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "00     0\n",
       "000    0\n",
       "005    0\n",
       "011    0\n",
       "035    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm2.isnull().sum().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mhdal\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\mhdal\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
       "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgdc.fit(dtm2[features], train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pop() takes at most 1 argument (3 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-501-6b09690dec71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'polonski'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'skiver'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'susannah'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: pop() takes at most 1 argument (3 given)"
     ]
    }
   ],
   "source": [
    "features.pop('polonski', 'skiver', 'susannah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-505-5c4e8d17f86e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcategory_mapper\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mletter\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mletter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msgdc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtesting3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'polonski'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'skiver'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'susannah'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    279\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m         \"\"\"\n\u001b[1;32m--> 281\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    255\u001b[0m                                  \"yet\" % {'name': type(self).__name__})\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 573\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "y_pred = [category_mapper[letter] for letter in sgdc.predict(testing3[[x for x in features if x not in ['polonski', 'skiver', 'susannah']]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testing['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array length 2586 does not match index length 288",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-443-f180ef0437f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msubmission4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'category'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msubmission4\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'category'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubmission2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'category'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'kaggle submission 4.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msubmission\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    390\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[0;32m    391\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    326\u001b[0m                            \u001b[1;34m'length {idx_len}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m                            .format(length=lengths[0], idx_len=len(index)))\n\u001b[1;32m--> 328\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mibase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: array length 2586 does not match index length 288"
     ]
    }
   ],
   "source": [
    "submission4 = pd.DataFrame({'id':test['id'],'category':y_pred})\n",
    "submission4['category'] = submission2['category'].astype(int)\n",
    "filename = 'kaggle submission 4.csv'\n",
    "\n",
    "submission.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 1 candidates, totalling 7 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\mhdal\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\mhdal\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\mhdal\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\mhdal\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\mhdal\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\mhdal\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 528, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\mhdal\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\", line 743, in fit\n    sample_weight=sample_weight)\n  File \"C:\\Users\\mhdal\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\", line 570, in _fit\n    accept_large_sparse=False)\n  File \"C:\\Users\\mhdal\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 756, in check_X_y\n    estimator=estimator)\n  File \"C:\\Users\\mhdal\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 527, in check_array\n    array = np.asarray(array, dtype=dtype, order=order)\n  File \"C:\\Users\\mhdal\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\numpy\\core\\numeric.py\", line 501, in asarray\n    return array(a, dtype, copy=False, order=order)\n  File \"C:\\Users\\mhdal\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\pandas\\core\\generic.py\", line 1905, in __array__\n    return com.values_from_object(self)\n  File \"pandas\\_libs\\lib.pyx\", line 84, in pandas._libs.lib.values_from_object\n  File \"C:\\Users\\mhdal\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\pandas\\core\\generic.py\", line 5380, in get_values\n    return self.values\n  File \"C:\\Users\\mhdal\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\pandas\\core\\generic.py\", line 5325, in values\n    return self._data.as_array(transpose=self._AXIS_REVERSED)\n  File \"C:\\Users\\mhdal\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 768, in as_array\n    arr = mgr._interleave()\n  File \"C:\\Users\\mhdal\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 787, in _interleave\n    result = np.empty(self.shape, dtype=dtype)\nMemoryError\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-420-5640b1753455>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m }\n\u001b[0;32m      4\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msgdc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtm2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    720\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    709\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 711\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    931\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lambda-nlp\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lambda-nlp\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\lambda-nlp\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'penalty': ['l2']\n",
    "}\n",
    "grid_search = GridSearchCV(sgdc, parameters, cv=7, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(dtm2[features], train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lambda-nlp]",
   "language": "python",
   "name": "conda-env-lambda-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
