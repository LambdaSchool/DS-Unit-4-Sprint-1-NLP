{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 4, Sprint 1, Module 3*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification (Assignment)\n",
    "\n",
    "This notebook is for you to practice skills during lecture.\n",
    "\n",
    "Today's guided module project and assignment will be different. You already know how to do classification. You ready know how to extract features from documents. So? That means you're ready to combine and practice those skills in a kaggle competition. We we will open with a five minute sprint explaining the competition, and then give you 25 minutes to work. After those twenty five minutes are up, I will give a 5-minute demo an NLP technique that will help you with document classification (*and **maybe** the competition*).\n",
    "\n",
    "Today's all about having fun and practicing your skills.\n",
    "\n",
    "## Sections\n",
    "* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n",
    "* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n",
    "* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy\n",
    "* <a href=\"#p4\">Part 4</a>: Post Lecture Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Feature Extraction & Classification Pipelines (Learn)\n",
    "<a id=\"p1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along \n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model (try using the pipe method I just demoed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Competition Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# You may need to change the path\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "minority = train[train['ratingCategory'] == 2]\n",
    "majority = train[train['ratingCategory'] != 2]\n",
    "\n",
    "df_minority_upsampled = resample(minority,\n",
    "                                 replace=True,\n",
    "                                 n_samples=majority.shape[0]\n",
    "                                )\n",
    "\n",
    "train = pd.concat([majority, df_minority_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1321</td>\n",
       "      <td>\\nSometimes, when whisky is batched, a few lef...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3861</td>\n",
       "      <td>\\nAn uncommon exclusive bottling of a 6 year o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655</td>\n",
       "      <td>\\nThis release is a port version of Amrut’s In...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>555</td>\n",
       "      <td>\\nThis 41 year old single cask was aged in a s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1965</td>\n",
       "      <td>\\nQuite herbal on the nose, with aromas of dri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3190</td>\n",
       "      <td>\\nCooley produced some great Irish single malt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3736</td>\n",
       "      <td>\\nThis year’s Ardbeg Day bottling is named in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2643</td>\n",
       "      <td>\\nAs part of a rebranding of the entire Talisk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4817</td>\n",
       "      <td>\\nMacQueen’s has an impressive range of age st...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4528</td>\n",
       "      <td>\\nFull gold color. Layers of citrus fruit on t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>418</td>\n",
       "      <td>\\nThis has the classic sweetish, oily, floral,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4495</td>\n",
       "      <td>\\nFolklore tells of the Silkies, whose siren v...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>670</td>\n",
       "      <td>\\nA high-strength blend that takes no prisoner...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1554</td>\n",
       "      <td>\\nSweet and lightly smoky on the nose: toasted...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1663</td>\n",
       "      <td>\\nBunnahabhain has been marketing batches of p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2119</td>\n",
       "      <td>\\nVery fragrant. Spicy too, with notes of hone...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3901</td>\n",
       "      <td>\\nMore widely available than Buffalo Trace’s a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4486</td>\n",
       "      <td>\\nSomewhat forgotten, this table bourbon is ri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2189</td>\n",
       "      <td>\\nLike its Ledaig stablemate, this Tobermory i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2996</td>\n",
       "      <td>\\nThe official Fèis Ìle  2016 bottling. This i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                        description  ratingCategory\n",
       "0   1321  \\nSometimes, when whisky is batched, a few lef...               1\n",
       "1   3861  \\nAn uncommon exclusive bottling of a 6 year o...               0\n",
       "2    655  \\nThis release is a port version of Amrut’s In...               1\n",
       "3    555  \\nThis 41 year old single cask was aged in a s...               1\n",
       "4   1965  \\nQuite herbal on the nose, with aromas of dri...               1\n",
       "5   3190  \\nCooley produced some great Irish single malt...               1\n",
       "6   3736  \\nThis year’s Ardbeg Day bottling is named in ...               0\n",
       "7   2643  \\nAs part of a rebranding of the entire Talisk...               1\n",
       "8   4817  \\nMacQueen’s has an impressive range of age st...               0\n",
       "9   4528  \\nFull gold color. Layers of citrus fruit on t...               0\n",
       "10   418  \\nThis has the classic sweetish, oily, floral,...               1\n",
       "11  4495  \\nFolklore tells of the Silkies, whose siren v...               0\n",
       "12   670  \\nA high-strength blend that takes no prisoner...               1\n",
       "13  1554  \\nSweet and lightly smoky on the nose: toasted...               1\n",
       "14  1663  \\nBunnahabhain has been marketing batches of p...               1\n",
       "15  2119  \\nVery fragrant. Spicy too, with notes of hone...               1\n",
       "16  3901  \\nMore widely available than Buffalo Trace’s a...               0\n",
       "17  4486  \\nSomewhat forgotten, this table bourbon is ri...               0\n",
       "18  2189  \\nLike its Ledaig stablemate, this Tobermory i...               1\n",
       "19  2996  \\nThe official Fèis Ìle  2016 bottling. This i...               1"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>\\nStyle: Speyside single malt scotch Color: Wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>\\nVery bright and lively, with a nice balance ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>\\nA new oloroso-forward Chivas positioned to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>\\nAged in bourbon casks and then enhanced in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>\\nThere is a freshness to the wood on the nose...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                        description\n",
       "0  3461  \\nStyle: Speyside single malt scotch Color: Wa...\n",
       "1  2604  \\nVery bright and lively, with a nice balance ...\n",
       "2  3341  \\nA new oloroso-forward Chivas positioned to s...\n",
       "3  3764  \\nAged in bourbon casks and then enhanced in R...\n",
       "4  2306  \\nThere is a freshness to the wood on the nose..."
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSometimes, when whisky is batched, a few leftover barrels are returned to the warehouse. Canadian Club recently pulled and vatted several of these from the 1970s. Acetone, Granny Smith apples, and fresh-cut white cedar showcase this long age. Complex and spicy, yet reserved, this dram is ripe with strawberries, canned pears, cloves, pepper, and faint flowers, then slightly pulling oak tannins. Distinct, elegant, and remarkably vibrant, this ancient Canadian Club is anything but tired. (Australia only)\\xa0A$133'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['description'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1911118d0>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(x=train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    4022\n",
       "1    2881\n",
       "0    1141\n",
       "Name: ratingCategory, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['ratingCategory'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['description'] = train['description'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['description'] = test['description'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sometimes, when whisky is batched, a few leftover barrels are returned to the warehouse. Canadian Club recently pulled and vatted several of these from the 1970s. Acetone, Granny Smith apples, and fresh-cut white cedar showcase this long age. Complex and spicy, yet reserved, this dram is ripe with strawberries, canned pears, cloves, pepper, and faint flowers, then slightly pulling oak tannins. Distinct, elegant, and remarkably vibrant, this ancient Canadian Club is anything but tired. (Australia only)\\xa0A$133'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['description'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Style: Speyside single malt scotch Color: Walnut Aroma: Richly sherried and thick, with notes of nuts and toffee. Wood resins contribute spice and variety. Fruitcake at Christmas. Palate: Thick, chewy in texture, and quite ripe. Again the fruitcake. Very deep and mature with some underlying maltiness. Dry, spicy, oak notes fight off all that sherry and add balance and complexity. Long, soothing finish.'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['description'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "pipe = Pipeline([('vect', vect), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train['ratingCategory']\n",
    "\n",
    "features = train['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=4)]: Done 160 out of 160 | elapsed:   42.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words='english',\n",
       "                                                        strip...\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=4,\n",
       "             param_grid={'clf__max_depth': (15, 20),\n",
       "                         'clf__n_estimators': (5, 10),\n",
       "                         'vect__max_df': (0.75, 1.0),\n",
       "                         'vect__max_features': (500, 1000),\n",
       "                         'vect__min_df': (0.02, 0.05)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': ( 0.75, 1.0),\n",
    "    'vect__min_df': (.02, .05),\n",
    "    'vect__max_features': (500,1000),\n",
    "    'clf__n_estimators':(5, 10,),\n",
    "    'clf__max_depth':(15,20)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=4, verbose=1)\n",
    "grid_search.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7198456994251136"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File\n",
    "*Note:* In a typical Kaggle competition, you are only allowed two submissions a day, so you only submit if you feel you cannot achieve higher test accuracy. For this competition the max daily submissions are capped at **20**. Submit for each demo and for your assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = grid_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               1\n",
       "2  3341               1\n",
       "3  3764               1\n",
       "4  2306               1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "subNumber = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You're trying to achieve a minimum of 70% Accuracy on your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Indexing (Learn)\n",
    "<a id=\"p2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "4. Make a submission to Kaggle \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "svd = TruncatedSVD(n_components=100, # Just here for demo. \n",
    "                   algorithm='randomized',\n",
    "                   n_iter=10)\n",
    "\n",
    "\n",
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('lsi',\n",
      "                 Pipeline(memory=None,\n",
      "                          steps=[('vect',\n",
      "                                  TfidfVectorizer(analyzer='word', binary=False,\n",
      "                                                  decode_error='strict',\n",
      "                                                  dtype=<class 'numpy.float64'>,\n",
      "                                                  encoding='utf-8',\n",
      "                                                  input='content',\n",
      "                                                  lowercase=True, max_df=1.0,\n",
      "                                                  max_features=None, min_df=1,\n",
      "                                                  ngram_range=(1, 1), norm='l2',\n",
      "                                                  preprocessor=None,\n",
      "                                                  smooth_idf=True,\n",
      "                                                  stop_words='english',\n",
      "                                                  strip_accents=...\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=None, max_features='auto',\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=1, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('lsi',\n",
       "                                        Pipeline(memory=None,\n",
       "                                                 steps=[('vect',\n",
       "                                                         TfidfVectorizer(analyzer='word',\n",
       "                                                                         binary=False,\n",
       "                                                                         decode_error='strict',\n",
       "                                                                         dtype=<class 'numpy.float64'>,\n",
       "                                                                         encoding='utf-8',\n",
       "                                                                         input='content',\n",
       "                                                                         lowercase=True,\n",
       "                                                                         max_df=1.0,\n",
       "                                                                         max_features=None,\n",
       "                                                                         min_df=1,\n",
       "                                                                         ngram_range=(1,\n",
       "                                                                                      1),\n",
       "                                                                         norm='l2',\n",
       "                                                                         preprocessor=None,\n",
       "                                                                         smooth_...\n",
       "                                                               n_estimators=100,\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'clf__min_samples_leaf': [1, 2],\n",
       "                         'clf__n_estimators': [5, 10, 20],\n",
       "                         'lsi__svd__n_components': [10, 100, 250],\n",
       "                         'lsi__vect__max_df': [0.9, 0.95, 1.0]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'lsi__svd__n_components': [10,100,250],\n",
    "    'lsi__vect__max_df':[.9, .95, 1.0],\n",
    "    'clf__n_estimators':[5,10,20],\n",
    "    #'clf__min_samples_leaf':[1,2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7235152759364722"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = grid_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               1\n",
       "2  3341               1\n",
       "3  3764               1\n",
       "4  2306               1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "subNumber = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Continue to apply Latent Semantic Indexing (LSI) to various datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings with Spacy (Learn)\n",
    "<a id=\"p3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to your Dataset\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from scipy.stats import randint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue Word Embedding Work Here\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc = nlp(\"Two bananas in pyjamas\")\n",
    "#bananas_vector = doc.vector\n",
    "#print(len(bananas_vector))\n",
    "#print(bananas_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vectors(docs):\n",
    "    return [nlp(doc).vector for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_word_vectors(train['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X) == len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = get_word_vectors(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X, train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['ratingCategory'] = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['id', 'ratingCategory']].to_csv('testSolutionSubmission1.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying spacey, but in a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "pipe = Pipeline([('clf', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('clf',\n",
       "                                              RandomForestClassifier(bootstrap=True,\n",
       "                                                                     ccp_alpha=0.0,\n",
       "                                                                     class_weight=None,\n",
       "                                                                     criterion='gini',\n",
       "                                                                     max_depth=None,\n",
       "                                                                     max_features='auto',\n",
       "                                                                     max_leaf_nodes=None,\n",
       "                                                                     max_samples=None,\n",
       "                                                                     min_impurity_decrease=0.0,\n",
       "                                                                     min_impurity_split=None,\n",
       "                                                                     min_samples_leaf=1,\n",
       "                                                                     min_samples_split=2,\n",
       "                                                                     min_weight_fracti...\n",
       "                                                                     n_estimators=100,\n",
       "                                                                     n_jobs=None,\n",
       "                                                                     oob_score=False,\n",
       "                                                                     random_state=None,\n",
       "                                                                     verbose=0,\n",
       "                                                                     warm_start=False))],\n",
       "                                      verbose=False),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'clf__max_depth': (5, 10, 15, 20),\n",
       "                                        'clf__min_samples_leaf': (1, 2, 3),\n",
       "                                        'clf__n_estimators': (100, 200)},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    #'vect__max_df': ( 0.75, 1.0),\n",
    "    #'vect__min_df': (.02, .05),\n",
    "    #'vect__max_features': (500,1000),\n",
    "    #'clf__n_estimators':(5, 10,),\n",
    "    #'clf__max_depth':(15,20)\n",
    "    'clf__max_depth':(5,10,15,20),\n",
    "    'clf__min_samples_leaf':(1,2,3),\n",
    "    'clf__n_estimators':(100,200)\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = RandomizedSearchCV(pipe,parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.866732295638031"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0.8627544378789705\n",
    "## 0.8666086905435533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               1\n",
       "2  3341               1\n",
       "3  3764               1\n",
       "4  2306               1"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n",
    "4. Make a submission to Kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Lecture Assignment\n",
    "<a id=\"p4\"></a>\n",
    "\n",
    "Your primary assignment this afternoon is to achieve a minimum of 70% accuracy on the Kaggle competition. Once you have achieved 70% accuracy, please work on the following: \n",
    "\n",
    "1. Research \"Sentiment Analysis\". Provide answers in markdown to the following questions: \n",
    "    - What is \"Sentiment Analysis\"? \n",
    "    - Is Document Classification different than \"Sentiment Analysis\"? Provide evidence for your response\n",
    "    - How do create labeled sentiment data? Are those labels really sentiment?\n",
    "    - What are common applications of sentiment analysis?\n",
    "2. Research our why word embeddings worked better for the lecture notebook than on the whiskey competition.\n",
    "    - This [text classification documentation](https://developers.google.com/machine-learning/guides/text-classification/step-2-5) from Google might be of interest\n",
    "    - Neural Networks are becoming more popular for document classification. Why is that the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is \"Sentiment Analysis\"?\n",
    "\n",
    "Sentiment analysis takes source data (a review, for example) and extracts the sentiment of the user (positive, negative, neutral). It's possible to figure out sentiment for particular parts of a business, and use this information to get feedback on the business that would be impossible without this type of data analysis.\n",
    "\n",
    "One very important thing about sentiment analysis is that is takes in *unstructured* data, and then tags it with the type of sentiment. This means that meaning is ascribed where there was none before.\n",
    "\n",
    "\n",
    "\n",
    "# Is Document Classification different than \"Sentiment Analysis\"? Provide evidence for your response\n",
    "\n",
    "One answer: Document classificiation could do sentiment analysis on the whole document, whereas sentiment analysis could find different sentiments in different parts of a document.\n",
    "\n",
    "Another answer: document classification is objective, whereas sentiment analysis is subjective. Placing documents into classes is the goal of a machine learning model (and involves discrete classes), whereas sentiment analysis falls on a spectrum (78% positive, for example). \n",
    "\n",
    "\n",
    "# How do create labeled sentiment data? Are those labels really sentiment?\n",
    "\n",
    "One method would be to manually read the data and hand-apply a positive/negative label. This could be used to train a larger data set. This is just what your brain-computer thinks are the correct sentiment.\n",
    "\n",
    "Another way would be Bag of Words or Word2Vec that count the number of words that are postive vs. negative. These are decent models, but they don't contain the context of the words, just raw count. \n",
    "\n",
    "\n",
    "\n",
    "# What are common applications of sentiment analysis?\n",
    "\n",
    "• analyze social media sentiment in real time to handle PR crises\n",
    "• determine what aspects of a product people like based on Amazon reviews\n",
    "• analyze survey responses that are written comments, not just 1-10 ratings.\n",
    "• understand the overall sentiment towards a brand by scraping Twitter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
