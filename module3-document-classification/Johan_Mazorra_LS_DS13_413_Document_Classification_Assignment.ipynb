{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 4, Sprint 1, Module 3*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification (Assignment)\n",
    "\n",
    "This notebook is for you to practice skills during lecture.\n",
    "\n",
    "Today's guided module project and assignment will be different. You already know how to do classification. You ready know how to extract features from documents. So? That means you're ready to combine and practice those skills in a kaggle competition. We we will open with a five minute sprint explaining the competition, and then give you 25 minutes to work. After those twenty five minutes are up, I will give a 5-minute demo an NLP technique that will help you with document classification (*and **maybe** the competition*).\n",
    "\n",
    "Today's all about having fun and practicing your skills.\n",
    "\n",
    "## Sections\n",
    "* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n",
    "* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n",
    "* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy\n",
    "* <a href=\"#p4\">Part 4</a>: Post Lecture Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Feature Extraction & Classification Pipelines (Learn)\n",
    "<a id=\"p1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along \n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model (try using the pipe method I just demoed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Competition Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# You may need to change the path\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1321</td>\n",
       "      <td>\\nSometimes, when whisky is batched, a few lef...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3861</td>\n",
       "      <td>\\nAn uncommon exclusive bottling of a 6 year o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655</td>\n",
       "      <td>\\nThis release is a port version of Amrut’s In...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>555</td>\n",
       "      <td>\\nThis 41 year old single cask was aged in a s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1965</td>\n",
       "      <td>\\nQuite herbal on the nose, with aromas of dri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                        description  ratingCategory\n",
       "0  1321  \\nSometimes, when whisky is batched, a few lef...               1\n",
       "1  3861  \\nAn uncommon exclusive bottling of a 6 year o...               0\n",
       "2   655  \\nThis release is a port version of Amrut’s In...               1\n",
       "3   555  \\nThis 41 year old single cask was aged in a s...               1\n",
       "4  1965  \\nQuite herbal on the nose, with aromas of dri...               1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "minority = train[train['ratingCategory'] == 0]\n",
    "majority = train[train['ratingCategory'] == 1]\n",
    "df_minority_upsampled = resample(minority,\n",
    "                                 replace=True,\n",
    "                                 n_samples=majority.shape[0]\n",
    "                                )\n",
    "df_upsampled = pd.concat([majority, df_minority_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1321</td>\n",
       "      <td>\\nSometimes, when whisky is batched, a few lef...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655</td>\n",
       "      <td>\\nThis release is a port version of Amrut’s In...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>555</td>\n",
       "      <td>\\nThis 41 year old single cask was aged in a s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1965</td>\n",
       "      <td>\\nQuite herbal on the nose, with aromas of dri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3190</td>\n",
       "      <td>\\nCooley produced some great Irish single malt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                        description  ratingCategory\n",
       "0  1321  \\nSometimes, when whisky is batched, a few lef...               1\n",
       "2   655  \\nThis release is a port version of Amrut’s In...               1\n",
       "3   555  \\nThis 41 year old single cask was aged in a s...               1\n",
       "4  1965  \\nQuite herbal on the nose, with aromas of dri...               1\n",
       "5  3190  \\nCooley produced some great Irish single malt...               1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_upsampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1321</td>\n",
       "      <td>Sometimes, when whisky is batched, a few lefto...</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n, sometimes,, whisky, batched,, leftover, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3861</td>\n",
       "      <td>An uncommon exclusive bottling of a 6 year old...</td>\n",
       "      <td>0</td>\n",
       "      <td>[\\n, uncommon, exclusive, bottling, year, old,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655</td>\n",
       "      <td>This release is a port version of Amrut’s Inte...</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n, release, port, version, amrut’s, intermed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>555</td>\n",
       "      <td>This 41 year old single cask was aged in a she...</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n, year, old, single, cask, aged, sherry, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1965</td>\n",
       "      <td>Quite herbal on the nose, with aromas of dried...</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n, herbal, nose,, aromas, dried, tarragon,, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4082</th>\n",
       "      <td>3342</td>\n",
       "      <td>What lies beneath the surface of Dewar’s? Here...</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n, lies, beneath, surface, dewar’s?, here,, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4083</th>\n",
       "      <td>3130</td>\n",
       "      <td>After 6 to 7 years of maturation in bourbon ca...</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n, years, maturation, bourbon, casks,, spent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084</th>\n",
       "      <td>2811</td>\n",
       "      <td>Bright, delicate, and approachable. While not ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n, bright,, delicate,, approachable., showst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4085</th>\n",
       "      <td>478</td>\n",
       "      <td>I’m calling this the pitmaster’s dram: the nos...</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n, i’m, calling, pitmaster’s, dram:, nose, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4086</th>\n",
       "      <td>1209</td>\n",
       "      <td>Spicy sultanas, greengage plums, toffee, and n...</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n, spicy, sultanas,, greengage, plums,, toff...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4087 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                        description  ratingCategory  \\\n",
       "0     1321  Sometimes, when whisky is batched, a few lefto...               1   \n",
       "1     3861  An uncommon exclusive bottling of a 6 year old...               0   \n",
       "2      655  This release is a port version of Amrut’s Inte...               1   \n",
       "3      555  This 41 year old single cask was aged in a she...               1   \n",
       "4     1965  Quite herbal on the nose, with aromas of dried...               1   \n",
       "...    ...                                                ...             ...   \n",
       "4082  3342  What lies beneath the surface of Dewar’s? Here...               1   \n",
       "4083  3130  After 6 to 7 years of maturation in bourbon ca...               1   \n",
       "4084  2811  Bright, delicate, and approachable. While not ...               1   \n",
       "4085   478  I’m calling this the pitmaster’s dram: the nos...               1   \n",
       "4086  1209  Spicy sultanas, greengage plums, toffee, and n...               1   \n",
       "\n",
       "                                                 tokens  \n",
       "0     [\\n, sometimes,, whisky, batched,, leftover, b...  \n",
       "1     [\\n, uncommon, exclusive, bottling, year, old,...  \n",
       "2     [\\n, release, port, version, amrut’s, intermed...  \n",
       "3     [\\n, year, old, single, cask, aged, sherry, bu...  \n",
       "4     [\\n, herbal, nose,, aromas, dried, tarragon,, ...  \n",
       "...                                                 ...  \n",
       "4082  [\\n, lies, beneath, surface, dewar’s?, here,, ...  \n",
       "4083  [\\n, years, maturation, bourbon, casks,, spent...  \n",
       "4084  [\\n, bright,, delicate,, approachable., showst...  \n",
       "4085  [\\n, i’m, calling, pitmaster’s, dram:, nose, m...  \n",
       "4086  [\\n, spicy, sultanas,, greengage, plums,, toff...  \n",
       "\n",
       "[4087 rows x 4 columns]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def line_br_removal(df_upsampled):\n",
    "    df_upsampled['description'] = df_upsampled['description'].str.strip('\\n')\n",
    "    return df_upsampled\n",
    "\n",
    "line_br_removal(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "pipe = Pipeline([('vect', vect), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 8 candidates, totalling 56 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=5)]: Done  56 out of  56 | elapsed: 15.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=7, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words='english',\n",
       "                                                        strip...\n",
       "                                                               min_samples_leaf=1,\n",
       "                                                               min_samples_split=5,\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n_estimators=300,\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=42,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=5,\n",
       "             param_grid={'clf__max_depth': (5, 10, 15, 20),\n",
       "                         'vect__max_df': (0.75, 1.0)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': (0.75, 1.0),\n",
    "    'clf__max_depth':(5,10,15,20)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe,parameters, cv=7, n_jobs=5, verbose=1)\n",
    "grid_search.fit(train['description'], train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__max_depth': 20, 'vect__max_df': 1.0}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File\n",
    "*Note:* In a typical Kaggle competition, you are only allowed two submissions a day, so you only submit if you feel you cannot achieve higher test accuracy. For this competition the max daily submissions are capped at **20**. Submit for each demo and for your assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = grid_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               1\n",
       "2  3341               1\n",
       "3  3764               1\n",
       "4  2306               1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "subNumber = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'submission1.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You're trying to achieve a minimum of 70% Accuracy on your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Indexing (Learn)\n",
    "<a id=\"p2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "4. Make a submission to Kaggle \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=100,\n",
    "                   algorithm='randomized',\n",
    "                   n_iter=10)\n",
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "clf = RandomForestClassifier(n_estimators=100, \n",
    "                             random_state=20, \n",
    "                             max_features = 'sqrt',\n",
    "                             n_jobs=-1, verbose=1)\n",
    "params = { \n",
    "    'lsi__svd__n_components': stats.randint(90, 250),\n",
    "    'lsi__vect__max_df': stats.uniform(0.9, 1.0),\n",
    "    'clf__n_estimators': stats.randint(15, 20),\n",
    "    'clf__max_depth': (5, 10, 15, 20)\n",
    "}\n",
    "\n",
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 13.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('lsi',\n",
       "                                              Pipeline(memory=None,\n",
       "                                                       steps=[('vect',\n",
       "                                                               TfidfVectorizer(analyzer='word',\n",
       "                                                                               binary=False,\n",
       "                                                                               decode_error='strict',\n",
       "                                                                               dtype=<class 'numpy.float64'>,\n",
       "                                                                               encoding='utf-8',\n",
       "                                                                               input='content',\n",
       "                                                                               lowercase=True,\n",
       "                                                                               max_df=1.0,\n",
       "                                                                               max_features=None,\n",
       "                                                                               min_df=1,\n",
       "                                                                               ngram_range=(1,\n",
       "                                                                                            2),\n",
       "                                                                               norm='l2',\n",
       "                                                                               preprocessor=None,\n",
       "                                                                               s...\n",
       "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'clf__max_depth': (5, 10, 15, 20),\n",
       "                                        'lsi__svd__n_components': <scipy.stats._distn_infrastructure.rv_frozen object at 0x19811ab00>,\n",
       "                                        'lsi__vect__max_df': <scipy.stats._distn_infrastructure.rv_frozen object at 0x19811ae80>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=10)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(\n",
    "    pipe, params, cv=5, n_jobs=-1, verbose=10, random_state=42)\n",
    "random_search.fit(train['description'], train['ratingCategory']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__max_depth': 20,\n",
       " 'lsi__svd__n_components': 110,\n",
       " 'lsi__vect__max_df': 1.5174815096277166}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['analyzer', 'binary', 'decode_error', 'dtype', 'encoding', 'input', 'lowercase', 'max_df', 'max_features', 'min_df', 'ngram_range', 'norm', 'preprocessor', 'smooth_idf', 'stop_words', 'strip_accents', 'sublinear_tf', 'token_pattern', 'tokenizer', 'use_idf', 'vocabulary'])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def count(docs):\n",
    "    word_counts = Counter()\n",
    "    appears_in = Counter()\n",
    "        \n",
    "    total_docs = len(docs)\n",
    "\n",
    "    for doc in docs:\n",
    "        word_counts.update(doc)\n",
    "        appears_in.update(set(doc))\n",
    "\n",
    "    temp = zip(word_counts.keys(), word_counts.values())\n",
    "        \n",
    "    wc = pd.DataFrame(temp, columns = ['word', 'count'])\n",
    "\n",
    "    wc['rank'] = wc['count'].rank(method='first', ascending=False)\n",
    "    total = wc['count'].sum()\n",
    "\n",
    "    wc['pct_total'] = wc['count'].apply(lambda x: x / total)\n",
    "        \n",
    "    wc = wc.sort_values(by='rank')\n",
    "    wc['cul_pct_total'] = wc['pct_total'].cumsum()\n",
    "\n",
    "    t2 = zip(appears_in.keys(), appears_in.values())\n",
    "    ac = pd.DataFrame(t2, columns=['word', 'appears_in'])\n",
    "    wc = ac.merge(wc, on='word')\n",
    "\n",
    "    wc['appears_in_pct'] = wc['appears_in'].apply(lambda x: x / total_docs)\n",
    "        \n",
    "    return wc.sort_values(by='rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1321</td>\n",
       "      <td>Sometimes, when whisky is batched, a few lefto...</td>\n",
       "      <td>1</td>\n",
       "      <td>[sometimes,, whisky, batched,, leftover, barre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3861</td>\n",
       "      <td>An uncommon exclusive bottling of a 6 year old...</td>\n",
       "      <td>0</td>\n",
       "      <td>[uncommon, exclusive, bottling, year, old, cas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655</td>\n",
       "      <td>This release is a port version of Amrut’s Inte...</td>\n",
       "      <td>1</td>\n",
       "      <td>[release, port, version, amrut’s, intermediate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>555</td>\n",
       "      <td>This 41 year old single cask was aged in a she...</td>\n",
       "      <td>1</td>\n",
       "      <td>[year, old, single, cask, aged, sherry, butt, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1965</td>\n",
       "      <td>Quite herbal on the nose, with aromas of dried...</td>\n",
       "      <td>1</td>\n",
       "      <td>[herbal, nose,, aromas, dried, tarragon,, pars...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                        description  ratingCategory  \\\n",
       "0  1321  Sometimes, when whisky is batched, a few lefto...               1   \n",
       "1  3861  An uncommon exclusive bottling of a 6 year old...               0   \n",
       "2   655  This release is a port version of Amrut’s Inte...               1   \n",
       "3   555  This 41 year old single cask was aged in a she...               1   \n",
       "4  1965  Quite herbal on the nose, with aromas of dried...               1   \n",
       "\n",
       "                                              tokens  \n",
       "0  [sometimes,, whisky, batched,, leftover, barre...  \n",
       "1  [uncommon, exclusive, bottling, year, old, cas...  \n",
       "2  [release, port, version, amrut’s, intermediate...  \n",
       "3  [year, old, single, cask, aged, sherry, butt, ...  \n",
       "4  [herbal, nose,, aromas, dried, tarragon,, pars...  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(str(train['description']))\n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "tokens = []\n",
    "\n",
    "for doc in tokenizer.pipe(train['description'], batch_size=500):\n",
    "    \n",
    "    doc_tokens = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if (token.text.lower() not in STOP_WORDS) & (token.is_digit is False) & (token.is_punct is False):\n",
    "            doc_tokens.append(token.text.lower())\n",
    "            \n",
    "    tokens.append(doc_tokens)\n",
    "\n",
    "train['tokens'] = tokens\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>appears_in</th>\n",
       "      <th>count</th>\n",
       "      <th>rank</th>\n",
       "      <th>pct_total</th>\n",
       "      <th>cul_pct_total</th>\n",
       "      <th>appears_in_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>sweet</td>\n",
       "      <td>1145</td>\n",
       "      <td>1339</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007430</td>\n",
       "      <td>0.007430</td>\n",
       "      <td>0.280157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>notes</td>\n",
       "      <td>1014</td>\n",
       "      <td>1152</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.006393</td>\n",
       "      <td>0.013823</td>\n",
       "      <td>0.248104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>oak</td>\n",
       "      <td>932</td>\n",
       "      <td>1147</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.006365</td>\n",
       "      <td>0.020188</td>\n",
       "      <td>0.228040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>finish.</td>\n",
       "      <td>1101</td>\n",
       "      <td>1116</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>0.026381</td>\n",
       "      <td>0.269391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>finish</td>\n",
       "      <td>1090</td>\n",
       "      <td>1111</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.006165</td>\n",
       "      <td>0.032546</td>\n",
       "      <td>0.266699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  appears_in  count  rank  pct_total  cul_pct_total  \\\n",
       "64     sweet        1145   1339   1.0   0.007430       0.007430   \n",
       "281    notes        1014   1152   2.0   0.006393       0.013823   \n",
       "19       oak         932   1147   3.0   0.006365       0.020188   \n",
       "212  finish.        1101   1116   4.0   0.006193       0.026381   \n",
       "75    finish        1090   1111   5.0   0.006165       0.032546   \n",
       "\n",
       "     appears_in_pct  \n",
       "64         0.280157  \n",
       "281        0.248104  \n",
       "19         0.228040  \n",
       "212        0.269391  \n",
       "75         0.266699  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count = count(train.tokens)\n",
    "word_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import squarify\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "wc_top15 = word_count[word_count['rank'] <=15]\n",
    "\n",
    "squarify.plot(sizes=wc_top15['pct_total'], label=wc_top15['word'], alpha=.7)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>Style: Speyside single malt scotch Color: Waln...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>Very bright and lively, with a nice balance of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>A new oloroso-forward Chivas positioned to spl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>Aged in bourbon casks and then enhanced in Rio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>There is a freshness to the wood on the nose, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>2853</td>\n",
       "      <td>Care for a small batch, bourbon-matured blend ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>219</td>\n",
       "      <td>This is the pick of the bunch, the whisky equi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>1286</td>\n",
       "      <td>Port Ellen, for sure! Very old-fashioned in na...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>2201</td>\n",
       "      <td>Youthful and very lively. Bold, crisp, spices ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>4019</td>\n",
       "      <td>A mashbill of 60/20/10/10 corn/wheat/rye/malt,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1022 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                        description  ratingCategory\n",
       "0     3461  Style: Speyside single malt scotch Color: Waln...               1\n",
       "1     2604  Very bright and lively, with a nice balance of...               1\n",
       "2     3341  A new oloroso-forward Chivas positioned to spl...               1\n",
       "3     3764  Aged in bourbon casks and then enhanced in Rio...               1\n",
       "4     2306  There is a freshness to the wood on the nose, ...               1\n",
       "...    ...                                                ...             ...\n",
       "1017  2853  Care for a small batch, bourbon-matured blend ...               1\n",
       "1018   219  This is the pick of the bunch, the whisky equi...               1\n",
       "1019  1286  Port Ellen, for sure! Very old-fashioned in na...               1\n",
       "1020  2201  Youthful and very lively. Bold, crisp, spices ...               1\n",
       "1021  4019  A mashbill of 60/20/10/10 corn/wheat/rye/malt,...               0\n",
       "\n",
       "[1022 rows x 3 columns]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_br_removal(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = grid_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Continue to apply Latent Semantic Indexing (LSI) to various datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings with Spacy (Learn)\n",
    "<a id=\"p3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to your Dataset\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue Word Embedding Work Here\n",
    "def get_word_vectors(docs):\n",
    "    return [nlp(doc).vector for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = get_word_vectors(train['description'])\n",
    "len(X) == len(train['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = get_word_vectors(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='sqrt',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=-1, oob_score=False, random_state=20, verbose=1,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "test['ratingCategory'] = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X, train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred_ = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred_})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1022, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               0\n",
       "2  3341               1\n",
       "3  3764               1\n",
       "4  2306               1"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "print(submission.shape)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'submission4.csv', index=False)\n",
    "subNumber += 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n",
    "4. Make a submission to Kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Lecture Assignment\n",
    "<a id=\"p4\"></a>\n",
    "\n",
    "Your primary assignment this afternoon is to achieve a minimum of 70% accuracy on the Kaggle competition. Once you have achieved 70% accuracy, please work on the following: \n",
    "\n",
    "1. Research \"Sentiment Analysis\". Provide answers in markdown to the following questions: \n",
    "    - What is \"Sentiment Analysis\"? \n",
    "    Sentiment analysis refers to the use of NLP, text analysis, computational linguistics, and biometrics to systematically\n",
    "    identify, extract, quantify, and study affective states and subjective information.\n",
    "    - Is Document Classification different than \"Sentiment Analysis\"? Provide evidence for your response\n",
    "    - How do create labeled sentiment data? Are those labels really sentiment?\n",
    "    - What are common applications of sentiment analysis?\n",
    "2. Research our why word embeddings worked better for the lecture notebook than on the whiskey competition.\n",
    "    - This [text classification documentation](https://developers.google.com/machine-learning/guides/text-classification/step-2-5) from Google might be of interest\n",
    "    - Neural Networks are becoming more popular for document classification. Why is that the case?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
