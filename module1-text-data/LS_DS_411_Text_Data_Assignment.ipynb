{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Natural Language Processing (NLP)\n",
    "## *Data Science Unit 4 Sprint 1 Assignment 1*\n",
    "\n",
    "Your goal in this assignment: find the attributes of the best & worst coffee shops in the dataset. The text is fairly raw: dates in the review, extra words in the `star_rating` column, etc. You'll probably want to clean that stuff up for a better analysis. \n",
    "\n",
    "Analyze the corpus of text using text visualizations of token frequency. Try cleaning the data as much as possible. Try the following techniques: \n",
    "- Lemmatization\n",
    "- Custom stopword removal\n",
    "\n",
    "Keep in mind the attributes of good tokens. Once you have a solid baseline, layer in the star rating in your visualization(s). Key part of this assignment - produce a write-up of the attributes of the best and worst coffee shops. Based on your analysis, what makes the best the best and the worst the worst. Use graphs and numbesr from your analysis to support your conclusions. There should be plenty of markdown cells! :coffee:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "YouTubeVideo('Jml7NVYm8cs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-1-NLP/master/module1-text-data/data/yelp_coffeeshop_review_data.csv\"\n",
    "\n",
    "shops = pd.read_csv(url)\n",
    "shops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we want to analyze these coffee shop tokens? \n",
    "\n",
    "- Overall Word / Token Count\n",
    "- View Counts by Rating \n",
    "- *Hint:* a 'bad' coffee shops has a rating betweeen 1 & 3 based on the distribution of ratings. A 'good' coffee shop is a 4 or 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import statements\n",
    "\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataframe\n",
    "shops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizer pipe function\n",
    "def token_pipe(text_column):\n",
    "    tokens = []\n",
    "    \n",
    "    for doc in tokenizer.pipe(text_column, batch_size=1000):\n",
    "        doc_tokens = [token.text for token in doc]\n",
    "        tokens.append(doc_tokens)\n",
    "        \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use function\n",
    "shops_tokens = token_pipe(shops['full_review_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column on shops df.\n",
    "shops['tokens'] = shops_tokens\n",
    "\n",
    "shops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object from Base Python\n",
    "from collections import Counter\n",
    "\n",
    "# The object `Counter` takes an iterable, but you can instaniate an empty one and update it. \n",
    "word_counts = Counter()\n",
    "\n",
    "# Using function from lecture, I'll make my own down the line\n",
    "def count(docs):\n",
    "\n",
    "        word_counts = Counter()\n",
    "        appears_in = Counter()\n",
    "        \n",
    "        total_docs = len(docs)\n",
    "\n",
    "        for doc in docs:\n",
    "            word_counts.update(doc)\n",
    "            appears_in.update(set(doc))\n",
    "\n",
    "        temp = zip(word_counts.keys(), word_counts.values())\n",
    "        \n",
    "        wc = pd.DataFrame(temp, columns = ['word', 'count'])\n",
    "\n",
    "        wc['rank'] = wc['count'].rank(method='first', ascending=False)\n",
    "        total = wc['count'].sum()\n",
    "\n",
    "        wc['pct_total'] = wc['count'].apply(lambda x: x / total)\n",
    "        \n",
    "        wc = wc.sort_values(by='rank')\n",
    "        wc['cul_pct_total'] = wc['pct_total'].cumsum()\n",
    "\n",
    "        t2 = zip(appears_in.keys(), appears_in.values())\n",
    "        ac = pd.DataFrame(t2, columns=['word', 'appears_in'])\n",
    "        wc = ac.merge(wc, on='word')\n",
    "\n",
    "        wc['appears_in_pct'] = wc['appears_in'].apply(lambda x: x / total_docs)\n",
    "        \n",
    "        return wc.sort_values(by='rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = count(shops['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We've still got plenty of stop words and repeated words in different forms, let's do some lemmatizing\n",
    "def get_lemmas(text):\n",
    "    \n",
    "    # Create empty lemma list\n",
    "    lemmas = []\n",
    "    \n",
    "    # Create doc file containing text to be lemmatized\n",
    "    doc = nlp(text)\n",
    "    \n",
    "   # Check for token stop words, punctuation, pronouns, numbers and symbols, remove them, then append to lemma list \n",
    "    for token in doc:\n",
    "        if ((token.is_stop == False) and (token.is_punct == False)) and ((token.pos_ != 'PRON') and (token.pos_ != 'NUM') and (token.pos_ != 'SYM')):\n",
    "            lemmas.append(token.lemma_)\n",
    "    \n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "shops['lemmas'] = shops['full_review_text'].apply(get_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coffee_shop_name</th>\n",
       "      <th>full_review_text</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Factory - Cafe With a Soul</td>\n",
       "      <td>11/25/2016 1 check-in Love love loved the atm...</td>\n",
       "      <td>5.0 star rating</td>\n",
       "      <td>[ , 11/25/2016, 1, check-in, Love, love, loved...</td>\n",
       "      <td>[ , check, love, love, love, atmosphere, corne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Factory - Cafe With a Soul</td>\n",
       "      <td>12/2/2016 Listed in Date Night: Austin, Ambia...</td>\n",
       "      <td>4.0 star rating</td>\n",
       "      <td>[ , 12/2/2016, Listed, in, Date, Night:, Austi...</td>\n",
       "      <td>[ , list, Date, Night, Austin, Ambiance, Austi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Factory - Cafe With a Soul</td>\n",
       "      <td>11/30/2016 1 check-in Listed in Brunch Spots ...</td>\n",
       "      <td>4.0 star rating</td>\n",
       "      <td>[ , 11/30/2016, 1, check-in, Listed, in, Brunc...</td>\n",
       "      <td>[ , check, list, Brunch, Spots, love, eclectic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Factory - Cafe With a Soul</td>\n",
       "      <td>11/25/2016 Very cool decor! Good drinks Nice ...</td>\n",
       "      <td>2.0 star rating</td>\n",
       "      <td>[ , 11/25/2016, Very, cool, decor!, Good, drin...</td>\n",
       "      <td>[ , cool, decor, good, drink, nice, seating,  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Factory - Cafe With a Soul</td>\n",
       "      <td>12/3/2016 1 check-in They are located within ...</td>\n",
       "      <td>4.0 star rating</td>\n",
       "      <td>[ , 12/3/2016, 1, check-in, They, are, located...</td>\n",
       "      <td>[ , check, locate, Northcross, mall, shopping,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  coffee_shop_name  \\\n",
       "0  The Factory - Cafe With a Soul    \n",
       "1  The Factory - Cafe With a Soul    \n",
       "2  The Factory - Cafe With a Soul    \n",
       "3  The Factory - Cafe With a Soul    \n",
       "4  The Factory - Cafe With a Soul    \n",
       "\n",
       "                                    full_review_text        star_rating  \\\n",
       "0   11/25/2016 1 check-in Love love loved the atm...   5.0 star rating    \n",
       "1   12/2/2016 Listed in Date Night: Austin, Ambia...   4.0 star rating    \n",
       "2   11/30/2016 1 check-in Listed in Brunch Spots ...   4.0 star rating    \n",
       "3   11/25/2016 Very cool decor! Good drinks Nice ...   2.0 star rating    \n",
       "4   12/3/2016 1 check-in They are located within ...   4.0 star rating    \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [ , 11/25/2016, 1, check-in, Love, love, loved...   \n",
       "1  [ , 12/2/2016, Listed, in, Date, Night:, Austi...   \n",
       "2  [ , 11/30/2016, 1, check-in, Listed, in, Brunc...   \n",
       "3  [ , 11/25/2016, Very, cool, decor!, Good, drin...   \n",
       "4  [ , 12/3/2016, 1, check-in, They, are, located...   \n",
       "\n",
       "                                              lemmas  \n",
       "0  [ , check, love, love, love, atmosphere, corne...  \n",
       "1  [ , list, Date, Night, Austin, Ambiance, Austi...  \n",
       "2  [ , check, list, Brunch, Spots, love, eclectic...  \n",
       "3  [ , cool, decor, good, drink, nice, seating,  ...  \n",
       "4  [ , check, locate, Northcross, mall, shopping,...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [check, love, love, love, atmosphere, corner, ...\n",
       "1    [list, Date, Night, Austin, Ambiance, Austin, ...\n",
       "2    [check, list, Brunch, Spots, love, eclectic, h...\n",
       "3    [cool, decor, good, drink, nice, seating,  ,  ...\n",
       "4    [check, locate, Northcross, mall, shopping, ce...\n",
       "Name: lemmas, dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shops['lemmas'].head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We've got some whitespace, let's get rid of that\n",
    "for text in shops['lemmas']:\n",
    "    try:\n",
    "        text.remove(' ')\n",
    "    except ValueError:\n",
    "        pass  # do nothing!\n",
    "    \n",
    "# Had to run this about 20 times. I'd like to remove white space beforehand next time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [check, love, love, love, atmosphere, corner, ...\n",
       "1    [list, Date, Night, Austin, Ambiance, Austin, ...\n",
       "2    [check, list, Brunch, Spots, love, eclectic, h...\n",
       "3    [cool, decor, good, drink, nice, seating, over...\n",
       "4    [check, locate, Northcross, mall, shopping, ce...\n",
       "Name: lemmas, dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Much better\n",
    "shops['lemmas'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get some stats\n",
    "wc = count(shops['lemmas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>appears_in</th>\n",
       "      <th>count</th>\n",
       "      <th>rank</th>\n",
       "      <th>pct_total</th>\n",
       "      <th>cul_pct_total</th>\n",
       "      <th>appears_in_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>coffee</td>\n",
       "      <td>4826</td>\n",
       "      <td>10100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028488</td>\n",
       "      <td>0.028488</td>\n",
       "      <td>0.633666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>place</td>\n",
       "      <td>3876</td>\n",
       "      <td>6021</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.016983</td>\n",
       "      <td>0.045470</td>\n",
       "      <td>0.508929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>good</td>\n",
       "      <td>3588</td>\n",
       "      <td>5391</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.015206</td>\n",
       "      <td>0.060676</td>\n",
       "      <td>0.471113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>great</td>\n",
       "      <td>2843</td>\n",
       "      <td>3924</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.011068</td>\n",
       "      <td>0.071744</td>\n",
       "      <td>0.373293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>check</td>\n",
       "      <td>3175</td>\n",
       "      <td>3468</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.009782</td>\n",
       "      <td>0.081525</td>\n",
       "      <td>0.416886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  appears_in  count  rank  pct_total  cul_pct_total  appears_in_pct\n",
       "28   coffee        4826  10100   1.0   0.028488       0.028488        0.633666\n",
       "105   place        3876   6021   2.0   0.016983       0.045470        0.508929\n",
       "164    good        3588   5391   3.0   0.015206       0.060676        0.471113\n",
       "93    great        2843   3924   4.0   0.011068       0.071744        0.373293\n",
       "4     check        3175   3468   5.0   0.009782       0.081525        0.416886"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can you visualize the words with the greatest difference in counts between 'good' & 'bad'?\n",
    "\n",
    "Couple Notes: \n",
    "- Rel. freq. instead of absolute counts b/c of different numbers of reviews\n",
    "- Only look at the top 5-10 words with the greatest differences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not exactly sure what this is asking for, I'd like to revisit this after asking my TL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1dCb1q8XphcP",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Stretch Goals\n",
    "\n",
    "* Analyze another corpus of documents - such as Indeed.com job listings ;).\n",
    "* Play with the Spacy API to\n",
    " - Extract Named Entities\n",
    " - Extracting 'noun chunks'\n",
    " - Attempt Document Classification with just Spacy\n",
    " - *Note:* This [course](https://course.spacy.io/) will be of interesting in helping you with these stretch goals. \n",
    "* Try to build a plotly dash app with your text data \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_421_Text_Data_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "U4-S1-NLP (python 3.7)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
