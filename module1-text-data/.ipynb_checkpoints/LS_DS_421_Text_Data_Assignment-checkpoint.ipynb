{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Natural Language Processing (NLP)\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 1*\n",
    "\n",
    "Analyze a corpus of text using text visualization of token frequency. Try cleaning the data as much as possible. Try the following techniques: \n",
    "- Stemming\n",
    "- Lemmatization\n",
    "- Custom stopword removal\n",
    "- Using frequency based stopwrod removal\n",
    "\n",
    "You are free to use any dataset you are interested in. Kaggle is a great place to start. Feel free to sample the data if the dataset is too large to hanlde in memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>id</th>\n",
       "      <th>nct_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n      J-Valve TF Compassionate Use cases app...</td>\n",
       "      <td>3654765</td>\n",
       "      <td>NCT03876964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n      The study is designed to assess the ro...</td>\n",
       "      <td>3647891</td>\n",
       "      <td>NCT03966794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n      DHA on Breath Holding Spells\\n</td>\n",
       "      <td>3647953</td>\n",
       "      <td>NCT03965988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n      The purpose of this study is to assess...</td>\n",
       "      <td>3650218</td>\n",
       "      <td>NCT03936374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n      The purpose of this trial is to evalua...</td>\n",
       "      <td>3647820</td>\n",
       "      <td>NCT03967730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description       id       nct_id\n",
       "0  \\n      J-Valve TF Compassionate Use cases app...  3654765  NCT03876964\n",
       "1  \\n      The study is designed to assess the ro...  3647891  NCT03966794\n",
       "2         \\n      DHA on Breath Holding Spells\\n      3647953  NCT03965988\n",
       "3  \\n      The purpose of this study is to assess...  3650218  NCT03936374\n",
       "4  \\n      The purpose of this trial is to evalua...  3647820  NCT03967730"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('data/summaries.json')\n",
    "df = df.T\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    \\n      J-Valve TF Compassionate Use cases app...\n",
       "1    \\n      The study is designed to assess the ro...\n",
       "2           \\n      DHA on Breath Holding Spells\\n    \n",
       "3    \\n      The purpose of this study is to assess...\n",
       "4    \\n      The purpose of this trial is to evalua...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'investigators have designed a pilot study involving chronic hand dermatitis chd patients who attend the dermatology clinic at the george washington medical faculty associates gw mfa in order to assess the efficacy and safety of apremilast treatment for the treatment of moderate to severe chd'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r'[^a-zA-Z ^0-9]', '', text)\n",
    "    text = \" \".join(text.split())\n",
    "    return text\n",
    "\n",
    "clean_text(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    jvalve tf compassionate use cases approved on ...\n",
       "1    the study is designed to assess the role of fu...\n",
       "2                         dha on breath holding spells\n",
       "3    the purpose of this study is to assess the eff...\n",
       "4    the purpose of this trial is to evaluate the s...\n",
       "Name: clean_desc, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_desc'] = df['description'].apply(clean_text)\n",
    "df['clean_desc'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['\\n      ',\n",
       "  'J-Valve',\n",
       "  'TF',\n",
       "  'Compassionate',\n",
       "  'Use',\n",
       "  'cases',\n",
       "  'approved',\n",
       "  'on',\n",
       "  'a',\n",
       "  'case',\n",
       "  'by',\n",
       "  'case',\n",
       "  'basis',\n",
       "  'by',\n",
       "  'the',\n",
       "  'FDA',\n",
       "  '\\n    '],\n",
       " ['\\n      ',\n",
       "  'The',\n",
       "  'study',\n",
       "  'is',\n",
       "  'designed',\n",
       "  'to',\n",
       "  'assess',\n",
       "  'the',\n",
       "  'role',\n",
       "  'of',\n",
       "  'functional',\n",
       "  'neural',\n",
       "  'regeneration',\n",
       "  'collagen',\n",
       "  'scaffold',\n",
       "  '\\n      ',\n",
       "  'transplantation',\n",
       "  'combined',\n",
       "  'with',\n",
       "  'epidural',\n",
       "  'electrical',\n",
       "  'stimulation',\n",
       "  'in',\n",
       "  'spinal',\n",
       "  'cord',\n",
       "  'injury',\n",
       "  'patients.',\n",
       "  '\\n    '],\n",
       " ['\\n      ', 'DHA', 'on', 'Breath', 'Holding', 'Spells', '\\n    '],\n",
       " ['\\n      ',\n",
       "  'The',\n",
       "  'purpose',\n",
       "  'of',\n",
       "  'this',\n",
       "  'study',\n",
       "  'is',\n",
       "  'to',\n",
       "  'assess',\n",
       "  'the',\n",
       "  'effect',\n",
       "  'of',\n",
       "  'multiple',\n",
       "  'dose',\n",
       "  'administrations',\n",
       "  'of',\n",
       "  '\\n      ',\n",
       "  'Omeprazole',\n",
       "  'on',\n",
       "  'the',\n",
       "  'pharmacokinetics',\n",
       "  'of',\n",
       "  'BMS-986205.',\n",
       "  '\\n    '],\n",
       " ['\\n      ',\n",
       "  'The',\n",
       "  'purpose',\n",
       "  'of',\n",
       "  'this',\n",
       "  'trial',\n",
       "  'is',\n",
       "  'to',\n",
       "  'evaluate',\n",
       "  'the',\n",
       "  'safety',\n",
       "  'and',\n",
       "  'efficacy',\n",
       "  'of',\n",
       "  'sonodynamic',\n",
       "  'therapy',\n",
       "  '(SDT)',\n",
       "  '\\n      ',\n",
       "  'in',\n",
       "  'reducing',\n",
       "  'the',\n",
       "  'inflammation',\n",
       "  'of',\n",
       "  'perivascular',\n",
       "  'adipose',\n",
       "  'tissue',\n",
       "  'and',\n",
       "  'increasing',\n",
       "  'peak',\n",
       "  'walking',\n",
       "  'time',\n",
       "  '\\n      ',\n",
       "  '(PWT)',\n",
       "  'among',\n",
       "  'peripheral',\n",
       "  'artery',\n",
       "  'disease',\n",
       "  '(PAD)',\n",
       "  'patients',\n",
       "  'with',\n",
       "  'symptom',\n",
       "  'of',\n",
       "  'intermittent',\n",
       "  '\\n      ',\n",
       "  'claudication.',\n",
       "  '\\n    ']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = []\n",
    "\n",
    "for text in tokenizer.pipe(df['description'], batch_size=500):\n",
    "    text_tokens = [token.text for token in text]\n",
    "    tokens.append(text_tokens)\n",
    "    \n",
    "tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [\\n      , J-Valve, TF, Compassionate, Use, ca...\n",
       "1    [\\n      , The, study, is, designed, to, asses...\n",
       "2    [\\n      , DHA, on, Breath, Holding, Spells, \\...\n",
       "3    [\\n      , The, purpose, of, this, study, is, ...\n",
       "4    [\\n      , The, purpose, of, this, trial, is, ...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'] = tokens\n",
    "df['tokens'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StopWord Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = nlp.Defaults.stop_words.union(['I','\\n      '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_tokens = []\n",
    "\n",
    "for tokens in df['tokens']:\n",
    "    real_tokens = []\n",
    "    for token in tokens:\n",
    "        if token not in STOP_WORDS:\n",
    "            real_tokens.append(token)\n",
    "    updated_tokens.append(real_tokens)\n",
    "    \n",
    "df['tokens'] = updated_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7117      [Pupillary, diameter, monitoring, currently, r...\n",
       "53101     [Invasive, mechanical, ventilation, (IMV), ass...\n",
       "84439     [Alzheimer's, disease, (AD), prevalent, neurod...\n",
       "109930    [AC0010MA, new,, irreversible,, Epidermal, Gro...\n",
       "13154     [Contusive, cervical, spinal, cord, injury, (c...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "words = [\"game\", \"gaming\", \"gamed\", \"games\"]\n",
    "\n",
    "stemmed_tokens = []\n",
    "\n",
    "for tokens in df['tokens']:\n",
    "    stemmed_token = []\n",
    "    for token in tokens:\n",
    "        stem = ps.stem(token)\n",
    "        stemmed_token.append(stem)\n",
    "    stemmed_tokens.append(stemmed_token)\n",
    "    \n",
    "df['Stemmed Tokens'] = stemmed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [j-valv, TF, compassion, use, case, approv, ca...\n",
       "1    [the, studi, design, assess, role, function, n...\n",
       "2                   [dha, breath, hold, spell, \\n    ]\n",
       "3    [the, purpos, studi, assess, effect, multipl, ...\n",
       "4    [the, purpos, trial, evalu, safeti, efficaci, ...\n",
       "Name: Stemmed Tokens, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Stemmed Tokens'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemminization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = []\n",
    "\n",
    "for text in df['clean_desc']:\n",
    "    text = nlp(text)\n",
    "    token_lemma = []\n",
    "    for token in text:\n",
    "        token_lemma.append(token.lemma_)\n",
    "    lemmas.append(token_lemma)\n",
    "    \n",
    "df['lemmas'] = lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this\n",
      "be\n",
      "the\n",
      "start\n",
      "of\n",
      "-PRON-\n",
      "nlp\n",
      "adventure\n",
      ".\n",
      "-PRON-\n",
      "start\n",
      "here\n",
      "with\n",
      "spacy\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "df['lemmas'].head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_421_Text_Data_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "US4-S1-NLP (Python 3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
