{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 1*\n",
    "\n",
    "# Natural Language Processing (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qGUBe2FXilzx"
   },
   "source": [
    "# 1. String Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UwLjaXPCqACb"
   },
   "source": [
    "## 1.1 Count Characters\n",
    "\n",
    "Write a function to count the character frequency of any string, and return the counts as a dictionary.\n",
    "\n",
    "\"google.com\" -> {'o': 3, 'g': 2, '.': 1, 'e': 1, 'l': 1, 'm': 1, 'c': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Kk5bS5ujbwH"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def frequencies(string):\n",
    "    counts = collections.Counter(string)\n",
    "    return {char: n for char, n in counts.most_common()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'o': 3, 'g': 2, 'l': 1, 'e': 1, '.': 1, 'c': 1, 'm': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies(\"google.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mq2yhAciqH6w"
   },
   "source": [
    "## 1.2 Replace Characters\n",
    "\n",
    "Write a function that takes in two parameters: 1) a string of text and 2) individual character. This function should return a new string of text where any of the specified character has been replaced with dollar signs: `$` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redact(document, c, redaction_char=\"$\"):\n",
    "    return document.replace(c, redaction_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$oo$le'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redact(\"google\", \"g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v8iy3BKuq--f"
   },
   "source": [
    "## 1.3 Slice Suffixes\n",
    "\n",
    "Write a function that removes common suffixes from the ends of words. As a minimum this function should remove the suffixes: \"ed\",  \"ing\", \"es\", \"tion\", \"ly\"\n",
    "\n",
    "\"The daring fox leaped through the air gracefully, his eyes fixated on the capitulation of his prey.\" -> \n",
    "\n",
    "\"The dar fox leap through the air graceful, his ey fixat on the capitula of his prey.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_suffixes(string):\n",
    "    suffixes = [\"ed\", \"ing\", \"es\", \"tion\", \"ly\"]\n",
    "    \n",
    "    for suffix in suffixes:\n",
    "        string = string.replace(suffix, '')\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The dar fox leap through the air graceful, his ey fixat on the capitula of his prey.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_suffixes(\"The daring fox leaped through the air gracefully, his eyes fixated on the capitulation of his prey.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hAAJTIN_trH3"
   },
   "source": [
    "## 1.4 Remove Stopwords\n",
    "\n",
    "Write a function that removes common \"stopwords\" from text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QbHQkte9t_gK"
   },
   "outputs": [],
   "source": [
    "stopwords = ['i','me','my','myself','we''our','ours','ourselves',\n",
    "'you','your','yours','yourself','yourselves','he','him','his','himself',\n",
    "'she','her','hers','herself','it','its','itself','they','them','their',\n",
    "'theirs','themselves','what','which','who','whom','this','that','these',\n",
    "'those','am','is','are','was','were','be','been','being','have','has',\n",
    "'had','having','do','does','did','doing','a','an','the','and','but',\n",
    "'if','or','because','as','until','while','of','at','by','for','with',\n",
    "'about','against','between','into','through','during','before','after',\n",
    "'above','below','to','from','up','down','in','out','on','off','over',\n",
    "'under','again','further','then','once','here','there','when','where',\n",
    "'why','how','all','any','both','each','few','more','most','other','some',\n",
    "'such','no','nor','not','only','own','same','so','than','too','very',\n",
    "'s','t','can','will','just','don','should','now']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_stopwords(string):\n",
    "    return ' '.join(word for word in string.lower().split(' ') if word not in stopwords).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sure igor.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm_stopwords(\"I am not so sure igor.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EKEER1R3vyDM"
   },
   "source": [
    "## 1.5 Vectorize Words\n",
    "\n",
    "Below is a list of three strings. Each string is a job listing with the job title of \"data scientist\" from indeed.com. Write a function that does two things:\n",
    "\n",
    "1) Removes stopwords from each listing (uses above function)\n",
    "\n",
    "2) Creates a dataframe where the header of each column is a particular word and each cell of the dataframe should be a 1 or 0 denoting whether that word is present or not in the job listing a body of text. The final dataframe should only have 3 rows, one for each of the three job listings.\n",
    "\n",
    "Your final dataframe should not include any of the stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BmEykH6byT5n"
   },
   "outputs": [],
   "source": [
    "job_listings = ['Part-time, Contract, Internship\\nSr. Machine Learning/Data Scientist\\n\\ndata245, Bannockburn, IL seeks data scientists.\\n\\nWe are open to all levels of experience (down to an intern) as we are building a team around new initiatives.\\n\\nYou will be developing state of the art algorithms to power various aspects of highly complex business models\\nYou can articulate and understand a business problem, identify challenges, formulate the machine learning problem or NLP problems and provide/prototype solutions\\nYou will provide technical leadership, identify and understand key business challenges and opportunities, and develop end-to-end software solutions using machine learning/NLP and optimization methods.\\n\\nYou will collaborate extensively with internal and external partners, program management, and, at a senior level, the engineering team to ensure that solution meet business needs, permit valid inferences and have functional feasibility\\nYou will collect and manipulate large volumes of data; build new and improved techniques and/or solutions for data collection, management, and usage\\nYou will communicate results in a comprehensible manner to all levels of the company (field teams up to Snr. Management) - this will require client facing in the future - but not initially\\nYou will brainstorm with other team members and leadership - who has 30 plus years experience in the industry that requires the solution.\\nRequirements:\\n\\nPHD or MS in Statistics, Machine Learning, or Computer Science (or technical degree with commensurate industry experience)\\nIdeally the Senior position will possess at least 3 years of relevant work - or academic academic experience, as a Data Scientist / Machine Learning professional.\\nExpertise in NLP a bonus\\nStrong algorithmic design skills\\nOther positions require less tenure, but the same relevant ML understanding.\\nPrevious hands on experience, or thesis dedicated to the same\\nDeep understanding of classic machine learning and deep learning theory, and extensive hands-on experience putting it into practice\\nExcellent understanding of machine learning algorithms, processes, tools and platforms including CNN, RNN, NLP, tensorflow, keras, etc.\\nPython proficiency is must\\nApplied experience with machine learning on large datasets\\\\sparse data with structured and unstructured data.\\nExperience with deep learning, and their optimizations for efficient implementation.\\nGreat communication skills, ability to explain predictive analytics to non-technical audience (not client facing yet, and no sales)\\nExperienced in predictive modelling.\\nExecute analytical experiments methodically while outputting reproducible research.\\nExcited to change an industry struggling to control costs.\\nGood to have â€“ Familiar with one or more programming languages e.g. C++ / Java / Android / iOS\".\\nJob Types: Full-time, Part-time, Internship, Contract\\n\\nSalary: $75,000.00 to $125,000.00 /year\\n\\nEducation:\\n\\nMaster\\'s (Preferred)\\nWork authorization:\\n\\nUnited States (Preferred)\\nHours per week:\\n\\n30-39\\nOvertime often available:\\n\\nNo\\nContract Length:\\n\\nMore than 1 year\\nTypical end time:\\n\\n5PM', \"$96,970 - $148,967 a year\\nThe professionals at the National Security Agency (NSA) have one common goal: to protect our nation. The mission requires a strong offense and a steadfast defense. The offense collects, processes, and disseminates intelligence information derived from foreign signals for intelligence and counterintelligence purposes. The defense prevents adversaries from gaining access to sensitive classified national security information. NSA is the nation's leader in providing foreign signals intelligence while also protecting U.S. government information systems, forging the frontier of communications, and data analysis. We serve the American people by applying technical skills to meaningful work, keeping our friends and families safe for generations to come. You will make a lasting impact serving your country as a Data Scientist at the National Security Agency, using your curiosity to analyze large data sets to inform decision-making against foreign threats. We are looking for critical thinkers, problem solvers, and motivated individuals who are enthusiastic about data and believe that answers to hard questions lie in the yet-to-be-told story of diverse, complicated data sets. You will employ your mathematical science, computer science, and quantitative analysis skills to ensure solutions to complex data problems and take full advantage of the NSA's software and hardware capabilities in all areas of our enterprise, including analytic capabilities, research, and foreign intelligence operations. Data Scientists are hired into positions directly supporting a technical mission office or the Data Scientist Development Program (DSDP). The NSA/CSS Data Scientist Development Program is a three-year opportunity to build your data science talent, experience the breadth of data science at NSA through six- to nine-month assignments in a variety of diverse organizations, and collaborate with NSA's experts in the field of data science. You will have opportunities to attend technical conferences with experts from industry and academia. You will routinely discuss and share NSA's challenges and successes at weekly technical roundtables. We foster an environment where you will develop your data science skills, allowing you to quickly contribute to NSA's mission. As a member of a technical mission office or the DSDP, Data Scientists tackle challenging real-world problems leveraging big data, high-performance computing, machine learning, and a breadth of other methodologies. As a Data Scientist at NSA, responsibilities may include: - Collecting and combining data from multiple sources - Uncovering and exploring anomalous data (including metadata) - Applying the scientific process to data evaluation, performing statistical inference, and data mining - Developing analytic plans, engineer supporting algorithms, and design and implement solutions which execute analytic plans. - Designing and developing tools and techniques for analysis - Analyzing data using mathematical/statistical methods - Evaluating, documenting, and communicating research processes, analyses, and results to customers, peers, and leadership - Creating interpretable visualizations\\n\\nSkills\\n\\nThe ideal candidate is someone with a desire for continual learning and strong problem-solving, analytic and interpersonal skills. You might be a great fit for our team if any of the following describe you: - Completed a degree program in the fields of mathematics, statistics, computer science, computational sciences, or a passion for rigorous analysis of data - Tenacity, integrity, persistence, and willingness to learn - Ability to solve complex problems - Use critical thinking and reasoning to make analytic determinations - Works effectively in a collaborative environment - Strong communications skills to both technical and non-technical audiences - The desire to serve over 300 million fellow Americans and make a difference in world events\\n\\nPay, Benefits, & Work Schedule\\n\\nOn the job training, internal NSA courses, and external training will be made available based on the need and experience of the selectee. Monday - Friday, with basic 8 hr/day requirements between 0800 to 1800 (flexible)\\n\\nPosition Summary\\n\\nNSA is in search of Computer Science professionals to solve complex problems, test innovative approaches and research new solutions to storing, manipulating, and presenting information. We are looking for you to apply your computer science expertise to projects that seek to create new standards for the transformation of information. If you want to develop technologies and tools and be a part of cutting edge innovations ' join our team of experts! Help protect national security interests as part of the world's most advanced team of computer science professionals!\\n\\nMandatory Qualification Reqs\\n\\nCandidates for the NSA's Data Scientist roles are asked to complete a data science examination evaluating their knowledge of statistics, mathematics, and computer science topics that pertain to data science work. Passing this examination is a requirement in order to be considered for selection into a data scientist position. Salary Range: $69,545 - $86,659 (Entry Level/Developmental) *The qualifications listed are the minimum acceptable to be considered for the position. Salary offers are based on candidates' education level and years of experience relevant to the position and also take into account information provided by the hiring manager/organization regarding the work level for the position. Entry is with a Bachelor's degree and no experience. An Associate's degree plus 2 years of relevant experience may be considered for individuals with in-depth experience that is clearly related to the position. Degree must be in Mathematics, Applied Mathematics, Statistics, Applied Statistics, Machine Learning, Data Science, Operations Research, or Computer Science. A degree in a related field (e.g., Computer Information Systems, Engineering), a degree in the physical/hard sciences (e.g. physics, chemistry, biology, astronomy), or other science disciplines (i.e., behavioral, social, and life) may be considered if it includes a concentration of coursework (typically 5 or more courses) in advanced mathematics (typically 200 level or higher; such as calculus, differential equations, discrete mathematics) and/or computer science (e.g., algorithms, programming, data structures, data mining, artificial intelligence). College-level Algebra or other math courses intended to meet a basic college level requirement, or upper level math courses designated as elementary or basic do not count. Note: A broader range of degrees will be considered if accompanied by a Certificate in Data Science from an accredited college/university.\\n\\nRelevant experience must be in designing/implementing machine learning, data mining, advanced analytical algorithms, programming, data science, advanced statistical analysis, artificial intelligence, and/or software engineering. Experience in more than one area is strongly preferred. Salary Range: $80,445 - $107,140 (Full Performance) *The qualifications listed are the minimum acceptable to be considered for the position. Salary offers are based on candidates' education level and years of experience relevant to the position and also take into account information provided by the hiring manager/organization regarding the work level for the position. Entry is with a Bachelor's degree plus 3 years of relevant experience or a Master's degree plus 1 year of relevant experience or a Doctoral degree and no experience. An Associate's degree plus 5 years of relevant experience may be considered for individuals with in-depth experience that is clearly related to the position.\\nDegree must be in Mathematics, Applied Mathematics, Statistics, Applied Statistics, Machine Learning, Data Science, Operations Research, or Computer Science. A degree in a related field (e.g., Computer Information Systems, Engineering), a degree in the physical/hard sciences (e.g. physics, chemistry, biology, astronomy), or other science disciplines (i.e., behavioral, social, and life) may be considered if it includes a concentration of coursework (typically 5 or more courses) in advanced mathematics (typically 200 level or higher; such as calculus, differential equations, discrete mathematics) and/or computer science (e.g., algorithms, programming, data structures, data mining, artificial intelligence). College-level Algebra or other math courses intended to meet a basic college level requirement, or upper level math courses designated as elementary or basic do not count. Note: A broader range of degrees will be considered if accompanied by a Certificate in Data Science from an accredited college/university. Relevant experience must be in two or more of the following: designing/implementing machine learning, data mining, advanced analytical algorithms, programming, data science, advanced statistical analysis, artificial intelligence, or software engineering. Salary Range: $96,970 - $148,967 (Senior) *The qualifications listed are the minimum acceptable to be considered for the position. Salary offers are based on candidates' education level and years of experience relevant to the position and also take into account information provided by the hiring manager/organization regarding the work level for the position. Entry is with a Bachelor's degree plus 6 years of relevant experience or a Master's degree plus 4 years of relevant experience or a Doctoral degree plus 2 years of relevant experience. An Associate's degree plus 8 years of relevant experience may be considered for individuals with in-depth experience that is clearly related to the position. Degree must be in Mathematics, Applied Mathematics, Statistics, Applied Statistics, Machine Learning, Data Science, Operations Research, or Computer Science. A degree in a related field (e.g., Computer Information Systems, Engineering), a degree in the physical/hard sciences (e.g., physics, chemistry, biology, astronomy), or other science disciplines (i.e., behavioral, social, life) may be considered if it includes a concentration of coursework (typically 5 or more courses) in advanced mathematics (typically 200 level or higher; such as calculus, differential equations, discrete mathematics) and/or computer science (e.g., algorithms, programming, data structures, data mining, artificial intelligence). College-level Algebra or other math courses intended to meet a basic college level requirement, or upper level math courses designated as elementary or basic do not count. Note: A broader range of degrees will be considered if accompanied by a Certificate in Data Science from an accredited college/university. Relevant experience must be in two or more of the following: designing/implementing machine learning, data mining, advanced analytical algorithms, programming, data science, advanced statistical analysis, artificial intelligence, or software engineering. Salary Range: $134,789- $164,200 (Expert) *The qualifications listed are the minimum acceptable to be considered for the position. Salary offers are based on candidates' education level and years of experience relevant to the position and also take into account information provided by the hiring manager/organization regarding the work level for the position. Entry is with a Bachelor's degree plus 9 years of relevant experience or a Master's degree plus 7 years of relevant experience or a Doctoral degree plus 5 years of relevant experience. An Associate's degree plus 11 years of relevant experience may be considered for individuals with in-depth experience that is clearly related to the position. Degree must be in Mathematics, Applied Mathematics, Statistics, Applied Statistics, Machine Learning, Data Science, Operations Research, or Computer Science. A degree in a related field (e.g., Computer Information Systems, Engineering), a degree in the physical/hard sciences (e.g., physics, chemistry, biology, astronomy), or other science disciplines (i.e., behavioral, social, life) may be considered if it includes a concentration of coursework (typically 5 or more courses) in advanced mathematics (typically 200 level or higher; such as calculus, differential equations, discrete mathematics) and/or computer science (e.g., algorithms, programming, data structures, data mining, artificial intelligence). College-level Algebra or other math courses intended to meet a basic college level requirement, or upper level math courses designated as elementary or basic do not count. Note: A broader range of degrees will be considered if accompanied by a Certificate in Data Science from an accredited college/university. Relevant experience must be in two or more of the following: designing/implementing machine learning, data mining, advanced analytical algorithms, programming, data science, advanced statistical analysis, artificial intelligence, or software engineering.\\n\\nHow To Apply - External\\n\\nTo apply for this position, please click the 'Apply' button located at the top right of this posting. After completing the application for the first time, or reviewing previously entered information, and clicking the 'Submit' button, you will receive a confirmation email. Please ensure your spam filters are configured to accept emails from noreply@intelligencecareers.gov. ***PLEASE NOTE: U.S. Citizenship is required for all applicants. Reasonable accommodations provided to applicants with disabilities during the application and hiring process where appropriate. NSA is an equal opportunity employer and abides by applicable employment laws and regulations. All applicants and employees are subject to random drug testing in accordance with Executive Order 12564. Employment is contingent upon successful completion of a security background investigation and polygraph. This position is a Defense Civilian Intelligence Personnel System (DCIPS) position in the Excepted Service under 10 U.S.C. 1601. DoD Components with DCIPS positions apply Veterans' Preference to eligible candidates as defined by Section 2108 of Title 5 USC, in accordance with the procedures provided in DoD Instruction 1400.25, Volume 2005, DCIPS Employment and Placement. If you are a veteran claiming veterans' preference, as defined by Section 2108 of Title 5 U.S.C., you may be asked to submit documents verifying your eligibility. Please note that you may be asked a series of questions depending on the position you apply for. Your responses will be used as part of the screening process of your application and will assist in determining your eligibility for the position. Be sure to elaborate on experiences in your resume. Failure to provide the required information or providing inaccurate information will result in your application not being considered for this position. Only those applicants who meet the qualifications for the position will be contacted to begin employment processing. Please Note: Job Posting could close earlier than the closing date due to sufficient number of applicants or position no longer available. We encourage you to apply as soon as possible.\\n\\nDCIPS Disclaimer\\n\\nThe National Security Agency (NSA) is part of the DoD Intelligence Community Defense Civilian Intelligence Personnel System (DCIPS). All positions in the NSA are in the Excepted Services under 10 United States Codes (USC) 1601 appointment authority.\", '\\nMinneapolis, Providence or Framingham\\n\\nWho is Virgin Pulse?\\nVirgin Pulse, founded as part of Sir Richard Bransonâ€™s famed Virgin Group, helps organizations build employee health and wellbeing into the DNA of their corporate cultures. As the only company to deliver a powerful, mobile-first digital platform infused with live services, including coaching and biometric screenings, Virgin Pulseâ€™s takes a high-tech-meets-high-touch-approach to engage employees in improving across all aspects of their health and wellbeing, every day â€“ from prevention and building a healthy lifestyle to condition and disease management to condition reversal, all while engaging users daily in building and sustaining healthy habits and behaviors. A global leader in health and wellbeing, Virgin Pulse is committed to helping change lives and businesses around the world for good so that people and organizations can thrive, together. Today, more than 3100 organizations across the globe are using Virgin Pulseâ€™s solutions to improve health, employee wellbeing and engagement, reduce costs and create strong workplace cultures.\\n\\nWho are our employees?\\nAt Virgin Pulse weâ€™re passionate about changing lives for good. We want to make a difference in the world by helping people be healthy so they can perform at their best, every day, at work and home. Our award-winning solutions support leading employers in improving and simplifying the employee health and wellbeing journey and engaging people in all aspects of their health. But our world-class products and programs are nothing without our people â€“ the employees who design, build, promote, sell, test and perfect the latest innovations in workplace health and wellbeing. Our people are our top priority and we invest in their health and happiness. At Virgin Pulse, we have so much more than a strong, supportive company culture â€“ have a shared vision for a healthier, happier world.\\nWho you are.\\nYou are an experienced Data Scientist who is capable of providing support to our organizationâ€™s efforts to maintain an innovative leadership position in the employee engagement SaaS industry. The Data Scientist accesses datasets from various sources, conducts analysis, and presents the findings of each analytic and reporting project. The incumbent will be able to interpret the findings and clearly communicate results and recommendations to internal and external customers. Moreover, you are a professional who is self-directed and thrives working in a fast-paced, collaborative environment, in which expectations are high both for the quality and speed of work.\\nIn the role of a Data Scientist you will wear many hats and your skills will be crucial in the following:\\nWrite SQL, R, Python programs to access, clean, and transform required data prior to analysis and reporting\\nConsult to and collaborate with analytics and client reporting team members to ensure appropriate data is analyzed and that results are provided in a format consistent with standard and customized client reporting services\\nTroubleshoot and perform data audits to ensure and improve data integrity; investigate and resolve data discrepancies\\nPlan and manage data analytic and reporting process to ensure the projects remain on schedule\\nConduct ad hoc analysis as required using varied analytical tools and techniques\\nSupport Client Success, sales and Marketing staff with direct communication with Virgin Pulse clients and prospects regarding the results of the analysis\\nAchieve annual Key Performance Indicator objectives, which can include report volumes and scope, internal and external client satisfaction, introducing new areas of data and analysis, and influencing company product and process decisions\\n\\nWhat you bring to the team.\\nIn order to represent the best of what we have to offer, you come to us with a multitude of positive attributes including:\\nA bachelorâ€™s degree in statistics, computer science, economics, or related field; Masterâ€™s degree is a plus\\nA minimum of four years of work experience in a similar position\\nExperience with data and analytic programming languages such as SQL, R, Python\\nExperience with data visualization tools and techniques preferred\\nExperience with producing and delivering results using varied media (i.e., multiple MS office formats, dashboards/visualization tools, and potentially other formats)\\nExperience in employee health management/health engagement industry preferred\\n\\nIn addition, you possess the following additional competencies and characteristics:\\nStrong analytical skills, with an emphasis on quantitative analysis, descriptive and inferential statistics\\nExpertise in statistical analytical software, or the ability to learn through prior experience tools such as SAS, Stata, R, SPSS or similar statistical software\\nStrong consulting, communication and presentation skills\\nAdvanced R, SQL and database programming skills, experience with MS SQL Server, RedShift, Postgres, and Cassandra/NOSQL databases\\nExperience working with large-scale datasets and multiple projects simultaneously\\nCreative energy, self-starter, works equally well independently and collaboratively']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(string):\n",
    "    splitters = [\" \", \"-\", \"â€“\", \"\\\\\", \"/\"]\n",
    "    extraneous = [\"\\(\", \"\\)\", \"\\.\", \",\", \"\\:\", \"\\$\", \"\\?\", \"\\d+\", \"'\", '\\*', '&']\n",
    "\n",
    "    normalized = \" \".join(x for x in string.lower().replace('\\n', ' ').replace('/', ' ').split(' ') if x != ' ' and x != '')\n",
    "    dusted = re.sub(\"({})\".format(\"|\".join(extraneous)), '', normalized)\n",
    "    cleaned = re.split(\"({})\".format(\"|\".join(splitters)), dusted)\n",
    "    filtered = rm_stopwords(\" \".join(word for word in cleaned if word not in splitters))\n",
    "    \n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(string):\n",
    "    return list(set(clean(string).split(' ')))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(strings, words=None):\n",
    "    cleaned = [clean(string) for string in strings]\n",
    "    words = [token for tokens in map(unique, strings) for token in tokens]\n",
    "    vectors = np.array([[word in string for word in words] for string in strings]).astype(np.int).T\n",
    "    return pd.DataFrame({word: vector for word, vector in zip(words, vectors)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abides</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>academia</th>\n",
       "      <th>academic</th>\n",
       "      <th>accept</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>access</th>\n",
       "      <th>accesses</th>\n",
       "      <th>accommodations</th>\n",
       "      <th>...</th>\n",
       "      <th>work</th>\n",
       "      <th>working</th>\n",
       "      <th>workplace</th>\n",
       "      <th>works</th>\n",
       "      <th>world</th>\n",
       "      <th>worlds</th>\n",
       "      <th>write</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 862 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abides  ability  able  academia  academic  accept  acceptable  access  \\\n",
       "0       0        1     1         0         1       0           0       0   \n",
       "1       1        0     1         1         0       1           1       1   \n",
       "2       0        1     1         0         0       0           0       1   \n",
       "\n",
       "   accesses  accommodations ...   work  working  workplace  works  world  \\\n",
       "0         0               0 ...      1        0          0      0      0   \n",
       "1         0               1 ...      1        0          0      0      1   \n",
       "2         1               0 ...      1        1          1      1      1   \n",
       "\n",
       "   worlds  write  year  years  yet  \n",
       "0       0      0     1      1    1  \n",
       "1       0      0     1      1    1  \n",
       "2       0      0     1      1    0  \n",
       "\n",
       "[3 rows x 862 columns]"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize(job_listings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ij27L9cPizzB"
   },
   "source": [
    "# 2. Regex + Pandas Practice\n",
    "\n",
    "Load the contents of the following text file into your notebook:\n",
    "<https://raw.githubusercontent.com/CoreyMSchafer/code_snippets/master/Python-Regular-Expressions/data.txt>\n",
    "\n",
    "If you're using Google Colab then you will have to download the raw file from github and either upload to your google drive or upload it to the notebook like we have done with CSVs in the past."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F1CALmvAl0pQ"
   },
   "source": [
    "## 2.1 Make sure your notebook has access to the .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "EdByRNWgjcPx",
    "outputId": "0334cd86-5788-4591-f3e3-41f2feae6792"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  8833  100  8833    0     0  84932      0 --:--:-- --:--:-- --:--:-- 84932\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p data\n",
    "!curl https://raw.githubusercontent.com/CoreyMSchafer/code_snippets/master/Python-Regular-Expressions/data.txt > data/address.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TAR7mbJsl4hK",
    "toc-hr-collapsed": true
   },
   "source": [
    "## 2.2 Read in the contents of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "3zutl-6Dkk0f",
    "outputId": "71dd3d65-4401-4983-ba2b-04128a85ceec"
   },
   "outputs": [],
   "source": [
    "file = open('data/address.txt', 'r', encoding='utf-8')\n",
    "contents  = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oxxpx8l0k-wP"
   },
   "source": [
    "## 2.3 Turn the \"unstructured\" .txt file into a \"structured\" dataframe\n",
    "Once you have read in the file's contents your task is to get this unstructured text data into a dataframe with the following headers:\n",
    "\n",
    "- First Name\n",
    "- Last Name\n",
    "- Email\n",
    "- Phone Number\n",
    "- Street Address\n",
    "- City\n",
    "- State\n",
    "- Zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Xqo-GPdk-OM"
   },
   "outputs": [],
   "source": [
    "entries = contents.split(\"\\n\")\n",
    "\n",
    "names = entries[0:500:5]\n",
    "phones = entries[1:500:5]\n",
    "addresses = entries[2:500:5]\n",
    "emails = entries[3:500:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_names, last_names = np.array([name.split(' ') for name in names]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "street_addresses, locales = np.array([address.split(', ') for address in addresses]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = [word for locale in locales for word in locale.split()]\n",
    "cities = tokenized[0:300:3]\n",
    "states = tokenized[1:300:3]\n",
    "zip_codes = tokenized[2:300:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts = pd.DataFrame({\n",
    "    'First Name': first_names,\n",
    "    'Last Name': last_names,\n",
    "    'Email': emails,\n",
    "    'Phone Number': phones,\n",
    "    'Steet Address': street_addresses,\n",
    "    'City': cities,\n",
    "    'State': states,\n",
    "    'Zipcode': zip_codes\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Email</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>State</th>\n",
       "      <th>Steet Address</th>\n",
       "      <th>Zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Springfield</td>\n",
       "      <td>davemartin@bogusemail.com</td>\n",
       "      <td>Dave</td>\n",
       "      <td>Martin</td>\n",
       "      <td>615-555-7164</td>\n",
       "      <td>RI</td>\n",
       "      <td>173 Main St.</td>\n",
       "      <td>55924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Atlantis</td>\n",
       "      <td>charlesharris@bogusemail.com</td>\n",
       "      <td>Charles</td>\n",
       "      <td>Harris</td>\n",
       "      <td>800-555-5669</td>\n",
       "      <td>VA</td>\n",
       "      <td>969 High St.</td>\n",
       "      <td>34075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Faketown</td>\n",
       "      <td>laurawilliams@bogusemail.com</td>\n",
       "      <td>Eric</td>\n",
       "      <td>Williams</td>\n",
       "      <td>560-555-5153</td>\n",
       "      <td>AK</td>\n",
       "      <td>806 1st St.</td>\n",
       "      <td>86847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Epicburg</td>\n",
       "      <td>coreyjefferson@bogusemail.com</td>\n",
       "      <td>Corey</td>\n",
       "      <td>Jefferson</td>\n",
       "      <td>900-555-9340</td>\n",
       "      <td>NE</td>\n",
       "      <td>826 Elm St.</td>\n",
       "      <td>10671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sunnydale</td>\n",
       "      <td>jenniferwhite@bogusemail.com</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Martin-White</td>\n",
       "      <td>714-555-7405</td>\n",
       "      <td>CT</td>\n",
       "      <td>212 Cedar St.</td>\n",
       "      <td>74983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          City                          Email First Name     Last Name  \\\n",
       "0  Springfield      davemartin@bogusemail.com       Dave        Martin   \n",
       "1     Atlantis   charlesharris@bogusemail.com    Charles        Harris   \n",
       "2     Faketown   laurawilliams@bogusemail.com       Eric      Williams   \n",
       "3     Epicburg  coreyjefferson@bogusemail.com      Corey     Jefferson   \n",
       "4    Sunnydale   jenniferwhite@bogusemail.com   Jennifer  Martin-White   \n",
       "\n",
       "   Phone Number State  Steet Address Zipcode  \n",
       "0  615-555-7164    RI   173 Main St.   55924  \n",
       "1  800-555-5669    VA   969 High St.   34075  \n",
       "2  560-555-5153    AK    806 1st St.   86847  \n",
       "3  900-555-9340    NE    826 Elm St.   10671  \n",
       "4  714-555-7405    CT  212 Cedar St.   74983  "
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contacts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "udWbMfZdimhT"
   },
   "source": [
    "# 3. Web Scraping + Pandas\n",
    "\n",
    "Scrape the unordered list of information about Ohio University President's salaries from this article: \n",
    "[Ohio Private University President's Salaries](https://www.cleveland.com/metro/2017/12/case_western_reserve_university_president_barbara_snyders_base_salary_and_bonus_pay_tops_among_private_colleges_in_ohio.html)\n",
    "\n",
    "Get the data from this webpage into a dataframe with the following headers:\n",
    "\n",
    "- First Name\n",
    "- Last Name\n",
    "- School\n",
    "- Salary\n",
    "\n",
    "Salary information should be stored as an integer and not have \"$\" or commas \",\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cRq2bzEfjdLY"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.cleveland.com/metro/2017/12/case_western_reserve_university_president_barbara_snyders_base_salary_and_bonus_pay_tops_among_private_colleges_in_ohio.html\"\n",
    "html = requests.get(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = BeautifulSoup(html, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = [li.text for li in document.main.article.ul.children if li != ' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions, amounts = np.array([salary.split('$') for salary in salaries]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist if item != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "presidents_and_universities = flatten([[word.replace(':', '').strip() for word in re.sub('\\((\\w*|\\s)+\\)', '', desc).strip().split(',')] for desc in descriptions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "presidents = presidents_and_universities[0:34:2]\n",
    "universities = presidents_and_universities[1:34:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [name for president in presidents for name in president.split(\" \")]\n",
    "first_names = names[0:34:2]\n",
    "last_names = names[1:34:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = pd.DataFrame({\n",
    "    'First Name': first_names,\n",
    "    'Last Name': last_names,\n",
    "    'School': universities,\n",
    "    'Salary': amounts\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Salary</th>\n",
       "      <th>School</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grant</td>\n",
       "      <td>Cornwell</td>\n",
       "      <td>911,651</td>\n",
       "      <td>College of Wooster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marvin</td>\n",
       "      <td>Krislov</td>\n",
       "      <td>829,913</td>\n",
       "      <td>Oberlin College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mark</td>\n",
       "      <td>Roosevelt</td>\n",
       "      <td>507,672</td>\n",
       "      <td>Antioch College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Laurie</td>\n",
       "      <td>Joyner</td>\n",
       "      <td>463,504</td>\n",
       "      <td>Wittenberg University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Richard</td>\n",
       "      <td>Giese</td>\n",
       "      <td>453,800</td>\n",
       "      <td>University of Mount Union</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sean</td>\n",
       "      <td>Decatur</td>\n",
       "      <td>451,698</td>\n",
       "      <td>Kenyon College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adam</td>\n",
       "      <td>Weinberg</td>\n",
       "      <td>435,322</td>\n",
       "      <td>Denison University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Daniel</td>\n",
       "      <td>Dibiasio</td>\n",
       "      <td>414,716</td>\n",
       "      <td>Ohio Northern University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Denvy</td>\n",
       "      <td>Bowman</td>\n",
       "      <td>388,570</td>\n",
       "      <td>Capital University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Anne</td>\n",
       "      <td>Steele</td>\n",
       "      <td>384,233</td>\n",
       "      <td>Muskingum University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kathy</td>\n",
       "      <td>Krendl</td>\n",
       "      <td>378,035</td>\n",
       "      <td>Otterbein University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Rockwell</td>\n",
       "      <td>Jones</td>\n",
       "      <td>366,625</td>\n",
       "      <td>Ohio Wesleyan University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Robert</td>\n",
       "      <td>Helmer</td>\n",
       "      <td>365,616</td>\n",
       "      <td>Baldwin Wallace University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Robert</td>\n",
       "      <td>Huntington</td>\n",
       "      <td>300,005</td>\n",
       "      <td>Heidelberg University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lori</td>\n",
       "      <td>Varlotta</td>\n",
       "      <td>293,336</td>\n",
       "      <td>Hiram College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Joseph</td>\n",
       "      <td>Bruno</td>\n",
       "      <td>288,295</td>\n",
       "      <td>Marietta College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>W.</td>\n",
       "      <td>Richard</td>\n",
       "      <td>221,761</td>\n",
       "      <td>University of Mount Union</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   First Name   Last Name   Salary                      School\n",
       "0       Grant    Cornwell  911,651          College of Wooster\n",
       "1      Marvin     Krislov  829,913             Oberlin College\n",
       "2        Mark   Roosevelt  507,672             Antioch College\n",
       "3      Laurie      Joyner  463,504       Wittenberg University\n",
       "4     Richard       Giese  453,800   University of Mount Union\n",
       "5        Sean     Decatur  451,698              Kenyon College\n",
       "6        Adam    Weinberg  435,322          Denison University\n",
       "7      Daniel    Dibiasio  414,716    Ohio Northern University\n",
       "8       Denvy      Bowman  388,570          Capital University\n",
       "9        Anne      Steele  384,233        Muskingum University\n",
       "10      Kathy      Krendl  378,035        Otterbein University\n",
       "11   Rockwell       Jones  366,625    Ohio Wesleyan University\n",
       "12     Robert      Helmer  365,616  Baldwin Wallace University\n",
       "13     Robert  Huntington  300,005       Heidelberg University\n",
       "14       Lori    Varlotta  293,336               Hiram College\n",
       "15     Joseph       Bruno  288,295            Marietta College\n",
       "16         W.     Richard  221,761   University of Mount Union"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1dCb1q8XphcP",
    "toc-hr-collapsed": true
   },
   "source": [
    "# 4. Stretch Goals\n",
    "\n",
    "* Write a web scraper that can scrape \"Data Scientist\" job listings from indeed.com.\n",
    "* Look ahead to some of the topics from later this week:\n",
    " - Tokenization\n",
    " - Stemming\n",
    " - Lemmatization\n",
    " - Chunking\n",
    " - Part of Speech Tagging\n",
    " - Named Entity Recognition\n",
    " - Document Classification"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_421_Text_Data_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
