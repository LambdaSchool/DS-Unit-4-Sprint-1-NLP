{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Sprint Challenge\n",
    "## *Data Science Unit 4 Sprint 1*\n",
    "\n",
    "After a week of Natural Language Processing, you've learned some cool new stuff: how to process text, how turn text into vectors, and how to model topics from documents. Apply your newly acquired skills to one of the most famous NLP datasets out there: [Yelp](https://www.yelp.com/dataset/challenge). As part of the job selection process, some of my friends have been asked to create analysis of this dataset, so I want to empower you to have a head start.  \n",
    "\n",
    "The real dataset is massive (almost 8 gigs uncompressed). I've sampled the data for you to something more managable for the Sprint Challenge. You can analyze the full dataset as a stretch goal or after the sprint challenge. As you work on the challenge, I suggest adding notes about your findings and things you want to analyze in the future.\n",
    "\n",
    "## Challenge Objectives\n",
    "*Successfully complete these all these objectives to earn a 2. There are more details on each objective further down in the notebook.*\n",
    "* <a href=\"#p1\">Part 1</a>: Write a function to tokenize the yelp reviews\n",
    "* <a href=\"#p2\">Part 2</a>: Create a vector representation of those tokens\n",
    "* <a href=\"#p3\">Part 3</a>: Use your tokens in a classification model on yelp rating\n",
    "* <a href=\"#p4\">Part 4</a>: Estimate & Interpret a topic model of the Yelp reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyLDAvis in /anaconda3/lib/python3.7/site-packages (2.1.2)\n",
      "Requirement already satisfied: joblib>=0.8.4 in /anaconda3/lib/python3.7/site-packages (from pyLDAvis) (0.13.2)\n",
      "Requirement already satisfied: funcy in /anaconda3/lib/python3.7/site-packages (from pyLDAvis) (1.12)\n",
      "Requirement already satisfied: wheel>=0.23.0 in /anaconda3/lib/python3.7/site-packages (from pyLDAvis) (0.33.1)\n",
      "Requirement already satisfied: future in /anaconda3/lib/python3.7/site-packages (from pyLDAvis) (0.17.1)\n",
      "Requirement already satisfied: numpy>=1.9.2 in /anaconda3/lib/python3.7/site-packages (from pyLDAvis) (1.16.2)\n",
      "Requirement already satisfied: scipy>=0.18.0 in /anaconda3/lib/python3.7/site-packages (from pyLDAvis) (1.2.1)\n",
      "Requirement already satisfied: numexpr in /anaconda3/lib/python3.7/site-packages (from pyLDAvis) (2.6.9)\n",
      "Requirement already satisfied: pandas>=0.17.0 in /anaconda3/lib/python3.7/site-packages (from pyLDAvis) (0.24.2)\n",
      "Requirement already satisfied: pytest in /anaconda3/lib/python3.7/site-packages (from pyLDAvis) (4.3.1)\n",
      "Requirement already satisfied: jinja2>=2.7.2 in /anaconda3/lib/python3.7/site-packages (from pyLDAvis) (2.10)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /anaconda3/lib/python3.7/site-packages (from pandas>=0.17.0->pyLDAvis) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2011k in /anaconda3/lib/python3.7/site-packages (from pandas>=0.17.0->pyLDAvis) (2018.9)\n",
      "Requirement already satisfied: py>=1.5.0 in /anaconda3/lib/python3.7/site-packages (from pytest->pyLDAvis) (1.8.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /anaconda3/lib/python3.7/site-packages (from pytest->pyLDAvis) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /anaconda3/lib/python3.7/site-packages (from pytest->pyLDAvis) (40.8.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /anaconda3/lib/python3.7/site-packages (from pytest->pyLDAvis) (19.1.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /anaconda3/lib/python3.7/site-packages (from pytest->pyLDAvis) (1.3.0)\n",
      "Requirement already satisfied: pluggy>=0.7 in /anaconda3/lib/python3.7/site-packages (from pytest->pyLDAvis) (0.9.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /anaconda3/lib/python3.7/site-packages (from pytest->pyLDAvis) (6.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /anaconda3/lib/python3.7/site-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n",
      "Requirement already satisfied: gensim in /anaconda3/lib/python3.7/site-packages (3.8.0)\n",
      "Requirement already satisfied: smart-open>=1.7.0 in /anaconda3/lib/python3.7/site-packages (from gensim) (1.8.4)\n",
      "Requirement already satisfied: six>=1.5.0 in /anaconda3/lib/python3.7/site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /anaconda3/lib/python3.7/site-packages (from gensim) (1.16.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /anaconda3/lib/python3.7/site-packages (from gensim) (1.2.1)\n",
      "Requirement already satisfied: boto>=2.32 in /anaconda3/lib/python3.7/site-packages (from smart-open>=1.7.0->gensim) (2.49.0)\n",
      "Requirement already satisfied: requests in /anaconda3/lib/python3.7/site-packages (from smart-open>=1.7.0->gensim) (2.21.0)\n",
      "Requirement already satisfied: boto3 in /anaconda3/lib/python3.7/site-packages (from smart-open>=1.7.0->gensim) (1.9.187)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.7.0->gensim) (2019.3.9)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.7.0->gensim) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.7.0->gensim) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.7.0->gensim) (1.24.1)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.187 in /anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.7.0->gensim) (1.12.187)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.7.0->gensim) (0.2.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.7.0->gensim) (0.9.4)\n",
      "Requirement already satisfied: docutils>=0.10 in /anaconda3/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.187->boto3->smart-open>=1.7.0->gensim) (0.14)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /anaconda3/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.187->boto3->smart-open>=1.7.0->gensim) (2.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyLDAvis\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "yelp = pd.read_json('./data/review_sample.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nDuEqIyRc8YKS1q1fX0CZg</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-03-31 16:50:30</td>\n",
       "      <td>0</td>\n",
       "      <td>eZs2tpEJtXPwawvHnHZIgQ</td>\n",
       "      <td>1</td>\n",
       "      <td>BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...</td>\n",
       "      <td>10</td>\n",
       "      <td>n1LM36qNg4rqGXIcvVXv8w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eMYeEapscbKNqUDCx705hg</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-16 05:31:03</td>\n",
       "      <td>0</td>\n",
       "      <td>DoQDWJsNbU0KL1O29l_Xug</td>\n",
       "      <td>4</td>\n",
       "      <td>Came here for lunch Togo. Service was quick. S...</td>\n",
       "      <td>0</td>\n",
       "      <td>5CgjjDAic2-FAvCtiHpytA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6Q7-wkCPc1KF75jZLOTcMw</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-06-20 19:14:48</td>\n",
       "      <td>1</td>\n",
       "      <td>DDOdGU7zh56yQHmUnL1idQ</td>\n",
       "      <td>3</td>\n",
       "      <td>I've been to Vegas dozens of times and had nev...</td>\n",
       "      <td>2</td>\n",
       "      <td>BdV-cf3LScmb8kZ7iiBcMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k3zrItO4l9hwfLRwHBDc9w</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-07-13 00:33:45</td>\n",
       "      <td>4</td>\n",
       "      <td>LfTMUWnfGFMOfOIyJcwLVA</td>\n",
       "      <td>1</td>\n",
       "      <td>We went here on a night where they closed off ...</td>\n",
       "      <td>5</td>\n",
       "      <td>cZZnBqh4gAEy4CdNvJailQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6hpfRwGlOzbNv7k5eP9rsQ</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-30 02:30:01</td>\n",
       "      <td>0</td>\n",
       "      <td>zJSUdI7bJ8PNJAg4lnl_Gg</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5 to 4 stars\\n\\nNot bad for the price, $12.9...</td>\n",
       "      <td>5</td>\n",
       "      <td>n9QO4ClYAS7h9fpQwa5bhA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool                date  funny  \\\n",
       "0  nDuEqIyRc8YKS1q1fX0CZg     1 2015-03-31 16:50:30      0   \n",
       "1  eMYeEapscbKNqUDCx705hg     0 2015-12-16 05:31:03      0   \n",
       "2  6Q7-wkCPc1KF75jZLOTcMw     1 2010-06-20 19:14:48      1   \n",
       "3  k3zrItO4l9hwfLRwHBDc9w     3 2010-07-13 00:33:45      4   \n",
       "4  6hpfRwGlOzbNv7k5eP9rsQ     1 2018-06-30 02:30:01      0   \n",
       "\n",
       "                review_id  stars  \\\n",
       "0  eZs2tpEJtXPwawvHnHZIgQ      1   \n",
       "1  DoQDWJsNbU0KL1O29l_Xug      4   \n",
       "2  DDOdGU7zh56yQHmUnL1idQ      3   \n",
       "3  LfTMUWnfGFMOfOIyJcwLVA      1   \n",
       "4  zJSUdI7bJ8PNJAg4lnl_Gg      4   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...      10   \n",
       "1  Came here for lunch Togo. Service was quick. S...       0   \n",
       "2  I've been to Vegas dozens of times and had nev...       2   \n",
       "3  We went here on a night where they closed off ...       5   \n",
       "4  3.5 to 4 stars\\n\\nNot bad for the price, $12.9...       5   \n",
       "\n",
       "                  user_id  \n",
       "0  n1LM36qNg4rqGXIcvVXv8w  \n",
       "1  5CgjjDAic2-FAvCtiHpytA  \n",
       "2  BdV-cf3LScmb8kZ7iiBcMA  \n",
       "3  cZZnBqh4gAEy4CdNvJailQ  \n",
       "4  n9QO4ClYAS7h9fpQwa5bhA  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Tokenize Function\n",
    "<a id=\"#p1\"></a>\n",
    "\n",
    "Complete the function `tokenize`. Your function should\n",
    "- accept one document at a time\n",
    "- return a list of tokens\n",
    "\n",
    "You are free to use any method you have learned this week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = yelp['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "\n",
    "for review in tokenizer.pipe(text):\n",
    "    doc_tokens = [token.text for token in review]\n",
    "    tokens.append(doc_tokens)\n",
    "    \n",
    "yelp['tokens'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [BEWARE!!!, FAKE,, FAKE,, FAKE....We, also, ow...\n",
       "1    [Came, here, for, lunch, Togo., Service, was, ...\n",
       "2    [I've, been, to, Vegas, dozens, of, times, and...\n",
       "3    [We, went, here, on, a, night, where, they, cl...\n",
       "4    [3.5, to, 4, stars, \\n\\n, Not, bad, for, the, ...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp['tokens'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BEWARE!!!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hey Dakota, tread lightly: \n",
    "\n",
    "tokens[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Vector Representation\n",
    "<a id=\"#p2\"></a>\n",
    "1. Create a vector representation of the reviews\n",
    "2. Write a fake review and query for the 10 most similiar reviews, print the text of the reviews. Do you notice any patterns?\n",
    "    - Given the size of the dataset, it will probably be best to use a `NearestNeighbors` model for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>15</th>\n",
       "      <th>20</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>30</th>\n",
       "      <th>...</th>\n",
       "      <th>wow</th>\n",
       "      <th>write</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yelp</th>\n",
       "      <th>yes</th>\n",
       "      <th>young</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.169834</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153861</td>\n",
       "      <td>0.138843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.118308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.149121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172619</td>\n",
       "      <td>0.154652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00   10  100   11        12        15        20        24        25   30  \\\n",
       "0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.169834  0.000000  0.000000  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.153861  0.138843  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.172619  0.154652  0.000000  0.000000  0.000000  0.0   \n",
       "\n",
       "   ...  wow  write  wrong      year  years  yelp  yes     young  yum  yummy  \n",
       "0  ...  0.0    0.0    0.0  0.000000    0.0   0.0  0.0  0.000000  0.0    0.0  \n",
       "1  ...  0.0    0.0    0.0  0.000000    0.0   0.0  0.0  0.000000  0.0    0.0  \n",
       "2  ...  0.0    0.0    0.0  0.118308    0.0   0.0  0.0  0.149121  0.0    0.0  \n",
       "3  ...  0.0    0.0    0.0  0.000000    0.0   0.0  0.0  0.000000  0.0    0.0  \n",
       "4  ...  0.0    0.0    0.0  0.000000    0.0   0.0  0.0  0.000000  0.0    0.0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "\n",
    "\n",
    "dtm = tfidf.fit_transform(yelp['text'])\n",
    "\n",
    "docs = pd.DataFrame(dtm.todense(), columns = tfidf.get_feature_names())\n",
    "docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=None, n_neighbors=5, p=2, radius=1.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=5, algorithm='ball_tree')\n",
    "\n",
    "nn.fit(dtm.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 1.        , 1.        , 1.10324176, 1.12683859]]),\n",
       " array([[   1, 6204, 6311, 3134, 9490]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.kneighbors(dtm.todense()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vegan = [\"\"\"I was hoping to go on a romantic data with my \n",
    "                    girlfriend; however,it all went wrong when you \n",
    "                    guys began reiterating: 'Sir, this is a vegan restaurant,\n",
    "                    we don't serve any meat'. I was deeply offended by \n",
    "                    management's decision not to serve meat and I regret\n",
    "                    having chosen your restaurant. Not comning back.\"\"\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.        , 1.        , 1.10946087, 1.14596159, 1.16408996]]),\n",
       " array([[6311, 6204,  382, 5650, 5311]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = tfidf.transform(vegan)\n",
    "\n",
    "nn.kneighbors(new.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"I was having trouble with my laptop it was slow with viruses. I've lots of important data in my laptop. The technician was polite and very patient with me as I was freaking out how can I save my data. He saved all my data transferred it in new installed windows plus install all the needed software which I required. Took one day but job was done very well. Over all service is satisfied.\",\n",
       " \"Great food with friendly service. Place is small so be sure to make a reservation and they don't serve liquor so bring your own bottle. I don't eat meat and they were more than accommodating. I have the gnocchi (without meat) while my wife had the jumbo shrimp over penne, both were fantastic! Be sure to save room for their incredible desserts.\",\n",
       " \"Great spot for shami/ Mediterranean style food, you won't regret it. And they're well priced for the quantity they serve !! I would say it's a $.\",\n",
       " \"I gave this place only 4 stars because you pretty much have to serve yourself water but other than that this place is awesome! They have a wide selection of meat, seafood and vegetables. I didn't have a chance to try the oyster so I can't tell you if they are fresh or not. But for the price of I believe $26 for dinner, you can go wrong. So cheap for the amount and quality of food you get.\",\n",
       " 'My husband and I really enjoyed our meals!! Hubby had the beef and broccoli (requested spicy) and I had the triple delight which is jumbo shrimp, white meat chicken and beef with vegetables (also requested spicy). very good stuff!!! \\n\\nWe also ordered the wor wonton soup and it was SUPER good!! \\n\\nThe shrimp they use are HUGE and everything is FRESH, FRESH!!!\\n\\nNote, if you like white meat chicken, that the majority of their chicken dishes are white meat, but you can swap either for either (meaning dark for white or white for dark) with NO CHARGE!! My \"old\" Asian take out, as of discovering this place, charged 75 cents to upgrade to white meat even if it was a combo meat and it meant giving me three pieces of white meat, and EVERYTHING they serve is dark meat without the upgrade!\\n\\nThe portions are big. They are generous with the meat, except for the egg rolls which are mostly veggies. !\\n\\nI think they are offering a soda with the meals, as we were offered two sodas with our order.\\n\\nWe were so impressed with the packing of our to-go order!! It showed care and concern (okay LOVE) and so does the food!!!\\n\\nI noted LOTS of other menu items worth going back for, and we will be back for SURE!!')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[2661], text[5311], text[2914], text[5493], text[5614]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Classification\n",
    "<a id=\"#p3\"></a>\n",
    "Your goal in this section will be to predict `stars` from the review dataset. \n",
    "\n",
    "1. Create a piepline object with a sklearn `CountVectorizer` or `TfidfVector` and any sklearn classifier. Use that pipeline to estimate a model to predict `stars`. Use the Pipeline to predict a star rating for your fake review from Part 2. \n",
    "2. Tune the entire pipeline with a GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipeline\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "sgdc = SGDClassifier()\n",
    "\n",
    "pipe = Pipeline([('vect', vect), ('clf', sgdc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   17.5s finished\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...m_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'vect__max_df': (0.5, 1), 'clf__max_iter': (1, 5)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 1),\n",
    "    'clf__max_iter': (1, 5)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=2, n_jobs=-1, verbose=1)\n",
    "\n",
    "grid_search.fit(yelp['text'], yelp['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.5, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...m_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = grid_search.best_estimator_\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.predict(vegan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Topic Modeling\n",
    "\n",
    "Let's find out what those yelp reviews are saying! :D\n",
    "\n",
    "1. Estimate a LDA topic model of the review text\n",
    "2. Create 1-2 visualizations of the results\n",
    "    - You can use the most important 3 words of a topic in relevant visualizations. Refer to yesterday's notebook to extract. \n",
    "3. In markdown, write 1-2 paragraphs of analysis on the results of your topic model\n",
    "\n",
    "__*Note*__: You can pass the DataFrame column of text reviews to gensim. You do not have to use a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "import re\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim import corpora\n",
    "\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(yelp['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.corpora.dictionary.Dictionary at 0x122ce5320>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(STOPWORDS).union(set(['yelp']))\n",
    "\n",
    "def tokenize(text):\n",
    "    return [token for token in simple_preprocess(text) if token not in STOPWORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(307, 1), (960, 1), (2231, 1), (2242, 1), (2914, 1)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word.doc2bow(tokenize('Leaving reviews on Yelp is as good way to understand sentiment'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp['tokens'] = yelp['text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [id2word.doc2bow(text) for text in yelp['tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(17, 1),\n",
       " (22, 1),\n",
       " (25, 1),\n",
       " (27, 1),\n",
       " (28, 1),\n",
       " (29, 1),\n",
       " (34, 1),\n",
       " (37, 1),\n",
       " (38, 1),\n",
       " (39, 1),\n",
       " (40, 1),\n",
       " (41, 1),\n",
       " (42, 1),\n",
       " (43, 1),\n",
       " (44, 1),\n",
       " (45, 2),\n",
       " (47, 1),\n",
       " (51, 3),\n",
       " (54, 1),\n",
       " (55, 2),\n",
       " (56, 1),\n",
       " (58, 1),\n",
       " (59, 1),\n",
       " (61, 1),\n",
       " (65, 1),\n",
       " (67, 1),\n",
       " (69, 1),\n",
       " (927, 3),\n",
       " (6970, 1),\n",
       " (12287, 1),\n",
       " (14686, 1),\n",
       " (18275, 1),\n",
       " (25022, 1),\n",
       " (26440, 1),\n",
       " (34924, 1),\n",
       " (66253, 1)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaMulticore(corpus=corpus,\n",
    "                   id2word=id2word,\n",
    "                   random_state=42,\n",
    "                   num_topics =5,\n",
    "                   passes=10,\n",
    "                   workers=4\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.009*\"time\" + 0.008*\"service\" + 0.006*\"great\" + 0.006*\"like\" + 0.005*\"room\" + 0.005*\"said\" + 0.005*\"place\" + 0.005*\"got\" + 0.004*\"told\" + 0.004*\"staff\"'),\n",
       " (1,\n",
       "  '0.017*\"place\" + 0.013*\"food\" + 0.012*\"great\" + 0.012*\"good\" + 0.010*\"like\" + 0.006*\"service\" + 0.006*\"friendly\" + 0.006*\"pizza\" + 0.005*\"nice\" + 0.005*\"best\"'),\n",
       " (2,\n",
       "  '0.008*\"place\" + 0.007*\"time\" + 0.005*\"great\" + 0.004*\"people\" + 0.004*\"love\" + 0.004*\"know\" + 0.003*\"service\" + 0.003*\"come\" + 0.003*\"work\" + 0.003*\"like\"'),\n",
       " (3,\n",
       "  '0.017*\"food\" + 0.014*\"good\" + 0.010*\"place\" + 0.009*\"great\" + 0.008*\"service\" + 0.007*\"like\" + 0.007*\"time\" + 0.006*\"ordered\" + 0.006*\"chicken\" + 0.006*\"restaurant\"'),\n",
       " (4,\n",
       "  '0.006*\"great\" + 0.004*\"best\" + 0.004*\"la\" + 0.003*\"vegas\" + 0.003*\"et\" + 0.003*\"le\" + 0.002*\"like\" + 0.002*\"bike\" + 0.002*\"love\" + 0.002*\"les\"')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [re.findall(r'\"([^\"]*)\"',t[1]) for t in lda.print_topics()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [' '.join(t[0:5]) for t in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time service great like room',\n",
       " 'place food great good like',\n",
       " 'place time great people love',\n",
       " 'food good place great service',\n",
       " 'great best la vegas et']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "topic modeling analysis: \n",
    "\n",
    "From our topic modeling analysis, filtering by the top 3 highest probability words per topic, ther are a few interesting observations, namely: most topics contain positive descriptive adjectives, and the word food)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "distro = [lda[d] for d in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0.98099184)],\n",
       " [(0, 0.18687133),\n",
       "  (1, 0.7662311),\n",
       "  (2, 0.015611162),\n",
       "  (3, 0.015841657),\n",
       "  (4, 0.015444708)],\n",
       " [(0, 0.9903656)],\n",
       " [(0, 0.9568367),\n",
       "  (1, 0.010821961),\n",
       "  (2, 0.010720318),\n",
       "  (3, 0.010910774),\n",
       "  (4, 0.010710214)],\n",
       " [(1, 0.23023622), (3, 0.7556374)],\n",
       " [(1, 0.44098842), (3, 0.5362356)],\n",
       " [(0, 0.2999815), (2, 0.37734058), (3, 0.31507373)],\n",
       " [(1, 0.10150025), (2, 0.06211213), (3, 0.8194151)],\n",
       " [(0, 0.7427818), (3, 0.2497564)],\n",
       " [(0, 0.38036644), (3, 0.6011383)],\n",
       " [(1, 0.223496), (3, 0.77064836)],\n",
       " [(0, 0.99626297)],\n",
       " [(3, 0.96119696)],\n",
       " [(0, 0.08629222), (3, 0.89021254)],\n",
       " [(0, 0.99311906)],\n",
       " [(0, 0.049564052), (1, 0.30003592), (3, 0.642633)],\n",
       " [(0, 0.2866799), (1, 0.4532707), (3, 0.24966829)],\n",
       " [(3, 0.97350895)],\n",
       " [(0, 0.9797213)],\n",
       " [(0, 0.08129627), (1, 0.37283462), (3, 0.54145366)],\n",
       " [(1, 0.23307608), (3, 0.75282246)],\n",
       " [(0, 0.2674886), (1, 0.48930487), (2, 0.12044815), (3, 0.11914306)],\n",
       " [(0, 0.40490103), (1, 0.18911642), (2, 0.042255513), (3, 0.36249226)],\n",
       " [(2, 0.13358264), (3, 0.84925383)],\n",
       " [(0, 0.014534388),\n",
       "  (1, 0.014623645),\n",
       "  (2, 0.014436516),\n",
       "  (3, 0.9420305),\n",
       "  (4, 0.0143749695)],\n",
       " [(0, 0.213257), (1, 0.7702224)],\n",
       " [(0, 0.56694216),\n",
       "  (1, 0.01160846),\n",
       "  (2, 0.01134892),\n",
       "  (3, 0.33626807),\n",
       "  (4, 0.073832355)],\n",
       " [(1, 0.601436), (3, 0.37726238)],\n",
       " [(3, 0.96738476)],\n",
       " [(0, 0.011338268),\n",
       "  (1, 0.011365655),\n",
       "  (2, 0.011261132),\n",
       "  (3, 0.9548882),\n",
       "  (4, 0.011146789)],\n",
       " [(0, 0.6436528), (1, 0.3471669)],\n",
       " [(0, 0.02106609),\n",
       "  (1, 0.91820353),\n",
       "  (2, 0.020243466),\n",
       "  (3, 0.020324668),\n",
       "  (4, 0.020162223)],\n",
       " [(0, 0.10750679), (1, 0.35264137), (3, 0.18670182), (4, 0.3515873)],\n",
       " [(0, 0.09036423), (1, 0.8803158)],\n",
       " [(0, 0.4713579), (1, 0.1630957), (4, 0.35119864)],\n",
       " [(0, 0.64011157), (1, 0.34839603)],\n",
       " [(0, 0.36539677), (1, 0.49253753), (2, 0.1361462)],\n",
       " [(0, 0.97477853)],\n",
       " [(1, 0.574073), (2, 0.047550693), (3, 0.3663902)],\n",
       " [(1, 0.6896044), (3, 0.3023215)],\n",
       " [(0, 0.7514789), (1, 0.17451797), (4, 0.05873656)],\n",
       " [(1, 0.98719186)],\n",
       " [(1, 0.24779238), (3, 0.7380217)],\n",
       " [(0, 0.60510504), (3, 0.381805)],\n",
       " [(0, 0.010245846),\n",
       "  (1, 0.010249028),\n",
       "  (2, 0.4262419),\n",
       "  (3, 0.54314613),\n",
       "  (4, 0.010117067)],\n",
       " [(2, 0.08889937), (3, 0.9058432)],\n",
       " [(0, 0.70010406), (1, 0.13118033), (4, 0.16332509)],\n",
       " [(0, 0.016090615),\n",
       "  (1, 0.9369785),\n",
       "  (2, 0.015631666),\n",
       "  (3, 0.015861744),\n",
       "  (4, 0.015437449)],\n",
       " [(0, 0.6605248), (2, 0.32496285)],\n",
       " [(0, 0.010100617),\n",
       "  (1, 0.9594939),\n",
       "  (2, 0.010049898),\n",
       "  (3, 0.010310351),\n",
       "  (4, 0.010045198)],\n",
       " [(0, 0.01202185),\n",
       "  (1, 0.012763406),\n",
       "  (2, 0.011920615),\n",
       "  (3, 0.9505806),\n",
       "  (4, 0.0127135385)],\n",
       " [(0, 0.15180033), (1, 0.5674736), (3, 0.27714536)],\n",
       " [(1, 0.24599123), (3, 0.7467422)],\n",
       " [(0, 0.010897606),\n",
       "  (1, 0.12255202),\n",
       "  (2, 0.010710148),\n",
       "  (3, 0.8452332),\n",
       "  (4, 0.010607022)],\n",
       " [(1, 0.085416764), (3, 0.9066252)],\n",
       " [(1, 0.48623797), (3, 0.49906784)],\n",
       " [(3, 0.9728212)],\n",
       " [(0, 0.99277186)],\n",
       " [(0, 0.02280644),\n",
       "  (1, 0.9095317),\n",
       "  (2, 0.02267777),\n",
       "  (3, 0.022619728),\n",
       "  (4, 0.022364333)],\n",
       " [(1, 0.16823049), (3, 0.82616436)],\n",
       " [(3, 0.97738105)],\n",
       " [(0, 0.6497737), (2, 0.2843892), (4, 0.06068719)],\n",
       " [(0, 0.5586786),\n",
       "  (1, 0.4007489),\n",
       "  (2, 0.013521789),\n",
       "  (3, 0.013657044),\n",
       "  (4, 0.013393652)],\n",
       " [(3, 0.9915281)],\n",
       " [(1, 0.12829486), (3, 0.8653125)],\n",
       " [(1, 0.9873492)],\n",
       " [(0, 0.97921956)],\n",
       " [(1, 0.8649756), (3, 0.124362655)],\n",
       " [(0, 0.84046406),\n",
       "  (1, 0.115212515),\n",
       "  (2, 0.014650434),\n",
       "  (3, 0.014943393),\n",
       "  (4, 0.014729612)],\n",
       " [(0, 0.19783363), (3, 0.77953225)],\n",
       " [(0, 0.7703167), (2, 0.21661451)],\n",
       " [(0, 0.14796704), (1, 0.29458326), (3, 0.54190433)],\n",
       " [(0, 0.6959097), (3, 0.1775052), (4, 0.11856134)],\n",
       " [(0, 0.9194816), (2, 0.07171662)],\n",
       " [(0, 0.6254962), (1, 0.20325814), (3, 0.15719798), (4, 0.012204777)],\n",
       " [(0, 0.2319579), (1, 0.28393826), (3, 0.47409356)],\n",
       " [(0, 0.9682211)],\n",
       " [(3, 0.98053825)],\n",
       " [(1, 0.7599481), (2, 0.21078002)],\n",
       " [(0, 0.5797179), (3, 0.4158037)],\n",
       " [(0, 0.011383831),\n",
       "  (1, 0.19608146),\n",
       "  (2, 0.011275807),\n",
       "  (3, 0.7700365),\n",
       "  (4, 0.011222365)],\n",
       " [(1, 0.08901683), (3, 0.90523535)],\n",
       " [(0, 0.08620762),\n",
       "  (1, 0.01150283),\n",
       "  (2, 0.011192244),\n",
       "  (3, 0.8794675),\n",
       "  (4, 0.011629786)],\n",
       " [(0, 0.01454645),\n",
       "  (1, 0.94196856),\n",
       "  (2, 0.014481328),\n",
       "  (3, 0.01464265),\n",
       "  (4, 0.01436099)],\n",
       " [(1, 0.3894416), (3, 0.58950514)],\n",
       " [(0, 0.9903529)],\n",
       " [(0, 0.53843373),\n",
       "  (1, 0.41050762),\n",
       "  (2, 0.017044585),\n",
       "  (3, 0.017160095),\n",
       "  (4, 0.016853984)],\n",
       " [(0, 0.2638604), (1, 0.19549765), (3, 0.53608686)],\n",
       " [(1, 0.17474666), (3, 0.8042996)],\n",
       " [(0, 0.84098536), (1, 0.14667292)],\n",
       " [(0, 0.9804578)],\n",
       " [(1, 0.07015769), (3, 0.9239907)],\n",
       " [(0, 0.21015485), (3, 0.76335216)],\n",
       " [(0, 0.8859756), (1, 0.079490215), (2, 0.027968029)],\n",
       " [(1, 0.16240928), (3, 0.8263174)],\n",
       " [(0, 0.012847973),\n",
       "  (1, 0.012802328),\n",
       "  (2, 0.012623633),\n",
       "  (3, 0.94909906),\n",
       "  (4, 0.012626991)],\n",
       " [(0, 0.053398933), (3, 0.93744)],\n",
       " [(0, 0.98635507)],\n",
       " [(3, 0.9851933)],\n",
       " [(3, 0.9830459)],\n",
       " [(0, 0.6210633), (1, 0.36480084)],\n",
       " [(0, 0.116620325), (1, 0.08595092), (3, 0.7921032)],\n",
       " [(0, 0.9773993)],\n",
       " [(1, 0.3890474), (3, 0.5944457)],\n",
       " [(0, 0.3616197), (1, 0.4448694), (2, 0.056153413), (3, 0.13497446)],\n",
       " [(0, 0.082936525), (1, 0.041152123), (3, 0.87113017)],\n",
       " [(0, 0.989329)],\n",
       " [(0, 0.013563264),\n",
       "  (1, 0.013669273),\n",
       "  (2, 0.013593603),\n",
       "  (3, 0.9457947),\n",
       "  (4, 0.013379162)],\n",
       " [(0, 0.75805277), (1, 0.1194618), (3, 0.11564689)],\n",
       " [(0, 0.018376207),\n",
       "  (1, 0.01862222),\n",
       "  (2, 0.018354692),\n",
       "  (3, 0.92641777),\n",
       "  (4, 0.018229099)],\n",
       " [(0, 0.8967869), (2, 0.084682256)],\n",
       " [(0, 0.82834786), (3, 0.15982226)],\n",
       " [(0, 0.09402094), (1, 0.88901293)],\n",
       " [(1, 0.11639326), (3, 0.8679287)],\n",
       " [(0, 0.016877115),\n",
       "  (1, 0.017164156),\n",
       "  (2, 0.016839517),\n",
       "  (3, 0.93237495),\n",
       "  (4, 0.01674424)],\n",
       " [(0, 0.01272245),\n",
       "  (1, 0.9490844),\n",
       "  (2, 0.012750897),\n",
       "  (3, 0.012836494),\n",
       "  (4, 0.012605766)],\n",
       " [(0, 0.96733063)],\n",
       " [(0, 0.96156496)],\n",
       " [(0, 0.33957818),\n",
       "  (1, 0.59949654),\n",
       "  (2, 0.020350523),\n",
       "  (3, 0.020522306),\n",
       "  (4, 0.020052392)],\n",
       " [(1, 0.27502638), (3, 0.7159594)],\n",
       " [(0, 0.8941063), (1, 0.071858615), (2, 0.032149736)],\n",
       " [(0, 0.9876952)],\n",
       " [(0, 0.8706969), (1, 0.11592321)],\n",
       " [(0, 0.018573152),\n",
       "  (1, 0.92587197),\n",
       "  (2, 0.018468129),\n",
       "  (3, 0.018738884),\n",
       "  (4, 0.018347826)],\n",
       " [(0, 0.018735008),\n",
       "  (1, 0.018607065),\n",
       "  (2, 0.018341314),\n",
       "  (3, 0.9260492),\n",
       "  (4, 0.018267436)],\n",
       " [(3, 0.9865411)],\n",
       " [(0, 0.8239611), (3, 0.1598754)],\n",
       " [(0, 0.0128371725),\n",
       "  (1, 0.012913725),\n",
       "  (2, 0.012635489),\n",
       "  (3, 0.94904304),\n",
       "  (4, 0.012570622)],\n",
       " [(0, 0.41705143),\n",
       "  (1, 0.012152299),\n",
       "  (2, 0.011990741),\n",
       "  (3, 0.54691726),\n",
       "  (4, 0.011888319)],\n",
       " [(0, 0.9698269)],\n",
       " [(0, 0.9239038), (1, 0.056908682)],\n",
       " [(0, 0.9719617)],\n",
       " [(0, 0.8845519),\n",
       "  (1, 0.010736503),\n",
       "  (2, 0.010677555),\n",
       "  (3, 0.010742543),\n",
       "  (4, 0.083291456)],\n",
       " [(1, 0.23249146), (3, 0.7486233)],\n",
       " [(3, 0.99133295)],\n",
       " [(1, 0.22972214), (2, 0.036735114), (3, 0.7228969)],\n",
       " [(1, 0.8738364), (3, 0.12104378)],\n",
       " [(0, 0.01709915),\n",
       "  (1, 0.490812),\n",
       "  (2, 0.016809188),\n",
       "  (3, 0.45851973),\n",
       "  (4, 0.016759902)],\n",
       " [(3, 0.97523284)],\n",
       " [(3, 0.9929141)],\n",
       " [(0, 0.9260163),\n",
       "  (1, 0.018730788),\n",
       "  (2, 0.018469352),\n",
       "  (3, 0.01843351),\n",
       "  (4, 0.018350082)],\n",
       " [(0, 0.94226575), (2, 0.048734784)],\n",
       " [(0, 0.7510039), (2, 0.23760706)],\n",
       " [(0, 0.9779097)],\n",
       " [(0, 0.015859764),\n",
       "  (1, 0.015728874),\n",
       "  (2, 0.015666114),\n",
       "  (3, 0.9372198),\n",
       "  (4, 0.015525491)],\n",
       " [(1, 0.20126243), (3, 0.7946159)],\n",
       " [(0, 0.78737044),\n",
       "  (1, 0.020752747),\n",
       "  (2, 0.020955713),\n",
       "  (3, 0.15079907),\n",
       "  (4, 0.020122096)],\n",
       " [(1, 0.15588398), (3, 0.8392482)],\n",
       " [(3, 0.9786836)],\n",
       " [(0, 0.98609364)],\n",
       " [(3, 0.9728178)],\n",
       " [(0, 0.022425914),\n",
       "  (1, 0.022811502),\n",
       "  (2, 0.022359895),\n",
       "  (3, 0.91002434),\n",
       "  (4, 0.022378314)],\n",
       " [(3, 0.9660887)],\n",
       " [(0, 0.010370206),\n",
       "  (1, 0.010273603),\n",
       "  (2, 0.010145829),\n",
       "  (3, 0.95910543),\n",
       "  (4, 0.010104991)],\n",
       " [(1, 0.59130853), (3, 0.33003348), (4, 0.06081623)],\n",
       " [(0, 0.98302007)],\n",
       " [(1, 0.43732616), (2, 0.103213504), (3, 0.44472066)],\n",
       " [(0, 0.4627822), (2, 0.23466451), (3, 0.28542802)],\n",
       " [(0, 0.9187228),\n",
       "  (1, 0.020379273),\n",
       "  (2, 0.020261256),\n",
       "  (3, 0.020582449),\n",
       "  (4, 0.020054232)],\n",
       " [(0, 0.3409628), (3, 0.64462423)],\n",
       " [(0, 0.015738856),\n",
       "  (1, 0.015687821),\n",
       "  (2, 0.015593311),\n",
       "  (3, 0.9375129),\n",
       "  (4, 0.015467127)],\n",
       " [(0, 0.010836408),\n",
       "  (1, 0.010858357),\n",
       "  (2, 0.010693005),\n",
       "  (3, 0.9569037),\n",
       "  (4, 0.01070857)],\n",
       " [(3, 0.98254657)],\n",
       " [(0, 0.45891723), (1, 0.12578882), (3, 0.41149482)],\n",
       " [(0, 0.5438463),\n",
       "  (1, 0.014671037),\n",
       "  (2, 0.014484374),\n",
       "  (3, 0.41170943),\n",
       "  (4, 0.015288884)],\n",
       " [(0, 0.95682144),\n",
       "  (1, 0.01068319),\n",
       "  (2, 0.010996586),\n",
       "  (3, 0.010858694),\n",
       "  (4, 0.010640125)],\n",
       " [(0, 0.9879143)],\n",
       " [(0, 0.76796484),\n",
       "  (1, 0.017547045),\n",
       "  (2, 0.017261734),\n",
       "  (3, 0.017422834),\n",
       "  (4, 0.17980357)],\n",
       " [(0, 0.23054893), (1, 0.7612888)],\n",
       " [(0, 0.84315914), (2, 0.13123515)],\n",
       " [(0, 0.011488925),\n",
       "  (1, 0.95417947),\n",
       "  (2, 0.011448399),\n",
       "  (3, 0.011533283),\n",
       "  (4, 0.011349881)],\n",
       " [(3, 0.9728413)],\n",
       " [(0, 0.012706469),\n",
       "  (1, 0.3852328),\n",
       "  (2, 0.012651256),\n",
       "  (3, 0.57679206),\n",
       "  (4, 0.012617411)],\n",
       " [(0, 0.8526458), (2, 0.13944459)],\n",
       " [(3, 0.975956)],\n",
       " [(0, 0.39167252), (3, 0.59035295)],\n",
       " [(0, 0.4533481), (3, 0.52413327)],\n",
       " [(1, 0.43941015), (3, 0.5419271)],\n",
       " [(3, 0.98400605)],\n",
       " [(0, 0.626567), (2, 0.29363817), (3, 0.064685285)],\n",
       " [(0, 0.68048453), (2, 0.29687798)],\n",
       " [(0, 0.40365568), (3, 0.57038045)],\n",
       " [(0, 0.94586015),\n",
       "  (1, 0.0135847),\n",
       "  (2, 0.01349428),\n",
       "  (3, 0.013502166),\n",
       "  (4, 0.0135586625)],\n",
       " [(0, 0.5053085), (3, 0.4889625)],\n",
       " [(0, 0.77265686), (2, 0.055252835), (3, 0.1610309)],\n",
       " [(0, 0.97739357)],\n",
       " [(0, 0.01444405),\n",
       "  (1, 0.48083526),\n",
       "  (2, 0.014444243),\n",
       "  (3, 0.47589535),\n",
       "  (4, 0.014381102)],\n",
       " [(0, 0.01094529),\n",
       "  (1, 0.0108382525),\n",
       "  (2, 0.95674753),\n",
       "  (3, 0.010781691),\n",
       "  (4, 0.010687289)],\n",
       " [(0, 0.9810915)],\n",
       " [(0, 0.012190643),\n",
       "  (1, 0.2776699),\n",
       "  (2, 0.012063576),\n",
       "  (3, 0.68614376),\n",
       "  (4, 0.011932136)],\n",
       " [(0, 0.1644934), (1, 0.7317189), (3, 0.09468374)],\n",
       " [(3, 0.9915802)],\n",
       " [(0, 0.19823815), (1, 0.20792037), (3, 0.5895544)],\n",
       " [(3, 0.97539115)],\n",
       " [(0, 0.19695492), (1, 0.100946516), (3, 0.6978157)],\n",
       " [(0, 0.9842414)],\n",
       " [(0, 0.799833), (3, 0.18220183)],\n",
       " [(2, 0.42651066), (3, 0.5559809)],\n",
       " [(0, 0.029282624), (1, 0.7822048), (2, 0.03422883), (3, 0.15322785)],\n",
       " [(0, 0.80937755),\n",
       "  (1, 0.14358579),\n",
       "  (2, 0.015674217),\n",
       "  (3, 0.015869312),\n",
       "  (4, 0.015493098)],\n",
       " [(1, 0.03063886), (3, 0.9656803)],\n",
       " [(2, 0.115102544), (3, 0.87001497)],\n",
       " [(0, 0.011419179),\n",
       "  (1, 0.95457625),\n",
       "  (2, 0.011317943),\n",
       "  (3, 0.011428549),\n",
       "  (4, 0.011258016)],\n",
       " [(0, 0.31677428), (1, 0.6698971)],\n",
       " [(0, 0.112248324), (1, 0.64259964), (2, 0.23715055)],\n",
       " [(1, 0.033587415), (3, 0.9429546)],\n",
       " [(0, 0.94143635), (1, 0.04369281)],\n",
       " [(0, 0.74780625),\n",
       "  (1, 0.014707232),\n",
       "  (2, 0.01464111),\n",
       "  (3, 0.20848486),\n",
       "  (4, 0.014360542)],\n",
       " [(0, 0.9638929)],\n",
       " [(0, 0.95729935),\n",
       "  (1, 0.01074159),\n",
       "  (2, 0.010666136),\n",
       "  (3, 0.010713029),\n",
       "  (4, 0.01057987)],\n",
       " [(0, 0.7126709), (4, 0.2766925)],\n",
       " [(0, 0.079033464), (1, 0.25840753), (3, 0.6534817)],\n",
       " [(0, 0.011264058),\n",
       "  (1, 0.011548709),\n",
       "  (2, 0.011440752),\n",
       "  (3, 0.95450723),\n",
       "  (4, 0.011239212)],\n",
       " [(0, 0.1649753),\n",
       "  (1, 0.01370007),\n",
       "  (2, 0.013671418),\n",
       "  (3, 0.79421806),\n",
       "  (4, 0.013435101)],\n",
       " [(0, 0.9161454), (2, 0.072331905)],\n",
       " [(0, 0.42408043), (1, 0.1409621), (2, 0.42756107)],\n",
       " [(0, 0.9923816)],\n",
       " [(0, 0.4633116), (3, 0.5344712)],\n",
       " [(1, 0.46038184), (3, 0.53380466)],\n",
       " [(0, 0.9518309),\n",
       "  (1, 0.012096698),\n",
       "  (2, 0.012008457),\n",
       "  (3, 0.012208808),\n",
       "  (4, 0.011855144)],\n",
       " [(1, 0.39822814), (3, 0.59423184)],\n",
       " [(0, 0.03975294), (1, 0.10351148), (3, 0.85232663)],\n",
       " [(0, 0.8775176), (3, 0.116774805)],\n",
       " [(0, 0.7716427), (2, 0.22102705)],\n",
       " [(0, 0.10173141), (3, 0.8869806)],\n",
       " [(1, 0.2524814), (3, 0.7364085)],\n",
       " [(1, 0.09415861), (3, 0.8958626)],\n",
       " [(0, 0.020241722),\n",
       "  (1, 0.9190742),\n",
       "  (2, 0.02013579),\n",
       "  (3, 0.020470532),\n",
       "  (4, 0.02007782)],\n",
       " [(0, 0.03283051), (1, 0.22427177), (3, 0.73275256)],\n",
       " [(0, 0.85885584), (2, 0.12989187)],\n",
       " [(2, 0.12325096), (3, 0.85407513)],\n",
       " [(0, 0.023283929),\n",
       "  (1, 0.022863604),\n",
       "  (2, 0.9084472),\n",
       "  (3, 0.02269241),\n",
       "  (4, 0.02271286)],\n",
       " [(0, 0.6976984), (2, 0.22144762), (3, 0.074054085)],\n",
       " [(0, 0.5220963), (3, 0.4534163)],\n",
       " [(1, 0.7218688), (3, 0.14993708), (4, 0.111049704)],\n",
       " [(0, 0.015480728),\n",
       "  (1, 0.78588593),\n",
       "  (2, 0.015459615),\n",
       "  (3, 0.16769436),\n",
       "  (4, 0.015479345)],\n",
       " [(0, 0.020483721),\n",
       "  (1, 0.9187002),\n",
       "  (2, 0.020209035),\n",
       "  (3, 0.020458583),\n",
       "  (4, 0.020148411)],\n",
       " [(0, 0.518105), (4, 0.47590503)],\n",
       " [(2, 0.0803594), (3, 0.9147388)],\n",
       " [(1, 0.06604113), (3, 0.9248334)],\n",
       " [(1, 0.31220898), (3, 0.67396706)],\n",
       " [(0, 0.6917032), (2, 0.046965756), (3, 0.24497336)],\n",
       " [(0, 0.81979084),\n",
       "  (1, 0.011391328),\n",
       "  (2, 0.011306758),\n",
       "  (3, 0.1463584),\n",
       "  (4, 0.011152729)],\n",
       " [(3, 0.98585325)],\n",
       " [(0, 0.19197108), (3, 0.80622816)],\n",
       " [(4, 0.9878869)],\n",
       " [(0, 0.9853673)],\n",
       " [(0, 0.8462762), (3, 0.14776844)],\n",
       " [(0, 0.07008136), (3, 0.9224756)],\n",
       " [(1, 0.2364945), (3, 0.752152)],\n",
       " [(1, 0.62075704), (3, 0.35130906)],\n",
       " [(3, 0.99422)],\n",
       " [(0, 0.11988265), (1, 0.051975116), (3, 0.8185903)],\n",
       " [(0, 0.9688226)],\n",
       " [(0, 0.011927084),\n",
       "  (1, 0.29963952),\n",
       "  (2, 0.011913477),\n",
       "  (3, 0.6647178),\n",
       "  (4, 0.011802098)],\n",
       " [(0, 0.4624842), (1, 0.29534993), (3, 0.22653258)],\n",
       " [(0, 0.95209473),\n",
       "  (1, 0.012037021),\n",
       "  (2, 0.011982638),\n",
       "  (3, 0.01203299),\n",
       "  (4, 0.011852659)],\n",
       " [(1, 0.22676581), (3, 0.75477195)],\n",
       " [(0, 0.053484272), (1, 0.26894405), (3, 0.67260617)],\n",
       " [(0, 0.01268938),\n",
       "  (1, 0.012878912),\n",
       "  (2, 0.08822519),\n",
       "  (3, 0.87362367),\n",
       "  (4, 0.01258284)],\n",
       " [(3, 0.9772288)],\n",
       " [(3, 0.96854377)],\n",
       " [(0, 0.41319007),\n",
       "  (1, 0.029646106),\n",
       "  (2, 0.030081816),\n",
       "  (3, 0.49682373),\n",
       "  (4, 0.030258339)],\n",
       " [(0, 0.6374584), (3, 0.35474393)],\n",
       " [(1, 0.390614), (3, 0.5897129)],\n",
       " [(0, 0.022535665),\n",
       "  (1, 0.022741098),\n",
       "  (2, 0.022363098),\n",
       "  (3, 0.9100189),\n",
       "  (4, 0.02234123)],\n",
       " [(1, 0.6605518), (3, 0.3177377)],\n",
       " [(0, 0.014449788),\n",
       "  (1, 0.9419989),\n",
       "  (2, 0.014442923),\n",
       "  (3, 0.014724514),\n",
       "  (4, 0.014383836)],\n",
       " [(0, 0.057069242), (1, 0.18155152), (3, 0.75809383)],\n",
       " [(0, 0.018947078),\n",
       "  (1, 0.01851895),\n",
       "  (2, 0.018319637),\n",
       "  (3, 0.92594033),\n",
       "  (4, 0.018274045)],\n",
       " [(0, 0.9736242)],\n",
       " [(0, 0.09094901),\n",
       "  (1, 0.10554125),\n",
       "  (2, 0.04358809),\n",
       "  (3, 0.6727531),\n",
       "  (4, 0.08716856)],\n",
       " [(0, 0.45000032), (1, 0.42278388), (3, 0.12000271)],\n",
       " [(1, 0.695793), (3, 0.30059767)],\n",
       " [(1, 0.27045515), (3, 0.7137949)],\n",
       " [(0, 0.4850034), (1, 0.33854476), (3, 0.17218514)],\n",
       " [(1, 0.10211626), (3, 0.8900303)],\n",
       " [(0, 0.043059543), (1, 0.11578033), (3, 0.83536774)],\n",
       " [(0, 0.95492613),\n",
       "  (1, 0.01132987),\n",
       "  (2, 0.0112370355),\n",
       "  (3, 0.011314153),\n",
       "  (4, 0.011192867)],\n",
       " [(0, 0.15824324), (1, 0.08289995), (3, 0.746475)],\n",
       " [(0, 0.9718482)],\n",
       " [(0, 0.014515543),\n",
       "  (1, 0.5032806),\n",
       "  (2, 0.014381121),\n",
       "  (3, 0.45338434),\n",
       "  (4, 0.014438393)],\n",
       " [(1, 0.46330628), (3, 0.5169679)],\n",
       " [(0, 0.44529253), (3, 0.55145186)],\n",
       " [(0, 0.9897564)],\n",
       " [(3, 0.9687427)],\n",
       " [(2, 0.16213447), (3, 0.80870676)],\n",
       " [(0, 0.012269363),\n",
       "  (1, 0.8754841),\n",
       "  (2, 0.0881512),\n",
       "  (3, 0.012188251),\n",
       "  (4, 0.011907026)],\n",
       " [(0, 0.07897516), (1, 0.370123), (3, 0.5469053)],\n",
       " [(1, 0.13625011), (3, 0.85771006)],\n",
       " [(1, 0.07500616), (3, 0.9126349)],\n",
       " [(0, 0.38924044), (3, 0.6054521)],\n",
       " [(3, 0.98874366)],\n",
       " [(1, 0.09175012), (3, 0.90384847)],\n",
       " [(0, 0.1642282), (3, 0.82328814)],\n",
       " [(0, 0.35899752), (1, 0.629788)],\n",
       " [(1, 0.97542524)],\n",
       " [(0, 0.9815407)],\n",
       " [(1, 0.879639), (3, 0.109937824)],\n",
       " [(0, 0.9814561)],\n",
       " [(0, 0.5931195), (3, 0.4016553)],\n",
       " [(1, 0.59898454), (3, 0.37211412)],\n",
       " [(1, 0.1930646), (3, 0.80141217)],\n",
       " [(0, 0.16557314),\n",
       "  (1, 0.020448986),\n",
       "  (2, 0.020513881),\n",
       "  (3, 0.7734124),\n",
       "  (4, 0.02005162)],\n",
       " [(3, 0.98924094)],\n",
       " [(0, 0.023141278),\n",
       "  (1, 0.909356),\n",
       "  (2, 0.022600465),\n",
       "  (3, 0.022494666),\n",
       "  (4, 0.022407612)],\n",
       " [(0, 0.057965763), (1, 0.11943943), (3, 0.8122601)],\n",
       " [(0, 0.66149026), (1, 0.31933028)],\n",
       " [(0, 0.774639), (1, 0.115658276), (4, 0.10578977)],\n",
       " [(0, 0.5856745), (1, 0.3850357)],\n",
       " [(0, 0.9797065)],\n",
       " [(1, 0.059151154), (3, 0.9341716)],\n",
       " [(0, 0.108273804), (3, 0.8624556)],\n",
       " [(0, 0.010418897),\n",
       "  (1, 0.5548452),\n",
       "  (2, 0.15862058),\n",
       "  (3, 0.26603436),\n",
       "  (4, 0.010080909)],\n",
       " [(0, 0.25773445), (3, 0.7302121)],\n",
       " [(0, 0.016995212),\n",
       "  (1, 0.017305586),\n",
       "  (2, 0.016850704),\n",
       "  (3, 0.93212605),\n",
       "  (4, 0.01672243)],\n",
       " [(1, 0.5245928), (3, 0.44611493)],\n",
       " [(2, 0.03133223), (3, 0.9098584), (4, 0.053434424)],\n",
       " [(0, 0.9296949), (4, 0.049201906)],\n",
       " [(0, 0.35997894), (1, 0.26618043), (2, 0.3607335)],\n",
       " [(0, 0.013642237),\n",
       "  (1, 0.9457776),\n",
       "  (2, 0.013577096),\n",
       "  (3, 0.01360751),\n",
       "  (4, 0.013395571)],\n",
       " [(0, 0.49019393), (3, 0.4958913)],\n",
       " [(0, 0.01580518),\n",
       "  (1, 0.015771894),\n",
       "  (2, 0.015652185),\n",
       "  (3, 0.9372165),\n",
       "  (4, 0.015554196)],\n",
       " [(3, 0.96605194)],\n",
       " [(1, 0.6022073), (3, 0.38262978)],\n",
       " [(1, 0.16831206), (3, 0.7672648), (4, 0.049249504)],\n",
       " [(3, 0.9863764)],\n",
       " [(0, 0.93856853), (2, 0.05227482)],\n",
       " [(0, 0.87682986), (3, 0.11046222)],\n",
       " [(0, 0.37837094), (1, 0.5779743), (4, 0.038327854)],\n",
       " [(1, 0.06253029), (2, 0.0656224), (3, 0.86364543)],\n",
       " [(0, 0.30920383),\n",
       "  (1, 0.010372871),\n",
       "  (2, 0.010252407),\n",
       "  (3, 0.65987885),\n",
       "  (4, 0.010292031)],\n",
       " [(0, 0.7527354), (1, 0.22976989)],\n",
       " [(1, 0.1281358), (3, 0.8474408)],\n",
       " [(0, 0.9898427)],\n",
       " [(3, 0.8758393), (4, 0.0959874)],\n",
       " [(1, 0.28966585), (3, 0.6898204)],\n",
       " [(0, 0.10953372), (1, 0.31781724), (3, 0.50900644), (4, 0.057228304)],\n",
       " [(0, 0.26884112),\n",
       "  (1, 0.01716513),\n",
       "  (2, 0.0169174),\n",
       "  (3, 0.68031704),\n",
       "  (4, 0.016759325)],\n",
       " [(1, 0.28306803), (3, 0.7024172)],\n",
       " [(1, 0.3088931), (3, 0.671356)],\n",
       " [(0, 0.012798658),\n",
       "  (1, 0.77140224),\n",
       "  (2, 0.19034271),\n",
       "  (3, 0.012920286),\n",
       "  (4, 0.012536101)],\n",
       " [(0, 0.1315684), (1, 0.22162794), (3, 0.63635516)],\n",
       " [(0, 0.012359572),\n",
       "  (1, 0.9516596),\n",
       "  (2, 0.011917965),\n",
       "  (3, 0.012210035),\n",
       "  (4, 0.011852788)],\n",
       " [(0, 0.87811536), (3, 0.10478897)],\n",
       " [(0, 0.16323839),\n",
       "  (1, 0.80094296),\n",
       "  (2, 0.011970386),\n",
       "  (3, 0.012004217),\n",
       "  (4, 0.011844004)],\n",
       " [(0, 0.010321361),\n",
       "  (1, 0.01031207),\n",
       "  (2, 0.1588072),\n",
       "  (3, 0.8103786),\n",
       "  (4, 0.010180777)],\n",
       " [(1, 0.16579778), (3, 0.8203262)],\n",
       " [(0, 0.8988049),\n",
       "  (1, 0.025445005),\n",
       "  (2, 0.02543832),\n",
       "  (3, 0.025234407),\n",
       "  (4, 0.025077395)],\n",
       " [(0, 0.9551382), (2, 0.03492699)],\n",
       " [(0, 0.013599586),\n",
       "  (1, 0.9457009),\n",
       "  (2, 0.013537063),\n",
       "  (3, 0.0137272095),\n",
       "  (4, 0.0134352585)],\n",
       " [(0, 0.27903244), (3, 0.70815915)],\n",
       " [(3, 0.9728289)],\n",
       " [(3, 0.9630824)],\n",
       " [(0, 0.011436058),\n",
       "  (1, 0.74410015),\n",
       "  (2, 0.011346277),\n",
       "  (3, 0.22193204),\n",
       "  (4, 0.011185456)],\n",
       " [(1, 0.14272591), (3, 0.85193855)],\n",
       " [(1, 0.33101425), (3, 0.65670246)],\n",
       " [(0, 0.23199718), (1, 0.5543083), (3, 0.20865409)],\n",
       " [(0, 0.5621804), (3, 0.43293715)],\n",
       " [(0, 0.21681575), (1, 0.69929117), (2, 0.07780883)],\n",
       " [(0, 0.46704212),\n",
       "  (1, 0.40998068),\n",
       "  (2, 0.04105282),\n",
       "  (3, 0.04121522),\n",
       "  (4, 0.04070917)],\n",
       " [(0, 0.9522261),\n",
       "  (1, 0.012007465),\n",
       "  (2, 0.011923014),\n",
       "  (3, 0.012007212),\n",
       "  (4, 0.011836227)],\n",
       " [(0, 0.68948793), (3, 0.2871117)],\n",
       " [(0, 0.8821212), (1, 0.10540059)],\n",
       " [(1, 0.07424554), (3, 0.9119711)],\n",
       " [(0, 0.014827685),\n",
       "  (1, 0.941134),\n",
       "  (2, 0.014721309),\n",
       "  (3, 0.01477699),\n",
       "  (4, 0.014540057)],\n",
       " [(0, 0.85023487), (2, 0.13377394)],\n",
       " [(0, 0.5036968), (3, 0.49267843)],\n",
       " [(3, 0.98362714)],\n",
       " [(0, 0.08588387), (3, 0.9025356)],\n",
       " [(0, 0.97191167)],\n",
       " [(0, 0.011397229),\n",
       "  (1, 0.84095544),\n",
       "  (2, 0.011381825),\n",
       "  (3, 0.12506521),\n",
       "  (4, 0.011200271)],\n",
       " [(0, 0.21358237),\n",
       "  (1, 0.029477494),\n",
       "  (2, 0.029553318),\n",
       "  (3, 0.69861215),\n",
       "  (4, 0.028774658)],\n",
       " [(0, 0.017273791),\n",
       "  (1, 0.017528508),\n",
       "  (2, 0.2251521),\n",
       "  (3, 0.35411042),\n",
       "  (4, 0.3859352)],\n",
       " [(0, 0.017123051),\n",
       "  (1, 0.37224934),\n",
       "  (2, 0.016884664),\n",
       "  (3, 0.576935),\n",
       "  (4, 0.016807914)],\n",
       " [(0, 0.1883701), (2, 0.06913432), (3, 0.73779947)],\n",
       " [(1, 0.40721142), (3, 0.56947994)],\n",
       " [(1, 0.32155827), (3, 0.65208656)],\n",
       " [(0, 0.90428567), (1, 0.08803309)],\n",
       " [(0, 0.2816335), (1, 0.4277883), (2, 0.27487043)],\n",
       " [(0, 0.35147044),\n",
       "  (1, 0.5875685),\n",
       "  (2, 0.020146562),\n",
       "  (3, 0.020702146),\n",
       "  (4, 0.020112343)],\n",
       " [(0, 0.016838355),\n",
       "  (1, 0.017010063),\n",
       "  (2, 0.016850168),\n",
       "  (3, 0.9325213),\n",
       "  (4, 0.016780082)],\n",
       " [(0, 0.3178295),\n",
       "  (1, 0.015738372),\n",
       "  (2, 0.015631948),\n",
       "  (3, 0.63531756),\n",
       "  (4, 0.015482662)],\n",
       " [(0, 0.98105353)],\n",
       " [(0, 0.51923555), (3, 0.46275455)],\n",
       " [(0, 0.7098614),\n",
       "  (1, 0.017111877),\n",
       "  (2, 0.017162021),\n",
       "  (3, 0.23893423),\n",
       "  (4, 0.016930457)],\n",
       " [(1, 0.6303669), (3, 0.348743)],\n",
       " [(0, 0.012141446),\n",
       "  (1, 0.012030541),\n",
       "  (2, 0.011970416),\n",
       "  (3, 0.95189095),\n",
       "  (4, 0.011966651)],\n",
       " [(0, 0.012674118),\n",
       "  (1, 0.012866996),\n",
       "  (2, 0.0127213625),\n",
       "  (3, 0.94917166),\n",
       "  (4, 0.012565824)],\n",
       " [(0, 0.06981603), (1, 0.14132239), (3, 0.787154)],\n",
       " [(1, 0.16410898), (3, 0.8310772)],\n",
       " [(1, 0.82186663), (3, 0.15564568)],\n",
       " [(0, 0.9882626)],\n",
       " [(1, 0.14384818), (2, 0.42370147), (3, 0.4274548)],\n",
       " [(0, 0.5266086),\n",
       "  (1, 0.012184097),\n",
       "  (2, 0.43720698),\n",
       "  (3, 0.01214849),\n",
       "  (4, 0.011851886)],\n",
       " [(0, 0.025270943), (1, 0.27460745), (3, 0.6963512)],\n",
       " [(0, 0.3170608), (2, 0.05075268), (3, 0.6249461)],\n",
       " [(0, 0.1732048), (3, 0.81507415)],\n",
       " [(0, 0.109660886), (1, 0.03168883), (3, 0.84582853)],\n",
       " [(1, 0.61609834), (3, 0.37695834)],\n",
       " [(1, 0.47047904), (3, 0.52173185)],\n",
       " [(3, 0.9851344)],\n",
       " [(0, 0.9171732), (2, 0.06247827)],\n",
       " [(0, 0.20716995), (3, 0.7864964)],\n",
       " [(1, 0.18208073), (3, 0.7904675)],\n",
       " [(0, 0.6254671),\n",
       "  (1, 0.012145522),\n",
       "  (2, 0.01221327),\n",
       "  (3, 0.28621918),\n",
       "  (4, 0.063954964)],\n",
       " [(0, 0.012773619),\n",
       "  (1, 0.9488186),\n",
       "  (2, 0.012982827),\n",
       "  (3, 0.01282778),\n",
       "  (4, 0.012597129)],\n",
       " [(0, 0.6204688), (2, 0.09770457), (3, 0.27811998)],\n",
       " [(1, 0.97446924)],\n",
       " [(0, 0.024305303), (3, 0.9720054)],\n",
       " [(0, 0.86053544), (1, 0.07814542), (2, 0.05764197)],\n",
       " [(3, 0.9827496)],\n",
       " [(0, 0.011212912),\n",
       "  (1, 0.9551176),\n",
       "  (2, 0.011212377),\n",
       "  (3, 0.011276105),\n",
       "  (4, 0.011181027)],\n",
       " [(0, 0.9755353)],\n",
       " [(0, 0.9842857)],\n",
       " [(3, 0.9876526)],\n",
       " [(0, 0.14836927), (1, 0.31691697), (3, 0.52828115)],\n",
       " [(0, 0.4276747),\n",
       "  (1, 0.010296934),\n",
       "  (2, 0.010150213),\n",
       "  (3, 0.54182535),\n",
       "  (4, 0.010052784)],\n",
       " [(0, 0.9240725), (3, 0.06319294)],\n",
       " [(3, 0.98267686)],\n",
       " [(0, 0.92596674),\n",
       "  (1, 0.018668532),\n",
       "  (2, 0.018468374),\n",
       "  (3, 0.018645324),\n",
       "  (4, 0.018251022)],\n",
       " [(0, 0.38405293), (3, 0.61150455)],\n",
       " [(0, 0.53622425), (3, 0.4412204)],\n",
       " [(1, 0.5498122), (3, 0.33719748), (4, 0.097883604)],\n",
       " [(0, 0.020178141),\n",
       "  (1, 0.58471006),\n",
       "  (2, 0.020184696),\n",
       "  (3, 0.35483748),\n",
       "  (4, 0.020089652)],\n",
       " [(1, 0.6146964), (3, 0.3761142)],\n",
       " [(0, 0.02021252),\n",
       "  (1, 0.9187996),\n",
       "  (2, 0.020209573),\n",
       "  (3, 0.02063122),\n",
       "  (4, 0.020147061)],\n",
       " [(0, 0.92563707), (1, 0.06647889)],\n",
       " [(0, 0.1779614), (1, 0.36424264), (3, 0.452652)],\n",
       " [(0, 0.93714684),\n",
       "  (1, 0.015753845),\n",
       "  (2, 0.015870703),\n",
       "  (3, 0.015756227),\n",
       "  (4, 0.015472429)],\n",
       " [(1, 0.18774912), (2, 0.064917564), (3, 0.73273426)],\n",
       " [(0, 0.69714147), (3, 0.27509737)],\n",
       " [(0, 0.378586), (1, 0.6068199)],\n",
       " [(0, 0.62851274), (1, 0.1916258), (3, 0.17370489)],\n",
       " [(3, 0.9741721)],\n",
       " [(1, 0.49145842), (3, 0.49689746)],\n",
       " [(0, 0.9184121),\n",
       "  (1, 0.02043387),\n",
       "  (2, 0.020531332),\n",
       "  (3, 0.0204455),\n",
       "  (4, 0.020177206)],\n",
       " [(0, 0.012875167),\n",
       "  (1, 0.9488348),\n",
       "  (2, 0.012851321),\n",
       "  (3, 0.012814699),\n",
       "  (4, 0.01262401)],\n",
       " [(3, 0.99165696)],\n",
       " [(0, 0.5823215), (3, 0.41130975)],\n",
       " [(0, 0.5667088), (2, 0.40676445)],\n",
       " [(0, 0.8731679), (1, 0.071585245), (2, 0.04842255)],\n",
       " [(1, 0.33352017), (2, 0.06747457), (3, 0.581978)],\n",
       " [(2, 0.13869539), (3, 0.840884)],\n",
       " [(0, 0.041140832), (1, 0.34626544), (3, 0.60854286)],\n",
       " [(0, 0.0150512615),\n",
       "  (1, 0.941183),\n",
       "  (2, 0.014653596),\n",
       "  (3, 0.014703214),\n",
       "  (4, 0.014408944)],\n",
       " [(1, 0.5810494), (3, 0.3982613)],\n",
       " [(0, 0.59896594), (2, 0.37967965)],\n",
       " [(3, 0.9808971)],\n",
       " [(0, 0.884338), (3, 0.10498098)],\n",
       " [(0, 0.9544847),\n",
       "  (1, 0.0114257205),\n",
       "  (2, 0.011378858),\n",
       "  (3, 0.0114263855),\n",
       "  (4, 0.01128435)],\n",
       " [(0, 0.017051931),\n",
       "  (1, 0.4394953),\n",
       "  (2, 0.016943129),\n",
       "  (3, 0.5094712),\n",
       "  (4, 0.017038478)],\n",
       " [(0, 0.010198032),\n",
       "  (1, 0.16564201),\n",
       "  (2, 0.010127458),\n",
       "  (3, 0.8039849),\n",
       "  (4, 0.010047603)],\n",
       " [(1, 0.78819764), (3, 0.20997739)],\n",
       " [(0, 0.7904047), (2, 0.18855684)],\n",
       " [(0, 0.9810554)],\n",
       " [(0, 0.014684979),\n",
       "  (1, 0.014738571),\n",
       "  (2, 0.014503843),\n",
       "  (3, 0.9416559),\n",
       "  (4, 0.014416729)],\n",
       " [(0, 0.38153514), (2, 0.17398478), (3, 0.43138468)],\n",
       " [(0, 0.025572779),\n",
       "  (1, 0.025662819),\n",
       "  (2, 0.025288077),\n",
       "  (3, 0.89831245),\n",
       "  (4, 0.025163911)],\n",
       " [(1, 0.27568808), (3, 0.71610916)],\n",
       " [(0, 0.32715458), (2, 0.19175297), (3, 0.468002)],\n",
       " [(0, 0.7355251), (2, 0.23669766)],\n",
       " [(0, 0.022439338),\n",
       "  (1, 0.022645168),\n",
       "  (2, 0.022439295),\n",
       "  (3, 0.91014814),\n",
       "  (4, 0.022328088)],\n",
       " [(1, 0.198441), (3, 0.74755806), (4, 0.040318053)],\n",
       " [(0, 0.6857987), (1, 0.08155984), (3, 0.22643617)],\n",
       " [(3, 0.9661073)],\n",
       " [(0, 0.02536543),\n",
       "  (1, 0.7760322),\n",
       "  (2, 0.14793193),\n",
       "  (3, 0.025570301),\n",
       "  (4, 0.025100116)],\n",
       " [(0, 0.83421856), (1, 0.15699452)],\n",
       " [(3, 0.910845), (4, 0.06717483)],\n",
       " [(0, 0.01840713),\n",
       "  (1, 0.018433513),\n",
       "  (2, 0.018329022),\n",
       "  (3, 0.018337723),\n",
       "  (4, 0.9264926)],\n",
       " [(0, 0.40219775), (1, 0.2071539), (3, 0.37906265)],\n",
       " [(0, 0.8052955), (2, 0.18964334)],\n",
       " [(0, 0.011925954),\n",
       "  (1, 0.012055766),\n",
       "  (2, 0.011894084),\n",
       "  (3, 0.9522821),\n",
       "  (4, 0.011842125)],\n",
       " [(0, 0.01280808),\n",
       "  (1, 0.2038851),\n",
       "  (2, 0.012628714),\n",
       "  (3, 0.7581099),\n",
       "  (4, 0.012568218)],\n",
       " [(0, 0.76692104), (2, 0.21619101)],\n",
       " [(0, 0.18859585),\n",
       "  (1, 0.27324292),\n",
       "  (2, 0.011410267),\n",
       "  (3, 0.51522607),\n",
       "  (4, 0.011524936)],\n",
       " [(3, 0.9917057)],\n",
       " [(1, 0.010654113), (3, 0.9602357)],\n",
       " [(0, 0.01858291),\n",
       "  (1, 0.018737964),\n",
       "  (2, 0.13474227),\n",
       "  (3, 0.80949205),\n",
       "  (4, 0.018444767)],\n",
       " [(3, 0.9699521)],\n",
       " [(0, 0.23922384), (3, 0.69105715), (4, 0.054425545)],\n",
       " [(0, 0.8885926), (2, 0.09783937)],\n",
       " [(0, 0.12151633), (3, 0.87144935)],\n",
       " [(0, 0.9813776)],\n",
       " [(0, 0.22773875),\n",
       "  (1, 0.7283775),\n",
       "  (2, 0.014557231),\n",
       "  (3, 0.014945858),\n",
       "  (4, 0.0143806245)],\n",
       " [(0, 0.116888955), (1, 0.4554236), (3, 0.4242412)],\n",
       " [(0, 0.010310067),\n",
       "  (1, 0.010336685),\n",
       "  (2, 0.55982584),\n",
       "  (3, 0.329849),\n",
       "  (4, 0.08967838)],\n",
       " [(0, 0.9418487),\n",
       "  (1, 0.014622408),\n",
       "  (2, 0.014603575),\n",
       "  (3, 0.014548375),\n",
       "  (4, 0.014376936)],\n",
       " [(0, 0.86313623),\n",
       "  (1, 0.011993775),\n",
       "  (2, 0.011996958),\n",
       "  (3, 0.011992074),\n",
       "  (4, 0.10088094)],\n",
       " [(0, 0.34399137), (1, 0.62671137)],\n",
       " [(1, 0.16828492), (3, 0.81846154)],\n",
       " [(1, 0.39429745), (3, 0.5896769)],\n",
       " [(3, 0.9753044)],\n",
       " [(1, 0.33079705), (2, 0.05124187), (3, 0.604268)],\n",
       " [(0, 0.90823305), (2, 0.07809963)],\n",
       " [(0, 0.9766086)],\n",
       " [(0, 0.979754)],\n",
       " [(1, 0.78058296), (3, 0.21255907)],\n",
       " [(0, 0.6127346), (2, 0.3594617)],\n",
       " [(1, 0.41771805), (3, 0.566229)],\n",
       " [(0, 0.08888441), (2, 0.03899074), (3, 0.8661926)],\n",
       " [(1, 0.60295224), (3, 0.36924127)],\n",
       " [(0, 0.9729156)],\n",
       " [(0, 0.70156974), (1, 0.28039363)],\n",
       " [(1, 0.29359847), (3, 0.6955589)],\n",
       " [(0, 0.20263533), (1, 0.72543705), (2, 0.06537391)],\n",
       " [(1, 0.07674976), (3, 0.9182175)],\n",
       " [(0, 0.056858797), (3, 0.92206526)],\n",
       " [(3, 0.9818593)],\n",
       " [(0, 0.96432406)],\n",
       " [(0, 0.9840877)],\n",
       " [(0, 0.9572289),\n",
       "  (1, 0.010723816),\n",
       "  (2, 0.010706989),\n",
       "  (3, 0.010692103),\n",
       "  (4, 0.010648207)],\n",
       " [(0, 0.9746437)],\n",
       " [(0, 0.6288561),\n",
       "  (1, 0.33707875),\n",
       "  (2, 0.011368212),\n",
       "  (3, 0.011453106),\n",
       "  (4, 0.011243791)],\n",
       " [(0, 0.013792302),\n",
       "  (1, 0.43315837),\n",
       "  (2, 0.013613913),\n",
       "  (3, 0.5258741),\n",
       "  (4, 0.013561311)],\n",
       " [(0, 0.015099288),\n",
       "  (1, 0.0147566395),\n",
       "  (2, 0.014621065),\n",
       "  (3, 0.94114774),\n",
       "  (4, 0.014375279)],\n",
       " [(0, 0.99730945)],\n",
       " [(0, 0.06526626), (3, 0.927464)],\n",
       " [(0, 0.19585373), (1, 0.54819274), (2, 0.07848954), (3, 0.17364278)],\n",
       " [(0, 0.014706585),\n",
       "  (1, 0.014690068),\n",
       "  (2, 0.014564542),\n",
       "  (3, 0.94159395),\n",
       "  (4, 0.014444851)],\n",
       " [(0, 0.058958508), (1, 0.3726618), (3, 0.56379765)],\n",
       " [(0, 0.12640743),\n",
       "  (1, 0.012835193),\n",
       "  (2, 0.012786086),\n",
       "  (3, 0.835421),\n",
       "  (4, 0.012550267)],\n",
       " [(1, 0.34310514), (2, 0.16143583), (3, 0.47917467)],\n",
       " [(0, 0.010808884),\n",
       "  (1, 0.010354344),\n",
       "  (2, 0.010278332),\n",
       "  (3, 0.95846045),\n",
       "  (4, 0.01009797)],\n",
       " [(0, 0.4842868), (1, 0.3118253), (3, 0.18464383)],\n",
       " [(0, 0.53495324), (1, 0.45261097)],\n",
       " [(0, 0.08718291), (3, 0.9006526)],\n",
       " [(0, 0.70862323), (2, 0.287459)],\n",
       " [(3, 0.98263836)],\n",
       " [(1, 0.082067154), (3, 0.9073739)],\n",
       " [(2, 0.065895006), (4, 0.9155686)],\n",
       " [(1, 0.185643), (3, 0.7807559), (4, 0.027149213)],\n",
       " [(2, 0.35930467), (3, 0.6241712)],\n",
       " [(0, 0.3139735),\n",
       "  (1, 0.40467134),\n",
       "  (2, 0.22435473),\n",
       "  (3, 0.03993481),\n",
       "  (4, 0.01706566)],\n",
       " [(0, 0.844087), (1, 0.1448009)],\n",
       " [(0, 0.08661515), (3, 0.89979076)],\n",
       " [(0, 0.9873251)],\n",
       " [(1, 0.24696912), (3, 0.7078627), (4, 0.032872405)],\n",
       " [(0, 0.41169608), (3, 0.5703267)],\n",
       " [(0, 0.8784896), (1, 0.09784121)],\n",
       " [(0, 0.01572097),\n",
       "  (1, 0.93730074),\n",
       "  (2, 0.015644353),\n",
       "  (3, 0.015806202),\n",
       "  (4, 0.015527679)],\n",
       " [(1, 0.4721084), (3, 0.5151741)],\n",
       " [(0, 0.013551953),\n",
       "  (1, 0.38194668),\n",
       "  (2, 0.01366165),\n",
       "  (3, 0.5772112),\n",
       "  (4, 0.013628541)],\n",
       " [(0, 0.016939173),\n",
       "  (1, 0.017133558),\n",
       "  (2, 0.01680204),\n",
       "  (3, 0.7075093),\n",
       "  (4, 0.241616)],\n",
       " [(0, 0.0100960955),\n",
       "  (1, 0.01022673),\n",
       "  (2, 0.010085617),\n",
       "  (3, 0.9595286),\n",
       "  (4, 0.010062945)],\n",
       " [(0, 0.04821711), (3, 0.94209796)],\n",
       " [(0, 0.012165451),\n",
       "  (1, 0.95170593),\n",
       "  (2, 0.012084506),\n",
       "  (3, 0.012069528),\n",
       "  (4, 0.011974562)],\n",
       " [(0, 0.97390604), (3, 0.015812984)],\n",
       " [(0, 0.15051673), (3, 0.8320434)],\n",
       " [(0, 0.3077519),\n",
       "  (1, 0.39670363),\n",
       "  (2, 0.014506262),\n",
       "  (3, 0.26645988),\n",
       "  (4, 0.014578314)],\n",
       " [(1, 0.960996)],\n",
       " [(0, 0.22118665), (1, 0.3126615), (3, 0.45117283)],\n",
       " [(0, 0.95492566),\n",
       "  (1, 0.011338456),\n",
       "  (2, 0.011274882),\n",
       "  (3, 0.011299112),\n",
       "  (4, 0.0111619355)],\n",
       " [(0, 0.010661895),\n",
       "  (1, 0.6010406),\n",
       "  (2, 0.010646599),\n",
       "  (3, 0.36707082),\n",
       "  (4, 0.010580132)],\n",
       " [(1, 0.32098547), (3, 0.6564159)],\n",
       " [(3, 0.9873421)],\n",
       " [(0, 0.70752376), (1, 0.19666402), (4, 0.09199858)],\n",
       " [(0, 0.0135233),\n",
       "  (1, 0.013594075),\n",
       "  (2, 0.0135348765),\n",
       "  (3, 0.94586164),\n",
       "  (4, 0.013486111)],\n",
       " [(0, 0.0955787), (1, 0.25472802), (3, 0.6425596)],\n",
       " [(0, 0.49764755), (1, 0.35594997), (2, 0.06956291), (3, 0.07363117)],\n",
       " [(0, 0.9658925), (2, 0.026084986)],\n",
       " [(0, 0.34309587),\n",
       "  (1, 0.3650455),\n",
       "  (2, 0.1791264),\n",
       "  (3, 0.07748442),\n",
       "  (4, 0.035247874)],\n",
       " [(0, 0.018515201),\n",
       "  (1, 0.018826786),\n",
       "  (2, 0.018463582),\n",
       "  (3, 0.925929),\n",
       "  (4, 0.018265486)],\n",
       " [(1, 0.6472001), (3, 0.3250433)],\n",
       " [(0, 0.78212017), (1, 0.21145143)],\n",
       " [(3, 0.980611)],\n",
       " [(0, 0.085958846), (1, 0.22470936), (3, 0.68735385)],\n",
       " [(0, 0.113980606), (1, 0.86331123)],\n",
       " [(3, 0.97736734)],\n",
       " [(0, 0.049767844), (3, 0.94573283)],\n",
       " [(3, 0.98945475)],\n",
       " [(0, 0.022420933),\n",
       "  (1, 0.022702),\n",
       "  (2, 0.022417692),\n",
       "  (3, 0.91008645),\n",
       "  (4, 0.02237291)],\n",
       " [(3, 0.97685635)],\n",
       " [(0, 0.23887104), (1, 0.101236746), (3, 0.65169454)],\n",
       " [(0, 0.10836392), (1, 0.086363904), (3, 0.7978314)],\n",
       " [(0, 0.01688135),\n",
       "  (1, 0.9323107),\n",
       "  (2, 0.016855022),\n",
       "  (3, 0.0172055),\n",
       "  (4, 0.016747443)],\n",
       " [(0, 0.99186033)],\n",
       " [(3, 0.9802064)],\n",
       " [(0, 0.91244155), (1, 0.02883519), (2, 0.050734717)],\n",
       " [(0, 0.7321523), (2, 0.2528625)],\n",
       " [(0, 0.26209846),\n",
       "  (1, 0.01136907),\n",
       "  (2, 0.01125595),\n",
       "  (3, 0.5030514),\n",
       "  (4, 0.21222514)],\n",
       " [(0, 0.017351799),\n",
       "  (1, 0.017269105),\n",
       "  (2, 0.01708267),\n",
       "  (3, 0.93154675),\n",
       "  (4, 0.016749648)],\n",
       " [(0, 0.015491477),\n",
       "  (1, 0.015696108),\n",
       "  (2, 0.0155063085),\n",
       "  (3, 0.93786293),\n",
       "  (4, 0.015443177)],\n",
       " [(3, 0.97804916)],\n",
       " [(0, 0.99310815)],\n",
       " [(1, 0.41494197), (3, 0.571394)],\n",
       " [(0, 0.5516243), (3, 0.43803644)],\n",
       " [(0, 0.99202895)],\n",
       " [(0, 0.015851382),\n",
       "  (1, 0.63856506),\n",
       "  (2, 0.31436598),\n",
       "  (3, 0.015685324),\n",
       "  (4, 0.015532277)],\n",
       " [(1, 0.08396127), (3, 0.90525526)],\n",
       " [(3, 0.96627754)],\n",
       " [(0, 0.013828304),\n",
       "  (1, 0.28359506),\n",
       "  (2, 0.013798157),\n",
       "  (3, 0.67511386),\n",
       "  (4, 0.013664636)],\n",
       " [(0, 0.82068336), (2, 0.16428606)],\n",
       " [(0, 0.47622445), (1, 0.2870167), (3, 0.07542934), (4, 0.15696706)],\n",
       " [(0, 0.08373891), (1, 0.16588163), (3, 0.741167)],\n",
       " [(0, 0.04669554), (1, 0.17891245), (3, 0.7676915)],\n",
       " [(0, 0.22544529), (3, 0.74785787)],\n",
       " [(0, 0.74376565), (1, 0.168353), (3, 0.080274776)],\n",
       " [(0, 0.74580586), (3, 0.23845366)],\n",
       " [(0, 0.0137012275),\n",
       "  (1, 0.77524364),\n",
       "  (2, 0.013577744),\n",
       "  (3, 0.18401961),\n",
       "  (4, 0.013457767)],\n",
       " [(0, 0.9826311)],\n",
       " [(0, 0.9792109)],\n",
       " [(3, 0.9905982)],\n",
       " [(0, 0.17825332), (3, 0.809488)],\n",
       " [(1, 0.2769237), (3, 0.70743906)],\n",
       " [(0, 0.45819697),\n",
       "  (1, 0.21368456),\n",
       "  (2, 0.011296037),\n",
       "  (3, 0.30554292),\n",
       "  (4, 0.011279547)],\n",
       " [(0, 0.38792574),\n",
       "  (1, 0.012088059),\n",
       "  (2, 0.011886631),\n",
       "  (3, 0.57626104),\n",
       "  (4, 0.011838504)],\n",
       " [(0, 0.20881955), (3, 0.7853108)],\n",
       " [(1, 0.034450024), (3, 0.9408788)],\n",
       " [(0, 0.98188925)],\n",
       " [(0, 0.012124689),\n",
       "  (1, 0.012000688),\n",
       "  (2, 0.011937278),\n",
       "  (3, 0.95210445),\n",
       "  (4, 0.0118328845)],\n",
       " [(3, 0.9782135)],\n",
       " [(2, 0.0272793), (3, 0.96133995)],\n",
       " [(0, 0.9818777)],\n",
       " [(0, 0.057967003), (3, 0.9246727)],\n",
       " [(0, 0.03421061),\n",
       "  (1, 0.034146693),\n",
       "  (2, 0.864011),\n",
       "  (3, 0.033895295),\n",
       "  (4, 0.033736404)],\n",
       " [(0, 0.30083892), (2, 0.09701122), (3, 0.5890612)],\n",
       " [(3, 0.987688)],\n",
       " [(1, 0.24615902), (3, 0.73720187)],\n",
       " [(3, 0.9814645)],\n",
       " [(0, 0.2986068), (1, 0.67237455)],\n",
       " [(0, 0.93755287), (4, 0.04185786)],\n",
       " [(0, 0.020469218),\n",
       "  (1, 0.020637233),\n",
       "  (2, 0.020359585),\n",
       "  (3, 0.91838354),\n",
       "  (4, 0.020150444)],\n",
       " [(0, 0.016877424),\n",
       "  (1, 0.7669337),\n",
       "  (2, 0.016746314),\n",
       "  (3, 0.18272321),\n",
       "  (4, 0.016719362)],\n",
       " [(0, 0.018358735),\n",
       "  (1, 0.83125085),\n",
       "  (2, 0.018273901),\n",
       "  (3, 0.11386393),\n",
       "  (4, 0.018252544)],\n",
       " [(0, 0.77201384), (2, 0.20933215)],\n",
       " [(0, 0.6816197), (4, 0.29155746)],\n",
       " [(0, 0.9852117)],\n",
       " [(1, 0.9795974)],\n",
       " [(3, 0.9746178)],\n",
       " [(0, 0.98842114)],\n",
       " [(1, 0.45728302), (3, 0.53436065)],\n",
       " [(3, 0.9663042)],\n",
       " [(1, 0.24338824), (3, 0.74056864)],\n",
       " [(1, 0.24277505), (3, 0.73456097)],\n",
       " [(0, 0.2544885), (3, 0.67625755), (4, 0.050622504)],\n",
       " [(0, 0.31211528), (1, 0.57545847), (3, 0.10964339)],\n",
       " [(3, 0.9725537)],\n",
       " [(0, 0.14768727), (1, 0.8423134)],\n",
       " [(1, 0.6407161), (3, 0.3422265)],\n",
       " [(0, 0.7320826), (2, 0.25940052)],\n",
       " [(0, 0.0254604),\n",
       "  (1, 0.025534391),\n",
       "  (2, 0.02550479),\n",
       "  (3, 0.89836067),\n",
       "  (4, 0.025139779)],\n",
       " [(0, 0.053144183), (1, 0.3591546), (3, 0.58174324)],\n",
       " [(1, 0.38083613), (3, 0.60164094)],\n",
       " [(0, 0.9416853), (2, 0.05291411)],\n",
       " [(0, 0.9790609)],\n",
       " [(0, 0.24005134), (1, 0.7373618)],\n",
       " [(0, 0.92192113), (4, 0.06002319)],\n",
       " [(0, 0.98900586)],\n",
       " [(0, 0.081307106), (3, 0.91525334)],\n",
       " [(1, 0.5089447), (3, 0.4634218)],\n",
       " [(0, 0.53902775), (1, 0.44640538)],\n",
       " [(0, 0.097752854), (1, 0.4074177), (3, 0.48888916)],\n",
       " [(0, 0.9924354)],\n",
       " [(0, 0.9361477), (4, 0.05894524)],\n",
       " [(0, 0.010812138),\n",
       "  (1, 0.22179748),\n",
       "  (2, 0.010717344),\n",
       "  (3, 0.7460889),\n",
       "  (4, 0.010584129)],\n",
       " [(0, 0.73164076),\n",
       "  (1, 0.014645966),\n",
       "  (2, 0.014928034),\n",
       "  (3, 0.22435074),\n",
       "  (4, 0.014434503)],\n",
       " [(3, 0.9834294)],\n",
       " [(0, 0.9458064),\n",
       "  (1, 0.013639949),\n",
       "  (2, 0.0135748545),\n",
       "  (3, 0.01357628),\n",
       "  (4, 0.013402529)],\n",
       " [(0, 0.012684237),\n",
       "  (1, 0.32153085),\n",
       "  (2, 0.012634373),\n",
       "  (3, 0.640518),\n",
       "  (4, 0.012632529)],\n",
       " [(0, 0.3084345), (2, 0.11114406), (3, 0.56091297)],\n",
       " [(1, 0.17833464), (2, 0.798903)],\n",
       " [(1, 0.091041006), (3, 0.89407307)],\n",
       " [(3, 0.98212343)],\n",
       " [(0, 0.1139044), (3, 0.8783774)],\n",
       " [(0, 0.74719006), (3, 0.2259262)],\n",
       " [(0, 0.9797204)],\n",
       " [(3, 0.9862434)],\n",
       " [(0, 0.6891676), (2, 0.18091105), (3, 0.117877275)],\n",
       " [(0, 0.2112759),\n",
       "  (1, 0.010807831),\n",
       "  (2, 0.010706652),\n",
       "  (3, 0.7565805),\n",
       "  (4, 0.010629168)],\n",
       " [(0, 0.02542191),\n",
       "  (1, 0.2576358),\n",
       "  (2, 0.025533931),\n",
       "  (3, 0.666276),\n",
       "  (4, 0.0251324)],\n",
       " [(0, 0.7619956), (1, 0.22182103)],\n",
       " [(1, 0.11985312), (3, 0.87509376)],\n",
       " [(0, 0.6758012),\n",
       "  (1, 0.015705043),\n",
       "  (2, 0.27707356),\n",
       "  (3, 0.015839498),\n",
       "  (4, 0.015580622)],\n",
       " [(0, 0.47682956), (1, 0.250602), (2, 0.2658493)],\n",
       " [(1, 0.9803692)],\n",
       " [(0, 0.9645301)],\n",
       " [(0, 0.70076114), (1, 0.21062636), (4, 0.06904845)],\n",
       " [(0, 0.9768312)],\n",
       " [(1, 0.6922262), (3, 0.28331268)],\n",
       " [(0, 0.99225473)],\n",
       " [(0, 0.48924658),\n",
       "  (1, 0.4769306),\n",
       "  (2, 0.011298736),\n",
       "  (3, 0.011327812),\n",
       "  (4, 0.011196272)],\n",
       " [(3, 0.9905768)],\n",
       " [(0, 0.89379483), (2, 0.09485316)],\n",
       " [(3, 0.98078626)],\n",
       " [(0, 0.09431884), (1, 0.681525), (3, 0.20796931)],\n",
       " [(3, 0.9886965)],\n",
       " [(0, 0.9455831),\n",
       "  (1, 0.013609087),\n",
       "  (2, 0.013562031),\n",
       "  (3, 0.013861892),\n",
       "  (4, 0.013383923)],\n",
       " [(0, 0.77681535), (3, 0.21331684)],\n",
       " [(3, 0.9760267)],\n",
       " [(2, 0.4418011), (3, 0.5356159)],\n",
       " [(1, 0.4870101), (3, 0.500283)],\n",
       " [(0, 0.01127665),\n",
       "  (1, 0.62953675),\n",
       "  (2, 0.0112296),\n",
       "  (3, 0.33678195),\n",
       "  (4, 0.011175071)],\n",
       " [(1, 0.1570568), (3, 0.81780446)],\n",
       " [(1, 0.32878783), (3, 0.6584744)],\n",
       " [(0, 0.17309536), (1, 0.624929), (3, 0.19959797)],\n",
       " [(0, 0.39984903), (1, 0.57545656)],\n",
       " [(0, 0.93237275),\n",
       "  (1, 0.016889883),\n",
       "  (2, 0.016922636),\n",
       "  (3, 0.016914409),\n",
       "  (4, 0.016900338)],\n",
       " [(0, 0.9366697),\n",
       "  (1, 0.015854295),\n",
       "  (2, 0.015699752),\n",
       "  (3, 0.01619444),\n",
       "  (4, 0.015581793)],\n",
       " [(1, 0.93805826), (3, 0.056097563)],\n",
       " [(0, 0.70868695), (3, 0.2843876)],\n",
       " [(0, 0.02189884), (1, 0.084927395), (3, 0.8906819)],\n",
       " [(0, 0.015861942),\n",
       "  (1, 0.8488902),\n",
       "  (2, 0.01589535),\n",
       "  (3, 0.10381486),\n",
       "  (4, 0.015537693)],\n",
       " [(0, 0.02021063), (1, 0.49057987), (3, 0.47931007)],\n",
       " [(0, 0.9226215), (1, 0.06896585)],\n",
       " [(0, 0.9631045)],\n",
       " [(1, 0.4134247), (3, 0.5708209)],\n",
       " [(0, 0.029950382),\n",
       "  (1, 0.65221107),\n",
       "  (2, 0.25950873),\n",
       "  (3, 0.029297467),\n",
       "  (4, 0.02903234)],\n",
       " [(0, 0.02046501),\n",
       "  (1, 0.020413212),\n",
       "  (2, 0.02012382),\n",
       "  (3, 0.91889185),\n",
       "  (4, 0.020106047)],\n",
       " [(0, 0.9798752), (3, 0.015847152)],\n",
       " [(0, 0.8962483), (2, 0.08401101)],\n",
       " [(1, 0.6943294), (3, 0.27920407)],\n",
       " [(0, 0.4485089),\n",
       "  (1, 0.09846428),\n",
       "  (2, 0.014664381),\n",
       "  (3, 0.423523),\n",
       "  (4, 0.014839435)],\n",
       " [(0, 0.98900074)],\n",
       " [(1, 0.99319786)],\n",
       " [(0, 0.011360034),\n",
       "  (1, 0.011374243),\n",
       "  (2, 0.01143663),\n",
       "  (3, 0.954573),\n",
       "  (4, 0.011256148)],\n",
       " [(0, 0.12254927), (1, 0.69859266), (3, 0.09245924), (4, 0.08414858)],\n",
       " [(0, 0.1281712), (1, 0.24367103), (3, 0.61772007)],\n",
       " [(0, 0.12874636), (1, 0.21451746), (3, 0.6488114)],\n",
       " [(0, 0.5947405), (3, 0.38665372)],\n",
       " [(0, 0.01866432),\n",
       "  (1, 0.018809658),\n",
       "  (2, 0.01838516),\n",
       "  (3, 0.9258927),\n",
       "  (4, 0.018248105)],\n",
       " [(3, 0.9839734)],\n",
       " [(0, 0.5458075), (1, 0.06028), (2, 0.3901362)],\n",
       " [(0, 0.08353971), (3, 0.90941703)],\n",
       " [(0, 0.8941603), (4, 0.087163165)],\n",
       " [(0, 0.77416587),\n",
       "  (1, 0.18504563),\n",
       "  (2, 0.013749456),\n",
       "  (3, 0.013593996),\n",
       "  (4, 0.013445096)],\n",
       " [(0, 0.014645726),\n",
       "  (1, 0.014709066),\n",
       "  (2, 0.014525585),\n",
       "  (3, 0.94171876),\n",
       "  (4, 0.014400855)],\n",
       " [(0, 0.016977604),\n",
       "  (1, 0.39632815),\n",
       "  (2, 0.016964117),\n",
       "  (3, 0.5529243),\n",
       "  (4, 0.016805876)],\n",
       " [(0, 0.01839426),\n",
       "  (1, 0.9262918),\n",
       "  (2, 0.018277455),\n",
       "  (3, 0.0187396),\n",
       "  (4, 0.018296827)],\n",
       " [(0, 0.9288819), (2, 0.06062342)],\n",
       " [(1, 0.02686664), (3, 0.9487712)],\n",
       " [(0, 0.74810886), (3, 0.23785935)],\n",
       " [(1, 0.85986674), (3, 0.1295217)],\n",
       " [(0, 0.69682837), (3, 0.29431167)],\n",
       " [(0, 0.20589338),\n",
       "  (1, 0.010815367),\n",
       "  (2, 0.010679753),\n",
       "  (3, 0.7620151),\n",
       "  (4, 0.010596355)],\n",
       " [(0, 0.26327845),\n",
       "  (1, 0.25288242),\n",
       "  (2, 0.118095905),\n",
       "  (3, 0.29842523),\n",
       "  (4, 0.06731797)],\n",
       " [(0, 0.9481583),\n",
       "  (1, 0.013148887),\n",
       "  (2, 0.012802452),\n",
       "  (3, 0.013225858),\n",
       "  (4, 0.012664531)],\n",
       " [(0, 0.022719437),\n",
       "  (1, 0.90946555),\n",
       "  (2, 0.022620456),\n",
       "  (3, 0.022683602),\n",
       "  (4, 0.022510918)],\n",
       " [(1, 0.30696142), (2, 0.015540216), (3, 0.66852987)],\n",
       " [(1, 0.7113202), (3, 0.26391882)],\n",
       " [(0, 0.02032965),\n",
       "  (1, 0.02058956),\n",
       "  (2, 0.02026733),\n",
       "  (3, 0.9186842),\n",
       "  (4, 0.020129265)],\n",
       " [(0, 0.77706087), (3, 0.20127492)],\n",
       " [(0, 0.14447565), (1, 0.26367253), (3, 0.58637017)],\n",
       " [(0, 0.5437853),\n",
       "  (1, 0.42218304),\n",
       "  (2, 0.011415815),\n",
       "  (3, 0.011399101),\n",
       "  (4, 0.011216761)],\n",
       " [(0, 0.022442076),\n",
       "  (1, 0.9097149),\n",
       "  (2, 0.022400428),\n",
       "  (3, 0.023035232),\n",
       "  (4, 0.02240733)],\n",
       " [(1, 0.25307336), (2, 0.03934627), (3, 0.69905466)],\n",
       " [(0, 0.025480721),\n",
       "  (1, 0.025505306),\n",
       "  (2, 0.025962368),\n",
       "  (3, 0.8978749),\n",
       "  (4, 0.025176741)],\n",
       " [(0, 0.072546296), (1, 0.8997164)],\n",
       " [(1, 0.1865759), (3, 0.8098114)],\n",
       " [(1, 0.13316715), (3, 0.8546411)],\n",
       " [(0, 0.08042379), (3, 0.9138313)],\n",
       " [(0, 0.013502366),\n",
       "  (1, 0.013745194),\n",
       "  (2, 0.0134350285),\n",
       "  (3, 0.861615),\n",
       "  (4, 0.09770242)],\n",
       " [(0, 0.20898706), (1, 0.7341543), (4, 0.044007856)],\n",
       " [(0, 0.015948594),\n",
       "  (1, 0.015709061),\n",
       "  (2, 0.015811717),\n",
       "  (3, 0.9370977),\n",
       "  (4, 0.015432916)],\n",
       " [(1, 0.6117407), (2, 0.072981015), (3, 0.30947924)],\n",
       " [(0, 0.18918721), (3, 0.8041771)],\n",
       " [(0, 0.010310565),\n",
       "  (1, 0.5474272),\n",
       "  (2, 0.010226291),\n",
       "  (3, 0.4218514),\n",
       "  (4, 0.010184547)],\n",
       " [(0, 0.5987791), (1, 0.36732042), (3, 0.029182019)],\n",
       " [(1, 0.09330024), (3, 0.8997671)],\n",
       " [(0, 0.573777), (3, 0.4142287)],\n",
       " [(0, 0.6450941), (1, 0.06750551), (3, 0.27675506)],\n",
       " [(1, 0.112646334), (3, 0.8768095)],\n",
       " [(0, 0.94645566), (1, 0.04456366)],\n",
       " [(0, 0.08133), (3, 0.91408247)],\n",
       " [(0, 0.57444084),\n",
       "  (1, 0.013727996),\n",
       "  (2, 0.13511994),\n",
       "  (3, 0.26325747),\n",
       "  (4, 0.013453697)],\n",
       " [(0, 0.97914916)],\n",
       " [(3, 0.9827765)],\n",
       " [(0, 0.8733458), (2, 0.044948947), (3, 0.07885482)],\n",
       " [(1, 0.06995451), (3, 0.9205565)],\n",
       " [(0, 0.19060647),\n",
       "  (1, 0.010326598),\n",
       "  (2, 0.7785435),\n",
       "  (3, 0.010446625),\n",
       "  (4, 0.010076818)],\n",
       " [(1, 0.108197235), (3, 0.8673744)],\n",
       " [(0, 0.35823187), (1, 0.4953838), (2, 0.13750626)],\n",
       " [(0, 0.46989727), (3, 0.5208106)],\n",
       " [(0, 0.25973105), (1, 0.70108014), (4, 0.03244262)],\n",
       " [(0, 0.32262725), (3, 0.6674378)],\n",
       " [(1, 0.14133626), (3, 0.85538346)],\n",
       " [(0, 0.43662885),\n",
       "  (1, 0.36629456),\n",
       "  (2, 0.01875106),\n",
       "  (3, 0.16000119),\n",
       "  (4, 0.018324345)],\n",
       " [(3, 0.9615754)],\n",
       " [(0, 0.63343006), (1, 0.15065233), (3, 0.20637625)],\n",
       " [(0, 0.9743359)],\n",
       " [(1, 0.06423891), (3, 0.9314365)],\n",
       " [(0, 0.74550056), (2, 0.11761411), (3, 0.11919957)],\n",
       " [(0, 0.09654472), (3, 0.8955404)],\n",
       " [(1, 0.9840345)],\n",
       " [(0, 0.020827066),\n",
       "  (1, 0.020293612),\n",
       "  (2, 0.91812176),\n",
       "  (3, 0.020479001),\n",
       "  (4, 0.020278517)],\n",
       " [(1, 0.16692667), (3, 0.8073984)],\n",
       " [(1, 0.19158947), (3, 0.7790636)],\n",
       " [(0, 0.9878215)],\n",
       " [(0, 0.76193804), (3, 0.06707197), (4, 0.16843581)],\n",
       " [(0, 0.08149369), (1, 0.5378245), (3, 0.36613226)],\n",
       " [(1, 0.16562688), (3, 0.7954011), (4, 0.031089932)],\n",
       " [(0, 0.3505959), (3, 0.64405435)],\n",
       " [(3, 0.98235196)],\n",
       " [(3, 0.97383606)],\n",
       " [(0, 0.9646504)],\n",
       " [(0, 0.119605675), (1, 0.7151351), (3, 0.1475204)],\n",
       " [(0, 0.5396057), (1, 0.44328067)],\n",
       " [(0, 0.0131603265),\n",
       "  (1, 0.47025022),\n",
       "  (2, 0.012927067),\n",
       "  (3, 0.49079588),\n",
       "  (4, 0.012866536)],\n",
       " [(0, 0.96734774)],\n",
       " [(0, 0.072559915), (1, 0.6109546), (3, 0.31373885)],\n",
       " [(0, 0.62909), (1, 0.34286153)],\n",
       " [(0, 0.018540489),\n",
       "  (1, 0.018514726),\n",
       "  (2, 0.018337296),\n",
       "  (3, 0.9263804),\n",
       "  (4, 0.018227091)],\n",
       " [(0, 0.011398977),\n",
       "  (1, 0.95467997),\n",
       "  (2, 0.011245675),\n",
       "  (3, 0.011393347),\n",
       "  (4, 0.011282043)],\n",
       " [(0, 0.80735904), (2, 0.15745486), (3, 0.02175287)],\n",
       " [(1, 0.26482907), (3, 0.7280644)],\n",
       " [(0, 0.025157107),\n",
       "  (1, 0.025632475),\n",
       "  (2, 0.025125878),\n",
       "  (3, 0.8984995),\n",
       "  (4, 0.025585065)],\n",
       " [(0, 0.1347184),\n",
       "  (1, 0.010268033),\n",
       "  (2, 0.010103035),\n",
       "  (3, 0.8348452),\n",
       "  (4, 0.01006536)],\n",
       " [(3, 0.98019755)],\n",
       " [(0, 0.01355327),\n",
       "  (1, 0.30674213),\n",
       "  (2, 0.01352113),\n",
       "  (3, 0.65280026),\n",
       "  (4, 0.013383176)],\n",
       " [(0, 0.70650923), (1, 0.16781564), (2, 0.111494526)],\n",
       " [(0, 0.943273), (2, 0.040049758)],\n",
       " [(3, 0.96740687)],\n",
       " [(0, 0.9750815)],\n",
       " [(0, 0.011295858),\n",
       "  (1, 0.011531521),\n",
       "  (2, 0.011224948),\n",
       "  (3, 0.95471495),\n",
       "  (4, 0.011232668)],\n",
       " [(0, 0.013674702),\n",
       "  (1, 0.20610417),\n",
       "  (2, 0.013522338),\n",
       "  (3, 0.7531151),\n",
       "  (4, 0.013583671)],\n",
       " [(0, 0.13925074), (3, 0.84675467)],\n",
       " [(1, 0.92922467), (3, 0.059948407)],\n",
       " [(0, 0.022485007),\n",
       "  (1, 0.022541897),\n",
       "  (2, 0.022502204),\n",
       "  (3, 0.78721297),\n",
       "  (4, 0.14525793)],\n",
       " [(0, 0.01215002),\n",
       "  (1, 0.53480476),\n",
       "  (2, 0.0120638935),\n",
       "  (3, 0.42913625),\n",
       "  (4, 0.011845157)],\n",
       " [(0, 0.015957005),\n",
       "  (1, 0.58624905),\n",
       "  (2, 0.015930375),\n",
       "  (3, 0.36626977),\n",
       "  (4, 0.015593852)],\n",
       " [(0, 0.69667166), (1, 0.2863478)],\n",
       " [(3, 0.9835749)],\n",
       " [(3, 0.97462994)],\n",
       " [(0, 0.4889272), (3, 0.49813867)],\n",
       " [(0, 0.9772262), (1, 0.017760161)],\n",
       " [(0, 0.547177), (3, 0.44150385)],\n",
       " [(0, 0.6642081), (1, 0.314696)],\n",
       " [(0, 0.33306003), (3, 0.6504184)],\n",
       " [(0, 0.7708092), (3, 0.2229458)],\n",
       " [(0, 0.020458244),\n",
       "  (1, 0.33104247),\n",
       "  (2, 0.02056296),\n",
       "  (3, 0.6077866),\n",
       "  (4, 0.020149758)],\n",
       " [(3, 0.9918796)],\n",
       " [(0, 0.012664719),\n",
       "  (1, 0.9492155),\n",
       "  (2, 0.0126041975),\n",
       "  (3, 0.012911841),\n",
       "  (4, 0.012603774)],\n",
       " [(0, 0.7199219),\n",
       "  (1, 0.17738028),\n",
       "  (2, 0.011999364),\n",
       "  (3, 0.012159444),\n",
       "  (4, 0.078539066)],\n",
       " [(0, 0.048847396), (1, 0.3463193), (3, 0.6000138)],\n",
       " [(0, 0.8529928), (4, 0.1315053)],\n",
       " [(3, 0.9683305)],\n",
       " [(2, 0.07191626), (3, 0.91272193)],\n",
       " [(1, 0.5640819), (3, 0.4131194)],\n",
       " [(0, 0.84791666),\n",
       "  (1, 0.01383291),\n",
       "  (2, 0.013550476),\n",
       "  (3, 0.11122124),\n",
       "  (4, 0.013478706)],\n",
       " [(0, 0.25594497),\n",
       "  (1, 0.36447668),\n",
       "  (2, 0.0135964705),\n",
       "  (3, 0.35254672),\n",
       "  (4, 0.013435149)],\n",
       " [(0, 0.9825048)],\n",
       " [(0, 0.55788606), (2, 0.38393715), (3, 0.054507665)],\n",
       " [(0, 0.11004645), (1, 0.2085665), (3, 0.6779069)],\n",
       " [(0, 0.01408583),\n",
       "  (1, 0.013635303),\n",
       "  (2, 0.013672905),\n",
       "  (3, 0.811232),\n",
       "  (4, 0.14737399)],\n",
       " [(0, 0.938546), (1, 0.041970957)],\n",
       " [(3, 0.96892565)],\n",
       " [(0, 0.015515215),\n",
       "  (1, 0.93739325),\n",
       "  (2, 0.015511403),\n",
       "  (3, 0.016109612),\n",
       "  (4, 0.0154704815)],\n",
       " [(1, 0.013701989), (3, 0.98460686)],\n",
       " [(0, 0.098075405),\n",
       "  (1, 0.018793467),\n",
       "  (2, 0.018553767),\n",
       "  (3, 0.8462756),\n",
       "  (4, 0.018301755)],\n",
       " [(0, 0.84738696), (2, 0.14815697)],\n",
       " [(0, 0.010672137),\n",
       "  (1, 0.2122957),\n",
       "  (2, 0.010714858),\n",
       "  (3, 0.7557148),\n",
       "  (4, 0.010602469)],\n",
       " [(1, 0.4701099), (3, 0.52024454)],\n",
       " [(0, 0.8291455),\n",
       "  (1, 0.013595795),\n",
       "  (2, 0.013552928),\n",
       "  (3, 0.0136494795),\n",
       "  (4, 0.13005632)],\n",
       " [(0, 0.5733556), (3, 0.21133028), (4, 0.20564978)],\n",
       " [(0, 0.72572327), (2, 0.07919525), (3, 0.17570207)],\n",
       " [(0, 0.016828943),\n",
       "  (1, 0.016912697),\n",
       "  (2, 0.016977),\n",
       "  (3, 0.9325453),\n",
       "  (4, 0.016736068)],\n",
       " [(1, 0.18846577), (3, 0.80401754)],\n",
       " [(0, 0.15460753), (3, 0.8325558)],\n",
       " [(0, 0.012862218),\n",
       "  (1, 0.012646147),\n",
       "  (2, 0.012748771),\n",
       "  (3, 0.9491658),\n",
       "  (4, 0.012577073)],\n",
       " [(0, 0.015568783),\n",
       "  (1, 0.9375071),\n",
       "  (2, 0.015542727),\n",
       "  (3, 0.015939407),\n",
       "  (4, 0.015441954)],\n",
       " [(3, 0.9686587)],\n",
       " [(0, 0.013621377),\n",
       "  (1, 0.013777102),\n",
       "  (2, 0.013553379),\n",
       "  (3, 0.9455674),\n",
       "  (4, 0.013480714)],\n",
       " [(0, 0.24293801), (1, 0.64201665), (3, 0.11194445)],\n",
       " [(0, 0.01366412),\n",
       "  (1, 0.013651851),\n",
       "  (2, 0.013523053),\n",
       "  (3, 0.94568217),\n",
       "  (4, 0.013478777)],\n",
       " [(0, 0.018463474),\n",
       "  (1, 0.9260162),\n",
       "  (2, 0.018420804),\n",
       "  (3, 0.01876265),\n",
       "  (4, 0.01833683)],\n",
       " [(0, 0.9629378), (2, 0.027671792)],\n",
       " [(0, 0.94617236), (2, 0.049742486)],\n",
       " [(0, 0.6081165), (1, 0.33509097), (3, 0.05269107)],\n",
       " [(0, 0.028876761),\n",
       "  (1, 0.029260937),\n",
       "  (2, 0.028844181),\n",
       "  (3, 0.8842513),\n",
       "  (4, 0.02876686)],\n",
       " [(0, 0.029413354),\n",
       "  (1, 0.02962967),\n",
       "  (2, 0.88211066),\n",
       "  (3, 0.029998206),\n",
       "  (4, 0.028848115)],\n",
       " [(1, 0.17954904), (3, 0.80434537)],\n",
       " [(0, 0.1476781), (1, 0.027967324), (3, 0.8214175)],\n",
       " [(0, 0.4388583),\n",
       "  (1, 0.5286443),\n",
       "  (2, 0.010810695),\n",
       "  (3, 0.011028172),\n",
       "  (4, 0.010658518)],\n",
       " [(0, 0.39845887), (1, 0.2635309), (3, 0.33385977)],\n",
       " [(1, 0.33195496), (3, 0.64261156)],\n",
       " [(0, 0.43094438), (2, 0.5540371)],\n",
       " [(1, 0.02837426), (3, 0.9490656)],\n",
       " [(2, 0.07863235), (3, 0.9098307)],\n",
       " [(0, 0.014501773),\n",
       "  (1, 0.3730971),\n",
       "  (2, 0.014569848),\n",
       "  (3, 0.58344126),\n",
       "  (4, 0.014389982)],\n",
       " [(3, 0.9839767)],\n",
       " [(0, 0.9408963), (4, 0.043691155)],\n",
       " [(1, 0.98022026)],\n",
       " [(0, 0.17658202), (3, 0.79495883)],\n",
       " [(1, 0.20507099), (3, 0.76277804), (4, 0.024714028)],\n",
       " [(1, 0.11004557), (3, 0.88405895)],\n",
       " [(1, 0.09798251), (3, 0.8956115)],\n",
       " [(1, 0.5270539), (2, 0.08956454), (3, 0.3665313)],\n",
       " [(0, 0.79020333), (2, 0.20493674)],\n",
       " [(0, 0.72035575), (1, 0.25300303)],\n",
       " [(0, 0.31840423),\n",
       "  (1, 0.18807715),\n",
       "  (2, 0.013537736),\n",
       "  (3, 0.46655914),\n",
       "  (4, 0.013421738)],\n",
       " [(3, 0.9902924)],\n",
       " [(0, 0.7533022), (2, 0.06837055), (3, 0.17481354)],\n",
       " [(0, 0.018643204),\n",
       "  (1, 0.6177485),\n",
       "  (2, 0.32637808),\n",
       "  (3, 0.018715305),\n",
       "  (4, 0.01851488)],\n",
       " [(0, 0.8680149), (2, 0.117129475)],\n",
       " [(1, 0.43170333), (3, 0.54474175)],\n",
       " [(0, 0.018508889),\n",
       "  (1, 0.44084418),\n",
       "  (2, 0.018383697),\n",
       "  (3, 0.50399595),\n",
       "  (4, 0.018267272)],\n",
       " [(0, 0.9697398)],\n",
       " [(0, 0.9095114),\n",
       "  (1, 0.022771519),\n",
       "  (2, 0.022611404),\n",
       "  (3, 0.02262561),\n",
       "  (4, 0.022480072)],\n",
       " [(3, 0.97467583)],\n",
       " [(0, 0.43631458), (3, 0.5418479)],\n",
       " [(0, 0.563301), (1, 0.18672487), (3, 0.23542914)],\n",
       " [(0, 0.010762268),\n",
       "  (1, 0.010858971),\n",
       "  (2, 0.010734812),\n",
       "  (3, 0.9570342),\n",
       "  (4, 0.010609766)],\n",
       " [(1, 0.2549507), (2, 0.1778536), (3, 0.56151915)],\n",
       " [(3, 0.9825248)],\n",
       " [(3, 0.97797537)],\n",
       " [(0, 0.98720837)],\n",
       " [(0, 0.23138088), (3, 0.75908005)],\n",
       " [(0, 0.9374419),\n",
       "  (1, 0.015756454),\n",
       "  (2, 0.015639741),\n",
       "  (3, 0.015683228),\n",
       "  (4, 0.015478696)],\n",
       " [(0, 0.6504839), (2, 0.33669087)],\n",
       " [(0, 0.7245354), (1, 0.2665379)],\n",
       " [(0, 0.2295299), (3, 0.75627494)],\n",
       " [(0, 0.015910331), (3, 0.9677531)],\n",
       " [(3, 0.9779787)],\n",
       " [(0, 0.9848572)],\n",
       " [(3, 0.9895193)],\n",
       " [(0, 0.9318178),\n",
       "  (1, 0.016903676),\n",
       "  (2, 0.016896896),\n",
       "  (3, 0.01701279),\n",
       "  (4, 0.01736877)],\n",
       " [(0, 0.55423844), (1, 0.42879188)],\n",
       " [(0, 0.20780423), (1, 0.17439918), (3, 0.5983836)],\n",
       " [(1, 0.07537919), (3, 0.9124018)],\n",
       " [(3, 0.99146634)],\n",
       " [(1, 0.6666761), (2, 0.08184058), (3, 0.2377978)],\n",
       " [(0, 0.529116), (3, 0.46622652)],\n",
       " [(0, 0.09213193), (1, 0.6634937), (3, 0.23251784)],\n",
       " [(1, 0.41608727), (3, 0.5797906)],\n",
       " [(1, 0.9753025)],\n",
       " [(0, 0.57933116), (2, 0.4015707)],\n",
       " [(0, 0.2563035), (1, 0.7289946)],\n",
       " [(1, 0.7869949), (3, 0.20327197)],\n",
       " [(0, 0.57699084), (1, 0.10354102), (2, 0.30555138)],\n",
       " [(1, 0.53869486), (3, 0.4442971)],\n",
       " [(0, 0.7931748), (3, 0.18716249)],\n",
       " [(0, 0.8278182), (2, 0.035560325), (3, 0.10670832), (4, 0.027028052)],\n",
       " [(0, 0.7328897), (1, 0.19897006), (2, 0.038677763), (4, 0.025775865)],\n",
       " [(0, 0.23228458), (3, 0.7524784)],\n",
       " [(3, 0.96888393)],\n",
       " [(3, 0.9785398)],\n",
       " [(0, 0.3438507), (1, 0.027980918), (2, 0.040847912), (3, 0.58510846)],\n",
       " [(1, 0.18010703), (3, 0.81070584)],\n",
       " [(0, 0.020392092),\n",
       "  (1, 0.020392554),\n",
       "  (2, 0.020220764),\n",
       "  (3, 0.91881615),\n",
       "  (4, 0.02017845)],\n",
       " [(0, 0.26096153), (1, 0.65444404), (4, 0.0668598)],\n",
       " [(3, 0.97203827)],\n",
       " [(1, 0.2864469), (3, 0.7011204)],\n",
       " [(0, 0.08874873), (1, 0.15923737), (3, 0.745391)],\n",
       " [(1, 0.32075244), (3, 0.6693284)],\n",
       " [(0, 0.9367585), (3, 0.052800827)],\n",
       " [(4, 0.97704715)],\n",
       " [(0, 0.012407103),\n",
       "  (1, 0.01199713),\n",
       "  (2, 0.011961965),\n",
       "  (3, 0.9517296),\n",
       "  (4, 0.011904241)],\n",
       " [(1, 0.10589379), (2, 0.07813033), (3, 0.81096834)],\n",
       " [(1, 0.074810825), (3, 0.9171274)],\n",
       " [(0, 0.989267)],\n",
       " [(0, 0.16185436), (1, 0.22537865), (3, 0.60889965)],\n",
       " [(0, 0.016245773),\n",
       "  (1, 0.44076443),\n",
       "  (2, 0.016053647),\n",
       "  (3, 0.4088369),\n",
       "  (4, 0.11809925)],\n",
       " [(1, 0.9698731)],\n",
       " [(0, 0.08404101), (1, 0.07639271), (3, 0.8279409)],\n",
       " [(0, 0.018421846),\n",
       "  (1, 0.018565845),\n",
       "  (2, 0.018303493),\n",
       "  (3, 0.9264246),\n",
       "  (4, 0.018284203)],\n",
       " [(0, 0.5190427), (2, 0.46564525)],\n",
       " [(0, 0.11401633), (2, 0.04357859), (3, 0.8376994)],\n",
       " [(0, 0.62297165), (2, 0.36979437)],\n",
       " [(0, 0.695159), (1, 0.27934933)],\n",
       " [(0, 0.95718217),\n",
       "  (1, 0.010736954),\n",
       "  (2, 0.0107450755),\n",
       "  (3, 0.010678087),\n",
       "  (4, 0.010657728)],\n",
       " [(0, 0.8806893), (2, 0.09173157)],\n",
       " [(0, 0.8315102),\n",
       "  (1, 0.012059191),\n",
       "  (2, 0.13256152),\n",
       "  (3, 0.012015779),\n",
       "  (4, 0.011853311)],\n",
       " [(3, 0.986758)],\n",
       " [(0, 0.32503867),\n",
       "  (1, 0.24897762),\n",
       "  (2, 0.011354522),\n",
       "  (3, 0.40339765),\n",
       "  (4, 0.0112315575)],\n",
       " [(0, 0.018821172),\n",
       "  (1, 0.6149561),\n",
       "  (2, 0.018700631),\n",
       "  (3, 0.018648472),\n",
       "  (4, 0.32887366)],\n",
       " [(0, 0.9420245),\n",
       "  (1, 0.014490318),\n",
       "  (2, 0.014511348),\n",
       "  (3, 0.014508599),\n",
       "  (4, 0.014465155)],\n",
       " [(1, 0.19065695), (3, 0.7970931)],\n",
       " [(1, 0.9106829), (3, 0.06277746)],\n",
       " [(0, 0.9906909)],\n",
       " [(0, 0.9823885)],\n",
       " [(0, 0.014734202),\n",
       "  (1, 0.0146168955),\n",
       "  (2, 0.01452651),\n",
       "  (3, 0.9416772),\n",
       "  (4, 0.014445174)],\n",
       " [(0, 0.3501861), (1, 0.6313372)],\n",
       " [(0, 0.96601516)],\n",
       " [(1, 0.7110353), (3, 0.17992395), (4, 0.095423445)],\n",
       " [(0, 0.91814154),\n",
       "  (1, 0.020328533),\n",
       "  (2, 0.020703599),\n",
       "  (3, 0.02042852),\n",
       "  (4, 0.020397771)],\n",
       " [(0, 0.58365285), (1, 0.39635754)],\n",
       " [(0, 0.961387)],\n",
       " [(0, 0.4464418), (1, 0.26566762), (3, 0.2827879)],\n",
       " [(0, 0.32010928), (1, 0.5421465), (2, 0.124986604)],\n",
       " [(0, 0.932219),\n",
       "  (1, 0.017032715),\n",
       "  (2, 0.016945992),\n",
       "  (3, 0.017004497),\n",
       "  (4, 0.016797774)],\n",
       " [(3, 0.98491347)],\n",
       " [(1, 0.31189653), (3, 0.66764075)],\n",
       " [(2, 0.07049305), (3, 0.90836227)],\n",
       " [(0, 0.9719952)],\n",
       " [(0, 0.47680676), (1, 0.2996863), (2, 0.16067892), (4, 0.058918156)],\n",
       " [(0, 0.7520451), (2, 0.22016609)],\n",
       " [(3, 0.98115325)],\n",
       " [(0, 0.9747541)],\n",
       " [(1, 0.25356677), (2, 0.028400837), (3, 0.71487075)],\n",
       " [(0, 0.27268362), (3, 0.7192527)],\n",
       " [(0, 0.9547494),\n",
       "  (1, 0.011392635),\n",
       "  (2, 0.011296038),\n",
       "  (3, 0.011329921),\n",
       "  (4, 0.011232033)],\n",
       " [(0, 0.857101), (2, 0.12432913)],\n",
       " [(0, 0.36209503), (3, 0.63020426)],\n",
       " [(0, 0.94138056),\n",
       "  (1, 0.01477555),\n",
       "  (2, 0.014549932),\n",
       "  (3, 0.0148667395),\n",
       "  (4, 0.014427194)],\n",
       " [(0, 0.9836241)],\n",
       " [(0, 0.020343212),\n",
       "  (1, 0.9187563),\n",
       "  (2, 0.020198531),\n",
       "  (3, 0.02060192),\n",
       "  (4, 0.020099975)],\n",
       " [(0, 0.015623194),\n",
       "  (1, 0.5960056),\n",
       "  (2, 0.015639884),\n",
       "  (3, 0.35706136),\n",
       "  (4, 0.015670007)],\n",
       " [(0, 0.98705244)],\n",
       " [(0, 0.29825968),\n",
       "  (1, 0.65819526),\n",
       "  (2, 0.014517456),\n",
       "  (3, 0.01462865),\n",
       "  (4, 0.01439895)],\n",
       " [(0, 0.30479768), (1, 0.40372464), (3, 0.28284863)],\n",
       " ...]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(doc):\n",
    "        d_dist = {k:0 for k in range(0,5)}\n",
    "        for t in doc:\n",
    "            d_dist[t[0]] = t[1]\n",
    "        return d_dist\n",
    "    \n",
    "new_distro = [update(d) for d in distro]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(new_distro)\n",
    "df.columns = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time service great like room</th>\n",
       "      <th>place food great good like</th>\n",
       "      <th>place time great people love</th>\n",
       "      <th>food good place great service</th>\n",
       "      <th>great best la vegas et</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.980992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.186871</td>\n",
       "      <td>0.766231</td>\n",
       "      <td>0.015611</td>\n",
       "      <td>0.015842</td>\n",
       "      <td>0.015445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.990366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.956837</td>\n",
       "      <td>0.010822</td>\n",
       "      <td>0.010720</td>\n",
       "      <td>0.010911</td>\n",
       "      <td>0.010710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.755637</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.440988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.536236</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.299982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.377341</td>\n",
       "      <td>0.315074</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101500</td>\n",
       "      <td>0.062112</td>\n",
       "      <td>0.819415</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.742782</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.249756</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.380366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.601138</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time service great like room  place food great good like  \\\n",
       "0                      0.980992                    0.000000   \n",
       "1                      0.186871                    0.766231   \n",
       "2                      0.990366                    0.000000   \n",
       "3                      0.956837                    0.010822   \n",
       "4                      0.000000                    0.230236   \n",
       "5                      0.000000                    0.440988   \n",
       "6                      0.299982                    0.000000   \n",
       "7                      0.000000                    0.101500   \n",
       "8                      0.742782                    0.000000   \n",
       "9                      0.380366                    0.000000   \n",
       "\n",
       "   place time great people love  food good place great service  \\\n",
       "0                      0.000000                       0.000000   \n",
       "1                      0.015611                       0.015842   \n",
       "2                      0.000000                       0.000000   \n",
       "3                      0.010720                       0.010911   \n",
       "4                      0.000000                       0.755637   \n",
       "5                      0.000000                       0.536236   \n",
       "6                      0.377341                       0.315074   \n",
       "7                      0.062112                       0.819415   \n",
       "8                      0.000000                       0.249756   \n",
       "9                      0.000000                       0.601138   \n",
       "\n",
       "   great best la vegas et  \n",
       "0                0.000000  \n",
       "1                0.015445  \n",
       "2                0.000000  \n",
       "3                0.010710  \n",
       "4                0.000000  \n",
       "5                0.000000  \n",
       "6                0.000000  \n",
       "7                0.000000  \n",
       "8                0.000000  \n",
       "9                0.000000  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stars'] = yelp['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGnZJREFUeJzt3X+UHWWd5/H3h8QEiATWEAwSMDmS0QOIChn8gT8GFYw/MKiA4aCwLmczOkTHcTQHdgWdiLsDzoxzHJCdKDiIMsCiHHvHOOgI6sJxMB1+JxinDTjphF6SAWJAQQKf/aOqzaW53V1JdfXtS39e59xzq5566qnv7cPhm3rqqeeRbSIiInbXHp0OICIiulsSSURE1JJEEhERtSSRRERELUkkERFRSxJJRETUkkQSERG1JJFEREQtjSYSSYskrZfUJ+mcNsenS7qmPH6rpHll+TGS7ig/d0p6T9U2IyJifKmpN9slTQF+ARwP9AOrgdNsr2up8yfAkbY/LGkJ8B7b75e0N/A72zskHQjcCbwI8GhttrP//vt73rx5Y/4bIyKey9asWbPV9uzR6k1tMIZjgD7bGwAkXQ0sBlr/p78Y+Gy5fR1wsSTZ/k1LnT0pEkjVNp9l3rx59Pb21vs1ERGTjKRfVanXZNfWQcDGlv3+sqxtHds7gG3ALABJr5a0Frgb+HB5vEqbERExjppMJGpTNrQfbdg6tm+1fTjwh8C5kvas2GbRsLRUUq+k3i1btuxC2BERsSuaTCT9wMEt+3OBzcPVkTQV2Bd4qLWC7XuBx4AjKrY5eN5K2wttL5w9e9QuvoiI2E1NJpLVwAJJ8yVNA5YAPUPq9ABnltsnAzfadnnOVABJLwZeCtxfsc2IiBhHjT1sL0dcLQNuAKYAl9teK2kF0Gu7B7gMuFJSH8WdyJLy9NcD50h6Enga+BPbWwHatdnUb4iIiNE1Nvx3Ilm4cKEzaisiYtdIWmN74Wj18mZ7RETUkkQSERG1NPlCYkREJcuXL2dgYIA5c+Zw0UUXdTqc2EVJJBHRcQMDA2zatKnTYcRuStdWRETUkkQSERG1JJFEREQtSSQREVFLEklERNSSRBIREbUkkURERC1JJBERUUsSSURE1JJEEhERtSSRRERELUkkERFRSxJJRETUkkQSERG1JJFEREQtSSQREVFLEklERNSSRBIREbUkkURERC1JJBERUUsSSURE1JJEEhERtSSRRERELY0mEkmLJK2X1CfpnDbHp0u6pjx+q6R5ZfnxktZIurv8fnPLOT8q27yj/BzQ5G+IiIiRTW2qYUlTgEuA44F+YLWkHtvrWqqdBTxs+1BJS4ALgfcDW4ETbW+WdARwA3BQy3mn2+5tKvaIiKiusUQCHAP02d4AIOlqYDHQmkgWA58tt68DLpYk27e31FkL7Clpuu0nGow3IqLjli9fzsDAAHPmzOGiiy7qdDiVNNm1dRCwsWW/n2feVTyjju0dwDZg1pA67wNuH5JEvlZ2a50nSWMbdkRE5wwMDLBp0yYGBgY6HUplTSaSdv+D967UkXQ4RXfXH7ccP932y4E3lJ8Ptr24tFRSr6TeLVu27FLgERFRXZOJpB84uGV/LrB5uDqSpgL7Ag+V+3OB64EzbP9y8ATbm8rv7cBVFF1oz2J7pe2FthfOnj17TH5QREQ8W5OJZDWwQNJ8SdOAJUDPkDo9wJnl9snAjbYtaT/gu8C5tm8ZrCxpqqT9y+3nAe8C7mnwN0RExCgaSyTlM49lFCOu7gWutb1W0gpJ7y6rXQbMktQHfAIYHCK8DDgUOG/IMN/pwA2S7gLuADYBX2nqN0RExOiaHLWF7VXAqiFl57dsPw6c0ua8C4ALhmn26LGMMSIi6smb7RERUUujdyQR0d1+/MY3jct1fjt1Ckj8tr9/XK75pp/8uPFrTCa5I4mIiFqSSCIiopYkkoiIqCWJJCIiakkiiYiIWpJIIiKiliSSiIioJYkkIiJqSSKJiIhaRk0kkuZXKYuIiMmpyh3Jt9qUXTfWgURERHcadq4tSS8DDgf2lfTelkMzgT2bDiwiYiK5+M//z7hc55Gtj/3+ezyuueyvT6zdxkiTNr6UYuGo/YDWK20H/mvtK0dExHPCsInE9neA70h6re2fjmNMERHRRao8I/kPST+UdA+ApCMlfbrhuCIioktUSSRfAc4FngSwfRfF+usRERGVEsnetn82pGxHE8FERET3qZJItkp6CWAASScDDzQaVUREdI0qS+2eDawEXiZpE3AfcHqjUUVERNcYNZHY3gC8VdIMYA/b25sPKyIiukWVOxIAbD/WZCAREdGdMmljRETUkkQSERG1VJn99xRJ+5Tbn5b0bUlHNR9aRER0gyp3JOfZ3i7p9cDbgCuAS5sNKyIiukWVRPJU+f1O4NJyDq5pVRqXtEjSekl9ks5pc3y6pGvK47dKmleWHy9pjaS7y+83t5xzdFneJ+lLklQlloiIaEaVRLJJ0t8DpwKrJE2vcp6kKcAlwNuBw4DTJB02pNpZwMO2DwW+CFxYlm8FTrT9cuBM4MqWcy4FlgILys+iCr8hIiIaUiWRnArcACyy/QjwAuBTFc47BuizvcH274CrgcVD6iym6CqDYrGst0iS7dttby7L1wJ7lncvBwIzbf/UtoGvAydViCUiIhoyaiKx/Rvb3wa2SToEeB7w8wptHwRsbNnvL8va1rG9A9gGzBpS533A7bafKOv3j9JmRESMoypdVO+W9G8UU6P8uPz+XoW22z278K7UkXQ4RXfXH+9Cm4PnLpXUK6l3y5YtFcKNiIjdUaVr63PAa4Bf2J4PvBW4pcJ5/cDBLftzgc3D1ZE0FdgXeKjcnwtcD5xh+5ct9eeO0iYAtlfaXmh74ezZsyuEGxERu6NKInnS9n8Ae0jaw/ZNwCsrnLcaWCBpvqRpFGuY9Ayp00PxMB3gZOBG25a0H/Bd4Fzbv09ath8Atkt6TTla6wzgOxViiYgJbD+bF9js57YdDJPKjGkzmTF9P2ZMm9npUCqrMtfWI5KeD/wE+KakB6mwHontHZKWUTyonwJcbnutpBVAr+0e4DLgSkl9FHcigwtmLQMOBc6TdF5ZdoLtB4GPAP8A7EXRxValmy0iJrAPPPV0p0OYMI59yXs7HcIuq5JIFgOPA39GMX38vsCKKo3bXgWsGlJ2fsv248Apbc67ALhgmDZ7gSOqXD8iIppXZRr51ll/rxi2YkRETEqjJhJJ23n2yKhtQC/w5+V6JRERMUlV6dr6G4qRUVdRDL9dAswB1gOXA3/UVHARETHxVRm1tcj239vebvvXtlcC77B9DfCfGo4vIiImuCqJ5GlJp0rao/yc2nIsY/UiIia5KonkdOCDwIPA/yu3PyBpL4phuhERMYlVGbW1AThxmMM3j204ERHRbarMtfUHkn4o6Z5y/0hJn24+tIiI6AZVura+ApwLPAlg+y52voEeERGTXJVEsrftnw0pG3WKlIiImByqJJKtkl5COUJL0snAA41GFRERXaPKC4lnAyuBl0naRLEeyemNRhUREV2jSiL5le23SpoB7GF7e9NBRURE96jStXWfpJUUi1s92nA8ERHRZaokkpcC/0LRxXWfpIslvb7ZsCIioluMmkhs/9b2tbbfC7wKmEmxdntERESlOxIkvUnSl4HbgD2BU0c5JSIiJokq65HcB9wBXAt8ashCVxERMclVGbX1Ctu/bjySiIjoSlWekSSJRETEsCo9I4mIiBhOEklERNRS5RkJkt4JHE4xYgsA2yuaCioiIrpHlfVI/hfwfuCjgIBTgBc3HFdERHSJKl1br7N9BvCw7b8AXgsc3GxYERHRLaokkt+W37+R9CKKBa7mNxdSRER0kyrPSP5J0n7AFyjebDfw1UajioiIrlHlPZLP2X7E9rcono28zPZ5VRqXtEjSekl9ks5pc3y6pGvK47dKmleWz5J0k6RHJV085JwflW3eUX4OqBJLREQ0Y9g7EknvHeEYtr89UsOSpgCXAMcD/cBqST2217VUO4vi2cuhkpYAF1I82H8cOA84ovwMdbrt3pGuHxER42Okrq0TRzhmYMREAhwD9NneACDpamAx0JpIFgOfLbevAy6WpHI+r5slHTrKNSIiosOGTSS2P1Sz7YOAjS37/cCrh6tje4ekbcAsYOsobX9N0lPAt4ALbHtoBUlLgaUAhxxyyG79gIiIGF2Tb7arTdnQ/+FXqTPU6bZfDryh/HywXSXbK20vtL1w9uzZowYbERG7p8lE0s8z3zeZC2wero6kqcC+wEMjNWp7U/m9HbiKogstIiI6pMqb7dOrlLWxGlggab6kacASoGdInR7gzHL7ZODGdt1ULdedKmn/cvt5wLuAeyrEEhPE8uXLOeOMM1i+fHmnQ4mIMVLlPZKfAkdVKHuG8pnHMuAGYApwue21klYAvbZ7gMuAKyX1UdyJLBk8X9L9FMv6TpN0EnAC8CvghjKJTKFYS/4rFX5DTBADAwNs2rSp02FExBgaafjvHIqH4XtJehU7n2fMBPau0rjtVcCqIWXnt2w/TjF3V7tz5w3T7NFVrh0REeNjpDuStwH/meLZxl+zM5FsB/5bs2FFRES3GGn47xXAFZLeV77VHhER8SxVRm3NlTRTha9Kuk3SCY1HFhERXaFKIvkv5brtJwAHAB8C/rLRqCIiomtUSSSDz0beAXzN9p20f5EwIiImoSqJZI2k71Mkkhsk7QM83WxYERHRLaq8R3IW8Epgg+3fSJpF0b0VETUsX76cgYEB5syZw0UXXdTpcCJ2W5U7EgOHAR8r92cAezYWUcQkMfhy5sDAQKdDiailSiL5MsU67aeV+9sp1hmJiIio1LX1attHSbodwPbD5dxZUVG6MCLiuaxKInmyXO3QAJJmk4ftuyTzS0XEc1mVrq0vAdcDL5T0eeBm4H80GlVERHSNUe9IbH9T0hrgLWXRSbbvbTasiIjoFlW6tqCY7Xewe2uv5sKJiIhuU2Vhq/OBK4AXAPtTrJf+6aYDi4iI7lDljuQ04FXl2iFI+kvgNuCCJgOLiIjuUOVh+/088wXE6cAvG4kmIiK6zkgrJP4dxTORJ4C1kn5Q7h9PMXIrIiJixK6t3vJ7DcXw30E/aiyaiIjoOqOtkBgRETGiKs9IIiIihpVEEhERtVR5j+SUKmURETE5VbkjObdiWURETEIjDf99O8XyugdJ+lLLoZnAjqYDi4iI7jDS8N/NFEOA300xBHjQduDPmgwqIiK6x0jDf+8E7pR0le0nxzGm6IB/X/HycbnOjodeAExlx0O/GpdrHnL+3Y1fI2Kyq/KMZJ6k6yStk7Rh8FOlcUmLJK2X1CfpnDbHp0u6pjx+q6R5ZfksSTdJelTSxUPOOVrS3eU5X5KkKrFEREQzqiSSrwGXUjwXOQ74OnDlaCeVqypeArwdOAw4TdJhQ6qdBTxs+1Dgi8CFZfnjwHnAJ9s0fSmwFFhQfhZV+A0REdGQKrP/7mX7h5Jk+1fAZyX9X+Azo5x3DNBnewOApKuBxcC6ljqLgc+W29cBF5fXeQy4WdKhrQ1KOhCYafun5f7XgZOA71X4Hc9y9Ke+vjun7bJ9tm5nCvDvW7ePyzXXfOGMxq/xXHbs3x07LteZ9sg09mAPNj6ycVyuectHb2n8GjE5VbkjeVzSHsC/SVom6T3AARXOOwjY2LLfX5a1rWN7B7ANmDVKm/2jtAmApKWSeiX1btmypUK4ERGxO6okko9TrJD4MeBo4APAmRXOa/fswrtRZ7fq215pe6HthbNnzx6hyYiIqKPKmu2rAYoeJ39oF9ruBw5u2Z9LMaS4XZ1+SVOBfYGHRmlz7ihtRkTEOKoyRcprJa0D7i33XyHpyxXaXg0skDRf0jRgCdAzpE4PO+9uTgZutD3sHYntB4Dtkl5TjtY6A/hOhVgiIqIhVR62/y3wNsokYPtOSW8c7STbOyQtA24ApgCX214raQXQa7sHuAy4UlIfxZ3IksHzJd1P8Rb9NEknASfYXgd8BPgHYC+Kh+y79aA9IiLGRpVEgu2NQ17XeKrieauAVUPKzm/ZfhxoOwGk7XnDlPcCR1S5fkRENK9KItko6XWAyy6qj1F2c0VERFQZtfVh4Gx2Dr19ZbkfEREx8h1J+Xb6B22fPk7xRERElxnxjsT2UxRvn0dERLRV5RnJLeXEidcAjw0W2r6tsagiIqJrVEkkryu/V7SUGXjz2IcTERHdpsqb7ceNRyAREdGdRk0kkj7RpngbsMb2HWMfUkREdJMqw38XUgwBPqj8LAX+CPiKpOXNhRYREd2gyjOSWcBRth8FkPQZirVD3kixlvtFzYX33PD0tBnP+I6IeC6pkkgOAX7Xsv8k8GLbv5X0RDNhPbc8tuCETocQEdGYKonkKuBfJQ3Osnsi8I+SZvDM1Q4jImISqjJq63OSVgGvp1hY6sPlxIkAeeM9Yjd5b/M0T+O9R1rLLWLiqzr77xqK5yERMUaePPbJTocQMSaqjNqKiIgYVqU7koixsv+eTwM7yu+IeC5IIolx9ckjH+l0CBExxtK1FRERtSSRRERELUkkERFRSxJJRETUkkQSERG1JJFEREQtSSQREVFLEklERNSSRBIREbU0mkgkLZK0XlKfpHPaHJ8u6Zry+K2S5rUcO7csXy/pbS3l90u6W9IdknqHthkREeOrsSlSJE0BLgGOB/qB1ZJ6bLeuYXIW8LDtQyUtAS4E3i/pMGAJcDjwIuBfJP2B7afK846zvbWp2CMiorom70iOAfpsb7D9O+BqYPGQOouBK8rt64C3SFJZfrXtJ2zfB/SV7UVExATTZCI5CNjYst9flrWtY3sHsI1ijfiRzjXwfUlrJC1tIO6IiNgFTc7+qzZlQ5eCG67OSOcea3uzpAOAH0j6ue2fPOviRZJZCnDIIYdUjzoiInZJk3ck/cDBLftzgc3D1ZE0FdgXeGikc20Pfj8IXM8wXV62V9peaHvh7Nmza/+YiIhor8lEshpYIGm+pGkUD897htTpAc4st08GbrTtsnxJOaprPrAA+JmkGZL2AZA0AzgBuKfB3xAREaNorGvL9g5Jy4AbgCnA5bbXSloB9NruAS4DrpTUR3EnsqQ8d62ka4F1wA7gbNtPSXohcH3xPJ6pwFW2/7mp3xAREaNrdIVE26uAVUPKzm/Zfhw4ZZhzPw98fkjZBuAVYx9pRETsrrzZHhERtSSRRERELUkkERFRSxJJRETUkkQSERG1JJFEREQtSSQREVFLEklERNSSRBIREbUkkURERC1JJBERUUsSSURE1JJEEhERtSSRRERELUkkERFRSxJJRETUkkQSERG1JJFEREQtSSQREVFLEklERNSSRBIREbUkkURERC1JJBERUUsSSURE1JJEEhERtSSRRERELUkkERFRS6OJRNIiSesl9Uk6p83x6ZKuKY/fKmley7Fzy/L1kt5Wtc2IiBhfjSUSSVOAS4C3A4cBp0k6bEi1s4CHbR8KfBG4sDz3MGAJcDiwCPiypCkV24yIiHHU5B3JMUCf7Q22fwdcDSweUmcxcEW5fR3wFkkqy6+2/YTt+4C+sr0qbUZExDhqMpEcBGxs2e8vy9rWsb0D2AbMGuHcKm1GRMQ4mtpg22pT5op1hitvl/iGtlk0LC0Flpa7j0paP0yc42V/YOt4XEh/deZ4XKaOcftb8Jl2/ylNKOP338XH8rf4PeVvMeijfzPi4RdXaaPJRNIPHNyyPxfYPEydfklTgX2Bh0Y5d7Q2AbC9Eli5u8GPNUm9thd2Oo6JIH+LnfK32Cl/i5267W/RZNfWamCBpPmSplE8PO8ZUqcHGPzn88nAjbZdli8pR3XNBxYAP6vYZkREjKPG7khs75C0DLgBmAJcbnutpBVAr+0e4DLgSkl9FHciS8pz10q6FlgH7ADOtv0UQLs2m/oNERExOhU3ANE0SUvL7rZJL3+LnfK32Cl/i5267W+RRBIREbVkipSIiKgliaRhki6X9KCkezodS6dJOljSTZLulbRW0p92OqZOkbSnpJ9JurP8W/xFp2PqpHLmitsl/VOnY+k0SfdLulvSHZJ6Ox1PFenaapikNwKPAl+3fUSn4+kkSQcCB9q+TdI+wBrgJNvrOhzauCtncJhh+1FJzwNuBv7U9r92OLSOkPQJYCEw0/a7Oh1PJ0m6H1hoe3zeqRkDuSNpmO2fUIxIm/RsP2D7tnJ7O3Avk3RmAhceLXefV34m5b/qJM0F3gl8tdOxxO5JIomOKGd6fhVwa2cj6ZyyO+cO4EHgB7Yn69/ib4HlwNOdDmSCMPB9SWvKGTomvCSSGHeSng98C/i47V93Op5Osf2U7VdSzNBwjKRJ1/Up6V3Ag7bXdDqWCeRY20dRzHJ+dtk9PqElkcS4Kp8HfAv4pu1vdzqeicD2I8CPKJZMmGyOBd5dPhe4GnizpG90NqTOsr25/H4QuJ5i1vMJLYkkxk35gPky4F7bI08V9xwnabak/crtvYC3Aj/vbFTjz/a5tufankcxs8WNtj/Q4bA6RtKMciAKkmYAJwATfsRnEknDJP0j8FPgpZL6JZ3V6Zg66FjggxT/6ryj/Lyj00F1yIHATZLuophD7ge2J/3Q1+CFwM2S7qSYX/C7tv+5wzGNKsN/IyKiltyRRERELUkkERFRSxJJRETUkkQSERG1JJFEREQtSSQRDZP0cUl7dzqOiKZk+G9Ew3ZnNldJUwaXl46Y6Bpbsz1iMirfRr6WYv6sKcD/Bl5E8fLhVtvHSboU+ENgL+A6258pz70fuJzibeaLJR0AfBjYAayzvWS8f09EFUkkEWNrEbDZ9jsBJO0LfAg4ruWO5L/bfkjSFOCHko60fVd57HHbry/P3QzMt/3E4HQqERNRnpFEjK27gbdKulDSG2xva1PnVEm3AbcDhwOHtRy7pmX7LuCbkj5AcVcSMSElkUSMIdu/AI6mSCj/U9L5rcclzQc+CbzF9pHAd4E9W6o81rL9TuCSsr01ktKDEBNSEknEGJL0IuA3tr8B/BVwFLAd2KesMpMiWWyT9EKKNSfatbMHcLDtmygWfdoPeH7D4UfslvwLJ2JsvRz4gqSngSeBjwCvBb4n6YHyYfvtwFpgA3DLMO1MAb5RPmMR8MVy3ZKICSfDfyMiopZ0bUVERC1JJBERUUsSSURE1JJEEhERtSSRRERELUkkERFRSxJJRETUkkQSERG1/H97xPJZ6O7oPwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=\"stars\", y=\"great best la vegas et\", data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=\"stars\", y=\"place time great people love\", data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis_data = pyLDAvis.gensim.prepare(lda, corpus, id2word)\n",
    "# pyLDAvis.show(vis_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stretch Goals\n",
    "\n",
    "Complete one of more of these to push your score towards a three: \n",
    "* Incorporate named entity recognition into your analysis\n",
    "* Compare vectorization methods in the classification section\n",
    "* Analyze more (or all) of the yelp dataset - this one is v. hard. \n",
    "* Use a generator object on the reviews file - this would help you with the analyzing the whole dataset.\n",
    "* Incorporate any of the other yelp dataset entities in your analysis (business, users, etc.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
