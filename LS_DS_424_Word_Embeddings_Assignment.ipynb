{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_424_Word_Embeddings_Assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tesseract314/DS-Unit-4-Sprint-2-NLP/blob/master/LS_DS_424_Word_Embeddings_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ASfGeMfI6Kgs"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 4*\n",
        "\n",
        "# Word Embeddings\n",
        "\n",
        "### Use Word2Vec to train your own model on a dataset.\n",
        "\n",
        "1) **Optional** - Find your own dataset of documents to train you model on. You are going to need a lot of data, so it's probably not realistic to scrape data for this assignment given the time constraints that we're working under. Try to find a dataset that has > 5000 documents.\n",
        "\n",
        "- If you can't find a dataset to use try this one: <https://www.kaggle.com/c/quora-question-pairs>\n",
        "\n",
        "2) Clean/Tokenize the documents.\n",
        "\n",
        "3) Vectorize the model using Word2Vec and explore the results using each of the following at least one time:\n",
        "\n",
        "- your_model.wv.most_similar()\n",
        "- your_model.wv.similarity()\n",
        "- your_model.wv.doesn't_match()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXBNrqSudKRl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRzeAbzMNlIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "pd.set_option('max_colwidth', 600)\n",
        "pd.set_option(\"display.max_rows\", None)\n",
        "pd.set_option(\"display.max_columns\", None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wy5lYo4K8wEy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "f7d26741-ca96-4c59-b39c-99b27c614176"
      },
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "df.head(10)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in share market in india?</td>\n",
              "      <td>What is the step by step guide to invest in share market?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Diamond?</td>\n",
              "      <td>What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet connection while using a VPN?</td>\n",
              "      <td>How can Internet speed be increased by hacking through DNS?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve it?</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] is divided by 24,23?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt, methane and carbon di oxide?</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?</td>\n",
              "      <td>I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>Should I buy tiago?</td>\n",
              "      <td>What keeps childern active and far from phone and video games?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>How can I be a good geologist?</td>\n",
              "      <td>What should I do to be a great geologist?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>When do you use シ instead of し?</td>\n",
              "      <td>When do you use \"&amp;\" instead of \"and\"?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>19</td>\n",
              "      <td>20</td>\n",
              "      <td>Motorola (company): Can I hack my Charter Motorolla DCX3400?</td>\n",
              "      <td>How do I hack Motorola DCX3400 for free internet?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  qid2  \\\n",
              "0   0     1     2   \n",
              "1   1     3     4   \n",
              "2   2     5     6   \n",
              "3   3     7     8   \n",
              "4   4     9    10   \n",
              "5   5    11    12   \n",
              "6   6    13    14   \n",
              "7   7    15    16   \n",
              "8   8    17    18   \n",
              "9   9    19    20   \n",
              "\n",
              "                                                                                question1  \\\n",
              "0                      What is the step by step guide to invest in share market in india?   \n",
              "1                                     What is the story of Kohinoor (Koh-i-Noor) Diamond?   \n",
              "2               How can I increase the speed of my internet connection while using a VPN?   \n",
              "3                                      Why am I mentally very lonely? How can I solve it?   \n",
              "4            Which one dissolve in water quikly sugar, salt, methane and carbon di oxide?   \n",
              "5  Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?   \n",
              "6                                                                     Should I buy tiago?   \n",
              "7                                                          How can I be a good geologist?   \n",
              "8                                                         When do you use シ instead of し?   \n",
              "9                            Motorola (company): Can I hack my Charter Motorolla DCX3400?   \n",
              "\n",
              "                                                                                    question2  \\\n",
              "0                                   What is the step by step guide to invest in share market?   \n",
              "1    What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?   \n",
              "2                                 How can Internet speed be increased by hacking through DNS?   \n",
              "3                           Find the remainder when [math]23^{24}[/math] is divided by 24,23?   \n",
              "4                                                     Which fish would survive in salt water?   \n",
              "5  I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?   \n",
              "6                              What keeps childern active and far from phone and video games?   \n",
              "7                                                   What should I do to be a great geologist?   \n",
              "8                                                       When do you use \"&\" instead of \"and\"?   \n",
              "9                                           How do I hack Motorola DCX3400 for free internet?   \n",
              "\n",
              "   is_duplicate  \n",
              "0             0  \n",
              "1             0  \n",
              "2             0  \n",
              "3             0  \n",
              "4             0  \n",
              "5             1  \n",
              "6             0  \n",
              "7             1  \n",
              "8             0  \n",
              "9             0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5u_PKrqBgFMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clean function\n",
        "def clean_doc(doc):\n",
        "    # split into tokens by white space\n",
        "    tokens = doc.split()\n",
        "    # remove punctuation from each token\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    tokens = [w.translate(table) for w in tokens]\n",
        "    # remove remaining tokens that are not alphabetic\n",
        "    tokens = [word for word in tokens if word.isalpha()]\n",
        "    # filter out stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [w for w in tokens if not w in stop_words]\n",
        "    # filter out short tokens\n",
        "    tokens = [word.lower() for word in tokens if len(word) > 1]\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRHD8D1UYEZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenize column\n",
        "df['question1'] = df['question1'].astype(str).apply(clean_doc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENuHIV0Bfdjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['question1'].head(40)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w5rFzkjisAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Word2Vec(df['question1'], min_count=5, size=300, window=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1W51rfEmi37P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "c54a9171-c20c-468a-9f18-76dc227cbe59"
      },
      "source": [
        "model.wv.most_similar('stuff')"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('fetish', 0.7076653242111206),\n",
              " ('clothes', 0.6959240436553955),\n",
              " ('anymore', 0.6464889049530029),\n",
              " ('liars', 0.6443381309509277),\n",
              " ('cockroaches', 0.6439735889434814),\n",
              " ('groceries', 0.6315992474555969),\n",
              " ('crackers', 0.6290179491043091),\n",
              " ('hoarding', 0.6283577680587769),\n",
              " ('khaki', 0.6248286962509155),\n",
              " ('nite', 0.6238281726837158)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOtZDw0li4KS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95253404-4016-4224-ad12-3a1ac035c8c0"
      },
      "source": [
        "model.wv.similarity('life', 'death')"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.32940596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgA3XjEBi4Hl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e2597bf4-d1ac-4ba7-f775-7b80704fda1e"
      },
      "source": [
        "model.wv.similarity('up', 'down')"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.51087546"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsuh5Nc4qt1F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ffdec578-c204-454f-c943-37703aa5520f"
      },
      "source": [
        "print(int(model.wv.similarity('nazi', 'communist')*100),'%', 'Similarity')"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "73 % Similarity\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xkzdOZm38yQ_"
      },
      "source": [
        "### Stretch Goals:\n",
        "\n",
        "1) Use Doc2Vec to train a model on your dataset, and then provide model with a new document and let it find similar documents.\n",
        "\n",
        "2) Download the pre-trained word vectors from Google. Access the pre-trained vectors via the following link: https://code.google.com/archive/p/word2vec\n",
        "\n",
        "  - Load the pre-trained word vectors and train the Word2vec model\n",
        "\n",
        "  - Examine the first 100 keys or words of the vocabulary\n",
        "\n",
        "  - Outputs the vector representation for a select set of words - the words can be of your choice\n",
        "\n",
        "  - Examine the similarity between words - the words can be of your choice\n",
        "\n",
        "  - For example:\n",
        "\n",
        "    - model.similarity('house', 'bungalow')\n",
        "\n",
        "    - model.similarity('house', 'umbrella')\n",
        "    \n",
        "3) Word2Vec is not the latest or greatest wording embedding model, but it has been around long enough to have well developed APIs in several of the major packages. Try one of the State of the Art (SoA) embeddings models on your dataset. The state of the art models are BERT and Elmo (and yes, that is a pun). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gakr5rP76IAJ",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}