{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Vector Representations\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "hyj-f9FDcVFp",
    "outputId": "5dd045fe-6e4c-458c-e2fc-253c3da9c805"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7bcmqfGXrFG"
   },
   "source": [
    "## 1) *Clean:* Job Listings from indeed.com that contain the title \"Data Scientist\" \n",
    "\n",
    "You have `job_listings.csv` in the data folder for this module. The text data in the description column is still messy - full of html tags. Use the [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) library to clean up this column. You will need to read through the documentation to accomplish this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/josephbell/Desktop/DS-Unit-4-Sprint-1-NLP/module2-vector-representations'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n",
       "      <td>Data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0  b\"<div><div>Job Requirements:</div><ul><li><p>...   \n",
       "1           1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...   \n",
       "2           2  b'<div><p>As a Data Scientist you will be work...   \n",
       "3           3  b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n",
       "4           4  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...   \n",
       "\n",
       "                          title  \n",
       "0               Data scientist   \n",
       "1              Data Scientist I  \n",
       "2  Data Scientist - Entry Level  \n",
       "3                Data Scientist  \n",
       "4                Data Scientist  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/job_listings.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcYlc1URXhlC"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Clean the text\n",
    "def clean_text(text):\n",
    "    text = text.replace('\\n', ' ')                # remove newline\n",
    "    text = BeautifulSoup(text, 'html.parser').get_text() # remove html\n",
    "    text = text.replace('/', ' ')                 # remove forward slashes\n",
    "    text = re.sub(r'[^a-zA-Z ^0-9]', '', text)    # letters and numbers only\n",
    "    text = text.lower()                           # lower case\n",
    "    text = re.sub(r'(x.[0-9])', '', text)         # remove special characters\n",
    "    return text\n",
    "\n",
    "df['description'] = df.apply(lambda x: clean_text(x['description']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>bjob requirementsnconceptual understanding in ...</td>\n",
       "      <td>Data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>bjob descriptionnnas a data scientist 1 you wi...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>bas a data scientist you will be working on co...</td>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>b4969  6756 a monthcontractunder the general s...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>blocation usa  multiple locationsn2 years of a...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0  bjob requirementsnconceptual understanding in ...   \n",
       "1           1  bjob descriptionnnas a data scientist 1 you wi...   \n",
       "2           2  bas a data scientist you will be working on co...   \n",
       "3           3  b4969  6756 a monthcontractunder the general s...   \n",
       "4           4  blocation usa  multiple locationsn2 years of a...   \n",
       "\n",
       "                          title  \n",
       "0               Data scientist   \n",
       "1              Data Scientist I  \n",
       "2  Data Scientist - Entry Level  \n",
       "3                Data Scientist  \n",
       "4                Data Scientist  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C4xFZNtX1m2"
   },
   "source": [
    "## 2) Use Spacy to tokenize the listings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tech terms list\n",
    "tech_terms = ['python', 'r', 'sql', 'hadoop', 'spark', 'java', 'sas', 'tableau',\n",
    "              'hive', 'scala', 'aws', 'c', 'c++', 'matlab', 'tensorflow', 'excel',\n",
    "              'nosql', 'linux', 'azure', 'scikit', 'machine learning', 'statistic',\n",
    "              'analysis', 'computer science', 'visual', 'ai', 'deep learning',\n",
    "              'nlp', 'natural language processing', 'neural network', 'mathematic',\n",
    "              'database', 'oop', 'blockchain',\n",
    "              'html', 'css', 'javascript', 'jquery', 'git', 'photoshop', 'illustrator',\n",
    "              'word press', 'seo', 'responsive design', 'php', 'mobile', 'design', 'react',\n",
    "              'security', 'ruby', 'fireworks', 'json', 'node', 'express', 'redux', 'ajax',\n",
    "              'java', 'api', 'state management',\n",
    "              'wireframe', 'ui prototype', 'ux writing', 'interactive design',\n",
    "              'metric', 'analytic', 'ux research', 'empathy', 'collaborate', 'mockup', \n",
    "              'prototype', 'test', 'ideate', 'usability', 'high-fidelity design',\n",
    "              'framework',\n",
    "              'swift', 'xcode', 'spatial reasoning', 'human interface', 'core data',\n",
    "              'grand central', 'network', 'objective-c', 'foundation', 'uikit', \n",
    "              'cocoatouch', 'spritekit', 'scenekit', 'opengl', 'metal', 'api', 'iot',\n",
    "              'karma']\n",
    "\n",
    "data_terms = ['data', 'science', 'scientist', 'insights', 'analytics', 'analysis', \n",
    "              'machine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokenizer import Tokenizer\n",
    "# Initialize the tokenizer\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "STOP_WORDS = nlp.Defaults.stop_words.union(tech_terms, data_terms)\n",
    "# Tokenizer pipe removing stop words and blank words and lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhUHuMr-X-II"
   },
   "outputs": [],
   "source": [
    "# Tokenizer pipe removing stop words and blank words and lemmatizing\n",
    "tokens = []\n",
    "\n",
    "for doc in tokenizer.pipe(df['description'], batch_size=500):\n",
    "    \n",
    "    doc_tokens = []\n",
    "    for token in doc:\n",
    "        if (token.lemma_ not in STOP_WORDS) & (token.text != ' '):\n",
    "            doc_tokens.append(token.lemma_)\n",
    "\n",
    "    tokens.append(doc_tokens)\n",
    "\n",
    "df['tokens'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>bjob requirementsnconceptual understanding in ...</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>[bjob, requirementsnconceptual, understand, le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>bjob descriptionnnas a data scientist 1 you wi...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>[bjob, descriptionnnas, datum, 1, help, build,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>bas a data scientist you will be working on co...</td>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "      <td>[bas, datum, work, consult, business, responsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>b4969  6756 a monthcontractunder the general s...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[b4969, 6756, monthcontractunder, general, sup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>blocation usa  multiple locationsn2 years of a...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[blocation, usa, multiple, locationsn2, year, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0  bjob requirementsnconceptual understanding in ...   \n",
       "1           1  bjob descriptionnnas a data scientist 1 you wi...   \n",
       "2           2  bas a data scientist you will be working on co...   \n",
       "3           3  b4969  6756 a monthcontractunder the general s...   \n",
       "4           4  blocation usa  multiple locationsn2 years of a...   \n",
       "\n",
       "                          title  \\\n",
       "0               Data scientist    \n",
       "1              Data Scientist I   \n",
       "2  Data Scientist - Entry Level   \n",
       "3                Data Scientist   \n",
       "4                Data Scientist   \n",
       "\n",
       "                                              tokens  \n",
       "0  [bjob, requirementsnconceptual, understand, le...  \n",
       "1  [bjob, descriptionnnas, datum, 1, help, build,...  \n",
       "2  [bas, datum, work, consult, business, responsi...  \n",
       "3  [b4969, 6756, monthcontractunder, general, sup...  \n",
       "4  [blocation, usa, multiple, locationsn2, year, ...  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lgCZNL_YycP"
   },
   "source": [
    "## 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2PZ8Pj_YxcF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josephbell/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['central', 'computer', 'core', 'deep', 'fidelity', 'grand', 'high', 'human', 'interactive', 'interface', 'language', 'learning', 'management', 'natural', 'neural', 'objective', 'press', 'processing', 'reasoning', 'research', 'responsive', 'spatial', 'state', 'ui', 'ux', 'word', 'writing'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "# Apply CountVectorizer to our Data\n",
    "# Use custom Spacy Vectorizer\n",
    "# BBC articles in `data` variable\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "vect = CountVectorizer(stop_words=text.ENGLISH_STOP_WORDS.union(tech_terms, data_terms))\n",
    "\n",
    "#Learn our Vocab\n",
    "vect.fit(df['description'])\n",
    "\n",
    "# Get sparse dtm\n",
    "dtm = vect.transform(df['description'])\n",
    "\n",
    "dtm = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>02</th>\n",
       "      <th>02115njob</th>\n",
       "      <th>03</th>\n",
       "      <th>030nnmicrosoft</th>\n",
       "      <th>04</th>\n",
       "      <th>06366</th>\n",
       "      <th>08</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>...</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zf</th>\n",
       "      <th>zfs</th>\n",
       "      <th>zheng</th>\n",
       "      <th>zillow</th>\n",
       "      <th>zillows</th>\n",
       "      <th>zonesnability</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 15966 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   02  02115njob  03  030nnmicrosoft  04  06366  08  10  100  1000  ...  zeus  \\\n",
       "0   0          0   0               0   0      0   0   0    0     0  ...     0   \n",
       "1   0          0   0               0   0      0   0   0    0     0  ...     0   \n",
       "2   0          0   0               0   0      0   0   0    0     0  ...     0   \n",
       "3   0          0   0               0   0      0   0   0    0     0  ...     0   \n",
       "4   0          0   0               0   0      0   0   0    0     0  ...     0   \n",
       "\n",
       "   zf  zfs  zheng  zillow  zillows  zonesnability  zoom  zuckerberg  zurich  \n",
       "0   0    0      0       0        0              0     0           0       0  \n",
       "1   0    0      0       0        0              0     0           0       0  \n",
       "2   0    0      0       0        0              0     0           0       0  \n",
       "3   0    0      1       0        0              0     0           0       0  \n",
       "4   0    0      0       0        0              0     0           0       0  \n",
       "\n",
       "[5 rows x 15966 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zo1iH_UeY7_n"
   },
   "source": [
    "## 4) Visualize the most common word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5LB00uyZKV5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business       1111\n",
       "experience     1031\n",
       "work            932\n",
       "team            859\n",
       "learning        857\n",
       "statistical     565\n",
       "product         554\n",
       "models          530\n",
       "new             526\n",
       "skills          454\n",
       "solutions       435\n",
       "years           432\n",
       "help            432\n",
       "using           419\n",
       "working         395\n",
       "dtype: int64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words = dtm.sum().sort_values(ascending=False)[:15]\n",
    "top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nO3dd2Ab5d0H8N/daW9ZlrflveMkTpxBQgaBMhpWCCVt4aWlgxZKW6BldG9GC4XuMgs0LbSlrLDKSiAJWSYmy3a8l2RZtrW3brx/BNOUxM4gOdnJ9/OXpXvuud8j2V89fnTSMZIkEQAAyINNdwEAAKcThC4AgIwQugAAMkLoAgDICKELACAjxWQbK+68r0muQuDj0zvTXcHUFlwcS3cJJ4U0qk53CSdUZjOT7hI+th2P3tw40TbMdAEAZITQBQCQEUIXAEBGCF0AABkhdAEAZITQBQCQEUIXAEBGCF0AABkhdAEAZITQBQCQEUIXAEBGCF0AABkhdAEAZITQBQCQEUIXAEBGCF0AABkhdAEAZITQBQCQEUIXAEBGCF34WPb95cf1qUjwkGvt7f/HPdVERHGfR9W69o46IqJgb4ux89k/lMtdI8BUgtCFk6Jqzbfb0l0DwFQ06dWAAQ4mJONsz0uPlPLRoEqSJCZrzgrXh9tSCaZn3UPlppIZvqyG5aO7H7itYeZX7m6eqK9gb4vBtfkFx/jtisu/2capteLJHgNAuiF04agFunablDpjqnzV1zqJiPh4hHNve5WEZJztfeUvpdbKuWOZM88cO5q+PO9vyMlfsqrP6KiKCIkYyypUCFw4LWB5AY6a1l4QC7u6TYMbns4P9rUaFBq9QETU+/Ij5dbqxtGjDVwiIn12Udj17guFwztey+LjUY7huJNXOMAUgtCFo6bNzEtUrvlWi8aWG3NvfzXftfmFXCIibZYjHOrfb5Yk6aj7yj1jpbvwrDV9opBiO5/5XXVsxKk5aYUDTCEIXThqyaBXySnVYmb9Yq991jJ3bNSpIyLKW3SRi1Nr+f43/u44Uh/j4l63WpftiOUuXOnW2nIjMe8QQhdOCwhdOGrRkQHt/n/cW9P2t7tqPe+9kZc979yh8W2FKz49IAkpdnDDvwqOpi/PzreyWtfeUde69s5ahuUkS9mswMmr/MRJukZUAzfdW3e07cf++lKe719vZJ/Mmk62cNNOs2/dyznpruNE2PXUT+pT0UNPcdz3/L3VctWAN9LgqFnKZgUtZbNaDr6v7pof7xn/ufj8z/eO/zx+5oLGmpWsueq7+4iITMW1IVNxbYiIyHHOZwdkKRo+NkPjnAARTYsXxclIojDhtrpLviXbKY4I3Y/oufPH9YU33NyqMJr4dNcCU5Qokee3TxUlepwGzmxI5tx+TSc/6lONPvK8QwzHFIxKIWZ+eVWfujgvfvBuzu//sUpVkB1NdPQbJVFkMr+8qkdbWxpNxxBSwx7V8AOPVBT88Dv7iIh8L72aLSWSHKvX8uGtO+zEspLSbo9nf/WL3cG3N9oS/YN6+/99pt/zyOPFrFotJJ0uvRCOKC0rzxs0Lpzvk0SRRtc+5Uh09xo5szFJLCcZFjSOGRfO952Iep07X8lmWIWUN/sTnt5N/yiM+d3amgu/2e7v32ccad+WaSmsCbj3bsghiRhTXoW/aNHlTiKi9564vcFWNmck5O42ORZe2j/en5BKMB2vP1xucdT5cmYsH33vidsb5l59V7N/oMXoev+1PIVal4oHRrRaa260/OxrehiGIW/P++bBppcKWIVS1GcWhpNhn7rqgus7j3UsCN2DTPZKCDCOH/Nr7F+7oltT6ehz3/14aXhjszW8sTkz80uX9qkcOYnYvm792CPPO/J+dl37R/eVkim24N6bWqLv7zeMPvRsSeF939qXjjFMJPj2ppyCn3x/D6tUSkI4cthTSoRQSJl7y41tSadL43nosXLjwvm+8PYmK+/zq/J/ePs+IRBQOO+4ZwYtaDzqs1mOxJhTHnbv3ZBNRJ6o16WTRJ4VBZ4JubsMGlNm3Nn8n/zai29qVWgM/P6Xf1851tlksZU3+iUhxertRZHixVcMflh/Ks52vvVYqa1szlhWzaFn3MT9w9q6S7/drTJYUy0v3FcddO03GLJLI/1bnyuquuC6Nq0lO9nx+iMlxzuWUyZ0x15/JZvhOCljxbme4X8/VZj0uLWF193YHmndawzs2Japr64N+DeuzyEiRltW6c+69MArYdePbmswzpozEuvtNtkvXPXhK6GYTDCuxx4q19fM8FmXLB9N28BgyuGspoSm0hEjIlIV50b5EZ860esyeH7zZNl4G4kXmMPtq188y0tEpJtdFR594BlWCEU4zqifMq/2yqysmOehx0p09XV+Q2OD/3BttPV1foZlSV1YEBcjESURUaKrx6CfVe9jWJYUViuvLi4Knci6DNkl0djGJ/V8IsoyLCdprbnh8HC3LuzpNZoLqv0Ge1FIpTPzREQZJbO9IXe3wVbe6CeGoczyxv+ZbXe88Wh5dt1Sd1b1Iu9hx5eRF1EbbSkiIq0lJ5oIjqk4pUZQGSwJrSU7SUSUUTrbO9q+zX48YzllQldbWh72b1yfTUSe5JBLJwk8K/E8E+vuMqhsmXHvG6/mF95wcyunN/CDD/6uMtjcZDE1NPqlVIrVFBZFsi5b8+EroRiPs+61fyk1zJ47Zjnj6M89hdMDo+A+PDeOYVmJD4QVrFbNF9x7U8tk+xERMcxHs/iw2XzycZxEB53iJ/E8S0SU8/WvdsRa9xuju/eaXW9tyM3//m2HzMQZheLozw08QVhOIan0loSndXOm3u4I6zLyYkFXuzEZ9qnVRlsyOnbgTJpDamUVIsP+74Rdn1kYDjr3m+1VZ3gPfT6IWPag55dhSJLEE/oknTJnL2iLSqIJ95BeiEZZhuMkdX5hONbbrYv39xpZrVbQOIpCCpOZZziOjPUN3nhPl4GIiBiGjHPn/c8r4dBfHyk3zmkcReDC0WC1alGRYU6GNjRZiYgkSaJ4R7/2cG3D7+6yEhFFd3UYGK1a4Iy6tMxyFRYzL0ajCiEY4sRUiom1HjjPmh8dU+lm1IZsV1zmFBMJTozFj+pTK+rSknB0916rJIrE+/yKRF+f8UTXbMgqCnvaNmcbc8pCprzK0Ghnk11rzY4asksjkZE+YyoaVEiiQN6eXRnG3LLwRP0UzrvIxak0fM87R3+Ko9aaG0+G/ep4wKMiIvL27Mo43nGcMjNdRqGQFGZLIrB1U6a60BFW5+bHop3txpTfp1ZabcmEa/Dwr4SKQ18J1QWOcLR9v9k0f9FhXwkBPsr+9TXdow89WxRYtzFXEgRG11jn1VQcWII4GKNUSIPfvr9WEgQm88uretJRK9GBvxfTimVDrnvur+GMxpTSnhknUWRGHv9biZhIcCRJjPGMBR7OcHRLH4YFjb54e4fR+dO76jizManKyYmyWu0JfUEx5JSFhls25ZhyKyKcSiOyrELSZ5WE1QZrKq/hPGfbK3+oHH8jzVY297BLI+OKz/z0QPf6J4r73n26oGjR5YOTtSUi4pRqqXD+xX3trz1UwSqUoi4jL3K842Am+xRRxZ33NR1vx+kw8tJzeeFdzTb7pZf3avILYwN/uK9GlZMbzVq1pn/wz7+pPrC8oOedD/y+0rzwTI+xYa6/60e3NZT95L9fzDJ+9sLYf17KlUSRybniyv7JjjmV6J3prmBqCy4+JANl5fz+H6tsV14woKkpOaFnLEij6hPZ3XETYzGW1WpFIRjiXPfcX5N70w1tCqv1mM8CymyemhMdPhljFSqtKEkS9bzzd4fGlBnPazjPc7i2Ox69uXGifk6ZmS4RkbakPBTYsilHV1oRYTUakVEoJI2jOKy0WlMZZ5/ndD74+0r64I00Y8Pkr4RZqz894P7748We5/5VkHXpp474SghwunP/4cEKMR7nSBAY89nLh44ncKcyz753Mr09zZmSKDIaS040e8bxvcF+Ss10T3eY6U4u3TPdk2WqzHRPlKk60z0Wk810T5k30gAApgOELgCAjBC6AAAyQugCAMgIoQsAICOELgCAjBC6AAAyQugCAMgIoQsAICOELgCAjBC6AAAyOqW+8OZ0l/XgjnSXMKUFF89IdwkAmOkCAMgJoQsAICOELgCAjBC6AAAyQugCAMgIoQsAICOELgCAjBC6AAAyQugCAMgIoQsAICOELgCAjBC6AAAywhfewGnD9rom3SVMS/Nu2CnvARfLezi5YaYLACAjhC4AgIwQugAAMpp0TXfZJ3bJVQecAP0/SncFAHAkmOkCAMgIoQsAICOELgCAjBC6AAAyQugCAMgIoQsAICOELgCAjPDdC3BcIlJQ1cxvqDAxtnBQ8hpUjCY5hzurM04RVauww5GSEgqWOLFWsaDPQOb4Jv6F+iWKS/akKMm9zT8zu4Fbtj+TzQtv4/9TVcst6DUylkS6xwQgB4QuHLcYRTUz2EXdFjazbye/oXRI7LEOST2ZNdz8PiNjSXjFYX2rsMOxQHFuu5YxxEOSTxOlkFpP5qhX8hisUlYkIcVUCFw4nSB04bhpSJuwsJkxIiITY43GKKwOSj7Dbn5T2XgbiUSGiMjMZIbGJLcxRhF1MVc95BS77T5pJGxgLJF01Q+QDghdOG4MsdJBt6SUlFQoSMkvVl7Y8tG2GUxWeEDssCcprqpiG5x90v4cr+Q2Whh7WM6aAdINb6TBCaNglKKGtEmn2GUlIpIkifziqJaIyMpkRUKSz0DESByjkAyMOTok9tozmOxQeqsGkBdCF06oesXibpfYk7k59WLtZv7FOo80YCEi4hiFpCJN0sxkRIiIrIw9LBDPmhlbLL0Vnzwt6+6vCrm7dJO1GetsskRGBz/8dvX+bc/l+fr2GE9+dZAuWF6A46JnTMkzlRftG79dzs0cHv95nuKcjsPts1B5/v7xnwu4Cm8BV+E9uVVOfb7+vRaLJAb0mQVxIiLHgktd6a7pVCHyIrGKqTevROgCHAMhGWc73ny0NBUNqkiSmJz6s1wKrYF3Nr1UKEki6TLyoiVLPtvHKpTSwfu998TtDXOvvquZiGi0Y7vVP9BizqpaNBJ0dVgiI31G9563csvO+nyXs/nVXEthbSCzYr7P17/XeLh+dz31k3pryayxoHO/WZJEpmz51d06W37cP9BqGNzxvOPAERmqXvmNNoVaK8r/KB27Tfc05WlMar7x2noPEdHGu3fkazM0KTElMj0bBjKElMgUnZnvX/ytuS4ioheue7MsOhJTCSmBrVtdMTz76tpRIqIHFz3VUHlB8Yir2WM685bG/t4Ng+aBLUMWhmOkvLnZweXfXzCYznESIXQBjomvb49JqTWmqi+4vpOIiI9HuL3P/qqu8rxr9+sy8hKdb/6l2L13vT1v9rmeI/Vlyq+MmPIq/OMhe/A2gU8yfZufLpmoX4XGwM+47LbWod1v2od2v5lddtbVfcN71+cULljVZ86vivDJGMsqVNMicImIZlxeOfrqt98ua7y23iMKEvVsGLQ2XlvvdG53m654amWrJBGtu+6N8r7NTkPR4vzwOb9Y3KvL0AipGM/88zMv1VauLPHpbFpBSAhsdn1mZPkPFg5Gx2LcO7/YXnzlC5fsZViGYv44l+5xEiF0AY6JzpYfc773cmHfu0/nWxwzApxKI6j05oQuIy9BRGSrmDc20ro5i4iOGLqTiXldmsn6tZU2+IiI9HZH1N+/z0pEpM8qCg/uWFcYGen32srm+BSq6THLJSKyFJuSKqOKH9o1oo2OxJQZZeaoZ9+Y3rXTY3rq8hdriYj4OM/6e4OaosX54ea/7Mvu2+y0EBFFR+NKb1dAo7NpIwzLUNWFpT4iIrVJLbAqVnzt9k3FRUvy/eXnFQXSOcZxCF2AY6DLyEvUXnJzi693t9nZ/Gq+Mbs0eDT7MQf9LPIpZsKGR4nlDixfMAwrSdKBc6EL5q50Wx31AV//XnPbS7+rrvjElzt0tvz4xz2WXKovLhttfbYzM+aNK6svLhsb3DZknHll9VDDB0sH4/o2Oo2uncPGy9de0KbSKcV/X/1qlZAQWCIiVsmK4+u4nJKlK578ZGvv205T1xv91n1Pt2etfvz89jQM7X9MvVVmgCksEfIqWaVazKpZ7M2uW+aOjPYbktGAKuYbUhMRjXU22QzZJYecBsdp9KnI2KBGkkTy9++1fni/Ui0Iyfghf4fajLz40fR7sJjPrdbbHbGCuZ90azPyIjHf0LS65nzlyhK/q2nYPNbh05euKAw4FucF21/qyUyEkywRUdAZVoY9UUUilORUBpWg0inF0f1ezWi7T3+4/hLhJBsPJLnyc4sCy743f8DfG5z0TBK5YKYLcAyiY4PawfdeKmAYhojhpKIzLuvjkzGua/0TZeNveOXMOGvko/vlN5zn7Hzj0XKFWsfrMvKiAn8gSDJK53j7t/y7eGT/luyysz7XNd6eU6ikokWX9x6p34O5967PCg/3moghSWPKilmLZ02Jf6ePlkLFSTmz7EGVQSmwCpZKVziC3q6A5t9XvVpNRKTQcuI5v1jcU3p2YaDlmQ772oufrzPlG+KZldbDfqoxGUpxL9+4vlxIigxJRPOvmzUg74gOj5EkacKNX2r6fJOMtcDH1L8ome4SpjTfVY3pLmFamnfDTlmOIwoS/eNTL9ae+8slXbby6f19HH+cs3bCXzYsLwBA2o20ejVrL3y2PrfBHpzugXskWF4AgLSz12TEr37lsj3prkMOmOkCAMgIoQsAICOELgCAjBC6AAAyQugCAMgIoQsAICOELgCAjBC6AAAyQugCAMjotA3drfduz+vb0I9rUQGArE7LjwGLgkgLvzUf16ICANlNqdBtfboto/Xp/dkiLzK2KlukalXF6OY7txat+ttFraIgMs9d9WLNWb9Y2hXzxpTND+7KU2gVQngorMmamRVc/tMl/QzLUO9bfabmh3fliSmRMeTqE2fdsaxXZVCJT17wz3rHskKv+71hU91na93OLU5z4ZkFgcqLK3zu5mHdtvt2FPJxnlWb1Pzyny3pNeQaUs9/7sWqzBpbePh9jykVSXGLv3NGb8Gi/LAoiPTuXVsLhprcZmIZqWJl2ejsL8z0TNRPuh9XAJg6pkzojraNaXre6Mu45K8XtnFKTtrww40Of7dfU7Awz7/13u35QkJgS84uGrPXZsb7Nw0ovZ0+/aq/XbTX5DAlX7r21YqOFzutBYvyQ7se25O78qHz21V6ldj0x505zQ/vyl5w47whIiK1Sc2v/telrUREzi1OMxGRkBKYLfdsc5x3/zmdOruO3/9cu3Xbb5ryz75reS8RkchLzGVPXdLa/XqPufnhXXkFi/Lb96zdZw+7I6rV/7p0H6tgKeaNcUfqBwCAaAqF7uC7TqOvy6d79jMv1BARCUmB1Vg1/PxvNg49+5kXalgVJy750eL+8fYZ5daIpcSSJCIqOafY637fY+DUCjE4ENK88LmXqomIRF5kMqtt4fF9Ki4s8330uN4OnzrYH9K+fN1/KomIJFEijVXz4ey05JxiHxFR9sysyPbfNKmIiIaa3KbqyypHxi8Los3QCiMto5rJ+gEAIJpCoUtETMk5xWOLblvoPPjO8FBYycd5lhVEho/zrEp/+CucMgwRSRJlz84Knnvf2T2Ha6PUKQ/dV5IYU6ExturvF7cdbh+Fij1wLSqOIUmQJr621RH6AQAgmkKhW3BGfvCNW9eXz7omMqzP0vMxb4xLhpPc5ju3OmZ9YaYr5AyptvxyW8GynyzpJyLydvr0/t6AyuwwJXvf7MuovKRiJHduTmTb/U0OX5dPbS2zJpKRJBt2hZUZFRkTfilyRkVGPBFMKJzbXfr8+XkRISUw3g6f2l6bOeEF/fLm5QbbnmnPdCwpDI4vLxxPPycaw02JK0xPWRlPNh/2/vZfzpa5kunllc0N/3O78PVpc5Hh9Hlh4k1TJnQza2zxhi/OdL5y/WuVkkTEcoxUsCjfzypYqWZ1lVcURHruqher+94ZMDLsgeWFzXducYy/kVaxsszPsAwt/u4Zveu/+06pwB+4QmrDl2Y5JwtdTsVJZ92xrGvrPdsdWyLbOFGUmJrVVcOTheWMz9aOBPqD6qcvf7aO5VipfGXZyOwvzBw51n4A4PQzLa+R1r9pwLhn7b7slX8+vzPdtUwlA0uEdJcwLWGme2ww0z2yd164BddIAwCYCqbM8sKxcJxZGHKcWRhKdx0AAMcKM10AABkhdAEAZITQBQCQEUIXAEBGCF0AABkhdAEAZITQBQCQEUIXAEBGCF0AABkhdAEAZITQBQCQEUIXAEBGCF0AABkhdAEAZITQBQCQEUIXAEBGCF0AABkhdAEAZITQhQl18buzeCl1xN+Rj7bbkXitPCnFJ7we/LG2n0gf32bbk9zsONb9ppPg2xttI3998rjGGHx7o40f8ypPdE1T1bbXfl6fjAcnvQTZ0bQ52RC6MKFBviNbIP6IvyMfbTdPfW6nitFMeGniY21/KpKEkz/c8I6dmbzPf9qE7nQxLS9MCSceL6XY5uT60gTFVBIRk8UWeJMUV+5IvlapIBW/UH1B++7kJkdI8ulFElg7W+CrVja6uvg9WR9t93b83/UL1Z9s5UghHtxnCVfrSlBcOVF7NaPl+/n9tn6hLZuISM+YYw2q5T1DQo+5h9+XK5HIKkjFz1It6dYwej7dj9lEUsMe1fCfHq5Q5uVEU0NuncJuj2V94epe58/vrtPV13njnV0m01lL3SRJTOCtt3NIkhhtVaXftma1k4gouGGjLbD+nVxWoxaUOdlRRqGQiIg8jzxerK2rCRgXzvcREfV96zsNRffe2UxE5Fv3ck7k/d0ZxDCkrSwPqByF0dSQWze69slSUijEvFtubGXVail9j8rhRcMjqr1bH64wmPMj4cCgQW/Ki2QXNo72t7+Rz6eiisrZa7p1xuzE/p1/L07E/GqWU4rlM1f3mayOWDIe4lqbnihNJsIqgyU/TPTf4bl6380Y6t2aLYkCYzDnR6oa1vQx7H//meJTcbZlx2OlyXhQJUkSU1i+3JVTtMAnx5gRukBERMNCv0nFaFPzVOd2EhElpQTnFnoz56nObVczWp6IqErZ6FQzGkGURNqe/E+VXxzVlinqPYN8e/bB7SbrU8WohYnaB8QxTS/fkrtAfX6bmtHyiQ+WHGxsbjhHVdzGMAz18i2ZXfyenDrlwkF5Hpnjw3u9GtunV/dqq6sinkefKA68ud5ORMTqdXz+925t5ce8yqFf/64699YbWzmDgR+6/w+V4e3vWTTlpZHA62/l5d56Yyun0wlD9/2uSpmbG53sWJHmXaZYS5sl75ab2liNWhRCIY4zGoXQpi1ZGZdeNKApL510/3RLxPyamrlXdhssBb07N/y6ZsTZbGtY+s22EWezZaDjzVyVxpzUm3Kj9Wdc2zXmbjG2N/+jpHHFLS09rS/nGa1F4dK6C4dGnO+bR127M4mIwgGnZtS1J6Nh6TfaWFYhte180jHUt9WWV7J4bPyYY+69JqXamJq56KudRESpZPSYl7eOF5YXgIiITGxGzC96TC2pbfmjgsugYtSH/P/rEroyNideqHk3ua42KoU0YdGn+bh9HmxMdJnsXIFvPIzVHyw5xKSwakfytYpNiedr+4X9ORExoP04Y5UDZzQmtdVVESIiw7y5Y4mePgMRkWF+o4+IKN7do1eXFIUUZjPPcBzp58z2xju7DPHO7v/er1RKuln13iMdK9bWbtLPmzvKatTiB8eeVks1aq05YbQ6YgzDktZgj1kyy4MMw5DBnB9NxALqkL/fmOOYP0ZEZMupDfF8TJFKRtmQr9+Y45g3RkRkz58d4BQHfr+8nv3GaMit27nhvpqmt35VG/T2muJRr/rgYxrM+bHgWI+pY/cz+V7PfoNSpZPtMcNMF4iIyMhaEwvVK1s8Qp+5k38/f0wcCh68PSIGVAP8/uyF6k+2qhiN8H7y7WKBhElftA/XZ5Vy7tCx1taa2uEoUlS7c7mSwIgwaOzi9+Qdax+yYw5/m1EfCMbjwrISSQf+hZZEkSRB+OhRpiWG4Q5a9mCIYQ8spxDDkiSJDMOwx7YsIklMZt7MsfL6Vc6JmuhNuYmGZTe2jA7tNve1/SffP9IRLK278Jh/N48HZrpAREQxKaxUkEIsVFR5ixS17pDk03GMQuClJEtElKIkxzKcqCS1EJciCp84bB7f9+B2R+pzsvY2Ni84IgxaE1KMIyIaX14QKMVpGH2KiMgpdNtOziNwYgnBkCq2v11PRBRu2pmhLikOH7xdU1YaSfT2GflAUCEJAkWbd2VoKsrCmvID9wvBECfxPBPdvdc6vo8iw5pM9g/qiIgiTc0WEkWGiEhbXRmM7HgvU4wnWCIiIRTiiIhYtUoQ48d+VshUY7Q4Qu6BHTYiIu9wq1Gh1PJKlU40Wh0h90CTjYhoxLXLJPAJjojImlUV9A63WhOxgIKIKJkIc7HwiOrgPuNRr5JTqMS84kXe/LKl7kjQpZNrPJjpAhERBUWvtoNvLiBiiCVGqlHO7/OJHsN7qbcqVaRJLlRf0G5gLNGNiedmqBlt0sTaPgyRPK509OB2k/U5WXsza4sXK2qGtidfq2aIJANjic5WLestUcxw7U5uKlMwSt7K2kNxKaKmKU6RkREPvrM5a+ypp3UKe2bcvGL5SPjdbVn/3W5NWS441+n+7R8rx99IM8yb6yciMp+zwuW697c1rEYtqHJzPlyPNS09c2T4gUfKB39+d622ojzAKJUiEZG+YVYwOejUue6+t4Y4TtJWVQRsn7rMqZ/fOOp9+tki73PrpuwbaUejpHala//Ovxc3vfXLWpZTipWz1/QQEZXUfNLV2vRE6Y43764zWArCKrUxSURktBTEHRVnO/dsebCSSCKGYaWyGZf2aw325HifYb9T29v2SsGBmTUrldev6pNrPIwkTfw8fKnp801yFQIf38CSabWUN2W0/3L2Ce0vNexRDT/wSEXBD7+z74R2PEUUvn78KySni3deuKVxom1YXgAAkBFCF+AEU2ZnJU/VWS58fJOu6d6T96ZcdcAJsIaWp7sEADgCzHQBAGSE0FZJlp0AAAnASURBVAUAkBFCFwBARghdAAAZIXQBAGSE0AUAkBFCFwBARghdAAAZIXQBAGSE0AUAkBFCFwBARghdAAAZIXQBAGSE0AUAkBFCFwBARghdAAAZIXQBAGSE0AUAkBFCFwBARghdAAAZTXphSphenDfMSXcJ05K+P90V/K/ffu3P6S5hchelu4Dp4JYJt2CmCwAgI4QuAICMELoAADJC6AIAyAihCwAgI4QuAICMELoAADJC6AIAyAihCwAgI4QuAICMELoAADJC6AIAyAihCwAgoykfuh1dKdWcxUN1H6eP/gFeufrKkdITVRMAwPGa8qF7IjgKFal//83ene46AACmRegKAtFnPj9aMvuMobrVV46UhsMiWzPHVT88LCiIiN7dmtCdvXK4iojotTdjhvlL3bXzl7pr5y9z1/oDInvwbPmBR0K2yz4zUnbBKk9F/fyhGTfd5isYP866l2OmJZ8Yrl6w3F1z+ZUjpcGgyBIRfes7vvyGM4bqGpe4a2+89UD7tU9FrHMWD9XNW+KuPeuCA8cGADiSafEl5v0Dgua+u629K5ZpIp+/dqz4t38K2Sdq+/s/h3Pu+pmlb8UyTSQYFFmtlhFHPtKmrZ3XbXojq0WjYcQ5i9wzvn6dcVivZaRf/y6Y+/Iz9najkRV/dlcg55f3B7O/cZ3R8/pbcev7W3L2sixDY16BIyK67/eh3GeftLcXORSp8fsAAI5kWsx0s+xscsUyTYSIaM3lurHtTUnDRG0b56jCP/hpoPBX9wezvD6RUyqZQ9osnK8KZlg5QadlpdISRbynl1dv2pLQ9/TymrNXeqrnL3XXPvN81DboFFRWCyuoVYz4ha96i5/8Z8Ri0LMiEdGcWcrwtV/3Fv/+z6FMQThpQweAU8y0CF2GOfQ2xzGSIB64HYtLH47jh98xu397j7UvHpfY8y/1VO/em9R8tD+VipHGf+ZYRuJ5iZEkooXz1cHt7+S0bH8np6V5S+6+xx6w9SmVDL3zenbrJRdqff95I25ZuXqkgojooT/Y+r93q8nldAmqZecN13pGMNsFgCObFqE77BFVGzbG9URE/3wmmjG/URXOy+WS25sSOiKi59ZFreNt29pT6rkNqtgPbje762qVkda21CGheziLz1BHmnclDa1tKTURUSgksvtakupgUGR9PpFbdbEu8Ou7LQMdnSnd+HGWLtZE7vypxWW1sHxvH6868SMHgFPNtFjTdRRy8QcfDWfdeKtPV1aiiH/9q8aReXPVkZtv8xXf/eugsGCeOjTe9jd/DGVt25EwsSwjlZcqYhdfqAsMOnnlkY6Rm8Px9//S2vvF68dKkyliiIhuu8nkNJlYcc3nRsuTSWIkieh7t5oHiIi++yN/Qd+AoJYkiTljvjrYOEcVO3mPAACcKhhJkibc6HcVNslYC3xMZ953c7pLgBNgyl8NGI5oRfH+xom2TYvlBQCAUwVCFwBARghdSBs+FuFGtr054TnXMHV8sqaj4WQf46k/e+3PPeGznezjpNu0eCMNTk1CLML592zLsi84+6OfX4FTlMBLxCkOPXeeiOjTX804LX4PELqQNu4NzxekQn51x6N31eoLyoKczpAKdezJkESBMZTU+HNXXOoiIur955/K+EhQJQo8mzFr0XDmvLNGiYha7r+twVLbOBLubzcrtIZU9pKVg8PvrCtMhYOq7KUX9ltq5wbSO8JT06P3jmZvfi2cwackZsFZev/1P8hyERHdctVg2dgwr0olJfaiK83DV1ybMUp0YJZ89iXGkd3bY6YbfpzV/6OvuCouuMLsadoYMavUjHjHo/md9lwl/8efefK0ela45ubM4esv6auqrNeE9zbFTNGwyN34i+ze+cv04WhEZH92g6t4oDulzXUo474RXvmNn2T1z1ygi6b3UTl6WF6AtMlZfsmg0mhJVHzh9hZDcVUw6R/VlH3+ltbya25riY84daHuVgMRUcHKq3rLr7mttfzqb7f4dm3J5iMhjohI4lOsvqgiWPml7+1jVWpheNPL+cWf+Xp74cWf6xzZ+np+ekd3atr4asjk6ktpHn6lqPUvrxe3dLYkdNs2RAxERN+9P6f30deLWx98pahl3d8D2d4RniMiSsQltqZBG3n8rZKWeUv14URcYmvnaMKPv1XSUjtHG37mMf9hl5gEXmIefrW49drb7QN//c1YHhHRPx7w2vVGTlj7dsm+L34709nXkdTLN/oTAzNdmBLCvW2m6ECXqfMvd9cSEYmpJJv0ejRUWhMe3f5mdqi71UJExEeCyvioW2PQGyPEcpKpclaQiEhty44xnEJkOYWkzXHE+FAAH1Y5CXa8HTXt3hY1XfOJ3loionhMYge6kpoFy/XhJ//kzd62PmIhIvKO8MrejqQmw66IsCzReatNvvE+FAqSVlxkDBARVdZrIu9tipgOd6xlK40+IqK6uZrIn+848OGjlp1xw2XXWDxERNWzNPGCUtW0meGOQ+jClCBJEtnmLh3KnL9i9OD7Q10txshAl7H0/25u41RqsXvtfVUSn2KJiBiWlZgPPiPOMAyxnEL64H6SJPHwC4fwsUiSRKu/YB1a85WM/3metr4VNu7eFjP+aV1Rm07Pitdf0leVjB/4lj6lihEPXsflFIzEsAducxyRKNBhn6vxj+uzHEOiIJ0yzyeWFyBtOLVWEFNJlojIWFIT9Le8lykkYiwRUTIwpkyFAgohEeNYtVbgVGox5nFq4h7XtPt38lQyf7k++PqzwcxISGCJiIYGUspRd0oRDoic3sgKOj0rdu6La7paEyfleapp0ITXrwtZiYja98Q1gz1J7ck4zsmEmS6kjUJvFDTZBeGOh++o0zsqAqaqWd7uv95XTUTEKFViwcqrekyVMwO+XVvs7Q/9vE5ltsU1WXmRdNd9OltyvjHY257UXHdxfzURkUbLit/9TU7PkgsMgRefDNivXNpTl+dQxstq1CfleVrzFevIT782VHzVsgPHyS9Sxg1mblp9zx8+BnwKwceATw34GPDEBF6iVEpiNFpW6u1IqG/9P2fl2reL96rU7MRBlgaTfQwYM10AmDZiEZH9xqcGqgT+wBrv9T+w9021wD0ShC4ATBsGMyc++lpxa7rr+DjwRhoAgIwQugAAMkLoAgDICKELACAjhC4AgIwQugAAMkLoAgDICKELACAjhC4AgIwQugAAMkLoAgDICKELACAjhC4AgIwQugAAMkLoAgDICKELACAjhC4AgIwQugAAMkLoAgDICKELACAjhC4AgIwQugAAMmIkaVpdMh4AYFrDTBcAQEYIXQAAGSF0AQBkhNAFAJARQhcAQEYIXQAAGf0/ajYkSwEOpcoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import squarify\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "squarify.plot(sizes=top_words, label=top_words.index, alpha=.8 )\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwFsTqrVZMYi"
   },
   "source": [
    "## 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gx2gZCbl5Np"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>02</th>\n",
       "      <th>02115njob</th>\n",
       "      <th>03</th>\n",
       "      <th>030nnmicrosoft</th>\n",
       "      <th>04</th>\n",
       "      <th>06366</th>\n",
       "      <th>08</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>...</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zf</th>\n",
       "      <th>zfs</th>\n",
       "      <th>zheng</th>\n",
       "      <th>zillow</th>\n",
       "      <th>zillows</th>\n",
       "      <th>zonesnability</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 16025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    02  02115njob   03  030nnmicrosoft   04  06366   08   10  100  1000  ...  \\\n",
       "0  0.0        0.0  0.0             0.0  0.0    0.0  0.0  0.0  0.0   0.0  ...   \n",
       "1  0.0        0.0  0.0             0.0  0.0    0.0  0.0  0.0  0.0   0.0  ...   \n",
       "2  0.0        0.0  0.0             0.0  0.0    0.0  0.0  0.0  0.0   0.0  ...   \n",
       "3  0.0        0.0  0.0             0.0  0.0    0.0  0.0  0.0  0.0   0.0  ...   \n",
       "4  0.0        0.0  0.0             0.0  0.0    0.0  0.0  0.0  0.0   0.0  ...   \n",
       "\n",
       "   zeus   zf  zfs     zheng  zillow  zillows  zonesnability  zoom  zuckerberg  \\\n",
       "0   0.0  0.0  0.0  0.000000     0.0      0.0            0.0   0.0         0.0   \n",
       "1   0.0  0.0  0.0  0.000000     0.0      0.0            0.0   0.0         0.0   \n",
       "2   0.0  0.0  0.0  0.000000     0.0      0.0            0.0   0.0         0.0   \n",
       "3   0.0  0.0  0.0  0.103678     0.0      0.0            0.0   0.0         0.0   \n",
       "4   0.0  0.0  0.0  0.000000     0.0      0.0            0.0   0.0         0.0   \n",
       "\n",
       "   zurich  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  \n",
       "\n",
       "[5 rows x 16025 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Instantiate vectorizer object\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Create a vocabulary and get word counts per document\n",
    "# Similiar to fit_predict\n",
    "dtm = tfidf.fit_transform(df['description'])\n",
    "\n",
    "# Print word counts\n",
    "\n",
    "# Get feature names to use as dataframe column headers\n",
    "dtm = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names())\n",
    "\n",
    "# View Feature Matrix as DataFrame\n",
    "dtm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(document):\n",
    "    \n",
    "    doc = nlp(document)\n",
    "    \n",
    "    return [token.lemma_.strip() for token in doc if (token.is_stop != True) and (token.is_punct != True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>analytic</th>\n",
       "      <th>big</th>\n",
       "      <th>business</th>\n",
       "      <th>datum</th>\n",
       "      <th>deep</th>\n",
       "      <th>disability</th>\n",
       "      <th>engineer</th>\n",
       "      <th>...</th>\n",
       "      <th>year relevant</th>\n",
       "      <th>year work</th>\n",
       "      <th>yes</th>\n",
       "      <th>york</th>\n",
       "      <th>york city</th>\n",
       "      <th>young</th>\n",
       "      <th>younnabout</th>\n",
       "      <th>younnwe</th>\n",
       "      <th>yrs</th>\n",
       "      <th>zf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.044144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.042668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.055515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.103009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ability   able   analytic   big   business   datum   deep  \\\n",
       "0  0.044144       0.0    0.0        0.0   0.0        0.0     0.0    0.0   \n",
       "1  0.042668       0.0    0.0        0.0   0.0        0.0     0.0    0.0   \n",
       "2  0.000000       0.0    0.0        0.0   0.0        0.0     0.0    0.0   \n",
       "3  0.055515       0.0    0.0        0.0   0.0        0.0     0.0    0.0   \n",
       "4  0.103009       0.0    0.0        0.0   0.0        0.0     0.0    0.0   \n",
       "\n",
       "    disability   engineer  ...  year relevant  year work  yes  york  \\\n",
       "0          0.0        0.0  ...            0.0        0.0  0.0   0.0   \n",
       "1          0.0        0.0  ...            0.0        0.0  0.0   0.0   \n",
       "2          0.0        0.0  ...            0.0        0.0  0.0   0.0   \n",
       "3          0.0        0.0  ...            0.0        0.0  0.0   0.0   \n",
       "4          0.0        0.0  ...            0.0        0.0  0.0   0.0   \n",
       "\n",
       "   york city  young  younnabout  younnwe  yrs   zf  \n",
       "0        0.0    0.0         0.0      0.0  0.0  0.0  \n",
       "1        0.0    0.0         0.0      0.0  0.0  0.0  \n",
       "2        0.0    0.0         0.0      0.0  0.0  0.0  \n",
       "3        0.0    0.0         0.0      0.0  0.0  0.0  \n",
       "4        0.0    0.0         0.0      0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tunning Parameters\n",
    "\n",
    "# Instantiate vectorizer object\n",
    "tfidf = TfidfVectorizer(stop_words='english', \n",
    "                       tokenizer=tokenize, \n",
    "                       min_df=2, \n",
    "                       max_df=.95,\n",
    "                       max_features=5000,\n",
    "                       ngram_range=(1,2)\n",
    "                       )\n",
    "\n",
    "# Create a vocabulary and get word counts per document\n",
    "dtm = tfidf.fit_transform(df['description'])\n",
    "\n",
    "# Print word counts\n",
    "\n",
    "# Get feature names to use as dataframe column headers\n",
    "dtm = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names())\n",
    "\n",
    "# View Feature Matrix as DataFrame\n",
    "dtm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Create a NearestNeighbor Model. Write the description of your ideal datascience job and query your job listings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "                 metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Fit on DTM\n",
    "nn = NearestNeighbors(n_neighbors=5, algorithm='kd_tree')\n",
    "nn.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "dream_job = [ \"\"\"\n",
    "XYZ company is hiring an entry level data or business analyst to solve business problems. Our\n",
    "company has a strong culture. We believe in having a good work life balance.  We have a casual\n",
    "dress code, easy access to the subway and close to Penn station for the Long Island Railroad.\n",
    "Applicants should have experience using python, sql, github, etc. Applicant would preferably\n",
    "have prior experience with investing in the stock market.  Bootcamp in lieu of computer science\n",
    "degree is ok.  We have offices in New York City and Long Island.  Salary range is 80,000 - 120,000\n",
    "and is commensurate with experience.  \n",
    "\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query for Sim of Random job description\n",
    "new = tfidf.transform(dream_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.24459273, 1.25512601, 1.27007021, 1.28194501, 1.29040031]]),\n",
       " array([[124, 169, 136, 215, 358]]))"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.kneighbors(new.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bkeysight marketing is hiring a data scientist to scale up insights that are a foundational element for marketing transformation you will be part of the data analysts team whose goal is to build analytic capabilities that support the strategy planning and execution of marketing activitiesnnyou will need to have a deep competency and strong experience with statistics modeling using data science tools and applying them to the real world of customer targeting and optimizing roinnresponsibilitiesnyour focus will be generating customer insights the improve online and offline customer experience and targetingnyou will also focus on automating reporting that can be easily consumed by different stakeholdersnyou will consolidate validate and investigate big data from multiple sources to find and deliver actionable insights to business partners and to upper management to make informed business decisionsnyou will create datadriven attribution statistical models of marketing touches and customer responses to measure and maximize roindevelop propensity score matching for segmentation of customersnjob descriptionnkeysight marketing is hiring a data scientist to scale up insights that are a foundational element for marketing transformation you will be part of the data analysts team whose goal is to build analytic capabilities that support the strategy planning and execution of marketing activitiesnnyou will need to have a deep competency and strong experience with statistics modeling using data science tools and applying them to the real world of customer targeting and optimizing roinnresponsibilitiesnyour focus will be generating customer insights the improve online and offline customer experience and targetingnyou will also focus on automating reporting that can be easily consumed by different stakeholdersnyou will consolidate validate and investigate big data from multiple sources to find and deliver actionable insights to business partners and to upper management to make informed business decisionsnyou will create datadriven attribution statistical models of marketing touches and customer responses to measure and maximize roindevelop propensity score matching for segmentation of customersnjob qualificationsnwho you arennanalytical with a proven track record of expertlevel ability in analytical techniques model development and deployment of highvelocity transactional datana leader you can lead others to solve complex problems use sophisticated analytical thought to exercise judgment identify innovative solutions and coordinate with multiple stakeholdersna communicator with strong interpersonal skills ability to work effectively with all levels of the organizationna selfmotivator who is highly organized can assess prioritize of projects and manage multiple tasks simultaneouslnndesired skills and qualificationsnnbs ms in a field related to data science computer engineering statistics mathematics or a closely related quantitative field with 4 years of work or research experience in applied data sciencencomfortable with both structured and unstructured datanstrong competency in r python or sqlnexperience with visualization tools such as domo or tableaunexperience with analytics tools as adobe analytics google analyticsnfamiliarity with big data processing such as hadoop is a plusnjob functionnnprivacy statementnkeysight is an equal opportunity employernkeysight technologies inc is an equal opportunity employer qualified applicants will receive consideration for employment without regard to race color religion sex sexual orientation gender identity national origin protected veteran status disability or any other protected categories under all applicable lawsncandidates can be considered to work from the following locationsnamericas  united states  arizona  tempe  americas  united states  california  anaheim  americas  united states  california  calabasas  americas  united states  california  el segundo  americas  united states  california  irvine voscal  americas  united states  california  roseville  americas  united states  california  san diego  americas  united states  california  santa clara  americas  united states  california  santa rosa  americas  united states  california  westlake village  americas  united states  colorado  colorado springs  americas  united states  colorado  englewood  americas  united states  colorado  englewood  americas  united states  colorado  loveland  americas  united states  florida  boca raton  americas  united states  florida  orlando  americas  united states  georgia  alpharetta  americas  united states  georgia  atlanta  americas  united states  illinois  arlington heights  americas  united states  illinois  schaumburg  americas  united states  iowa  elk horn  americas  united states  maryland  columbia  americas  united states  massachusetts  andover  americas  united states  michigan  detroit  americas  united states  michigan  novi  americas  united states  new hampshire  nashua  americas  united states  new jersey  budd lake  americas  united states  new mexico  albuquerque  americas  united states  new york  cold springs  americas  united states  new york  pittsford  americas  united states  new york  rochester  americas  united states  new york  utica  americas  united states  north carolina  apex  americas  united states  north carolina  morrisville  americas  united states  ohio  mentor  americas  united states  oregon  beaverton  americas  united states  oregon  lake oswego  americas  united states  pennsylvania  bethlehem  americas  united states  pennsylvania  philadelphia  americas  united states  puerto rico  san juan  americas  united states  texas  austin  americas  united states  texas  dallas  americas  united states  texas  plano  americas  united states  texas  richardson  americas  united states  utah  salt lake city  americas  united states  virginia  chantilly  americas  united states  washington  everett  americas  united states  washington  pleasantonnjob id  33051'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description'][124]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiDfTWceoRkH"
   },
   "source": [
    "## Stretch Goals\n",
    "\n",
    " - Try different visualizations for words and frequencies - what story do you want to tell with the data?\n",
    " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
    " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
    " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
    "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data.\n",
    " - Create a labeled dataset - which jobs will you apply for? Train a model to select the jobs you are most likely to apply for. :) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_422_BOW_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "U4S1NLP",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "0.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
