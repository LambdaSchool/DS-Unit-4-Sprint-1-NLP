{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 1 Assignment 2*\n",
    "\n",
    "# Document Representations: Bag-Of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "!pip install -U nltk\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import sent_tokenize # Sentence Tokenizer\n",
    "from nltk.tokenize import word_tokenize # Word Tokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-1-NLP/master/module2-vector-representations/job_listings.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) (optional) Scrape 100 Job Listings that contain the title \"Data Scientist\" from indeed.com\n",
    "\n",
    "At a minimum your final dataframe of job listings should contain\n",
    "- Job Title\n",
    "- Job Description\n",
    "\n",
    "If you choose to not to scrape the data, there is a CSV with outdated data in the directory. Remeber, if you scrape Indeed, you're helping yourself find a job. ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "raise Exception(\"\\nThis task is not complete. \\nReplace this line with your code for the task.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b\"<div><div>Job Requirements:</div><ul><li><p>\\\\nConceptual understanding in Machine Learning models like Nai\\\\xc2\\\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them</p>\\\\n</li><li><p>Intermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role)</p>\\\\n</li><li><p>Exposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R</p>\\\\n</li><li><p>Ability to communicate Model findings to both Technical and Non-Technical stake holders</p>\\\\n</li><li><p>Hands on experience in SQL/Hive or similar programming language</p>\\\\n</li><li><p>Must show past work via GitHub, Kaggle or any other published article</p>\\\\n</li><li><p>Master\\'s degree in Statistics/Mathematics/Computer Science or any other quant specific field.</p></li></ul><div><div><div><div><div><div>\\\\nApply Now</div></div></div></div></div></div></div><div></div>\"'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Use Spacy to tokenize / clean the listings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "nlp = spacy.load(\"en\")\n",
    "\n",
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "\n",
    "\"\"\"make tokens\"\"\"\n",
    "for doc in tokenizer.pipe(df['description'], batch_size=500):\n",
    "    doc_tokens = [token.text for token in doc]\n",
    "    tokens.append(doc_tokens)\n",
    "    \n",
    "df['tokens'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(df['tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "vectorizer.fit(list(df['description']))\n",
    "\n",
    "vectorizer.vocabulary_\n",
    "\n",
    "dtm = vectorizer.transform(list(df['description']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 2, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = pd.DataFrame(dtm.todense(), columns = vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>02115</th>\n",
       "      <th>03</th>\n",
       "      <th>0356</th>\n",
       "      <th>04</th>\n",
       "      <th>057</th>\n",
       "      <th>062</th>\n",
       "      <th>06366</th>\n",
       "      <th>08</th>\n",
       "      <th>...</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zf</th>\n",
       "      <th>zheng</th>\n",
       "      <th>zillow</th>\n",
       "      <th>zogsports</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  02115  03  0356  04  057  062  06366  08  ...  zero  zeus  zf  \\\n",
       "0   0    0      0   0     0   0    0    0      0   0  ...     0     0   0   \n",
       "1   0    0      0   0     0   0    0    0      0   0  ...     0     0   0   \n",
       "2   0    0      0   0     0   0    0    0      0   0  ...     0     0   0   \n",
       "3   0    0      0   0     0   0    0    0      0   0  ...     0     0   0   \n",
       "4   0    0      0   0     0   0    0    0      0   0  ...     0     0   0   \n",
       "\n",
       "   zheng  zillow  zogsports  zones  zoom  zuckerberg  zurich  \n",
       "0      0       0          0      0     0           0       0  \n",
       "1      0       0          0      0     0           0       0  \n",
       "2      0       0          0      0     0           0       0  \n",
       "3      1       0          0      0     0           0       0  \n",
       "4      0       0          0      0     0           0       0  \n",
       "\n",
       "[5 rows x 9202 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Visualize the most common word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_top_n_words(corpus, n=None):\n",
    "    \"\"\"\n",
    "    List the top n words in a vocabulary according to occurrence in a text corpus.\n",
    "    \"\"\"\n",
    "    vec = CountVectorizer(stop_words='english').fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in     vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('li', 12785),\n",
       " ('and', 11746),\n",
       " ('to', 6931),\n",
       " ('div', 6870),\n",
       " ('the', 5397),\n",
       " ('of', 4612),\n",
       " ('data', 4452),\n",
       " ('br', 3894),\n",
       " ('in', 3614),\n",
       " ('with', 3070),\n",
       " ('ul', 2636),\n",
       " ('for', 2067),\n",
       " ('or', 1936),\n",
       " ('you', 1672),\n",
       " ('experience', 1584),\n",
       " ('we', 1522),\n",
       " ('our', 1508),\n",
       " ('is', 1451),\n",
       " ('xe2', 1417),\n",
       " ('x80', 1404)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_n_words(df['description'])[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english', max_features=5000, min_df=.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = tfidf.fit_transform(df['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>2019</th>\n",
       "      <th>40</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>academic</th>\n",
       "      <th>access</th>\n",
       "      <th>...</th>\n",
       "      <th>x99ll</th>\n",
       "      <th>x99re</th>\n",
       "      <th>x99s</th>\n",
       "      <th>x99t</th>\n",
       "      <th>x9d</th>\n",
       "      <th>xe2</th>\n",
       "      <th>xs</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>york</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067365</td>\n",
       "      <td>0.0352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.119005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032782</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325896</td>\n",
       "      <td>0.069212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091059</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1003 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000   10  100  2019   40  abilities   ability  able  academic  access  ...  \\\n",
       "0  0.0  0.0  0.0   0.0  0.0        0.0  0.101507   0.0       0.0     0.0  ...   \n",
       "1  0.0  0.0  0.0   0.0  0.0        0.0  0.019120   0.0       0.0     0.0  ...   \n",
       "2  0.0  0.0  0.0   0.0  0.0        0.0  0.000000   0.0       0.0     0.0  ...   \n",
       "3  0.0  0.0  0.0   0.0  0.0        0.0  0.000000   0.0       0.0     0.0  ...   \n",
       "4  0.0  0.0  0.0   0.0  0.0        0.0  0.000000   0.0       0.0     0.0  ...   \n",
       "\n",
       "   x99ll     x99re    x99s  x99t  x9d       xe2        xs      year     years  \\\n",
       "0    0.0  0.000000  0.0000   0.0  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "1    0.0  0.067365  0.0352   0.0  0.0  0.119005  0.000000  0.032782  0.000000   \n",
       "2    0.0  0.000000  0.0000   0.0  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "3    0.0  0.000000  0.0000   0.0  0.0  0.000000  0.325896  0.069212  0.000000   \n",
       "4    0.0  0.000000  0.0000   0.0  0.0  0.083943  0.000000  0.000000  0.091059   \n",
       "\n",
       "   york  \n",
       "0   0.0  \n",
       "1   0.0  \n",
       "2   0.0  \n",
       "3   0.0  \n",
       "4   0.0  \n",
       "\n",
       "[5 rows x 1003 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names())\n",
    "docs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 6) Create a NearestNeighbor Model. Write the description of your ideal datascience job and query your job listings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=None, n_neighbors=5, p=2, radius=1.0)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=5, algorithm='ball_tree')\n",
    "\n",
    "nn.fit(dtm.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_job_description = [\"We’re looking for a data scientist with a passion for tackling big problems. A member of our Predictive Modeling team, you will be embedded in our Advocate Center with a mission to identify opportunities to apply your unique skillset, ensure confidence in your products and promote their adoption among our Advocate teams. Your predictive models will inform decisions and drive real-time strategy in this critical area. You will have the opportunity to work with a top-caliber team of former professors and PhDs, develop insights from a large array of proprietary datasets, and apply cutting edge methods in machine learning, experimental design, simulation and optimization, and statistics. Most importantly, you will have the satisfaction of working side-by-side with our advocates and witnessing the direct impact your products have as they use them to enhance the customer experience.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.23109268, 1.23109268, 1.25836823, 1.26230218, 1.26270597]]),\n",
       " array([[142,  52,  36, 404, 342]]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = tfidf.transform(ideal_job_description)\n",
    "\n",
    "nn.kneighbors(new.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"b'<div><p><b>Position Summary\\\\n</b></p><p></p>In today\\\\xe2\\\\x80\\\\x99s fast evolving technology world, one aspect remains common \\\\xe2\\\\x80\\\\x93 reliance on data to drive the next wave of innovation. Strategic Analytics is Samsung\\\\xe2\\\\x80\\\\x99s Center-of-Excellence for driving the adoption of data driven decision making and product development across the company. The team\\\\xe2\\\\x80\\\\x99s core focus is developing best-in-class solutions that provide Samsung\\\\xe2\\\\x80\\\\x99s marketing and service organizations with a 360 degree view of the Samsung customers.\\\\n<br/>\\\\n<br/>\\\\nStrategic Analytics is powering a paradigm shift at Samsung and the global industry. We are looking for highly technical team members who are passionate about data, have the rigor needed to solve billion dollar problems, and possess an innate entrepreneurial spirit to explore the uncharted. Strategic Analytics combines the engineering backbone of a best-in-class Big Data Platform with the analytic expertise of advanced mining and predictive modeling.\\\\n<br/>\\\\n<br/>\\\\nIf you want to work among the very best talent in the industry, working on the most innovative products in the world, Samsung is the place to be.\\\\n<p></p><p><b>Role and Responsibilities\\\\n</b></p><p></p><p><b>Position Summary\\\\n</b></p><p></p><p>Data Scientists are responsible for managing the successful design, execution, and measurement of major data initiatives across all customer-facing channels. They provide a critical link between the most technical areas of the organization and our business partners who activate against Strategic Analytics\\\\xe2\\\\x80\\\\x99 deliverables. Balancing excellent business communication skills with a deep analytical understanding is needed to 1) successfully build never-been-done-before analytic solutions in a Big Data environment and 2) interface daily with business partners, engineering, and product management teams.\\\\n</p><p></p><p><b>Common Essential Duties &amp; Responsibilities\\\\n</b></p><p></p><ul><li>Discover and apply insights from massive data sets of structured, semi-structured, and unstructured data\\\\n</li><li>Collaborate with Line of Business teams and executive sponsors to develop novel, practical, and operationalized analytics that drive explicit business value at the customer level\\\\n</li><li>Combine strengths in data management, analysis, applied statistics, and visualization capabilities\\\\n</li><li>Develop data analysis solutions based on descriptive analyses and predictive models\\\\n</li><li>Collaborate with marketing, service, development, and engineering teams to ensure that requirements for integration, security, data quality and cross functional usage are addressed\\\\n</li></ul><p></p><p><b>Skills and Qualifications\\\\n</b></p><p></p><p><b>Background /Experience\\\\n</b></p><p></p><p>Extensive experience solving analytic problems using quantitative approaches and a proven passion for generating actionable insights and predictions from data. Have marketing or service industry experience manipulating and analyzing complex, high-volume, high-dimensionality data from varying sources. Strong knowledge of statistical methods and particularly in the areas of predictive modeling/scoring.\\\\n</p><ul><li>7+ years experience in sales or marketing functions for consumer products, retail, tech, telecom, or financial industries\\\\n</li><li>5+ years experience developing analytic results that directly inform and/or enable quantifiable business action, either by providing insights or building analytic applications\\\\n</li><li>5+ years Statistical programming expertise: R required; Python &amp; Spark preferred\\\\n</li><li>3+ years Big data mining expertise: Hive &amp; Impala required; SQL preferred\\\\n</li><li>Machine learning expertise: GLM Regression (linear, logit, multinomial), kMeans/Hierarchical Clustering, Principle Component Analysis, &amp; Decision Tree required; Neural Network, Panel Regression, Bayesian Regression, Times Series, &amp; A Priori preferred\\\\n</li><li>Data scale expertise: Regular use of data with high-volume (1TB+) &amp; high-dimensionality (500+ variables per schema) required; clear understanding of Hadoop framework with hands-on experience both querying and applying statistics on massive data sets\\\\n</li><li>Education background: MS or PhD in Mathematics, Computer Science, Engineering, or Economics required; incremental MBA preferred\\\\n</li><li>Ability to communicate complex quantitative analysis in a clear, precise, and actionable manner.\\\\n</li></ul><p></p><p><b>Necessary Skills /Attributes\\\\n</b></p><p></p><p>Develop and maintain excellent working relationships with all assigned levels within and outside the company. The ability to convince others, in a potentially adversarial and highly technical environment, including customer leadership, VPs, directors &amp; managers, staff, and vendors with opposing views to accept/approve plans, technical, and project recommendations. Plan, organize, and prioritize multiple complex assignments and projects. Read and interpret detailed and complex engineering product development and marketing documents, media materials, and contracts (or related documents) based on corporate legal and marketing standards and philosophy. Work independently and in a team environment in order to achieve personal and team goals and complete assignments within established time frames. Ability to lead and direct the activities of staff members in order to achieve customer business objectives and team goals and to complete assigned projects within established time frames and specifications. The ability to develop tasks and work assignments, clearly define objectives, and give direction with applied knowledge of alternatives and decision-making experience to guide subordinates. Ability to negotiate on behalf of function to come to agreement by managing communications through discussions and compromise; issues are short-term operational and medium-term tactical or limited strategic nature.\\\\n</p><p></p><p><b>Physical /Mental Demands &amp; Conditions\\\\n</b></p><p></p><p>Work is generally performed in an office environment. Operate a computer keyboard and view a video display terminal between 50% - 95% of work time, including prolonged periods of time. Requires considerable (90%+) work utilizing high visual acuity/detail, numeric/character distinction, and moderate hand/finger dexterity. The movement and transportation of equipment, most of the time is under 25 pounds. Performs work under time schedules and stress which are normally periodic or cyclical, including time sensitive deadlines, intellectual challenge, some language barriers, and project management deadlines. Machines, tools, equipment, and work aids include printers, copiers, faxes, and other equipment commonly associated with an office work area. May require working additional hours beyond normal schedule. Travel varies depending on position. Consistently demonstrates a commitment to policies and procedures, including but not limited to, attendance, confidentiality, conflict of interest, and ethical responsibilities.\\\\n</p><p></p><p>* Please visit Samsung membership to see Privacy Policy, which defaults according to your location. You can change Country/Language at the bottom of the page. If you are European Economic Resident, please click here .</p></div>'\""
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description'][36]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stretch Goals\n",
    "\n",
    " - Try different visualizations for words and frequencies - what story do you want to tell with the data?\n",
    " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
    " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
    " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
    "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python 3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
