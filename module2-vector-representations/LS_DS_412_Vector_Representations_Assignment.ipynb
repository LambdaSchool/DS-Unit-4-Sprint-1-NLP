{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Vector Representations\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "hyj-f9FDcVFp",
    "outputId": "5dd045fe-6e4c-458c-e2fc-253c3da9c805"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from spacy.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7bcmqfGXrFG"
   },
   "source": [
    "## 1) *Clean:* Job Listings from indeed.com that contain the title \"Data Scientist\" \n",
    "\n",
    "You have `job_listings.csv` in the data folder for this module. The text data in the description column is still messy - full of html tags. Use the [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) library to clean up this column. You will need to read through the documentation to accomplish this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcYlc1URXhlC"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "jobs = pd.read_csv(\"data/job_listings.csv\")\n",
    "\n",
    "jobs.head(20)\n",
    "\n",
    "jobs = jobs.drop(columns='Unnamed: 0')\n",
    "\n",
    "##### Your Code Here #####\n",
    "#raise Exception(\"\\nThis task is not complete. \\nReplace this line with your code for the task.\")\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n",
       "      <td>Data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>b\"&lt;b&gt;About Us:&lt;/b&gt;&lt;br/&gt;\\nWant to be part of a ...</td>\n",
       "      <td>Senior Data Science Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
       "      <td>2019 PhD Data Scientist Internship - Forecasti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
       "      <td>Data Scientist - Insurance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>b\"&lt;p&gt;&lt;/p&gt;&lt;div&gt;&lt;p&gt;SENIOR DATA SCIENTIST&lt;/p&gt;&lt;p&gt;\\...</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>b'&lt;div&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;p&gt;Cerner Int...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>426 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           description  \\\n",
       "0    b\"<div><div>Job Requirements:</div><ul><li><p>...   \n",
       "1    b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...   \n",
       "2    b'<div><p>As a Data Scientist you will be work...   \n",
       "3    b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n",
       "4    b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...   \n",
       "..                                                 ...   \n",
       "421  b\"<b>About Us:</b><br/>\\nWant to be part of a ...   \n",
       "422  b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n",
       "423  b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n",
       "424  b\"<p></p><div><p>SENIOR DATA SCIENTIST</p><p>\\...   \n",
       "425  b'<div></div><div><div><div><div><p>Cerner Int...   \n",
       "\n",
       "                                                 title  \n",
       "0                                      Data scientist   \n",
       "1                                     Data Scientist I  \n",
       "2                         Data Scientist - Entry Level  \n",
       "3                                       Data Scientist  \n",
       "4                                       Data Scientist  \n",
       "..                                                 ...  \n",
       "421                       Senior Data Science Engineer  \n",
       "422  2019 PhD Data Scientist Internship - Forecasti...  \n",
       "423                         Data Scientist - Insurance  \n",
       "424                              Senior Data Scientist  \n",
       "425                                     Data Scientist  \n",
       "\n",
       "[426 rows x 2 columns]"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs\n",
    "\n",
    "###OK now I need to use Beautiful Soup to parse the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_description(desc):\n",
    "    soup = BeautifulSoup(desc)\n",
    "    #soup = soup.stripped_strings\n",
    "    soup = soup.get_text()\n",
    "    soup = soup.replace(\"\\\\n\", \"\")\n",
    "\n",
    "    \n",
    "        #strip=True\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs['clean_desc'] = jobs['description'].apply(clean_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"b'<div>Create various Business Intelligence Analytical reports, visualization and dashboards with BI tools like Tableau, Power BI or similar;<br/>\\\\nUtilize experience in scientific data, logic programming and calculated columns, and decision making;<br/>\\\\nDevelop and maintain dashboards for KPIs, purchase trends with time series and customer flows with Tableau and Teradata;<br/>\\\\nDevelop recommendation models utilizing machine learning and predictive analysis with supervised and unsupervised algorithms like random forest, support vector machine and k-means clustering;<br/>\\\\nUtilize experience with SQL with strong concepts of database, data warehouse and metadata;<br/>\\\\nWork closely with frontend web developer and UX designer on improving online shopping experience and deploying business strategies like promotion or similar;<br/>\\\\nAnalyze customer behaviors and purchase trends to create customized recommended items;<br/>\\\\nConduct and apply A/B test to monitor and test new or modified features for online shopping experiences across desktop and mobile platforms;<br/>\\\\nCollect real time data from A/B test and generate feedback reports for presentations and communications to other teams, both technical and non-technical;<br/>\\\\nUtilize clustering models to categorize customers and generate optimized business strategies for different categories;<br/>\\\\nCreate novel computational approaches and analytical tools as required by market and business goals;<br/>\\\\nDesign databases and develop algorithms for processing and analyzing purchase, device information and customer information;<br/>\\\\nAnalyze geographic trends for online shopper sessions with business strategy implications and present on dashboard;<br/>\\\\nConsult with clients to analyze business problem, setup market goals, recommend technology-based solutions, or determine computational strategies;<br/>\\\\nWork with large data access, admin &amp; configuration and application data services;<br/>\\\\nWork with business stakeholders to identify requirements and outcomes, and to frame meaningful business scenarios that impact critical business functions;<br/>\\\\nDesign experiments, test hypothesis, build models to conduct data analysis and design algorithms and utilize appropriate designs to conduct analytics and discover patterns;</div>\\\\n<br/><div><div>Key Skills: </div><div>Python, R, SQL, Tableau, Excel</div></div>'\""
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs['description'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"b'Create various Business Intelligence Analytical reports, visualization and dashboards with BI tools like Tableau, Power BI or similar;Utilize experience in scientific data, logic programming and calculated columns, and decision making;Develop and maintain dashboards for KPIs, purchase trends with time series and customer flows with Tableau and Teradata;Develop recommendation models utilizing machine learning and predictive analysis with supervised and unsupervised algorithms like random forest, support vector machine and k-means clustering;Utilize experience with SQL with strong concepts of database, data warehouse and metadata;Work closely with frontend web developer and UX designer on improving online shopping experience and deploying business strategies like promotion or similar;Analyze customer behaviors and purchase trends to create customized recommended items;Conduct and apply A/B test to monitor and test new or modified features for online shopping experiences across desktop and mobile platforms;Collect real time data from A/B test and generate feedback reports for presentations and communications to other teams, both technical and non-technical;Utilize clustering models to categorize customers and generate optimized business strategies for different categories;Create novel computational approaches and analytical tools as required by market and business goals;Design databases and develop algorithms for processing and analyzing purchase, device information and customer information;Analyze geographic trends for online shopper sessions with business strategy implications and present on dashboard;Consult with clients to analyze business problem, setup market goals, recommend technology-based solutions, or determine computational strategies;Work with large data access, admin & configuration and application data services;Work with business stakeholders to identify requirements and outcomes, and to frame meaningful business scenarios that impact critical business functions;Design experiments, test hypothesis, build models to conduct data analysis and design algorithms and utilize appropriate designs to conduct analytics and discover patterns;Key Skills: Python, R, SQL, Tableau, Excel'\""
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs['clean_desc'][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C4xFZNtX1m2"
   },
   "source": [
    "## 2) Use Spacy to tokenize the listings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhUHuMr-X-II"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "#raise Exception(\"\\nThis task is not complete. \\nReplace this line with your code for the task.\"\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "tokens = []\n",
    "\n",
    "for doc in tokenizer.pipe(jobs['clean_desc'], batch_size=500):\n",
    "    doc_tokens = [token.text for token in doc]\n",
    "    tokens.append(doc_tokens)\n",
    "\n",
    "jobs['clean_desc_token'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b\"Job',\n",
       " 'Requirements:Conceptual',\n",
       " 'understanding',\n",
       " 'in',\n",
       " 'Machine',\n",
       " 'Learning',\n",
       " 'models',\n",
       " 'like',\n",
       " 'Nai\\\\xc2\\\\xa8ve',\n",
       " 'Bayes,',\n",
       " 'K-Means,',\n",
       " 'SVM,',\n",
       " 'Apriori,',\n",
       " 'Linear/',\n",
       " 'Logistic',\n",
       " 'Regression,',\n",
       " 'Neural,',\n",
       " 'Random',\n",
       " 'Forests,',\n",
       " 'Decision',\n",
       " 'Trees,',\n",
       " 'K-NN',\n",
       " 'along',\n",
       " 'with',\n",
       " 'hands-on',\n",
       " 'experience',\n",
       " 'in',\n",
       " 'at',\n",
       " 'least',\n",
       " '2',\n",
       " 'of',\n",
       " 'themIntermediate',\n",
       " 'to',\n",
       " 'expert',\n",
       " 'level',\n",
       " 'coding',\n",
       " 'skills',\n",
       " 'in',\n",
       " 'Python/R.',\n",
       " '(Ability',\n",
       " 'to',\n",
       " 'write',\n",
       " 'functions,',\n",
       " 'clean',\n",
       " 'and',\n",
       " 'efficient',\n",
       " 'data',\n",
       " 'manipulation',\n",
       " 'are',\n",
       " 'mandatory',\n",
       " 'for',\n",
       " 'this',\n",
       " 'role)Exposure',\n",
       " 'to',\n",
       " 'packages',\n",
       " 'like',\n",
       " 'NumPy,',\n",
       " 'SciPy,',\n",
       " 'Pandas,',\n",
       " 'Matplotlib',\n",
       " 'etc',\n",
       " 'in',\n",
       " 'Python',\n",
       " 'or',\n",
       " 'GGPlot2,',\n",
       " 'dplyr,',\n",
       " 'tidyR',\n",
       " 'in',\n",
       " 'RAbility',\n",
       " 'to',\n",
       " 'communicate',\n",
       " 'Model',\n",
       " 'findings',\n",
       " 'to',\n",
       " 'both',\n",
       " 'Technical',\n",
       " 'and',\n",
       " 'Non-Technical',\n",
       " 'stake',\n",
       " 'holdersHands',\n",
       " 'on',\n",
       " 'experience',\n",
       " 'in',\n",
       " 'SQL/Hive',\n",
       " 'or',\n",
       " 'similar',\n",
       " 'programming',\n",
       " 'languageMust',\n",
       " 'show',\n",
       " 'past',\n",
       " 'work',\n",
       " 'via',\n",
       " 'GitHub,',\n",
       " 'Kaggle',\n",
       " 'or',\n",
       " 'any',\n",
       " 'other',\n",
       " 'published',\n",
       " \"articleMaster's\",\n",
       " 'degree',\n",
       " 'in',\n",
       " 'Statistics/Mathematics/Computer',\n",
       " 'Science',\n",
       " 'or',\n",
       " 'any',\n",
       " 'other',\n",
       " 'quant',\n",
       " 'specific',\n",
       " 'field.Apply',\n",
       " 'Now\"']"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs['clean_desc_token'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(jobs['description'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(jobs['clean_desc'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(jobs['clean_desc_token'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobs['clean_desc'][9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lgCZNL_YycP"
   },
   "source": [
    "## 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Can just plug in the whole pandas series (df column) into the vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b\"DescriptionA',\n",
       " 'rare',\n",
       " 'opportunity',\n",
       " 'to',\n",
       " 'join',\n",
       " 'the',\n",
       " 'development',\n",
       " 'division',\n",
       " 'within',\n",
       " 'Information',\n",
       " 'Systems',\n",
       " 'at',\n",
       " 'Steward',\n",
       " 'Health',\n",
       " 'Care,',\n",
       " 'the',\n",
       " 'top',\n",
       " 'leader',\n",
       " 'in',\n",
       " 'the',\n",
       " 'competitive',\n",
       " 'for-profit',\n",
       " 'hospital',\n",
       " 'industry.',\n",
       " 'We',\n",
       " 'are',\n",
       " 'seeking',\n",
       " 'a',\n",
       " 'motivated',\n",
       " 'and',\n",
       " 'experienced',\n",
       " 'Data',\n",
       " 'Scientist',\n",
       " 'to',\n",
       " 'contribute',\n",
       " 'to',\n",
       " 'the',\n",
       " 'software',\n",
       " 'development',\n",
       " 'initiatives',\n",
       " 'that',\n",
       " 'improve',\n",
       " 'the',\n",
       " 'quality',\n",
       " 'of',\n",
       " 'health',\n",
       " 'care',\n",
       " 'across',\n",
       " 'the',\n",
       " 'country.',\n",
       " 'This',\n",
       " 'individual',\n",
       " 'will',\n",
       " 'be',\n",
       " 'working',\n",
       " 'with',\n",
       " 'programmers,',\n",
       " 'analysts',\n",
       " 'and',\n",
       " 'senior',\n",
       " 'level',\n",
       " 'management',\n",
       " 'to',\n",
       " 'optimize',\n",
       " 'the',\n",
       " 'development',\n",
       " 'process',\n",
       " 'within',\n",
       " 'the',\n",
       " 'enterprise',\n",
       " 'by',\n",
       " 'expanding',\n",
       " 'our',\n",
       " 'existing',\n",
       " 'predictive',\n",
       " 'analytics',\n",
       " 'field.Key',\n",
       " 'ResponsibilitiesConduct',\n",
       " 'research',\n",
       " 'and',\n",
       " 'build',\n",
       " 'actionable',\n",
       " 'visualizations',\n",
       " 'that',\n",
       " 'drive',\n",
       " 'decisions.Collect',\n",
       " 'data',\n",
       " 'required',\n",
       " 'to',\n",
       " 'extract',\n",
       " 'actionable',\n",
       " 'insights.Work',\n",
       " 'with',\n",
       " 'the',\n",
       " 'subject',\n",
       " 'matter',\n",
       " 'experts',\n",
       " 'and',\n",
       " 'key',\n",
       " 'stakeholders',\n",
       " 'to',\n",
       " 'understand',\n",
       " 'end',\n",
       " 'goals',\n",
       " 'for',\n",
       " 'enhancements',\n",
       " 'and',\n",
       " 'new',\n",
       " 'predictive',\n",
       " 'tools.Values',\n",
       " 'critical',\n",
       " 'thinking',\n",
       " 'and',\n",
       " 'has',\n",
       " 'the',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'solve',\n",
       " 'complex',\n",
       " 'problems',\n",
       " 'with',\n",
       " 'incomplete',\n",
       " 'data',\n",
       " 'and',\n",
       " 'a',\n",
       " 'genuine',\n",
       " 'curiosity.Contribute',\n",
       " 'to',\n",
       " 'the',\n",
       " \"team's\",\n",
       " 'overall',\n",
       " 'knowledge',\n",
       " 'by',\n",
       " 'educating',\n",
       " 'colleagues',\n",
       " 'and',\n",
       " 'peers',\n",
       " 'about',\n",
       " 'new',\n",
       " 'functionality',\n",
       " 'and',\n",
       " 'upcoming',\n",
       " 'tools',\n",
       " 'applicable',\n",
       " 'to',\n",
       " 'data',\n",
       " 'science.Ability',\n",
       " 'and',\n",
       " 'willingness',\n",
       " 'to',\n",
       " 'adapt',\n",
       " 'quickly',\n",
       " 'to',\n",
       " 'changing',\n",
       " 'priorities',\n",
       " 'and',\n",
       " 'requests.Skills/Experience2+',\n",
       " 'years',\n",
       " 'of',\n",
       " 'experience',\n",
       " 'in',\n",
       " 'a',\n",
       " 'data',\n",
       " 'scientist',\n",
       " 'role.Can',\n",
       " 'solve',\n",
       " 'business',\n",
       " 'problems',\n",
       " 'using',\n",
       " 'data',\n",
       " 'analytics',\n",
       " 'and',\n",
       " 'big',\n",
       " 'data',\n",
       " 'and',\n",
       " 'data',\n",
       " 'lake',\n",
       " 'technologies.Basic',\n",
       " 'python',\n",
       " 'programming',\n",
       " 'experience',\n",
       " 'at',\n",
       " 'the',\n",
       " 'minimum.Familiar',\n",
       " 'with',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'and',\n",
       " 'modeling',\n",
       " 'capabilities.Knowledge',\n",
       " 'of',\n",
       " 'tools',\n",
       " 'required',\n",
       " 'to',\n",
       " 'extract,',\n",
       " 'transform,',\n",
       " 'and',\n",
       " 'visualize',\n",
       " 'big',\n",
       " 'data.Understanding',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Agile',\n",
       " 'Software',\n",
       " 'Development',\n",
       " 'principles',\n",
       " 'and',\n",
       " 'practices',\n",
       " 'a',\n",
       " 'plus.Job',\n",
       " 'RelationshipThe',\n",
       " 'Data',\n",
       " 'Scientist',\n",
       " 'reports',\n",
       " 'to',\n",
       " 'the',\n",
       " 'Development',\n",
       " 'Director.\"']"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs['clean_desc_token'][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobs_data = jobs['clean_desc_token']\n",
    "\n",
    "#This creates a list, which vectorize doesn't like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(jobs['clean_desc_token'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_data = jobs['clean_desc']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "\n",
    "vect.fit(jobs_data)\n",
    "\n",
    "dtm = vect.transform(jobs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<426x12061 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 112033 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12061"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"Job Requirements:Conceptual understanding in Machine Learning models like Nai\\xc2\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests,"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 2, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(dtm\n",
    "dtm.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pay</th>\n",
       "      <th>02115job</th>\n",
       "      <th>03</th>\n",
       "      <th>0356</th>\n",
       "      <th>04</th>\n",
       "      <th>062</th>\n",
       "      <th>06366</th>\n",
       "      <th>08</th>\n",
       "      <th>...</th>\n",
       "      <th>zenreach</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zf</th>\n",
       "      <th>zheng</th>\n",
       "      <th>zillow</th>\n",
       "      <th>zonesability</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>426 rows × 12061 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     00  000  000pay  02115job  03  0356  04  062  06366  08  ...  zenreach  \\\n",
       "0     0    0       0         0   0     0   0    0      0   0  ...         0   \n",
       "1     0    0       0         0   0     0   0    0      0   0  ...         0   \n",
       "2     0    0       0         0   0     0   0    0      0   0  ...         0   \n",
       "3     0    0       0         0   0     0   0    0      0   0  ...         0   \n",
       "4     0    0       0         0   0     0   0    0      0   0  ...         0   \n",
       "..   ..  ...     ...       ...  ..   ...  ..  ...    ...  ..  ...       ...   \n",
       "421   0    0       0         0   0     0   0    0      0   0  ...         0   \n",
       "422   0    0       0         0   0     0   0    0      0   0  ...         0   \n",
       "423   0    2       0         0   0     0   0    0      0   0  ...         0   \n",
       "424   0    0       0         0   0     0   0    0      0   0  ...         0   \n",
       "425   0    1       0         0   0     0   0    0      0   0  ...         0   \n",
       "\n",
       "     zero  zeus  zf  zheng  zillow  zonesability  zoom  zuckerberg  zurich  \n",
       "0       0     0   0      0       0             0     0           0       0  \n",
       "1       0     0   0      0       0             0     0           0       0  \n",
       "2       0     0   0      0       0             0     0           0       0  \n",
       "3       0     0   0      1       0             0     0           0       0  \n",
       "4       0     0   0      0       0             0     0           0       0  \n",
       "..    ...   ...  ..    ...     ...           ...   ...         ...     ...  \n",
       "421     0     0   0      0       0             0     0           0       0  \n",
       "422     0     0   0      0       0             0     0           0       0  \n",
       "423     1     0   0      0       0             0     0           0       0  \n",
       "424     0     0   0      0       0             0     0           0       0  \n",
       "425     0     0   0      0       0             0     0           0       0  \n",
       "\n",
       "[426 rows x 12061 columns]"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names())\n",
    "dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zo1iH_UeY7_n"
   },
   "source": [
    "## 4) Visualize the most common word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "and           11727\n",
       "to             6924\n",
       "the            5427\n",
       "of             4606\n",
       "data           4346\n",
       "in             3618\n",
       "with           3061\n",
       "for            2065\n",
       "or             1931\n",
       "you            1722\n",
       "we             1598\n",
       "our            1538\n",
       "is             1448\n",
       "xe2            1417\n",
       "x80            1404\n",
       "experience     1384\n",
       "will           1315\n",
       "as             1248\n",
       "on             1204\n",
       "business       1172\n",
       "dtype: int64"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_20_words = dtm.sum().sort_values(ascending=False).head(20)\n",
    "top_20_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_20_word_counts = result.count().sort_values(ascending=False).head(20)\n",
    "\n",
    "#top_20_word_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwFsTqrVZMYi"
   },
   "source": [
    "## 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gx2gZCbl5Np"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>04</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1079302who</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>125</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>youyou</th>\n",
       "      <th>yrs</th>\n",
       "      <th>zenreach</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zf</th>\n",
       "      <th>zillow</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.077232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.334631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.165942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         000   04   10       100  1079302who   11   12  125   14   15  ...  \\\n",
       "0   0.000000  0.0  0.0  0.000000         0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "1   0.000000  0.0  0.0  0.000000         0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "2   0.000000  0.0  0.0  0.000000         0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "3   0.000000  0.0  0.0  0.000000         0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "4   0.000000  0.0  0.0  0.000000         0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "5   0.000000  0.0  0.0  0.000000         0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "6   0.000000  0.0  0.0  0.000000         0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "7   0.000000  0.0  0.0  0.000000         0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "8   0.000000  0.0  0.0  0.000000         0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "9   0.000000  0.0  0.0  0.042607         0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "10  0.000000  0.0  0.0  0.000000         0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "11  0.077232  0.0  0.0  0.000000         0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "12  0.000000  0.0  0.0  0.000000         0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "13  0.000000  0.0  0.0  0.000000         0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "14  0.000000  0.0  0.0  0.000000         0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "15  0.000000  0.0  0.0  0.000000         0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "16  0.000000  0.0  0.0  0.000000         0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "17  0.000000  0.0  0.0  0.000000         0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "18  0.000000  0.0  0.0  0.000000         0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "19  0.334631  0.0  0.0  0.165942         0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "    young    youyou  yrs  zenreach  zero  zeus   zf  zillow  zuckerberg  \\\n",
       "0     0.0  0.000000  0.0       0.0   0.0   0.0  0.0     0.0         0.0   \n",
       "1     0.0  0.000000  0.0       0.0   0.0   0.0  0.0     0.0         0.0   \n",
       "2     0.0  0.000000  0.0       0.0   0.0   0.0  0.0     0.0         0.0   \n",
       "3     0.0  0.000000  0.0       0.0   0.0   0.0  0.0     0.0         0.0   \n",
       "4     0.0  0.000000  0.0       0.0   0.0   0.0  0.0     0.0         0.0   \n",
       "5     0.0  0.000000  0.0       0.0   0.0   0.0  0.0     0.0         0.0   \n",
       "6     0.0  0.096882  0.0       0.0   0.0   0.0  0.0     0.0         0.0   \n",
       "7     0.0  0.000000  0.0       0.0   0.0   0.0  0.0     0.0         0.0   \n",
       "8     0.0  0.000000  0.0       0.0   0.0   0.0  0.0     0.0         0.0   \n",
       "9     0.0  0.000000  0.0       0.0   0.0   0.0  0.0     0.0         0.0   \n",
       "10    0.0  0.000000  0.0       0.0   0.0   0.0  0.0     0.0         0.0   \n",
       "11    0.0  0.000000  0.0       0.0   0.0   0.0  0.0     0.0         0.0   \n",
       "12    0.0  0.000000  0.0       0.0   0.0   0.0  0.0     0.0         0.0   \n",
       "13    0.0  0.096882  0.0       0.0   0.0   0.0  0.0     0.0         0.0   \n",
       "14    0.0  0.000000  0.0       0.0   0.0   0.0  0.0     0.0         0.0   \n",
       "15    0.0  0.000000  0.0       0.0   0.0   0.0  0.0     0.0         0.0   \n",
       "16    0.0  0.000000  0.0       0.0   0.0   0.0  0.0     0.0         0.0   \n",
       "17    0.0  0.000000  0.0       0.0   0.0   0.0  0.0     0.0         0.0   \n",
       "18    0.0  0.000000  0.0       0.0   0.0   0.0  0.0     0.0         0.0   \n",
       "19    0.0  0.000000  0.0       0.0   0.0   0.0  0.0     0.0         0.0   \n",
       "\n",
       "    zurich  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "5      0.0  \n",
       "6      0.0  \n",
       "7      0.0  \n",
       "8      0.0  \n",
       "9      0.0  \n",
       "10     0.0  \n",
       "11     0.0  \n",
       "12     0.0  \n",
       "13     0.0  \n",
       "14     0.0  \n",
       "15     0.0  \n",
       "16     0.0  \n",
       "17     0.0  \n",
       "18     0.0  \n",
       "19     0.0  \n",
       "\n",
       "[20 rows x 5000 columns]"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Instantiate vectorizer object\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "\n",
    "# Create a vocabulary and get word counts per document\n",
    "# Similiar to fit_predict\n",
    "dtm = tfidf.fit_transform(jobs_data)\n",
    "\n",
    "# Print word counts\n",
    "\n",
    "# Get feature names to use as dataframe column headers\n",
    "dtm = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names())\n",
    "\n",
    "# View Feature Matrix as DataFrame\n",
    "dtm.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 5000)"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Create a NearestNeighbor Model. Write the description of your ideal datascience job and query your job listings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "                 metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NearestNeighbors(n_neighbors=5, algorithm='kd_tree')\n",
    "nn.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 1.28956338, 1.29087035, 1.295877  , 1.29730159]]),\n",
       " array([[  0, 274, 366, 338, 115]]))"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.kneighbors([dtm.iloc[0].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 0.        , 1.20894849, 1.23852435, 1.24256154]]),\n",
       " array([[ 47, 100, 201, 307, 147]]))"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.kneighbors([dtm.iloc[100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b\"DescriptionA rare opportunity to join the development division within Information Systems at Steward Health Care, the top leader in the competitive for-profit hospital industry. We are seeking a motivated and experienced Data Scientist to contribute to the software development initiatives that improve the quality of health care across the country. This individual will be working with programmers, analysts and senior level management to optimize the development process within the enterprise by '"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_data[100][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"b'InternshipOverviewData Science InternshipsPortland, OR or Seattle, WAThese twelve-week internships are scheduled to begin in May/June 2019Responsibilities & RequirementsCambia Health Solutions is working to create a seamless and frictionless health care experience for consumers nationwide. This presents a unique challenge and opportunity for innovative and disruptive solutions from our Artificial Intelligence team.Our Data Scientists design, develop, and implement data-driven solutions using m\""
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_data[201][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Nice, these seem like similar job descriptions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Writing my own job description:\n",
    "\n",
    "wills_jd = [\"\"\"\n",
    "This job is about 10% programming, 10% visual art, and 80% chilling.\n",
    "Every day you will research solutions to the climate crisis, while also having plenty of time to hike outside.\n",
    "We will pay a salary of $1M per year, and only require you to be in the office one week per month.\n",
    "You will have awesome co-workers who are as excited about this opportunity as you are.\n",
    "You need to know Python, pandas, artificial general intelligence, and machine learning. \n",
    "The ideal candidate also enjoys kayaking, skiing, and paragliding.\n",
    "Keywords: climate change, environmental science, hydrology, earth science, geology, geomorphology\n",
    "Other keywords: GIS, geospatial analysis, AI\n",
    "\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 42 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = tfidf.transform(wills_jd)\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.29527379, 1.31123947, 1.32754159, 1.32754159, 1.32880595]]),\n",
       " array([[306,  84, 315, 207, 255]]))"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.kneighbors(new.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"b'Please review the job details below.Radiant Solutions is growing and we are looking for motivated data evangelists who are passionate about delivering new and innovative solutions for our customers. The ideal candidate needs limited direction, is passionate about technology and is curious about earth sensing and the new space economy.What you\\\\'ll get to do:You will be applying the latest machine learning techniques to extract insights from geospatial data.You will have access to an enormous corpus of training data and will work to build the best models through bake-offs, hyperparameter searching, and incremental learning techniques.You will quantitatively assess model performance and document the overall life-cycle.You will work with other members of the data science and engineering teams to improve data science products and experiences.Additionally, you will be developing rapid prototype solutions as needed for the focused collection, parsing, managing, analyzing, and visualizing large sets of disparate data to extract meaningful insights.Requirements:Must have a current/active TS/SCI8-10 years\\\\' experience designing, implementing, training, evaluating, and optimizing algorithms based on state-of-the-art machine learning techniquesExperience with applying deep learning for computer vision and natural language processing.Experience with major deep learning framework such as Caffe, CNTK, Theano, Torch, and Tensorflow.#cjpostMAXAR Technologies offers a generous compensation package including a competitive salary; choice of medical plan; dental, life, and disability insurance; a 401(K) plan with competitive company match; paid holidays and paid time off.'\""
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_data[306]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hey, this job sounds cool!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eveything below this is garbage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2PZ8Pj_YxcF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef vectorize(text):\\n    vect.fit(text)\\n    dtm = vect.transform(text)\\n    return dtm\\n\\ndef vectorize_str(text):\\n    vect.fit([text])\\n    dtm = vect.transform([text])\\n    return dtm \\n'"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This attempt isn't as clean\n",
    "'''\n",
    "def vectorize(text):\n",
    "    vect.fit(text)\n",
    "    dtm = vect.transform(text)\n",
    "    return dtm\n",
    "\n",
    "def vectorize_str(text):\n",
    "    vect.fit([text])\n",
    "    dtm = vect.transform([text])\n",
    "    return dtm \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorized_description_1 = vectorize_str(jobs['description'][0])\n",
    "\n",
    "#vectorized_description_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtm = pd.DataFrame(vectorized_description_1.todense(), columns=vect.get_feature_names())\n",
    "#dtm[\"description\"] = jobs['description'][0]\n",
    "\n",
    "#dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorized_description_2 = vectorize_str(jobs['description'][1])\n",
    "\n",
    "#vectorized_description_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtm2 = pd.DataFrame(vectorized_description_2.todense(), columns=vect.get_feature_names())\n",
    "#dtm2[\"description\"] = jobs['description'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = pd.concat([dtm, dtm2], axis=0, sort=False)\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "#range(len(jobs['description']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type(jobs_dtms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\njobs_dtms = []\\n\\nfor row in range(len(jobs[\\'description\\'])):\\n#for row in range(5):\\n    vectorized_description = vectorize_str(jobs[\\'description\\'][row])\\n    dtm = pd.DataFrame(vectorized_description.todense(), columns=vect.get_feature_names())\\n    dtm[\"description\"] = jobs[\\'description\\'][row]\\n    dtm[\"title\"] = jobs[\\'title\\'][row]\\n    \\n    jobs_dtms.append(dtm)\\n    \\nresult = pd.concat(jobs_dtms, axis=0, sort=False)\\nresult\\n'"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "jobs_dtms = []\n",
    "\n",
    "for row in range(len(jobs['description'])):\n",
    "#for row in range(5):\n",
    "    vectorized_description = vectorize_str(jobs['description'][row])\n",
    "    dtm = pd.DataFrame(vectorized_description.todense(), columns=vect.get_feature_names())\n",
    "    dtm[\"description\"] = jobs['description'][row]\n",
    "    dtm[\"title\"] = jobs['title'][row]\n",
    "    \n",
    "    jobs_dtms.append(dtm)\n",
    "    \n",
    "result = pd.concat(jobs_dtms, axis=0, sort=False)\n",
    "result\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtm = jobs['description'].apply(vectorize_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(dtm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtm[0].todense().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dtm[0])\n",
    "\n",
    "#dtm[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtm = pd.DataFrame(dtm[0].todense(), columns=vect.get_feature_names())\n",
    "#dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(jobs['description'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(jobs['clean_desc_list'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "##workflow for one row\n",
    "\n",
    "#token_text = jobs['clean_desc_list'][0]\n",
    "\n",
    "#token_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "#token_text = [token_text]\n",
    "\n",
    "#type(token_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#og_text = jobs['description'][0]\n",
    "#og_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#og_text = [og_text]\n",
    "#vectorize(og_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "#og_text[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtm = vectorize(og_text)\n",
    "#dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtm.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtm = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names())\n",
    "#dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for item in jobs['description']:\n",
    "#    item = [item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(jobs['description'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobs['description'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "raise Exception(\"\\nThis task is not complete. \\nReplace this line with your code for the task.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 9455)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiDfTWceoRkH"
   },
   "source": [
    "## Stretch Goals\n",
    "\n",
    " - Try different visualizations for words and frequencies - what story do you want to tell with the data?\n",
    " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
    " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
    " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
    "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data.\n",
    " - Create a labeled dataset - which jobs will you apply for? Train a model to select the jobs you are most likely to apply for. :) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_422_BOW_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "0.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
