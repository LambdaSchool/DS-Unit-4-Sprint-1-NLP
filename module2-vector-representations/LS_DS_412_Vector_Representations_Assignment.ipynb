{"cells":[{"cell_type":"markdown","metadata":{},"source":["<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n","<br></br>\n","\n","# Vector Representations\n","## *Data Science Unit 4 Sprint 2 Assignment 2*"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":"import re\nimport string\n\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport spacy"},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"M7bcmqfGXrFG"},"source":["## 1) *Optional:* Scrape 100 Job Listings that contain the title \"Data Scientist\" from indeed.com\n","\n","At a minimum your final dataframe of job listings should contain\n","- Job Title\n","- Job Description\n","\n","If you choose to not to scrape the data, there is a CSV with outdated data in the directory. Remeber, if you scrape Indeed, you're helping yourself find a job. ;)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>description</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n      <td>Data scientist</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n      <td>Data Scientist I</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n      <td>Data Scientist - Entry Level</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n      <td>Data Scientist</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n      <td>Data Scientist</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"   Unnamed: 0                                        description  \\\n0           0  b\"<div><div>Job Requirements:</div><ul><li><p>...   \n1           1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...   \n2           2  b'<div><p>As a Data Scientist you will be work...   \n3           3  b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n4           4  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...   \n\n                          title  \n0               Data scientist   \n1              Data Scientist I  \n2  Data Scientist - Entry Level  \n3                Data Scientist  \n4                Data Scientist  "},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":"##### Your Code Here #####\nimport pandas\n\npath = 'module2-vector-representations/data/job_listings.csv'\njobs = pandas.read_csv(path)\njobs.head()"},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":"ellipsis"},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":"type(...)"},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":"'–'"},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":"str(b'\\xe2\\x80\\x93'.decode('utf-8'))"},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5C4xFZNtX1m2"},"source":"## 2) Use Spacy to tokenize / clean the listings"},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":"import spacy\n\nnlp = spacy.load(\"en_core_web_lg\")\ntokenizer = spacy.tokenizer.Tokenizer(nlp.vocab)"},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":"from bs4 import BeautifulSoup\nimport ast\nimport re\n\ndef tokenize(text):\n    utf8 = ast.literal_eval(text).decode('utf-8')\n    soup = BeautifulSoup(utf8)\n    cleaned = soup.get_text(' ', strip=True)\n    cleaned = cleaned.replace('\\n','').lower()\n    tokenized = tokenizer(cleaned)\n    stripped_tokens = []\n    for token in tokenized:\n        if token.is_stop == False and token.is_punct == False:\n            append = token.lemma_\n            append = re.sub(r'^[^a-z0-9]*','',append)\n            append = re.sub(r'[^a-z0-9]*$','',append)\n            stripped_tokens.append(append)\n    return (stripped_tokens)"},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"data":{"text/plain":"['job',\n 'requirements',\n 'conceptual',\n 'understand',\n 'machine',\n 'learn',\n 'model',\n 'like',\n 'nai¨ve',\n 'bayes',\n 'k-means',\n 'svm',\n 'apriori',\n 'linear',\n 'logistic',\n 'regression',\n 'neural',\n 'random',\n 'forests',\n 'decision',\n 'trees',\n 'k-nn',\n 'hands-on',\n 'experience',\n '2',\n 'intermediate',\n 'expert',\n 'level',\n 'code',\n 'skill',\n 'python/r',\n 'ability',\n 'write',\n 'functions',\n 'clean',\n 'efficient',\n 'datum',\n 'manipulation',\n 'mandatory',\n 'role',\n 'exposure',\n 'package',\n 'like',\n 'numpy',\n 'scipy',\n 'pandas',\n 'matplotlib',\n 'etc',\n 'python',\n 'ggplot2',\n 'dplyr',\n 'tidyr',\n 'r',\n 'ability',\n 'communicate',\n 'model',\n 'finding',\n 'technical',\n 'non-technical',\n 'stake',\n 'holder',\n 'hand',\n 'experience',\n 'sql/hive',\n 'similar',\n 'programme',\n 'language',\n 'past',\n 'work',\n 'github',\n 'kaggle',\n 'publish',\n 'article',\n \"master's\",\n 'degree',\n 'statistics/mathematics/computer',\n 'science',\n 'quant',\n 'specific',\n 'field',\n 'apply']"},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":"tokenize(jobs['description'][0])"},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-lgCZNL_YycP"},"source":"## 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":"from sklearn.feature_extraction.text import CountVectorizer\n\ncountVectorizer = CountVectorizer(tokenizer=tokenize)\n\ncounts = countVectorizer.fit_transform(jobs['description'])"},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"data":{"text/plain":"<426x8766 sparse matrix of type '<class 'numpy.int64'>'\n\twith 91345 stored elements in Compressed Sparse Row format>"},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":"counts"},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(426, 8766)\n"},{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>0</th>\n      <th>0-2</th>\n      <th>0-3</th>\n      <th>0-30</th>\n      <th>00</th>\n      <th>02115</th>\n      <th>03/18/19</th>\n      <th>03/25/19</th>\n      <th>0305-47069</th>\n      <th>...</th>\n      <th>zf’s</th>\n      <th>zheng</th>\n      <th>zillow</th>\n      <th>zillow's</th>\n      <th>zogsports</th>\n      <th>zone</th>\n      <th>zoom</th>\n      <th>zuckerberg</th>\n      <th>zurich</th>\n      <th>zurich’s</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 8766 columns</p>\n</div>","text/plain":"      0  0-2  0-3  0-30  00  02115  03/18/19  03/25/19  0305-47069  ...  zf’s  \\\n0  0  0    0    0     0   0      0         0         0           0  ...     0   \n1  0  0    0    0     0   0      0         0         0           0  ...     0   \n2  0  0    0    0     0   0      0         0         0           0  ...     0   \n3  0  0    0    0     0   0      0         0         0           0  ...     0   \n4  0  0    0    0     0   0      0         0         0           0  ...     0   \n\n   zheng  zillow  zillow's  zogsports  zone  zoom  zuckerberg  zurich  \\\n0      0       0         0          0     0     0           0       0   \n1      0       0         0          0     0     0           0       0   \n2      0       0         0          0     0     0           0       0   \n3      1       0         0          0     0     0           0       0   \n4      0       0         0          0     0     0           0       0   \n\n   zurich’s  \n0         0  \n1         0  \n2         0  \n3         0  \n4         0  \n\n[5 rows x 8766 columns]"},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":"df = pandas.DataFrame(data=counts.todense(), columns=countVectorizer.get_feature_names())\n\nprint(df.shape)\ndf.head()"},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Zo1iH_UeY7_n"},"source":"## 4) Visualize the most common word counts"},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"data":{"text/plain":"datum         3931\nexperience    2010\nwork          1660\nteam          1275\nbusiness      1227\nscience        950\nmodel          908\nlearn          830\nproduct        776\nanalysis       769\ndtype: int64"},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":"df.sum(axis='rows').sort_values(ascending=False)[:10]"},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bwFsTqrVZMYi"},"source":"## 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[{"data":{"text/plain":"<426x8766 sparse matrix of type '<class 'numpy.float64'>'\n\twith 91345 stored elements in Compressed Sparse Row format>"},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidfVectorizer = TfidfVectorizer(tokenizer=tokenize)\n\ntfidfs = tfidfVectorizer.fit_transform(jobs['description'])\n\ntfidfs"},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(426, 8766)\n"},{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>0</th>\n      <th>0-2</th>\n      <th>0-3</th>\n      <th>0-30</th>\n      <th>00</th>\n      <th>02115</th>\n      <th>03/18/19</th>\n      <th>03/25/19</th>\n      <th>0305-47069</th>\n      <th>...</th>\n      <th>zf’s</th>\n      <th>zheng</th>\n      <th>zillow</th>\n      <th>zillow's</th>\n      <th>zogsports</th>\n      <th>zone</th>\n      <th>zoom</th>\n      <th>zuckerberg</th>\n      <th>zurich</th>\n      <th>zurich’s</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.10937</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 8766 columns</p>\n</div>","text/plain":"          0  0-2  0-3  0-30   00  02115  03/18/19  03/25/19  0305-47069  ...  \\\n0  0.0  0.0  0.0  0.0   0.0  0.0    0.0       0.0       0.0         0.0  ...   \n1  0.0  0.0  0.0  0.0   0.0  0.0    0.0       0.0       0.0         0.0  ...   \n2  0.0  0.0  0.0  0.0   0.0  0.0    0.0       0.0       0.0         0.0  ...   \n3  0.0  0.0  0.0  0.0   0.0  0.0    0.0       0.0       0.0         0.0  ...   \n4  0.0  0.0  0.0  0.0   0.0  0.0    0.0       0.0       0.0         0.0  ...   \n\n   zf’s    zheng  zillow  zillow's  zogsports  zone  zoom  zuckerberg  zurich  \\\n0   0.0  0.00000     0.0       0.0        0.0   0.0   0.0         0.0     0.0   \n1   0.0  0.00000     0.0       0.0        0.0   0.0   0.0         0.0     0.0   \n2   0.0  0.00000     0.0       0.0        0.0   0.0   0.0         0.0     0.0   \n3   0.0  0.10937     0.0       0.0        0.0   0.0   0.0         0.0     0.0   \n4   0.0  0.00000     0.0       0.0        0.0   0.0   0.0         0.0     0.0   \n\n   zurich’s  \n0       0.0  \n1       0.0  \n2       0.0  \n3       0.0  \n4       0.0  \n\n[5 rows x 8766 columns]"},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":"df = pandas.DataFrame(data=tfidfs.todense(), columns=tfidfVectorizer.get_feature_names())\n\nprint(df.shape)\ndf.head()"},{"cell_type":"markdown","metadata":{},"source":"## 6) Create a NearestNeighbor Model. Write the description of your ideal datascience job and query your job listings."},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[{"data":{"text/plain":"NearestNeighbors(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n                 metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n                 radius=1.0)"},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":"from sklearn.neighbors import NearestNeighbors\n\nnearestNeighbors = NearestNeighbors(n_neighbors=5, algorithm='ball_tree')\nnearestNeighbors.fit(df)"},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[{"data":{"text/plain":"(array([[0.        , 1.29006558, 1.32003726, 1.32076359, 1.3339386 ]]),\n array([[  0, 276, 274, 115, 338]]))"},"execution_count":68,"metadata":{},"output_type":"execute_result"}],"source":"nearestNeighbors.kneighbors([df.loc[0]])"},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"['2', 'ability', 'ability', 'apply', 'apriori', 'article', 'bayes', 'clean', 'code', 'communicate', 'conceptual', 'datum', 'decision', 'degree', 'dplyr', 'efficient', 'etc', 'experience', 'experience', 'expert', 'exposure', 'field', 'finding', 'forests', 'functions', 'ggplot2', 'github', 'hand', 'hands-on', 'holder', 'intermediate', 'job', 'k-means', 'k-nn', 'kaggle', 'language', 'learn', 'level', 'like', 'like', 'linear', 'logistic', 'machine', 'mandatory', 'manipulation', \"master's\", 'matplotlib', 'model', 'model', 'nai¨ve', 'neural', 'non-technical', 'numpy', 'package', 'pandas', 'past', 'programme', 'publish', 'python', 'python/r', 'quant', 'r', 'random', 'regression', 'requirements', 'role', 'science', 'scipy', 'similar', 'skill', 'specific', 'sql/hive', 'stake', 'statistics/mathematics/computer', 'svm', 'technical', 'tidyr', 'trees', 'understand', 'work', 'write']\n['2', 'advance', 'algorithmic', 'algorithms', 'analysis', 'analysis', 'analysis', 'analysis', 'analysis', 'analytic', 'analytic', 'analytic', 'analytics', 'app', 'approach', 'aptitude', 'billion', 'bring', 'bring', 'build', 'build', 'build', 'build', 'build', 'build', 'build', 'builder', 'business', 'business', 'c', 'caffe2', 'candidate', 'classification', 'cleaning', 'close', 'close', 'cluster', 'collect', 'communicate', 'community', 'community', 'community', 'company', 'complexity', 'compute', 'compute', 'computer', 'connect', 'connect', 'constantly', 'continue', 'cost', 'create', 'critical', 'cross-functionally', 'data', 'dataset', 'datum', 'datum', 'datum', 'datum', 'datum', 'datum', 'datum', 'decision', 'decision', 'define', 'degree', 'degree', 'different', 'distribute', 'dplyr', 'drive', 'drive', 'drive', 'drive', 'e.g', 'effective', 'efficient', 'empower', 'enable', 'engineering', 'etc', 'expand', 'experience', 'experience', 'experience', 'experience', 'experience', 'experience', 'experience', 'experience', 'experience', 'experience', 'experience', 'experiments', 'extraction', 'facebook', 'facebook', \"facebook's\", 'facebook’s', 'family', 'field', 'field', 'field', 'final', 'forecast', 'forecasting', 'get', 'ggplot2', 'ggplot2', 'give', 'global', 'graduate', 'group', 'growth', 'hadoop', 'hadoop', 'heart', 'help', 'help', 'help', 'hive', 'hypothesis', 'i.e', 'ideal', 'industry', 'infrastructure', 'infrastructure', 'infrastructure', 'iterating', 'java', 'keras', 'kind', 'language', 'large', 'large-scale', 'learn', 'learn', 'learn', 'learning', 'leverage', 'leverage', 'library', 'library', 'like', 'machine', 'machine', 'machine', 'machine', 'maintain', 'making', 'making', 'master’s', 'mathematics', 'matplotlib', 'matter', 'meaningful', 'medium', 'method', 'minimum', 'mission', 'mobile', 'model', 'model', 'model', 'models', 'models', 'new', 'numpy', 'operation', 'optimization', 'organization', 'package', 'package', 'pandas', 'passionate', 'people', 'people', 'people', 'people', 'people', 'people', 'perform', 'phd', 'power', 'prefer', 'presentation', 'principle', 'problem', 'problem', 'problems', 'problems', 'product', 'proficiency', 'programme', 'pyplot', 'python', 'python', 'pytorch', 'qualification', 'qualification', 'quantitative', 'quantitative', 'quantitative', 'query', 'r', 'r', 'reach', 'recommendation', 'recommendations', 'regression', 'relate', 'research', 'research', 'responsibility', 'responsible', 'science', 'scientific', 'scikit-learn', 'scipy', 'series', 'services', 'share', 'small', 'solve', 'solve', 'solve', 'spark', 'sql', 'sql', 'started', 'statements', 'statistic', 'statistical', 'statistics', 'statistics', 'strategic', 'strategy', 'strong', 'strong', 'support', 'team', 'technique', 'tensorflow', 'testing', 'theano', 'them', 'time', 'together', 'together', 'together', 'tool', 'tool', 'tool', 'visualization', 'way', 'ways', \"we're\", \"we're\", \"we're\", 'web', 'work', 'work', 'work', 'world', 'world', 'world', 'write', 'year']\n"}],"source":"print(sorted(tokenize(jobs['description'][0])))\nprint(sorted(tokenize(jobs['description'][276])))"},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"FiDfTWceoRkH"},"source":"## Stretch Goals\n\n - Try different visualizations for words and frequencies - what story do you want to tell with the data?\n - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data.\n - Create a labeled dataset - which jobs will you apply for? Train a model to select the jobs you are most likely to apply for. :)"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}