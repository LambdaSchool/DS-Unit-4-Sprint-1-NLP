{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 2*\n",
    "\n",
    "# Document Representations: Bag-Of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "hyj-f9FDcVFp",
    "outputId": "5dd045fe-6e4c-458c-e2fc-253c3da9c805"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/16/4d247e27c55a7b6412e7c4c86f2500ae61afcbf5932b9e3491f8462f8d9e/nltk-3.4.4.zip (1.5MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5MB 3.8MB/s eta 0:00:01     |█████████████▌                  | 614kB 3.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: six in /home/nicklauswinters/anaconda3/lib/python3.7/site-packages (from nltk) (1.12.0)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/nedderlander/.cache/pip/wheels/41/c8/31/48ace4468e236e0e8435f30d33e43df48594e4d53e367cf061\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "  Found existing installation: nltk 3.4.3\n",
      "    Uninstalling nltk-3.4.3:\n",
      "      Successfully uninstalled nltk-3.4.3\n",
      "Successfully installed nltk-3.4.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/nedderlander/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/nedderlander/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "!pip install -U nltk\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import sent_tokenize # Sentence Tokenizer\n",
    "from nltk.tokenize import word_tokenize # Word Tokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7bcmqfGXrFG"
   },
   "source": [
    "# 1) (optional) Scrape 100 Job Listings that contain the title \"Data Scientist\" from indeed.com\n",
    "\n",
    "At a minimum your final dataframe of job listings should contain\n",
    "- Job Title\n",
    "- Job Description\n",
    "\n",
    "If you choose to not to scrape the data, there is a CSV with outdated data in the directory. Remeber, if you scrape Indeed, you're helping yourself find a job. ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcYlc1URXhlC"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull a single page to test:\n",
    "\n",
    "url = \"https://www.indeed.com/jobs?q=data+scientist&l=Seattle&start=10\"\n",
    "\n",
    "# conduct a request\n",
    "page = requests.get(url)\n",
    "\n",
    "# specify format of page\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "# pretty print\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Internal Audit - Forensic Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'UW MEDICINE CALL CENTER REPRESENTATIVE',\n",
       " 'Computer Scientist',\n",
       " 'Data Scientist/Machine Learning Engineer',\n",
       " 'Research Program Manager - Machine Learning',\n",
       " 'Internship Opportunities for PhD Students: Data & Applied Sciences',\n",
       " 'Data Scientist, Home Loans',\n",
       " 'Data Scientist - AMZ3704',\n",
       " 'Data & Applied Scientist',\n",
       " 'Data Scientist, Zillow Offers',\n",
       " 'AI Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist II',\n",
       " 'Data Scientist',\n",
       " 'Behavioral Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scient (Python)']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_job_title_from_result(soup):\n",
    "    jobs = []\n",
    "    for div in soup.find_all(name='div', attrs={'class':'title'}): #attrs={'class':'row'}\n",
    "        for a in div.find_all(name='a', attrs={'data-tn-element':'jobTitle'}):\n",
    "            jobs.append(a['title'])\n",
    "    return(jobs)\n",
    "\n",
    "extract_job_title_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PeopleTech',\n",
       " 'eBay Inc.',\n",
       " 'US Department of Agriculture - Milk Market Administrator',\n",
       " 'ASSURANCE Independent Agents',\n",
       " 'Blue Origin',\n",
       " 'Microsoft',\n",
       " 'Rover',\n",
       " 'Microsoft',\n",
       " 'T-Mobile',\n",
       " 'Amazon.com Services, Inc.',\n",
       " 'Beyondsoft Consulting',\n",
       " 'Microsoft',\n",
       " 'Seattle Cancer Care Alliance',\n",
       " 'Weyerhaeuser']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_company_from_result(soup):\n",
    "    companies = []\n",
    "    for span in soup.find_all(name='span', attrs={'class':'company'}):\n",
    "        for a in span.find_all(name='a', attrs={'data-tn-element' : 'companyName'}):\n",
    "            companies.append(a.text.strip())\n",
    "    return companies\n",
    "\n",
    "extract_company_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Job Summary Jr. Data scientist role Job description:  Job Type: Full time Job location: Redmond, WA We are seeking a Data Scientist with machine...',\n",
       " 'Looking for a company that inspires passion, courage and imagination, where you can help shape the future of global commerce?...',\n",
       " 'The candidate for Associate Scientist should have a PhD or MS in immunology, cell biology, chemistry or genetics....',\n",
       " 'About You:. You are a qualified, self-motivated and talented scientist that desires to collaborate with a team of like-minded and hard-working scientists and...',\n",
       " 'Position Title, Series, & Grade:. Dairy Scientist (Chemist), MA-1321; MA 11-12 (This is not equivalent to GS pay schedule). Vacancy Number:....',\n",
       " \"Earn from the industry's best comp plan selling Medicare Supplement using ASSURANCE, and access our leading-edge insurance sales platform as an independent,...\",\n",
       " 'As part of a small, passionate and accomplished team of experts, you will lead efforts to identify, capture, develop, and demonstrate technologies in the area...',\n",
       " 'At Canary we provide full spectrum of IT staffing services worldwide to organizations that require on-demand technical expertise....',\n",
       " '# Crowd Hero - Data Annotation Specialist*. Data is the new oil, and Canotic is the refinery for the next generation of AI applications....',\n",
       " 'Data Scientists at Microsoft help to improve the quality of experiences on our devices and services. We are looking for highly motivated and passionate Data...',\n",
       " 'Who we are:. Rover.com connects pet parents with the world’s largest network of pet sitters and dog walkers. Founded in 2011 on the belief that everyone should...',\n",
       " 'The Worldwide Customer Success team focuses on helping our customers get to successful business outcomes using our technology and solution offerings....',\n",
       " 'Data Scientist. The Financial Operations Analytics (FOA) team provides consultative analytics and reporting services to multiple teams within the Finance...',\n",
       " 'Currently pursuing aMaster’s degree in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.)....',\n",
       " 'Beyondsoft Consulting, Inc., is a leading, technical solutions and consulting partner. We combine emerging technologies and proven methodologies to tailor...',\n",
       " 'Data Scientists at Microsoft help to improve the quality of experiences on our devices and services. We are looking for highly motivated and passionate Data...',\n",
       " 'The Seattle Cancer Care Alliance (SCCA), located in Seattle, Washington, is part of a dynamic collaboration among three organizations known nationally and...',\n",
       " 'You are a data scientist who wants to grow your career with a truly great company. You have excellent judgement and knowledge of business processes and can...']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_summary_from_result(soup):\n",
    "    summaries = []\n",
    "    for div in soup.find_all(name='div', attrs={'class':'summary'}):\n",
    "        summaries.append(div.text.strip())\n",
    "    return summaries\n",
    "\n",
    "extract_summary_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Redmond, WA',\n",
       " 'Seattle, WA',\n",
       " 'Redmond, WA',\n",
       " 'Seattle, WA',\n",
       " 'Redmond, WA',\n",
       " 'Bellevue, WA',\n",
       " 'Seattle, WA',\n",
       " 'Redmond, WA',\n",
       " 'Redmond, WA']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_location_from_result(soup):\n",
    "    locations = []\n",
    "    spans = soup.findAll('span', attrs={'class': 'location'})\n",
    "    for span in spans:\n",
    "        locations.append(span.text)\n",
    "    return(locations)\n",
    "\n",
    "extract_location_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_results_per_city = 20\n",
    "\n",
    "city_set = ['Seattle', 'New+York', 'Austin', 'San+Fransisco', 'LA']\n",
    "\n",
    "columns = ['city', 'job_title', 'company_name', 'job_summary', 'location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seattle\n",
      "0 Seattle\n",
      "10 Seattle\n",
      "New+York\n",
      "0 New+York\n",
      "10 New+York\n",
      "Austen\n",
      "0 Austen\n",
      "10 Austen\n",
      "San+Fransisco\n",
      "0 San+Fransisco\n",
      "10 San+Fransisco\n",
      "LA\n",
      "0 LA\n",
      "10 LA\n"
     ]
    }
   ],
   "source": [
    "#scraping\n",
    "for city in city_set:\n",
    "    print(city)\n",
    "    \n",
    "    \n",
    "    #work through results in groups of 10 and wait between requests\n",
    "    for start in range(0, max_results_per_city, 10):\n",
    "        page = requests.get('http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=' +str(city) \n",
    "                            + '&start='+str(start))\n",
    "        time.sleep(1)\n",
    "        \n",
    "        #soup object\n",
    "        soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "        \n",
    "        for \n",
    "        #list of results\n",
    "        job\n",
    "        \n",
    "        \n",
    "        print(start,city)\n",
    "        temp_city = [city]*10\n",
    "        city_list.extend(temp_city)\n",
    "        job_title.extend(extract_job_title_from_result(soup))\n",
    "        company_name.extend(extract_company_from_result(soup))\n",
    "        job_summary.extend(extract_summary_from_result(soup))\n",
    "        location.extend(extract_location_from_result(soup))\n",
    "        \n",
    "#add to a dictionary\n",
    "data = {\n",
    "    'city' : [x for x in city_list],\n",
    "    'job_title' : [job for job in job_title],\n",
    "    'company_name': [name for name in company_name],\n",
    "    'job_summary': [s for s in job_summary],\n",
    "    'location' : [l for l in location]\n",
    "}  \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'city': ['Seattle',\n",
       "  'Seattle',\n",
       "  'Seattle',\n",
       "  'Seattle',\n",
       "  'Seattle',\n",
       "  'Seattle',\n",
       "  'Seattle',\n",
       "  'Seattle',\n",
       "  'Seattle',\n",
       "  'Seattle',\n",
       "  'Seattle',\n",
       "  'Seattle',\n",
       "  'Seattle',\n",
       "  'Seattle',\n",
       "  'Seattle',\n",
       "  'Seattle',\n",
       "  'Seattle',\n",
       "  'Seattle',\n",
       "  'Seattle',\n",
       "  'Seattle',\n",
       "  'New+York',\n",
       "  'New+York',\n",
       "  'New+York',\n",
       "  'New+York',\n",
       "  'New+York',\n",
       "  'New+York',\n",
       "  'New+York',\n",
       "  'New+York',\n",
       "  'New+York',\n",
       "  'New+York',\n",
       "  'New+York',\n",
       "  'New+York',\n",
       "  'New+York',\n",
       "  'New+York',\n",
       "  'New+York',\n",
       "  'New+York',\n",
       "  'New+York',\n",
       "  'New+York',\n",
       "  'New+York',\n",
       "  'New+York',\n",
       "  'Austen',\n",
       "  'Austen',\n",
       "  'Austen',\n",
       "  'Austen',\n",
       "  'Austen',\n",
       "  'Austen',\n",
       "  'Austen',\n",
       "  'Austen',\n",
       "  'Austen',\n",
       "  'Austen',\n",
       "  'Austen',\n",
       "  'Austen',\n",
       "  'Austen',\n",
       "  'Austen',\n",
       "  'Austen',\n",
       "  'Austen',\n",
       "  'Austen',\n",
       "  'Austen',\n",
       "  'Austen',\n",
       "  'Austen',\n",
       "  'San+Fransisco',\n",
       "  'San+Fransisco',\n",
       "  'San+Fransisco',\n",
       "  'San+Fransisco',\n",
       "  'San+Fransisco',\n",
       "  'San+Fransisco',\n",
       "  'San+Fransisco',\n",
       "  'San+Fransisco',\n",
       "  'San+Fransisco',\n",
       "  'San+Fransisco',\n",
       "  'San+Fransisco',\n",
       "  'San+Fransisco',\n",
       "  'San+Fransisco',\n",
       "  'San+Fransisco',\n",
       "  'San+Fransisco',\n",
       "  'San+Fransisco',\n",
       "  'San+Fransisco',\n",
       "  'San+Fransisco',\n",
       "  'San+Fransisco',\n",
       "  'San+Fransisco',\n",
       "  'LA',\n",
       "  'LA',\n",
       "  'LA',\n",
       "  'LA',\n",
       "  'LA',\n",
       "  'LA',\n",
       "  'LA',\n",
       "  'LA',\n",
       "  'LA',\n",
       "  'LA',\n",
       "  'LA',\n",
       "  'LA',\n",
       "  'LA',\n",
       "  'LA',\n",
       "  'LA',\n",
       "  'LA',\n",
       "  'LA',\n",
       "  'LA',\n",
       "  'LA',\n",
       "  'LA'],\n",
       " 'job_title': ['Jr. Data scientist role',\n",
       "  'Internal Audit - Forensic Data Scientist',\n",
       "  'Medicare Insurance Agent – Industry-best comp plan, popular carriers',\n",
       "  'Dairy Scientist (Chemist)',\n",
       "  'Principal Technologist - Machine Learning and Data Science',\n",
       "  'Data Scientist',\n",
       "  'Environmental Scientist',\n",
       "  'Data Annotation Specialist',\n",
       "  'Associate Data Scientist, New Business Lines',\n",
       "  'Data Scientist',\n",
       "  'Data Scientist Intern',\n",
       "  'Full Time Opportunities for Students or Recent Graduates: Data & Applied Sciences',\n",
       "  'Data Scientist',\n",
       "  'Data Coordinator Trainee',\n",
       "  'Principal NLP Data Scientist',\n",
       "  'UW MEDICINE CALL CENTER REPRESENTATIVE',\n",
       "  'Data Scientist',\n",
       "  'Data Scientist',\n",
       "  'Internal Audit - Forensic Data Scientist',\n",
       "  'Principal Technologist - Machine Learning and Data Science',\n",
       "  'Medicare Insurance Agent – Industry-best comp plan, popular carriers',\n",
       "  'Environmental Scientist',\n",
       "  'Data Scientist',\n",
       "  'Data & Applied Scientist',\n",
       "  'Full Time Opportunities for PhD Students or Recent Graduates: Data & Applied Sciences',\n",
       "  'Data Scientist',\n",
       "  'data scientist - Seattle, WA',\n",
       "  'Data Scientist',\n",
       "  'Data Scientist, Home Loans',\n",
       "  'Product Data Scientist',\n",
       "  'Data Scientist',\n",
       "  'Data Scientist II',\n",
       "  'UW MEDICINE CALL CENTER REPRESENTATIVE',\n",
       "  'Jr. Data scientist role',\n",
       "  'MODA Data Scientist',\n",
       "  'Data Scientist',\n",
       "  'Data Scientist I',\n",
       "  'Data Scientist',\n",
       "  'UX Data Scientist',\n",
       "  'Data Scientist',\n",
       "  'Data Analyst',\n",
       "  'Data Scientist I',\n",
       "  'Data Scientist',\n",
       "  'Data Scientist,Creator Marketplace – all levels',\n",
       "  'Junior Data Scientist',\n",
       "  'Data Scientist',\n",
       "  'Data Analyst',\n",
       "  'Data Scientist – Personalization',\n",
       "  'Artificial Intelligence',\n",
       "  'Junior Data Scientist',\n",
       "  'Academic Statistician',\n",
       "  'Data Scientist',\n",
       "  'Data Scientist I',\n",
       "  'Data Scientist',\n",
       "  'Software Data Engineer',\n",
       "  'Laboratory Technician',\n",
       "  'Junior Data Scientist',\n",
       "  'Data Scientist',\n",
       "  'Junior Data Scientist',\n",
       "  'Data Scientist',\n",
       "  'Data Scientist, Risk',\n",
       "  'Data Scientist',\n",
       "  'Data Scientist',\n",
       "  'Senior Data Scientist',\n",
       "  'Data Scientist',\n",
       "  'Data Scientist',\n",
       "  'Data Entry Analysis Associate',\n",
       "  'Computational Materials Scientist - Multiphysics',\n",
       "  'Senior Consulting Research Scientist',\n",
       "  'Data Engineer',\n",
       "  'Senior Scientist',\n",
       "  'Computational Materials Scientist - Multiphysics',\n",
       "  'Chief Data Scientist',\n",
       "  'Multiphase Flow Modeling VV&UQ Scientist',\n",
       "  'Research & Grants Analyst-OBGYN',\n",
       "  'Territory Sales Manager - Morgantown, WV',\n",
       "  'Post-Graduate Combustion Engineer/Scientist-PGRP',\n",
       "  'Workforce Development Research Engineer',\n",
       "  'Senior Consulting Research Scientist',\n",
       "  'Workforce Development - Research Scientists / Engineers',\n",
       "  'Multiphase Flow Modeling VV&UQ Scientist',\n",
       "  'Data Scientist',\n",
       "  'Power Plant Data Integrator- Relocation to Saudi Arabia',\n",
       "  'Senior Immunology Statistician with Global Pharmaceutical Group - Homebased',\n",
       "  'Portfolio Data Analyst',\n",
       "  'Chief Data Scientist',\n",
       "  'Data Scientist',\n",
       "  'Data Scientist',\n",
       "  'Data Analyst',\n",
       "  'Surface Characterization Scientist',\n",
       "  'Staff Data Scientist',\n",
       "  'Data Scientist',\n",
       "  'Data Scientist (Anti-Fraud Team)',\n",
       "  'Data Scientist (Search Science Team)',\n",
       "  'Data Scientist',\n",
       "  'Data Scientist (Advertising Personalization Team)',\n",
       "  'Data Scientist, Payments',\n",
       "  'Data Scientist',\n",
       "  'Data Scientist',\n",
       "  'Data Scientist',\n",
       "  'Data Scientist - Insurance',\n",
       "  'Data Scientist',\n",
       "  'Data Scientist',\n",
       "  'Data Analyst',\n",
       "  'Data Scientist',\n",
       "  'Data Scientist',\n",
       "  'Data Scientist (FinCrime)',\n",
       "  'Data Scientist',\n",
       "  'Data Scientist',\n",
       "  'Data Scientist',\n",
       "  'Data Scientist, Capital',\n",
       "  'Data Scientist',\n",
       "  'Data Scientist',\n",
       "  'Data Scientist - San Francisco',\n",
       "  'Fire Prevention Forester',\n",
       "  'Data Scientist - Insurance',\n",
       "  'Data Scientist',\n",
       "  'Medicare Insurance Agent – Industry-best comp plan, popular carriers',\n",
       "  'Computer Scientist',\n",
       "  'Data Engineer',\n",
       "  'Data Scientist',\n",
       "  'Core Data Scientist/Analyst',\n",
       "  'innovationOchsner (iO) - Data Scientist - Benson Tower',\n",
       "  'Environmental Scientist or Geologist - Entry to Mid Level',\n",
       "  'Data Scientist - Advanced Analytics - Benson Tower',\n",
       "  'Information Technology Consultant (Research Data Scientist)',\n",
       "  'Environmental Scientist II',\n",
       "  'Field Applications Scientist 2',\n",
       "  'Institutional Research Analyst',\n",
       "  'Lead Data Scientist',\n",
       "  'Data Scientist',\n",
       "  'Data Scientist',\n",
       "  'Clinical Lab Supervisor - Microbiology',\n",
       "  'Environmental Scientist II',\n",
       "  'Associate Fabrication Technician',\n",
       "  'WATER QUALITY SCIENTIST II (4073)',\n",
       "  'Senior Data Mining Specialist - Big Data',\n",
       "  'Med Tech, ASCP Blood Bank',\n",
       "  'Machine Learning Research Scientist',\n",
       "  'Med Tech, ASCP Blood Bank',\n",
       "  'Senior Data Integration Specialist – Big Data',\n",
       "  'Med Tech, ASCP - Lab',\n",
       "  'Social Scientist Subject Matter Expert Assessments Manager (SSSMEAM)',\n",
       "  'Data Engineer',\n",
       "  'Computer Scientist'],\n",
       " 'company_name': ['PeopleTech',\n",
       "  'Weyerhaeuser',\n",
       "  'ASSURANCE Independent Agents',\n",
       "  'US Department of Agriculture - Milk Market Administrator',\n",
       "  'Blue Origin',\n",
       "  'Seattle Cancer Care Alliance',\n",
       "  'Rover',\n",
       "  'Amazon.com Services, Inc.',\n",
       "  'Microsoft',\n",
       "  'T-Mobile',\n",
       "  'Fred Hutchinson Cancer Research Center',\n",
       "  'Logicmelon',\n",
       "  'University of Washington',\n",
       "  'eBay Inc.',\n",
       "  'eBay Inc.',\n",
       "  'Weyerhaeuser',\n",
       "  'Blue Origin',\n",
       "  'ASSURANCE Independent Agents',\n",
       "  'Seattle Cancer Care Alliance',\n",
       "  'Microsoft',\n",
       "  'Microsoft',\n",
       "  'Starbucks',\n",
       "  'Beyondsoft Consulting',\n",
       "  'Zillow Group',\n",
       "  'Invitae',\n",
       "  'Fred Hutchinson Cancer Research Center',\n",
       "  'University of Washington',\n",
       "  'PeopleTech',\n",
       "  'AIG',\n",
       "  'VISITING NURSE SERVICE OF NEW YORK',\n",
       "  'Bloomberg',\n",
       "  'Veritone',\n",
       "  'Bank of America',\n",
       "  'AETNA',\n",
       "  'Spotify',\n",
       "  'Viacom',\n",
       "  'Sprinklr',\n",
       "  'Spotify',\n",
       "  'Bank of America',\n",
       "  'Noom Inc.',\n",
       "  'Disney Streaming Services',\n",
       "  'AIG',\n",
       "  'Disney Streaming Services',\n",
       "  '1010data',\n",
       "  'Amneal Pharmaceuticals',\n",
       "  'Viacom',\n",
       "  'NYC Office Of The Mayor',\n",
       "  'Square',\n",
       "  'WebMD',\n",
       "  'Rent the Runway',\n",
       "  'Oshkosh Corporation',\n",
       "  'Leidos',\n",
       "  'Leidos',\n",
       "  'Transportation Insight',\n",
       "  'Mylan',\n",
       "  'Leidos',\n",
       "  'Leidos',\n",
       "  'Leidos',\n",
       "  'WVU Medicine',\n",
       "  'JUUL Labs',\n",
       "  'Leidos',\n",
       "  'Leidos',\n",
       "  'Leidos',\n",
       "  'Leidos',\n",
       "  'Oshkosh Corporation',\n",
       "  'Saudi Aramco',\n",
       "  'i-Pharm Consulting',\n",
       "  'United Bank',\n",
       "  'Leidos',\n",
       "  'Oshkosh Corporation',\n",
       "  'Stealth Mode Startup',\n",
       "  'Stealth Mode Startup',\n",
       "  'eBay Inc.',\n",
       "  'University of California San Francisco',\n",
       "  'Walmart eCommerce',\n",
       "  'Walmart eCommerce',\n",
       "  'Walmart eCommerce',\n",
       "  'Square',\n",
       "  'Khoros',\n",
       "  'MasterClass',\n",
       "  'MasterClass',\n",
       "  'Stealth Mode Startup',\n",
       "  'Skillz Inc.',\n",
       "  'Revolut',\n",
       "  'Scoop Technologies',\n",
       "  'Square',\n",
       "  'RiskIQ',\n",
       "  'Davey Resource Group',\n",
       "  'ASSURANCE Independent Agents',\n",
       "  'Federal Bureau of Investigation',\n",
       "  'Transportation Insight',\n",
       "  'Ochsner Health System',\n",
       "  'Groundwater & Environmental Services',\n",
       "  'Ochsner Health System',\n",
       "  'Louisiana State University',\n",
       "  'Illumina',\n",
       "  'State of Louisiana',\n",
       "  'DXC',\n",
       "  'Oshkosh Corporation',\n",
       "  'Oshkosh Corporation',\n",
       "  'North Oaks Medical Center',\n",
       "  'BOEING',\n",
       "  'Jefferson Parish',\n",
       "  'Blue Cross Blue Shield of Louisiana',\n",
       "  'Baton Rouge General Medical Center',\n",
       "  'Radiance Technologies Inc.',\n",
       "  'Blue Cross Blue Shield of Louisiana',\n",
       "  'Baton Rouge General Medical Center',\n",
       "  'SOSi',\n",
       "  'Transportation Insight',\n",
       "  'Federal Bureau of Investigation'],\n",
       " 'job_summary': ['Data scientist role Job description:. Working closely with the current team of Data scientists and engineers on various complex problems....',\n",
       "  'You are a data scientist who wants to grow your career with a truly great company. Actively listens and builds rapport with others....',\n",
       "  'Progress-tracking and business-growing dashboards and tools. Daily payouts – 3 times per day. Join the ASSURANCE agent network, and take advantage of these...',\n",
       "  'Healthcare spending or reimbursement accounts such as HSAs or FSAs. Must undergo a medical examination. Must be a United States citizen....',\n",
       "  'Familiarity with applying machine learning techniques to real-time, safety-critical systems. Prepare and manage design/technology reviews....',\n",
       "  'Experience with statistical methodologies and machine learning techniques such as:. Proficiency in Python, R or Julia....',\n",
       "  \"Oversee the operation and maintenance of remedial systems. Why you'll love working for us:. In compliance with State and Federal standards....\",\n",
       "  'Maintain ownership of each annotation assignment, and respond to any changes in procedure and auditors. Data is the new oil, and Canotic is the refinery for the...',\n",
       "  'You are passionate about designing and measuring tests. B.S in a quantitative discipline required; Python and/or R a plus. You are scary good with data....',\n",
       "  'Assist in development and deployment of statistical and platform code on high-performance computing systems. Currently we are looking for a “Data Scientist”....',\n",
       "  'Experience with AWS technologies like Redshift, S3, EC2, EMR, Kinesis, Lambda, and IAM roles and permissions. Strong written and verbal communication skills....',\n",
       "  'As a Data Scientist, you will formulate approaches to solve problems using well-defined algorithms and data sources....',\n",
       "  '3+ years of experience with statistical reporting and predictive modeling. Strong understanding of relational databases and a high-degree of technical...',\n",
       "  'Interpret, classify, and report on experimental, molecular, and pathologic test results from patient transcripts....',\n",
       "  'Our client is a Machine Learning driven Ed-Tech Firm based in Seattle. The company offers the following perks:....',\n",
       "  'Ability to analyze and solve complex problems that may require research and creative solutions with patient on the telephone line and make sound decisions with...',\n",
       "  'Work with data scientists, engineers, and cross functional teams to produce end-to-end production-ready solutions. Familiarity with Hadoop is a must....',\n",
       "  'Looking for a company that inspires passion, courage and imagination, where you can help shape the future of global commerce?...',\n",
       "  'You are a data scientist who wants to grow your career with a truly great company. You have excellent judgement and knowledge of business processes and can...',\n",
       "  'As part of a small, passionate and accomplished team of experts, you will lead efforts to identify, capture, develop, and demonstrate technologies in the area...',\n",
       "  \"Earn from the industry's best comp plan selling Medicare Supplement using ASSURANCE, and access our leading-edge insurance sales platform as an independent,...\",\n",
       "  'Techsolve Environmental, Inc. Is seeking an Environmental Scientist to support our team in Kenmore, WA. Candidates should have completed a Bachelor of Science...',\n",
       "  'The Seattle Cancer Care Alliance (SCCA), located in Seattle, Washington, is part of a dynamic collaboration among three organizations known nationally and...',\n",
       "  'The Worldwide Customer Success team focuses on helping our customers get to successful business outcomes using our technology and solution offerings....',\n",
       "  'Data Scientists at Microsoft help to improve the quality of experiences on our devices and services. We are looking for highly motivated and passionate Data...',\n",
       "  'Shelf Engine is optimizing ordering for food retailers like grocery stores, food service and cafes. We reduce their food waste and increase sales....',\n",
       "  'This position is part of the Global Payment and Fraud team. This is the business team responsible for Global Payment and Fraud strategy and execution at...',\n",
       "  'Beyondsoft Consulting, Inc., is a leading, technical solutions and consulting partner. We combine emerging technologies and proven methodologies to tailor...',\n",
       "  'About the team. You will join Zillow Group Home Loans a dynamic, collaborative, and driven team. We are. Data-hungry and make almost all decisions using data....',\n",
       "  'Invitae envisions a world in which genomic sequencing routinely informs lifelong health care decisions. We are committed to enabling the utilization of genomic...',\n",
       "  'Computational researchers with experience in genomics or other big data efforts are needed to develop and support our rare disease genomics program....',\n",
       "  'Cures Start Here. At Fred Hutchinson Cancer Research Center, home to three Nobel laureates, interdisciplinary teams of world-renowned scientists seek new and...',\n",
       "  'Recruitment for CCR positions is ongoing. This requisition serves as a candidate bank that is used to fill multiple openings. Shift Detail:....',\n",
       "  'Job Summary Jr. Data scientist role Job description:  Job Type: Full time Job location: Redmond, WA We are seeking a Data Scientist with machine...',\n",
       "  'The mission of the Mayor’s Office of Data Analytics (MODA) is to help City agencies apply strategic analytical thinking to data, to deliver services more...',\n",
       "  'The Data Scientist assists in creating and maintaining data infrastructure for gathering multiple sources of data into a single data hub for the generation of...',\n",
       "  'American General Life Insurance Company. Data Scientists collaborate with AIG’s Life and Retirement businesses across multiple functions, including product,...',\n",
       "  'The Visiting Nurse Service of New York (VNSNY) is the nation’s largest not-for-profit home- and community-based health care organization, serving the five...',\n",
       "  \"Bloomberg's UX, Product, and Technology teams are committed to creating better user experiences with technology. In this role, you will......\",\n",
       "  \"Indeed Prime is a free service that connects qualified job-seekers (that's you) with top companies hiring tech roles....\",\n",
       "  'Veritone is a leading provider of artificial intelligence (AI) technology and solutions. The company’s proprietary operating system, aiWARE™, orchestrates an...',\n",
       "  'As part of Wholesale Credit, the Analytics & Information Strategy team is responsible for leveraging data to build and deliver analytics that influence and...',\n",
       "  'Lookingfor opportunities to use cutting edge technologies analyzing petabytes of datain a world class Hadoop cluster, generating insights to guide consumers...',\n",
       "  'Creator Marketplace is the home for Spotify’s music industry products, such as Spotify for Artists, Spotify Label Analytics and Spotify Publisher Analytics....',\n",
       "  'Viacom’s Advertising Science team uses data science to empower and bring value and data-driven decision-making to our Ad Solutions department....',\n",
       "  \"At a time when consumers are connected and empowered like never before, Sprinklr is helping the world's largest brands provide amazing experiences at every turn...\",\n",
       "  'Nautilus is building artificial intelligence to advance the efficiency of ocean commerce. We deliver technology to help shipping companies minimize fuel...',\n",
       "  'We are seeking a Data Scientist to join our Product Insights team, focusing on Personalization. We have several roles open across different levels of seniority....',\n",
       "  'The Bank of America AI Solutions & Erica team is seeking a seasoned Sr. Digital Product Consultant to help advance the development of Erica, our virtual...',\n",
       "  'BerlandTeam is a new kind of insights and strategy firm. We Decode Data into Momentum™ for individuals, organizations and movements. We love a good lunch....',\n",
       "  'At Noom, we use scientifically proven methods to help our users create healthier lifestyles, and manage important conditions like Type-II Diabetes, Obesity, and...',\n",
       "  'The Data Scientist is a critical position within DSS and in the Data organization who specializes in applying machine learning methods to meet optimization,...',\n",
       "  'Functional Area:. SM - Sales & Marketing. Estimated Travel Percentage (%):. Up to 25%....',\n",
       "  'The Data Scientist is a critical position within DSS and in the Data organization who specializes in applying machine learning methods to meet optimization,...',\n",
       "  '1010data values:. Doing the right things for the right reasons. Adapting and thriving in a dynamic environment. Combining our strengths to do amazing things....',\n",
       "  'Perform when needed Data entry, wash glass clean /dust lab and adjoining areas, wash dissolution baths keeping them free of mold move documents from one...',\n",
       "  'Overview and Responsibilities. Viacom’s Advertising Science team uses data science to empower and bring value and data-driven decision-making to our Ad...',\n",
       "  'The mission of the Mayor’s Office of Data Analytics (MODA) is to help City agencies apply strategic analytical thinking to data, to deliver services more...',\n",
       "  'About us:. BerlandTeam is a new kind of insights and strategy firm. We Decode Data into Momentum™ for individuals, organizations and movements....',\n",
       "  'Are you ready for a new challenge? Celonis is the leader in business transformation software, turning process insights into action with The Celonis Intelligent...',\n",
       "  'Job Description. As a Senior Data Scientist at Square working on Risk, you will lead projects that derive value from our unique, rich, and rapidly growing data....',\n",
       "  'Medscape, a division of WebMD, develops and hosts physician portals and related mobile applications that make it easier for physicians and healthcare...',\n",
       "  'About Us:. At Rent the Runway, our mission is to make women feel empowered and self-confident every single day by combining best in class technology, logistics,...',\n",
       "  'Amplicare is a SaaS company on an audacious mission to positively impact one billion patients by 2030. We sit at the intersection of healthcare and technology...',\n",
       "  'The Data Scientist will help the organization classify, predict, or enrich data, improve efficiency, and reduce risk using data science and machine learning....',\n",
       "  'COMPANY PROFILE. Oshkosh Corporation is a leading manufacturer and marketer of access equipment, specialty vehicles and truck bodies for the primary markets of...',\n",
       "  'Cisive is a leading provider in HR solutions is seeking motivated and career-minded talent to join our growing organization....',\n",
       "  \"An opportunity exists for a computational scientist to develop and utilize computational multiphysics models and data analysis tools to support NETL's solid...\",\n",
       "  'This is a senior level consulting position where the incumbent will lead and participate in efforts to develop and apply advanced kinetics knowledge to...',\n",
       "  'Job Title:. Data Engineer. Job Purpose *. The Data Engineer will lead data engineering with the collaboration of software developers, database architects, data...',\n",
       "  \"Primary Location - USA-WV-Morgantown. Organization - Mylan Inc. Senior Scientist - 19000878. For Us, It's A Mission....\",\n",
       "  'Job Description:. An opportunity exists for a computational scientist to develop and utilize computational multiphysics models and data analysis tools to...',\n",
       "  \"Job Description:. Leidos' Energy and Environment Division currently has an opening for a Senior Researcher specializing in Machine Learning for our energy...\",\n",
       "  'Job Description:. The incumbent in this position will support collaborative research in modeling of coal-based and natural gas-based energy systems that...',\n",
       "  'JOB TITLE &CODE:. Research & Grants Analyst (81439). Obstetrics and Gynecology. REPORTS TO:....',\n",
       "  \"THE COMPANY:. JUUL's mission is to improve the lives of the world's one billion adult smokers by driving innovation to eliminate cigarettes....\",\n",
       "  'Organization National Energy Technology Laboratory (NETL). Reference Code NETL-2019-PGRP-Ferguson-1. How to Apply. A complete application consists of:....',\n",
       "  \"Job Description:. The Leidos Civil Group is seeking a Research Scientist for its Research Support Services (RSS) contract for the Department of Energy's (DOE)...\",\n",
       "  'Job Description:. This is a senior level consulting position where the incumbent will lead and participate in efforts to develop and apply advanced kinetics...',\n",
       "  'Job Description:. The Leidos Research Support Team supporting the National Energy Technology Laboratory is seeking Research Scientists and Engineers to join our...',\n",
       "  'The incumbent in this position will support collaborative research in modeling of coal-based and natural gas-based energy systems that involves both NETL and...',\n",
       "  'COMPANY PROFILE. Oshkosh Corporation is a leading manufacturer and marketer of access equipment, specialty vehicles and truck bodies for the primary markets of...',\n",
       "  'We are looking for a Power Plant Data Integrator to support the iPower Center under Power Systems Engineering Department (PSED)....',\n",
       "  \"A Global Pharmaceutical group is looking to build on their already thriving Biometrics group. The industry leader has experienced success within it's post...\",\n",
       "  'The Portfolio Data Analyst conducts analyses of the entire Bank’s loan portfolio to access portfolio risk based on geography and type of loans....',\n",
       "  \"Leidos' Energy and Environment Division currently has an opening for a Senior Researcher specializing in Machine Learning for our energy research and...\",\n",
       "  'Oshkosh Corporation is a leading manufacturer and marketer of access equipment, specialty vehicles and truck bodies for the primary markets of defense, concrete...',\n",
       "  'Hope you are doing well.. *This is Nasim Shah from Tredence. We have an exciting opportunity for those who are passionate about Data Analytics....',\n",
       "  'Data Analyst at Big Data Biotech Company. Solid analytical skills, understanding of statistics and measurement theory. Proficient with python and Matlab....',\n",
       "  'Join a small but rapidly growing startup that is developing exciting new life sciences technology. Characterizes and analyzes surface-modified substrates,...',\n",
       "  'Job ID:. Staff Data Scientist. San Francisco, CA. Looking for a company that inspires passion, courage and imagination, where you will shape the future of...',\n",
       "  'The missions of the Cardiology Division are patient care, teaching, translational basic and clinical research, and public service within the specialty of...',\n",
       "  \"Imagine working in an environment where one experiment can catapult an entire industry toward a smarter future. That's what we do at Walmart Labs....\",\n",
       "  \"Imagine working in an environment where one experiment can catapult an entire industry toward a smarter future. That's what we do at Walmart Labs....\",\n",
       "  \"ClassDojo's vision is to create a modern education system that gives every child on Earth a 10x better learning experience than today's....\",\n",
       "  'Imagine working in an environment where one experiment can catapult an entire industry toward a smarter future. That’s what we do at Walmart Labs....',\n",
       "  'Job Description. As a Data Scientist at Square working on Payments, you will lead projects that derive value from our unique, rich, and rapidly growing data....',\n",
       "  'Responsibilities include:. Support/develop models for GAP INC. Pricing platform. Develop code for measurement of pricing actions....',\n",
       "  'Khoros is looking for a Data Scientist to join our Engineering Team to support our engineering solutions at scale....',\n",
       "  'San Francisco Bay Area. As one of the first employees at Unlearn, you will have the opportunity to shape the future of how data is used in clinical science and...',\n",
       "  'A million people a year die in car collisions around the world and we want that number to be zero. We invite you to help us build an InsurTech company that uses...',\n",
       "  'Who we are:. MasterClass is transforming online education by enabling anyone in the world to learn from the very best....',\n",
       "  'MasterClass is transforming online education by enabling anyone in the world to learn from the very best. We are deconstructing what makes an actor able to cry...',\n",
       "  'Data Analyst at Big Data Biotech Company. Solid analytical skills, understanding of statistics and measurement theory. Proficient with python and Matlab....',\n",
       "  'Skillz is driving the future of entertainment by accelerating the convergence of sports, video games and media for an exploding mobile-first audience worldwide....',\n",
       "  'Perform hands-on analysis of large volumes of web analytics, transaction, customer data, second and third-party data. SQL Server, Redshift, Hive etc.)....',\n",
       "  'The Financial Crime Technology department is at the forefront of Revolut’s efforts to keep customers and their money safe....',\n",
       "  'South San Francisco Bay, California. BS in Computer Science or Math or equivalent experience. At least 2+ years of experience in cryptocurrency....',\n",
       "  'Spin operates electric scooters in cities and campuses nationwide, bringing sustainable last-mile mobility solutions to diverse communities....',\n",
       "  'Scoop brings co-workers and neighbors together to enjoy a smooth carpooling experience—unlocking new opportunities to create friendships, improve their well...',\n",
       "  'As a Data Scientist at Square working on Capital, you will lead projects that derive value from our unique, rich, and rapidly growing data....',\n",
       "  'AllSTEM Connections is looking for a Data Scientist to work in San Francisco, California. This is a contract to direct hire position with benefits....',\n",
       "  'RiskIQ is the world leader in Attack Surface Management, providing the most comprehensive discovery, intelligence, and mitigation of threats associated with an...',\n",
       "  'Debt collection is failing consumers. Every year, 77 Million Americans have negative experiences with the collections process, and they deserve a better...',\n",
       "  'Northern and Central California - (San Luis Obispo, Santa Cruz, Monterey, Santa Clara, San Mateo, Marin, and Napa Counties). A 100% employee owned company....',\n",
       "  'A million people a year die in car collisions around the world and we want that number to be zero. We invite you to help us build an InsurTech company that uses...',\n",
       "  'Hope you are doing well.. *This is Nasim Shah from Tredence. We have an exciting opportunity for those who are passionate about Data Analytics....',\n",
       "  \"Earn from the industry's best comp plan selling Medicare Supplement using ASSURANCE, and access our leading-edge insurance sales platform as an independent,...\",\n",
       "  'As an FBI Computer Scientist, you will be part of a highly collaborative investigative team working to thwart cyberattacks that include counterintelligence...',\n",
       "  'Job Title:. Data Engineer. Job Purpose *. The Data Engineer will lead data engineering with the collaboration of software developers, database architects, data...',\n",
       "  'ROMPH & POU is not a typical Advertising & Marketing Agency. We also play with numbers, too. Our Culture:. Our philosophy is that through data, all things are...',\n",
       "  'Finance is increasingly a data driven business. The Code Willing Core Data Services team works closely with both our Cloud Computing group and our Front Office...',\n",
       "  \"We've made a lot of progress since opening the doors in 1942, but one thing has never changed - our commitment to serve, heal, lead, educate, and innovate....\",\n",
       "  'Under supervision, executes, supervises, and documents the field aspects of environmental site assessment and remediation using standard operating procedures ...',\n",
       "  \"We've made a lot of progress since opening the doors in 1942, but one thing has never changed - our commitment to serve, heal, lead, educate, and innovate....\",\n",
       "  'All Job Postings will close at 12:01a.m. On the specified Posting End Date (if designated). Job Posting Title:....',\n",
       "  'An Environmental Scientist II is an entry level position and participates as a member of an emergency response team to conduct environmental sampling and data...',\n",
       "  'Position Summary:. The Field Applications Scientist 2 position is responsible for enabling customer success within the territory....',\n",
       "  \"Supplemental Information. Additional Requirements:. Proof of Education. A valid Louisiana Driver's License....\",\n",
       "  'Job Description:. DXC Technology (NYSE:. DXC) is the world’s leading independent, end-to-end IT services company, helping clients harness the power of...',\n",
       "  'COMPANY PROFILE. Oshkosh Corporation is a leading manufacturer and marketer of access equipment, specialty vehicles and truck bodies for the primary markets of...',\n",
       "  'Oshkosh Corporation is a leading manufacturer and marketer of access equipment, specialty vehicles and truck bodies for the primary markets of defense, concrete...',\n",
       "  'High stress position with exposure to dangerous infectious materials, odorous chemicals and specimens. May be exposed to low levels of radiation, electrical...',\n",
       "  'An Environmental Scientist II is an entry level position and participates as a member of an emergency response team to conduct environmental sampling and data...',\n",
       "  'The Boeing Company is seeking an Fabrication Technician to support the team in New Orleans, Louisiana. This position is with the Boeing Exploration Launch...',\n",
       "  'EXAMINATION IS ANNOUNCED TO ESTABLISH AN EMPLOYMENT LIST TO FILL ONE (1) CURRENT EAST JEFFERSON VACANCY IN THE WATER DEPARTMENT AND FUTURE VACANCIES AS THEY...',\n",
       "  'We take great strides to ensure our employees have the resources to live well, be healthy, continue learning, develop skills, grow professionally and serve our...',\n",
       "  'Performs routine and special clinical laboratory tests on patient specimens, correlates and interprets data based on knowledge of techniques, principles and...',\n",
       "  'Radiance Technologies, a rapidly growing employee owned company supporting multiple technology development efforts, is searching for a talented Machine Learning...',\n",
       "  'Our laboratory consists of both Medical Technologist and Medical Laboratory Technicians both of whom are certified by an accrediting agency and licensed by the...',\n",
       "  'We take great strides to ensure our employees have the resources to live well, be healthy, continue learning, develop skills, grow professionally and serve our...',\n",
       "  'Performs routine and special clinical laboratory tests on patient specimens, correlates and interprets data based on knowledge of techniques, principles and...',\n",
       "  'For 30 years, clients in the private and public sectors have relied upon SOS International LLC (SOSi) for critical operations in the world’s most challenging...',\n",
       "  'The Data Engineer will lead data engineering with the collaboration of software developers, database architects, data analysts, and data scientists on data...',\n",
       "  'As an FBI Computer Scientist, you will be part of a highly collaborative investigative team working to thwart cyberattacks that include counterintelligence...'],\n",
       " 'location': ['Seattle, WA',\n",
       "  'Seattle, WA',\n",
       "  'Redmond, WA',\n",
       "  'Seattle, WA',\n",
       "  'Redmond, WA',\n",
       "  'Bellevue, WA',\n",
       "  'Seattle, WA 98109 (Westlake area)',\n",
       "  'Seattle, WA',\n",
       "  'Redmond, WA',\n",
       "  'Redmond, WA',\n",
       "  'Seattle, WA',\n",
       "  'Seattle, WA 98134 (Industrial Complex area)',\n",
       "  'Redmond, WA',\n",
       "  'Seattle, WA 98101 (Downtown area)',\n",
       "  'Seattle, WA',\n",
       "  'Bellevue, WA',\n",
       "  'Seattle, WA 98109 (Westlake area)',\n",
       "  'Manhattan, NY',\n",
       "  'New York, NY 10036',\n",
       "  'New York, NY 10016 (Gramercy area)',\n",
       "  'New York, NY 10011 (Chelsea area)',\n",
       "  'New York, NY 10036',\n",
       "  'New York, NY',\n",
       "  'New York, NY',\n",
       "  'New York, NY 10011 (Chelsea area)',\n",
       "  'New York, NY 10281 (Battery Park area)',\n",
       "  'New York, NY',\n",
       "  'New York, NY 10036',\n",
       "  'New York, NY',\n",
       "  'New York, NY',\n",
       "  'New York, NY 10036',\n",
       "  'New York, NY 10032 (Washington Heights area)',\n",
       "  'New York, NY 10011 (Chelsea area)',\n",
       "  'New York, NY',\n",
       "  'New York, NY 10001 (Chelsea area)',\n",
       "  'New York, NY',\n",
       "  'Morgantown, WV',\n",
       "  'Morgantown, WV 26501',\n",
       "  'Morgantown, WV 26501',\n",
       "  'Morgantown, WV 26501',\n",
       "  'Morgantown, WV',\n",
       "  'Morgantown, WV',\n",
       "  'Morgantown, WV',\n",
       "  'Morgantown, WV 26501',\n",
       "  'Morgantown, WV 26501',\n",
       "  'Morgantown, WV 26501',\n",
       "  'Morgantown, WV 26505',\n",
       "  'Morgantown, WV 26501',\n",
       "  'San Francisco, CA',\n",
       "  'San Francisco Bay Area, CA',\n",
       "  'San Francisco Bay Area, CA',\n",
       "  'San Francisco, CA 94103 (South Of Market area)',\n",
       "  'San Francisco Bay Area, CA',\n",
       "  'San Francisco, CA 94103 (South Of Market area)',\n",
       "  'San Francisco, CA',\n",
       "  'San Francisco, CA 94104 (Financial District area)',\n",
       "  'San Francisco Bay Area, CA',\n",
       "  'San Francisco, CA',\n",
       "  'San Francisco, CA',\n",
       "  'San Francisco, CA',\n",
       "  'San Francisco Bay Area, CA',\n",
       "  'San Francisco, CA',\n",
       "  'San Francisco, CA',\n",
       "  'San Francisco, CA 94103 (South Of Market area)',\n",
       "  'South San Francisco, CA 94080',\n",
       "  'San Francisco, CA 94103 (South Of Market area)',\n",
       "  'San Francisco, CA',\n",
       "  'Shreveport, LA 71105 (Springlake-University Terrace area)',\n",
       "  'Baton Rouge, LA',\n",
       "  'New Orleans, LA',\n",
       "  'Baton Rouge, LA 70802',\n",
       "  'New Orleans, LA',\n",
       "  'Baton Rouge, LA 70811',\n",
       "  'Kenner, LA',\n",
       "  'Louisiana',\n",
       "  'Baton Rouge, LA 70806',\n",
       "  'New Orleans, LA 70121',\n",
       "  'Kenner, LA',\n",
       "  'New Orleans, LA',\n",
       "  'Jefferson Parish, LA',\n",
       "  'Baton Rouge, LA',\n",
       "  'Baton Rouge, LA',\n",
       "  'Ruston, LA',\n",
       "  'Baton Rouge, LA 70809',\n",
       "  'Baton Rouge, LA',\n",
       "  'Baton Rouge, LA']}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-c4ad22f976ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    390\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[1;32m    391\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arrays must all be same length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C4xFZNtX1m2"
   },
   "source": [
    "## 2) Use Spacy to tokenize / clean the listings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhUHuMr-X-II"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "raise Exception(\"\\nThis task is not complete. \\nReplace this line with your code for the task.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lgCZNL_YycP"
   },
   "source": [
    "# 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2PZ8Pj_YxcF"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "raise Exception(\"\\nThis task is not complete. \\nReplace this line with your code for the task.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zo1iH_UeY7_n"
   },
   "source": [
    "# 4) Visualize the most common word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5LB00uyZKV5"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "raise Exception(\"\\nThis task is not complete. \\nReplace this line with your code for the task.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwFsTqrVZMYi"
   },
   "source": [
    " # 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gx2gZCbl5Np"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "raise Exception(\"\\nThis task is not complete. \\nReplace this line with your code for the task.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 6) Create a NearestNeighbor Model. Write the description of your ideal datascience job and query your job listings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "raise Exception(\"\\nThis task is not complete. \\nReplace this line with your code for the task.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiDfTWceoRkH"
   },
   "source": [
    "## Stretch Goals\n",
    "\n",
    " - Try different visualizations for words and frequencies - what story do you want to tell with the data?\n",
    " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
    " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
    " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
    "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_422_BOW_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
