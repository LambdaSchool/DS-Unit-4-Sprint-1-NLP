{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ASfGeMfI6Kgs"
   },
   "source": [
    "### Use Word2Vec to train your own model on a dataset.\n",
    "\n",
    "1) **Optional** - Find your own dataset of documents to train you model on. You are going to need a lot of data, so it's probably not realistic to scrape data for this assignment given the time constraints that we're working under. Try to find a dataset that has > 5000 documents.\n",
    "\n",
    "- If you can't find a dataset to use try this one: <https://www.kaggle.com/c/quora-question-pairs>\n",
    "\n",
    "2) Clean/Tokenize the documents.\n",
    "\n",
    "3) Vectorize the model using Word2Vec and explore the results using each of the following at least one time:\n",
    "\n",
    "- your_model.wv.most_similar()\n",
    "- your_model.wv.similarity()\n",
    "- your_model.wv.doesn't_match()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wy5lYo4K8wEy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\brit2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\abc.zip.\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     C:\\Users\\brit2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\alpino.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('all')\n",
    "\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "def split_lemma(v):\n",
    "    stop_words = stopwords.words('english')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return word_tokenize(v)\n",
    "#   return [lemmatizer.lemmatize(w).lower() for w in word_tokenize(v) if w.isalpha() and w not in stop_words and len(w) > 1]\n",
    "\n",
    "df[\"question1\"] = df[\"question1\"].apply(lambda v: split_lemma(v))\n",
    "df[\"question2\"] = df[\"question2\"].apply(lambda v: split_lemma(v))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xkzdOZm38yQ_"
   },
   "source": [
    "### Stretch Goals:\n",
    "\n",
    "1) Use Doc2Vec to train a model on your dataset, and then provide model with a new document and let it find similar documents.\n",
    "\n",
    "2) Download the pre-trained word vectors from Google. Access the pre-trained vectors via the following link: https://code.google.com/archive/p/word2vec\n",
    "\n",
    "Load the pre-trained word vectors and train the Word2vec model\n",
    "\n",
    "Examine the first 100 keys or words of the vocabulary\n",
    "\n",
    "Outputs the vector representation for a select set of words - the words can be of your choice\n",
    "\n",
    "Examine the similarity between words - the words can be of your choice\n",
    "\n",
    "For example:\n",
    "\n",
    "model.similarity('house', 'bungalow')\n",
    "\n",
    "model.similarity('house', 'umbrella')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gakr5rP76IAJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_424_Word_Embeddings_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
